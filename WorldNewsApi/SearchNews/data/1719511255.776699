{"id": 223786836, "title": "Experts seeing \u2019more and more\u2019 hate content created by artificial intelligence", "text": "Tenove said there is \u201ca fair amount of guesswork out there right now,\u201d similar to broader societal questions about \u201charmful or problematic content that spreads on social-media platforms.\u201d Systems like ChatGPT have safeguards built in, Lin said. An OpenAI spokesperson confirmed before the company releases any new system, it teaches the model to refuse to generate hate speech. But Lin said there are ways of jailbreaking AI systems, noting certain prompts can \u201ctrick the model\u201d into producing what he described as nasty content. David Evan Harris, a chancellor\u2019s public scholar at the University of California, Berkeley, said it\u2019s hard to know where AI content is coming from unless the companies behind these models ensure it is watermarked. He said some AI models, like those made by OpenAI or Google, are closed-source models. Others, like Meta\u2019s Llama, are made more openly available. Once a system is opened up to all, he said bad actors can strip safety features out and produce hate speech, scams and phishing messages in ways that are very difficult to detect. A statement from Meta said the company builds safeguards into its systems and doesn\u2019t open source \u201ceverything.\u201d", "summary": "In Canada, there is federal legislation, including BillC-63, the Liberal government says will help address the issue.", "url": "https://montrealgazette.com/news/national/experts-seeing-more-and-more-hate-content-created-by-artificial-intelligence", "image": "https://smartcdn.gprod.postmedia.digital/montrealgazette/wp-content/uploads/2024/05/ai-hate-20240527.jpg", "video": null, "publish_date": "2024-05-26 16:22:50", "author": "The Canadian Press", "authors": ["The Canadian Press"], "language": "en", "source_country": "ca", "sentiment": -0.499}