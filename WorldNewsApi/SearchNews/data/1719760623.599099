{"id": 225009378, "title": "I\u2019ve read over 100 AI requests for proposals from major companies. Here\u2019s the matrix of guardrails and obligations that is emerging", "text": "With this advancement comes an equal need for consideration of the risks. These include software vulnerabilities, cyberattacks, improper system access, and sensitive data exposure. There are also ethical and legal considerations, such as copyright or data privacy law violations, bias or toxicity in the generated output, the propagation of disinformation and deep fakes, and a furthering of the digital divide. We\u2019re seeing the worst of it in public life right now, with algorithms used to spread false information, manipulate public opinion, and undermine trust in institutions. All of this highlights the importance of security, transparency, and accountability in how we create and use AI systems. There is good work afoot! In the U.S., President Biden\u2019s Executive Order on AI aims to promote the responsible use of AI and address issues such as bias and discrimination. The National Institute of Standards and Technology (NIST) has developed a comprehensive framework for AI systems\u2019 trustworthiness. The European Union has proposed the AI Act, a regulatory framework to ensure the ethical and responsible use of AI. And the AI Safety Institute in the U.K. is working towards developing safety standards and best practices for AI deployment. The responsibility for establishing a common set of AI guardrails ultimately lies with the government, but we\u2019re not there yet. Today, we have a rough patchwork of guidelines that are regionally inconsistent and unable to keep up with the rapid pace of AI innovation. In the meantime, the onus for its safe and responsible use will be on us: AI vendors and our enterprise customers. Indeed, we need a set of guardrails. A new matrix of obligations Forward-thinking companies are getting proactive. They\u2019re creating internal steering committees and oversight groups to define and enforce policies according to their legal obligations and ethical standards. I\u2019ve read more than a hundred requests for proposals (RFPs) from these organizations, and they\u2019re good. They\u2019ve informed our framework here at Writer for building our own trust and safety programs. One way to organize our thinking is in a matrix with four areas of obligation: data, models, systems, and operations; and plot them across three responsible parties: vendors, enterprises, and governments. Guardrails within the \u201cdata\u201d category include data integrity, provenance, privacy, storage, and legal and regulatory compliance. In \u201cmodels,\u201d they\u2019re transparency, accuracy, bias, toxicity, and misuse. In \u201csystem,\u201d they\u2019re security, reliability, customization, and configuration. And in \u201coperations,\u201d they\u2019re the software development lifecycle, testing and validation, access and other policies (human and machine), and ethics. Within each guardrail category, I recommend enumerating your key obligations, articulating what\u2019s at stake, defining what \u201cgood\u201d looks like, and establishing a measurement system. Each area will look different across vendors, enterprises, and government entities, but ultimately they should dovetail with and support each other. I\u2019ve chosen a sample question from our customers\u2019 RFPs and translated each to demonstrate how each AI guardrail might work. As we transform business with generative AI, it\u2019s crucial to recognize and address the risks associated with its implementation. While government initiatives are underway, today the responsibility for safe and responsible AI use is on our shoulders. By proactively implementing AI guardrails across data, models, systems, and operations, we can gain the benefits of AI while minimizing harm. May Habib is CEO and co-founder of Writer. More must-read commentary published by Fortune: Fannie Mae CEO: Beyonc\u00e9 is right. Climate change has already hit the housing market\u2014and homeowners aren\u2019t prepared Trade and investment data in the last two years dispel the deglobalization and decoupling myths as U.S.-China competition ignites \u2018reglobalization\u2019 Big Tech employees missed out on $5.1 billion in 401(k) gains over the last decade because of fossil fuels, new research finds \u2018As quick as 5 minutes in California or as grueling as 11 hours in Texas\u2019: Research reveals new post-Dobbs map of abortion access driving times The opinions expressed in Fortune.com commentary pieces are solely the views of their authors and do not necessarily reflect the opinions and beliefs of Fortune.", "summary": "Forward-thinking companies are getting proactive\u2014and establishing their own guardrails without waiting for regulation.", "url": "https://fortune.com/2024/05/29/100-ai-requests-proposals-major-companies-guardrails-obligations-emerging-tech/", "image": "https://fortune.com/img-assets/wp-content/uploads/2024/05/GettyImages-1765529254-e1716985240543.jpg", "video": null, "publish_date": "2024-05-29 12:22:57", "author": "May Habib", "authors": ["May Habib"], "language": "en", "source_country": "US", "sentiment": 0.094}