{"id": 223712304, "title": "Experts seeing &#8216;more and more&#8217; hate content created by artificial intelligence", "text": "OTTAWA \u2014 The clip is of a real historical event \u2014 a speech given by Nazi dictator Adolf Hitler in 1939 at the beginning of the Second World War. But there is one major difference. This viral video was altered by artificial intelligence, and in it, Hitler delivers antisemitic remarks in English. A far-right conspiracy influencer shared the content on X, formerly known as Twitter, earlier this year, and it quickly racked up more than 15 million views, Wired magazine reported in March. It\u2019s just one example of what researchers and organizations that monitor hateful content are calling a worrying trend. They say AI-generated hate is on the rise. \u201cI think everybody who researches hate content or hate media is seeing more and more AI-generated content,\u201d said Peter Smith, a journalist who works with the Canadian Anti-Hate Network. Chris Tenove, assistant director at the University of British Columbia\u2019s Centre for the Study of Democratic Institutions, said hate groups, such as white supremacist groups, \u201chave been historically early adopters of new internet technologies and techniques.\u201d It\u2019s a concern a UN advisory body flagged in December. It said it was \u201cdeeply concerned\u201d about the possibility that antisemitic, Islamophobic, racist and xenophobic content \u201ccould be supercharged by generative AI.\u201d Sometimes that content can bleed into real life. After AI was used to generate what Smith described as \u201cextremely racist Pixar-style movie posters,\u201d some individuals printed the signs and posted them on the side of movie theatres, he said. \u201cAnything that is available to the public, that is popular or is emerging, especially when it comes to technology, is very quickly adapted to produce hate propaganda.\u201d Generative AI systems can create images and videos almost instantly with just a simple prompt. Instead of an individual devoting hours to making a single image, they can make dozens \u201cin the same amount of time just with a few keystrokes,\u201d Smith said. B\u2019nai Brith Canada flagged the issue of AI-generated hate content in a recent report on antisemitism. The report says last year saw an \u201cunprecedented rise in antisemitic images and videos which have been created or doctored and falsified using AI.\u201d Director of research and advocacy Richard Robertson said the group has observed that \u201creally horrible and graphic images, generally relating to Holocaust denialism, diminishment or distortion, were being produced using AI.\u201d He cited the example of a doctored image depicting a concentration camp with an amusement park inside it. \u201cVictims of the Holocaust are riding on the rides, seemingly enjoying themselves at a Nazi concentration camp, and arguably that\u2019s something that could only be produced using AI,\u201d he said. The organization\u2019s report also says AI has \u201cgreatly impacted\u201d the spread of propaganda in the wake of the Israel-Hamas war. AI can be used to make deepfakes, or videos that feature remarkably realistic simulations of celebrities, politicians or other public figures. Tenove said deepfakes in the context of the Israel-Hamas war have caused the spread of false information about events and attributed false claims to both the Israeli military and Hamas officials. \u201cSo there\u2019s been that kind of stuff, that\u2019s trying to stoke people\u2019s anger or fear regarding the other side and using deception to do that.\u201d Jimmy Lin, a professor at the University of Waterloo\u2019s school of computer science, agrees there has been \u201can uptick in terms of fake content\u2026that\u2019s specifically designed to rile people up on both sides.\u201d Amira Elghawaby, Canada\u2019s special representative on combating Islamophobia, says there has been an increase in both antisemitic and Islamophobic narratives since the beginning of the conflict. She says the issue of AI and hate content begs for both more study and discussion. There\u2019s no disagreement that AI-generated hate content is an emerging issue, but experts have yet to reach a consensus on the scope of the problem. Tenove said there is \u201ca fair amount of guesswork out there right now,\u201d similar to broader societal questions about \u201charmful or problematic content that spreads on social-media platforms.\u201d Systems like ChatGPT have safeguards built in, Lin said. An OpenAI spokesperson confirmed that before the company releases any new system, it teaches the model to refuse to generate hate speech. But Lin said there are ways of jailbreaking AI systems, noting certain prompts can \u201ctrick the model\u201d into producing what he described as nasty content. David Evan Harris, a chancellor\u2019s public scholar at the University of California, Berkeley, said it\u2019s hard to know where AI content is coming from unless the companies behind these models ensure it is watermarked. He said some AI models, like those made by OpenAI or Google, are closed-source models. Others, like Meta\u2019s Llama, are made more openly available. Once a system is opened up to all, he said bad actors can strip safety features out and produce hate speech, scams and phishing messages in ways that are very difficult to detect. A statement from Meta said the company builds safeguards into its systems and doesn\u2019t open source \u201ceverything.\u201d \u201cOpen-source software is typically safer and more secure due to ongoing feedback, scrutiny, development and mitigations from the community,\u201d it said. In Canada, there is federal legislation that the Liberal government says will help address the issue. That includes Bill C-63, a proposed bill to address online harms. Chantalle Aubertin, a spokesperson for Justice Minister Arif Virani, said the bill\u2019s definition of content that foments hatred includes \u201cany type of content, such as images and videos, and any artificially generated content, such as deepfakes.\u201d Innovation Canada said its proposed artificial intelligence regulation legislation, Bill C-27, would require AI content to be identifiable, for example through watermarking. A spokesperson said that bill would also \u201crequire that companies responsible for high-impact and general-purpose AI systems assess risks and test and monitor their systems to ensure that they are working as intended, and put in place appropriate mitigation measures to address any risks of harm.\u201d This report by The Canadian Press was first published May 26, 2024. Anja Karadeglija, The Canadian Press", "summary": "OTTAWA \u2014 The clip is of a real historical event \u2014 a speech given by Nazi dictator Adolf Hitler in 1939 at the beginning of the Second World War. But there is one major difference. This viral video was altered by artificial intelligence, and in it, Hitler delivers antisemitic remarks in English. A far-right conspiracy [&#8230;]", "url": "https://toronto.citynews.ca/2024/05/26/experts-seeing-more-and-more-hate-content-created-by-artificial-intelligence/", "image": "https://toronto.citynews.ca/wp-content/blogs.dir/sites/10/2024/05/7cf86301-8547-4042-87d2-09f22f58d19e.jpg", "video": null, "publish_date": "2024-05-26 13:44:06", "author": "News Staff", "authors": ["News Staff"], "language": "en", "source_country": "ca", "sentiment": -0.024}