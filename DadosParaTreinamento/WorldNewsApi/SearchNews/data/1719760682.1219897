{"id": 225012702, "title": "NHTSA Investigates More Waymo Incidents, But Should They?", "text": "Share to Facebook Share to Twitter Share to Linkedin The growing number of Waymos are having more incidents, and NHTSA is curious about them Getty Images The National Highway Transportation Safety Agency regulates the safety of vehicles sold in the USA. Earlier in May they sent Waymo a letter indicating they were investigating 22 incidents involving Waymo vehicles. May 23, they wrote to say thy were adding 9 more. The incidents stretch back to August of 2021, but most are more recent. Most of these incidents are surprisingly minor, with no injuries and just minor property damage, plus a few violations of rules of the road. Twenty come from the mandatory reporting Waymo must do on any crash where police are involved or there is property damage or injury. Eleven come from recent online reports found on social media of Waymo vehicles driving strangely, including a couple where the vehicles used the oncoming lane for a significant distance to get around traffic problems\u2014NHTSA appears to be reading reddit and Twitter. The most concerning recent report involves an empty Waymo which hit a telephone pole in a narrow alley on the way to pick up passengers. Almost all the reports can be easily classed as things which should not happen. The telephone pole incident might even be classed as \u201cshould be impossible.\u201d Waymo had declined, so far, to answer queries about these events and the investigation. While it\u2019s common for companies to not comment on matters under official investigation, this is a change of tack for Waymo, which has been much more forthcoming than Cruise, Tesla or other companies in the space. Waymo vehicles are making mistakes, and it is reasonable for NHTSA to want to know about them. On the other hand, some level of error is to be expected from these vehicles, particularly in their early years, but even indefinitely into the future. Nobody expects or plans broad perfection. Frequently when a self-driving vehicle makes a mistake, public reaction often involves a quick declaration that they should not be on the roads if they are making mistakes. The phrase \u201cnot ready for prime time,\u201d as made famous by Saturday Night Live, is often heard. The California DMV pulled Cruise off the roads entirely for the combination of one serious mistake causing major injuries, and two days of cover-up of issues around the event, though it never cited which of these two reasons was most important, or if one was. It\u2019s time, if regulators plan to regulate, for them to decide and be public about the terms under which they will do this. Regulators are charged with improving overall road safety, which means analysis of data, not of incidents, except when they are part of data or help inform about larger trends. As incidents are tracked, the key questions should be: MORE FOR YOU Trump Trial Prosecutor Ends Closing Argument After Nearly 5 Hours Jury Instructions Set For Wednesday Gas Explosion In Downtown Youngstown Ohio Injures At Least 7 Trump Lashes Out At Robert De Niro After Actor Calls Him A Tyrant Outside Courthouse Are the driving systems at fault? (NHTSA does seem to have done that, as there are many more incidents in their databases where the systems are not likely to be at fault.) The current regulations do not support any evaluation of this. What is the severity, or potential severity of any incident How likely is the incident to recur, factored together with that severity Is the vendor fixing any problems in a timely manner, so that they are very unlikely to recur? Is the vendor being open about problems and their solutions? Pretty Minor Looking over the requested incidents, they involve things like hitting road debris, clipping parking gates and chains, hitting spikes, scraping the bottom in construction, winging a parked car at low speed, but also two collisions, and one intersection mistake which involved a moped sliding while trying to avoid the Waymo. There were also the uses of the opposing lane, use of a transit lane, getting stuck when a detour forced cars onto the highway (which Waymo\u2019s don\u2019t do with passengers) and most amusingly, getting confused following a truck which had a tree in a trailer, obviously wondering what a tree was doing driving down the middle of the road. Most surprising though, is the hitting of a pole, which reminds of of the time a Cruise hit the back of a transit bus\u2014that should be close to impossible. Waymo recently announced they have done a million trips and are doing 50,000 more a week, and also that they\u2019ve done 10 million autonomous miles. The considerable majority of these trips and miles are recent, and it reflects probably 15 human lifetimes of driving. (They announced 1 million miles just in Feb of 2023.) Frankly, if this is all that NHTSA has found worthy of investigation in that period, it\u2019s actually pretty good news for Waymo. Humans, in 10 million miles would probably have 100 small crashes (most not reported to insurance) and 20 police-handled crashes, including several injuries, and a 15% chance of a fatality. That\u2019s what regulators should look at\u2014averages and data. Unlike human crashes, it\u2019s very likely that every single incident listed was already fixed in the software not long after it happened, and is tested for in simulation with every new release. When regulators look at specific incidents, they can only look at the past, only address problems that are already solved. When one human makes a mistake on the road, that\u2019s a sign other people might also make that mistake. When a robot makes a mistake, no robot of that fleet will make the same mistake again. As such, what the regulators need to do is look at the statistics to see if they reach an unacceptable level of risk, not at the incidents. Hitting a Pole Hitting a pole is unusual, however. A good robocar like Waymo\u2019s has redundant systems to assure that even if bugs in the software want to drive the car into a pole, other, simpler systems will prevent it, because it\u2019s super obvious to the sensors. The same is true of the back of a bus. Something in the Waymo should have been screaming\u2014like the forward collision warning in human driven cars\u2014that there is a pole in front of the car and, since nobody is in it, and nobody is behind it, it should hard stop. NHTSA is right to ask why that didn\u2019t happen, because while mistakes will happen, you also want to handle them well, and that didn\u2019t happen here. Recent Changes? Waymo\u2019s record of problems has been so good that some have wondered if there has been a recent surge of problems, while others suggest this may just be because Waymo is driving a lot more, and so there will be more problems. The events involving driving in the oncoming lane to get around traffic indicate some style of new programming in the system, since a map based system like Waymo\u2019s will not confuse the two sides of the street as a Tesla might\u2014 their decision to drive on the wrong side is knowing, but possibly incorrect. This might be attributed to the use of more machine learning in Waymo\u2019s \u201cplanner\u201d\u2014the part of the system that picks the path for the vehicle. Machine learning systems are very powerful and more general, but they can also make human-like mistakes. Unfortunately, Waymo has also refused to comment on these incidents, and did so even before the investigation. Once again regulators should try to understand the frequency and severity of the incidents, not problems solve in the past. It is worth noting that NHTSA does not regulate the rules of the road\u2014that\u2019s up to the states. It broke that principle when it told Tesla not to make rolling stops, and may continue to do so. Follow me on Twitter or LinkedIn. Check out my website. Brad Templeton Following Editorial Standards Print Reprints & Permissions", "summary": "The National Highway Transportation Safety Agency regulates the safety of vehicles sold in the USA.", "url": "https://www.forbes.com/sites/bradtempleton/2024/05/29/nhtsa-investigates-more-waymo-incidents-but-should-they/", "image": "https://imageio.forbes.com/specials-images/imageserve/658d190418533544ce1034c3/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds", "video": null, "publish_date": "2024-05-29 12:37:10", "author": "Brad Templeton,Senior Contributor", "authors": ["Brad Templeton", "Senior Contributor"], "language": "en", "source_country": "US", "sentiment": -0.142}