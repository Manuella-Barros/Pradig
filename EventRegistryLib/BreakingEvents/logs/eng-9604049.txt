{"uri": "eng-9604049", "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 100, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 81, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 43, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 42, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 33, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 30, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 28, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 23, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 23, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 22, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 22, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 20, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 17, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 12, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 7, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 7, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 6, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 5, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_scientific_officer", "type": "wiki", "score": 5, "label": {"eng": "Chief scientific officer"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 5, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 5, "label": {"eng": "Sony"}}], "eventDate": "2024-05-28", "totalArticleCount": 132, "title": {"eng": "OpenAI sets up safety committee as it starts training new model"}, "summary": {"eng": "(Reuters) -OpenAI has formed a Safety and Security Committee which will be led by CEO Sam Altman as it begins training its next artificial intelligence model, the AI startup said on Tuesday.\n\nDirectors Bret Taylor, Adam D'Angelo and Nicole Seligman, will also lead the committee, OpenAI said on a company blog.\n\nFormer Chief Scientist Ilya Sutskever and Jan Leike, who were leaders of Microsoft-backed OpenAI's Superalignment team, which ensured AI stays aligned to the intended objectives, left the f"}, "location": null, "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 24}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 24}], "articleCounts": {"eng": 132}, "sentiment": 0.3490196078431373, "breakingScore": 0.4828244557540742}
{"uri": "8149655264", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "10:54:17", "dateTime": "2024-05-28T10:54:17Z", "dateTimePub": "2024-05-28T10:53:15Z", "dataType": "news", "sim": 0.9176470637321472, "url": "https://gulfnews.com/technology/media/openai-creates-oversight-board-featuring-sam-altman-after-dissolving-safety-team-1.1716893148606", "title": "OpenAI creates oversight board featuring Sam Altman after dissolving safety team", "body": "New committee will spend 90 days evaluating the safeguards before giving a report\n\nOpenAI has created a board committee to evaluate the safety and security of its artificial intelligence models, a governance change made weeks after its top executive on the the subject resigned and the company effectively disbanded his internal team.\n\nThe new committee will spend 90 days evaluating the safeguards in OpenAI's technology before giving a report. \"Following the full board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security,\" the company said in a blog post on Tuesday.\n\nOpenAI also said that it has recently started to train its latest AI model.\n\nread more OpenAI CEO Sam Altman says AI is 'safe enough' as scandals raise concerns Actress Scarlett Johansson's OpenAI feud rekindles Hollywood fear of artificial intelligence OpenAI to 'pause' voice linked to Scarlett Johansson News Corp makes deal to let OpenAI use its content\n\nThe private firm's recent rapid advances in AI have raised concerns about how it manages the technology's potential dangers. Those worries intensified last fall when Chief Executive Officer Sam Altman was briefly ousted in a boardroom coup after clashing with co-founder and chief scientist Ilya Sutskever over how quickly to develop AI products and the steps to limit harms.\n\nThose concerns returned this month after Sutskever and a key deputy, Jan Leike, left the company. The scientists ran OpenAI's so-called superalignment team, which focused on long-term threats of superhuman AI. Leike, who resigned, wrote afterward that his division was \"struggling\" for computing resources within OpenAI. Other departing employees echoed his criticism.\n\nFollowing Sutskever's departure, OpenAI dissolved his team. The company said on Tuesday that this particular work would continue under its research unit and John Schulman, a co-founder with the new title of Head of Alignment Science.\n\nThe startup has at times struggled to manage staff departures. Last week, OpenAI nixed a policy that canceled the equity from former staffers if they spoke out against the company. A spokesperson said OpenAI was aware of criticism from ex-employees and anticipated more, adding that the company was working to address concerns.\n\nOpenAI's new safety committee will consist of three board members \"- Chairman Bret Taylor, Quora CEO Adam D'Angelo and ex-Sony Entertainment executive Nicole Seligman \"- along with six employees, including Schulman and Altman. The company said it would continue to consult outside experts, naming two of them: Rob Joyce, a Homeland Security adviser to Donald Trump, and John Carlin, a former Justice Department official under President Joe Biden.", "source": {"uri": "gulfnews.com", "dataType": "news", "title": "GULF NEWS"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Scarlett_Johansson", "type": "person", "score": 4, "label": {"eng": "Scarlett Johansson"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Cinema_of_the_United_States", "type": "loc", "score": 2, "label": {"eng": "Cinema of the United States"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Coup_d'\u00e9tat", "type": "wiki", "score": 2, "label": {"eng": "Coup d'\u00e9tat"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Joe_Biden", "type": "person", "score": 1, "label": {"eng": "Joe Biden"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 1, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Equity_(finance)", "type": "wiki", "score": 1, "label": {"eng": "Equity (finance)"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Homeland_Security", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Homeland Security"}}, {"uri": "http://en.wikipedia.org/wiki/Donald_Trump", "type": "person", "score": 1, "label": {"eng": "Donald Trump"}}], "categories": [{"uri": "dmoz/Business/Human_Resources", "label": "dmoz/Business/Human Resources", "wgt": 15}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 17}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 17}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 17}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 15}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 70}], "image": "https://imagevars.gulfnews.com/2024/05/22/OpenAI-CEO-Sam-Altman-_18f9e49f2da_medium.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.09019607843137245, "wgt": 234, "relevance": 1}
{"uri": "8149620212", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "10:32:02", "dateTime": "2024-05-28T10:32:02Z", "dateTimePub": "2024-05-28T10:31:35Z", "dataType": "news", "sim": 0.8666666746139526, "url": "https://www.bnnbloomberg.ca/openai-creates-oversight-board-featuring-sam-altman-after-dissolving-safety-team-1.2078027", "title": "OpenAI Creates Oversight Board Featuring Sam Altman After Dissolving Safety Team -  BNN Bloomberg", "body": "(Bloomberg) -- OpenAI has created a board committee to evaluate the safety and security of its artificial intelligence models, a governance change made weeks after its top executive on the the subject resigned and the company effectively disbanded his internal team.\n\nThe new committee will spend 90 days evaluating the safeguards in OpenAI's technology before giving a report. \"Following the full board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security,\" the company said in a blog post on Tuesday.\n\nOpenAI also said that it has recently started to train its latest AI model.\n\nThe private firm's recent rapid advances in AI have raised concerns about how it manages the technology's potential dangers. Those worries intensified last fall when Chief Executive Officer Sam Altman was briefly ousted in a boardroom coup after clashing with co-founder and chief scientist Ilya Sutskever over how quickly to develop AI products and the steps to limit harms.\n\nThose concerns returned this month after Sutskever and a key deputy, Jan Leike, left the company. The scientists ran OpenAI's so-called superalignment team, which focused on long-term threats of superhuman AI. Leike, who resigned, wrote afterward that his division was \"struggling\" for computing resources within OpenAI. Other departing employees echoed his criticism.\n\nRead More: OpenAI Dissolves Key Safety Team After Chief Scientist's Exit\n\nFollowing Sutskever's departure, OpenAI dissolved his team. The company said on Tuesday that this particular work would continue under its research unit and John Schulman, a co-founder with the new title of Head of Alignment Science.\n\nThe startup has at times struggled to manage staff departures. Last week, OpenAI nixed a policy that canceled the equity from former staffers if they spoke out against the company. A spokesperson said OpenAI was aware of criticism from ex-employees and anticipated more, adding that the company was working to address concerns.\n\nOpenAI's new safety committee will consist of three board members -- Chairman Bret Taylor, Quora CEO Adam D'Angelo and ex-Sony Entertainment executive Nicole Seligman -- along with six employees, including Schulman and Altman. The company said it would continue to consult outside experts, naming two of them: Rob Joyce, a Homeland Security adviser to Donald Trump, and John Carlin, a former Justice Department official under President Joe Biden.", "source": {"uri": "bnnbloomberg.ca", "dataType": "news", "title": "BNN"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Bloomberg_News", "type": "org", "score": 3, "label": {"eng": "Bloomberg News"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Coup_d'\u00e9tat", "type": "wiki", "score": 2, "label": {"eng": "Coup d'\u00e9tat"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Joe_Biden", "type": "person", "score": 1, "label": {"eng": "Joe Biden"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 1, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Equity_(finance)", "type": "wiki", "score": 1, "label": {"eng": "Equity (finance)"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Homeland_Security", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Homeland Security"}}, {"uri": "http://en.wikipedia.org/wiki/Donald_Trump", "type": "person", "score": 1, "label": {"eng": "Donald Trump"}}], "categories": [{"uri": "dmoz/Business/Human_Resources", "label": "dmoz/Business/Human Resources", "wgt": 16}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 18}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 20}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 15}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 17}], "image": "http://www.bnnbloomberg.ca/polopoly_fs/1.2078028!/fileimage/httpImage/image.jpg_gen/derivatives/landscape_620/sam-altman-chief-executive-officer-of-openai-during-an-interview-at-bloomberg-house-on-the-opening-day-of-the-world-economic-forum-wef-in-davos-switzerland-on-tuesday-jan-16-2024.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.0117647058823529, "wgt": 221, "relevance": 1}
{"uri": "8149624036", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "10:34:43", "dateTime": "2024-05-28T10:34:43Z", "dateTimePub": "2024-05-28T10:33:59Z", "dataType": "news", "sim": 0.8666666746139526, "url": "https://www.irishtimes.com/business/2024/05/28/openai-creates-committee-to-monitor-safety-of-its-artificial-intelligence-models/", "title": "OpenAI creates committee to monitor safety of its artificial intelligence models", "body": "Move comes as Sam Altman's firm begins work on its latest large language model\n\nOpenAI has created a board committee to evaluate the safety and security of its artificial intelligence models, a governance change made weeks after its top executive on the subject resigned and the company effectively disbanded his internal team.\n\nThe new committee will spend 90 days evaluating the safeguards in OpenAI's technology before giving a report. \"Following the full board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security,\" the company said in a blog post on Tuesday.\n\nOpenAI also said that it has recently started to train its latest AI model.\n\nThe private firm's recent rapid advances in AI have raised concerns about how it manages the technology's potential dangers. Those worries intensified last fall when chief executive Sam Altman was briefly ousted in a boardroom coup after clashing with co-founder and chief scientist Ilya Sutskever over how quickly to develop AI products and the steps to limit harms.\n\nThose concerns returned this month after Sutskever and a key deputy, Jan Leike, left the company. The scientists ran OpenAI's so-called superalignment team, which focused on long-term threats of superhuman AI. Leike, who resigned, wrote afterward that his division was \"struggling\" for computing resources within OpenAI. Other departing employees echoed his criticism.\n\nFollowing Sutskever's departure, OpenAI dissolved his team. The company said on Tuesday that this particular work would continue under its research unit and John Schulman, a co-founder with the new title of Head of Alignment Science.\n\nThe start-up has at times struggled to manage staff departures. Last week, OpenAI nixed a policy that cancelled the equity from former staffers if they spoke out against the company. A spokesperson said OpenAI was aware of criticism from ex-employees and anticipated more, adding that the company was working to address concerns.\n\nOpenAI's new safety committee will consist of three board members - Chairman Bret Taylor, Quora CEO Adam D'Angelo and ex-Sony Entertainment executive Nicole Seligman - along with six employees, including Schulman and Altman. The company said it would continue to consult outside experts, naming two of them: Rob Joyce, a Homeland Security adviser to Donald Trump, and John Carlin, a former Justice Department official under President Joe Biden. - Bloomberg", "source": {"uri": "irishtimes.com", "dataType": "news", "title": "The Irish Times"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 4, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 3, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Bloomberg_News", "type": "org", "score": 1, "label": {"eng": "Bloomberg News"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Joe_Biden", "type": "person", "score": 1, "label": {"eng": "Joe Biden"}}, {"uri": "http://en.wikipedia.org/wiki/Equity_(finance)", "type": "wiki", "score": 1, "label": {"eng": "Equity (finance)"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Homeland_Security", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Homeland Security"}}, {"uri": "http://en.wikipedia.org/wiki/Donald_Trump", "type": "person", "score": 1, "label": {"eng": "Donald Trump"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Business/Human_Resources", "label": "dmoz/Business/Human Resources", "wgt": 17}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 19}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 17}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 16}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 16}], "image": "https://www.irishtimes.com/resizer/fr7RyaixPwt5hemG3YI7LEQoDi8=/1200x630/filters:format(jpg):quality(70)/cloudfront-eu-central-1.images.arcpublishing.com/irishtimes/VNYCZWP3UTNT5BVWCBSVZ75DKM.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.0117647058823529, "wgt": 221, "relevance": 1}
{"uri": "2024-05-370939446", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "13:52:13", "dateTime": "2024-05-28T13:52:13Z", "dateTimePub": "2024-05-28T12:49:38Z", "dataType": "news", "sim": 0.8588235378265381, "url": "https://www.kulr8.com/news/national/openai-forms-safety-committee-as-it-starts-training-latest-artificial-intelligence-model/article_2d7f8469-eea4-59d3-8128-5b4f5baf6069.html", "title": "OpenAI forms safety committee as it starts training latest artificial intelligence model", "body": "OpenAI says it's setting up a new safety and security committee and has begun training a new artificial intelligence model to supplant the GPT-4 system that underpins its ChatGPT chatbot\n\nOpenAI says it's setting up a safety and security committee and has begun training a new AI model to supplant the GPT-4 system that underpins its ChatGPT chatbot.\n\nThe San Francisco startup said in a blog post Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations.\n\nThe safety committee arrives as debate swirls around AI safety at the company, which was thrust into the spotlight after a researcher, Jan Leike, resigned and leveled criticism at OpenAI for letting safety \"take a backseat to shiny products.\" OpenAI co-founder and chief scientist Ilya Sutskever also resigned, and the company disbanded the \"superalignment\" team focused on AI risks that they jointly led.\n\nOpenAI said it has \"recently begun training its next frontier model\" and its AI models lead the industry on capability and safety, though it made no mention of the controversy. \"We welcome a robust debate at this important moment,\" the company said.\n\nAI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting edge AI systems.\n\nThe safety committee is filled with company insiders, including OpenAI CEO Sam Altman and Chairman Bret Taylor, and four OpenAI technical and policy experts. It also includes board members Adam D'Angelo, who's the CEO of Quora, and Nicole Seligman, a former Sony general counsel.\n\nThe committee's first job will be to evaluate and further develop OpenAI's processes and safeguards and make its recommendations to the board in 90 days. The company said it will then publicly release the recommendations it's adopting \"in a manner that is consistent with safety and security.\"\n\n-- --\n\nThe Associated Press and OpenAI have a licensing and technology agreement that allows OpenAI access to part of the AP's text archives.\n\nMore from this section\n\nBill Walton, Hall of Fame player who became a star broadcaster, dies of cancer at 71\n\nAt least 22 dead in Memorial Day weekend storms that devastated several US states\n\nClosing arguments, jury instructions and maybe a verdict? Major week looms in Trump hush money trial", "source": {"uri": "kulr8.com", "dataType": "news", "title": "KULR-8 Local News"}, "authors": [{"uri": "associated_press@kulr8.com", "name": "Associated Press", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 4, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 4, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 2, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Video_on_demand", "type": "wiki", "score": 2, "label": {"eng": "Video on demand"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Pro_Football_Hall_of_Fame", "type": "wiki", "score": 1, "label": {"eng": "Pro Football Hall of Fame"}}, {"uri": "http://en.wikipedia.org/wiki/Associated_Press", "type": "org", "score": 1, "label": {"eng": "Associated Press"}}, {"uri": "http://en.wikipedia.org/wiki/Cancer", "type": "wiki", "score": 1, "label": {"eng": "Cancer"}}, {"uri": "http://en.wikipedia.org/wiki/Donald_Trump", "type": "person", "score": 1, "label": {"eng": "Donald Trump"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 29}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 33}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 28}, {"uri": "news/Business", "label": "news/Business", "wgt": 66}], "image": "https://bloximages.newyork1.vip.townnews.com/kulr8.com/content/tncms/custom/image/ebec0578-57d0-11ee-978f-b7da313020af.jpg?resize=600%2C315", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.411764705882353, "wgt": 219, "relevance": 1}
{"uri": "2024-05-370921945", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "13:37:53", "dateTime": "2024-05-28T13:37:53Z", "dateTimePub": "2024-05-28T13:33:19Z", "dataType": "news", "sim": 0.8549019694328308, "url": "https://www.devdiscourse.com/article/technology/2952971-openai-forms-safety-committee-amid-ai-controversy", "title": "OpenAI Forms Safety Committee Amid AI Controversy", "body": "OpenAI has announced the formation of a safety and security committee as it begins training a new AI model to replace GPT-4. This move follows resignations and criticisms over the company's handling of AI safety. The committee's initial task is to evaluate and recommend safety processes within 90 days.\n\nOpenAI says it's setting up a safety and security committee and has begun training a new AI model to supplant the GPT-4 system that underpins its ChatGPT chatbot.\n\nThe San Francisco startup said in a blog post Tuesday that the committee will advise the full board on \"critical safety and security decisions'' for its projects and operations.\n\nThe safety committee arrives as debate swirls around AI safety at the company, which was thrust into the spotlight after a researcher, Jan Leike, resigned and levelled criticism at OpenAI for letting safety \"take a backseat to shiny products.'' OpenAI co-founder and chief scientist Ilya Sutskever also resigned, and the company disbanded the \"superalignment\" team focused on AI risks that they jointly led.\n\nOpenAI said it has \"recently begun training its next frontier model\" and its AI models lead the industry on capability and safety, though it made no mention of the controversy. \"We welcome a robust debate at this important moment,\" the company said.\n\nAI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting edge AI systems.\n\nThe safety committee is filled with company insiders, including OpenAI CEO Sam Altman and Chairman Bret Taylor, and four OpenAI technical and policy experts. It also includes board members Adam D'Angelo, who's the CEO of Quora, and Nicole Seligman, a former Sony general counsel.\n\nThe committee's first job will be to evaluate and further develop OpenAI's processes and safeguards and make its recommendations to the board in 90 days. The company said it will then publicly release the recommendations it's adopting \"in a manner that is consistent with safety and security.''\n\n(This story has not been edited by Devdiscourse staff and is auto-generated from a syndicated feed.)", "source": {"uri": "devdiscourse.com", "dataType": "news", "title": "Devdiscourse"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 4, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 4, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 31}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 34}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 28}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 31}, {"uri": "news/Business", "label": "news/Business", "wgt": 46}], "image": "https://www.devdiscourse.com/remote.axd?https://devdiscourse.blob.core.windows.net/aiimagegallery/27_05_2024_07_43_07_8181084.png?width=920&format=jpeg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3725490196078431, "wgt": 218, "relevance": 1}
{"uri": "8149855198", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "12:55:19", "dateTime": "2024-05-28T12:55:19Z", "dateTimePub": "2024-05-28T12:54:45Z", "dataType": "news", "sim": 0.8470588326454163, "url": "https://www.wral.com/story/openai-forms-safety-committee-as-it-starts-training-latest-artificial-intelligence-model/21453691/", "title": "OpenAI forms safety committee as it starts training latest artificial intelligence model", "body": "OpenAI says it's setting up a safety and security committee and has begun training a new AI model to supplant the GPT-4 system that underpins its ChatGPT chatbot.\n\nOpenAI says it's setting up a safety and security committee and has begun training a new AI model to supplant the GPT-4 system that underpins its ChatGPT chatbot.\n\nThe San Francisco startup said in a blog post Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations.\n\nThe safety committee arrives as debate swirls around AI safety at the company, which was thrust into the spotlight after a researcher, Jan Leike, resigned and leveled criticism at OpenAI for letting safety \"take a backseat to shiny products.\" OpenAI co-founder and chief scientist Ilya Sutskever also resigned, and the company disbanded the \"superalignment\" team focused on AI risks that they jointly led.\n\nOpenAI said it has \"recently begun training its next frontier model\" and its AI models lead the industry on capability and safety, though it made no mention of the controversy. \"We welcome a robust debate at this important moment,\" the company said.\n\nAI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting edge AI systems.\n\nThe safety committee is filled with company insiders, including OpenAI CEO Sam Altman and Chairman Bret Taylor, and four OpenAI technical and policy experts. It also includes board members Adam D'Angelo, who's the CEO of Quora, and Nicole Seligman, a former Sony general counsel.\n\nThe committee's first job will be to evaluate and further develop OpenAI's processes and safeguards and make its recommendations to the board in 90 days. The company said it will then publicly release the recommendations it's adopting \"in a manner that is consistent with safety and security.\"\n\n-- --\n\nThe Associated Press and OpenAI have a licensing and technology agreement that allows OpenAI access to part of the AP's text archives.", "source": {"uri": "wral.com", "dataType": "news", "title": "WRAL"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 5, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 5, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 5, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 2, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Associated_Press", "type": "org", "score": 1, "label": {"eng": "Associated Press"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 26}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 29}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 34}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 26}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 29}, {"uri": "news/Business", "label": "news/Business", "wgt": 56}], "image": "https://images.wral.com/asset/business/2024/05/28/21453693/media_ae7dab0bf3144de8a63e2f146a664d4c-DMID1-633bdjwwk-640x426.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3803921568627451, "wgt": 216, "relevance": 1}
{"uri": "8150002614", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:26:49", "dateTime": "2024-05-28T14:26:49Z", "dateTimePub": "2024-05-28T14:25:21Z", "dataType": "news", "sim": 0.8470588326454163, "url": "https://www.dailymail.co.uk/wires/pa/article-13468013/OpenAI-forms-safety-committee-starts-training-latest-AI-model.html", "title": "OpenAI forms safety committee as it starts training latest AI model", "body": "OpenAI said it is setting up a safety and security committee and has begun training a new AI model to supplant the GPT-4 system that underpins its ChatGPT chatbot.\n\nThe San Francisco startup said in a blog post on Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations.\n\nThe safety committee arrives as debate swirls around AI safety at the company, which was thrust into the spotlight after a researcher, Jan Leike, resigned and levelled criticism at OpenAI for letting safety \"take a backseat to shiny products\".\n\nOpenAI co-founder and chief scientist Ilya Sutskever also resigned, and the company disbanded the \"superalignment\" team focused on AI risks that they jointly led.\n\nWe welcome a robust debate at this important moment OpenAI\n\nOpenAI said it has \"recently begun training its next frontier model\" and its AI models lead the industry on capability and safety, though it made no mention of the controversy.\n\n\"We welcome a robust debate at this important moment,\" the company said.\n\nOpenAI has begun training a new AI model to supplant the GPT-4 system that underpins its ChatGPT chatbot (Michael Dwyer/AP)\n\nAI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting-edge AI systems.\n\nThe safety committee is filled with company insiders, including OpenAI CEO Sam Altman and chairman Bret Taylor, and four OpenAI technical and policy experts. It also includes board members Adam D'Angelo, who is the CEO of Quora, and Nicole Seligman, a former Sony general counsel.\n\nThe committee's first job will be to evaluate and further develop OpenAI's processes and safeguards and make its recommendations to the board in 90 days.\n\nThe company said it will then publicly release the recommendations it is adopting \"in a manner that is consistent with safety and security\".", "source": {"uri": "dailymail.co.uk", "dataType": "news", "title": "Daily Mail Online"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 4, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 3, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Associated_Press", "type": "org", "score": 1, "label": {"eng": "Associated Press"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 24}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 27}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 31}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 23}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 26}, {"uri": "news/Business", "label": "news/Business", "wgt": 56}], "image": "https://i.dailymail.co.uk/1s/2024/05/28/15/wire-85425639-1716906088-553_636x382.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.4352941176470588, "wgt": 216, "relevance": 1}
{"uri": "2024-05-370922381", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "13:38:18", "dateTime": "2024-05-28T13:38:18Z", "dateTimePub": "2024-05-28T12:49:38Z", "dataType": "news", "sim": 0.8470588326454163, "url": "https://www.wdrb.com/news/national/openai-forms-safety-committee-as-it-starts-training-latest-artificial-intelligence-model/article_d7430f80-92c5-52b1-ab69-742522981ca4.html", "title": "OpenAI forms safety committee as it starts training latest artificial intelligence model", "body": "OpenAI says it's setting up a new safety and security committee and has begun training a new artificial intelligence model to supplant the GPT-4 system that underpins its ChatGPT chatbot\n\nOpenAI says it's setting up a safety and security committee and has begun training a new AI model to supplant the GPT-4 system that underpins its ChatGPT chatbot.\n\nThe San Francisco startup said in a blog post Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations.\n\nThe safety committee arrives as debate swirls around AI safety at the company, which was thrust into the spotlight after a researcher, Jan Leike, resigned and leveled criticism at OpenAI for letting safety \"take a backseat to shiny products.\" OpenAI co-founder and chief scientist Ilya Sutskever also resigned, and the company disbanded the \"superalignment\" team focused on AI risks that they jointly led.\n\nOpenAI said it has \"recently begun training its next frontier model\" and its AI models lead the industry on capability and safety, though it made no mention of the controversy. \"We welcome a robust debate at this important moment,\" the company said.\n\nAI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting edge AI systems.\n\nRead more from WDRB News\n\nIMAGES | Strong winds, severe weather moves through Kentuckiana on Sunday\n\nGazebo Festival canceled Sunday due to severe weather in Louisville\n\n14-year-old boy found dead after swimming in Silver Creek, New Albany police say\n\nThe safety committee is filled with company insiders, including OpenAI CEO Sam Altman and Chairman Bret Taylor, and four OpenAI technical and policy experts. It also includes board members Adam D'Angelo, who's the CEO of Quora, and Nicole Seligman, a former Sony general counsel.\n\nThe committee's first job will be to evaluate and further develop OpenAI's processes and safeguards and make its recommendations to the board in 90 days. The company said it will then publicly release the recommendations it's adopting \"in a manner that is consistent with safety and security.\"\n\n-- --\n\nThe Associated Press and OpenAI have a licensing and technology agreement that allows OpenAI access to part of the AP's text archives.", "source": {"uri": "wdrb.com", "dataType": "news", "title": "WDRB"}, "authors": [{"uri": "associated_press@wdrb.com", "name": "Associated Press", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 4, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 4, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 2, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Associated_Press", "type": "org", "score": 1, "label": {"eng": "Associated Press"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Albany,_New_York", "type": "loc", "score": 1, "label": {"eng": "Albany, New York"}, "location": {"type": "place", "label": {"eng": "Albany, New York"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Louisville,_Kentucky", "type": "loc", "score": 1, "label": {"eng": "Louisville, Kentucky"}, "location": {"type": "place", "label": {"eng": "Louisville, Kentucky"}, "country": {"type": "country", "label": {"eng": "United States"}}}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 26}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 29}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 33}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 28}, {"uri": "news/Business", "label": "news/Business", "wgt": 49}], "image": "https://bloximages.newyork1.vip.townnews.com/wdrb.com/content/tncms/assets/v3/editorial/1/f7/1f7e7748-1cef-11ef-a96d-0febba0bac77/6655d02a48f6c.image.jpg?crop=1763%2C926%2C0%2C124&resize=438%2C230&order=crop%2Cresize", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.411764705882353, "wgt": 216, "relevance": 1}
{"uri": "8150306047", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "18:01:42", "dateTime": "2024-05-28T18:01:42Z", "dateTimePub": "2024-05-28T18:00:17Z", "dataType": "news", "sim": 0.8470588326454163, "url": "https://medicinehatnews.com/business/2024/05/28/openai-forms-safety-committee-as-it-starts-training-latest-artificial-intelligence-model/", "title": "OpenAI forms safety committee as it starts training latest artificial intelligence model - Medicine Hat News", "body": "FILE - The OpenAI logo is seen displayed on a cell phone with an image on a computer monitor generated by ChatGPT's Dall-E text-to-image model, Friday, Dec. 8, 2023, in Boston. OpenAI says it's setting up a new safety and security committee and has begun training a new artificial intelligence model to supplant the GPT-4 system that underpins its ChatGPT chatbot. The San Francisco startup said in a blog post Tuesday May 28, 2024 that the committee will advise the full board on \u00e2\u20ac\u0153critical safety and security decisions\" for its projects and operations. (AP Photo/Michael Dwyer, File)OpenAI says it's setting up a safety and security committee and has begun training a new AI model to supplant the GPT-4 system that underpins its ChatGPT chatbot. The San Francisco startup said in a blog post Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations. The safety committee arrives as debate swirls around AI safety at the company, which was thrust into the spotlight after a researcher, Jan Leike, resigned and leveled criticism at OpenAI for letting safety \"take a backseat to shiny products.\" OpenAI co-founder and chief scientist Ilya Sutskever also resigned, and the company disbanded the \"superalignment\"\u009d team focused on AI risks that they jointly led. Leike said Tuesday he's joining rival AI company Anthropic, founded by ex-OpenAI leaders, to \"continue the superalignment mission\"\u009d there. OpenAI said it has \"recently begun training its next frontier model\"\u009d and its AI models lead the industry on capability and safety, though it made no mention of the controversy. \"We welcome a robust debate at this important moment,\"\u009d the company said. AI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting edge AI systems. The safety committee is filled with company insiders, including OpenAI CEO Sam Altman and Chairman Bret Taylor, and four OpenAI technical and policy experts. It also includes board members Adam D'Angelo, who's the CEO of Quora, and Nicole Seligman, a former Sony general counsel. The committee's first job will be to evaluate and further develop OpenAI's processes and safeguards and make its recommendations to the board in 90 days. The company said it will then publicly release the recommendations it's adopting \"in a manner that is consistent with safety and security.\"\u009d - - The Associated Press and OpenAI have a licensing and technology agreement that allows OpenAI access to part of the AP's text archives.", "source": {"uri": "medicinehatnews.com", "dataType": "news", "title": "Medicine Hat News"}, "authors": [{"uri": "canadian_press@medicinehatnews.com", "name": "Canadian Press", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 4, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 4, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 4, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 4, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 4, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Text-to-image_model", "type": "wiki", "score": 3, "label": {"eng": "Text-to-image model"}}, {"uri": "http://en.wikipedia.org/wiki/Mobile_phone", "type": "wiki", "score": 3, "label": {"eng": "Mobile phone"}}, {"uri": "http://en.wikipedia.org/wiki/Boston", "type": "loc", "score": 3, "label": {"eng": "Boston"}, "location": {"type": "place", "label": {"eng": "Boston"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Anthropic", "type": "wiki", "score": 2, "label": {"eng": "Anthropic"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 2, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Associated_Press", "type": "org", "score": 1, "label": {"eng": "Associated Press"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "news/Business", "label": "news/Business", "wgt": 51}], "image": "https://medicinehatnews.com/wp-content/uploads/cp/20240528070536-6655c1f98ef00cc70754499ajpeg.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3254901960784313, "wgt": 216, "relevance": 1}
{"uri": "2024-05-371192311", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "17:59:45", "dateTime": "2024-05-28T17:59:45Z", "dateTimePub": "2024-05-28T11:36:56Z", "dataType": "news", "sim": 0.8470588326454163, "url": "https://www.oneidadispatch.com/2024/05/28/openai-forms-safety-committee-as-it-starts-training-latest-artificial-intelligence-model/", "title": "OpenAI forms safety committee as it starts training latest artificial intelligence model", "body": "OpenAI says it's setting up a safety and security committee and has begun training a new AI model to supplant the GPT-4 system that underpins its ChatGPT chatbot.\n\nThe San Francisco startup said in a blog post Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations.\n\nThe safety committee arrives as debate swirls around AI safety at the company, which was thrust into the spotlight after a researcher, Jan Leike, resigned and leveled criticism at OpenAI for letting safety \"take a backseat to shiny products.\" OpenAI co-founder and chief scientist Ilya Sutskever also resigned, and the company disbanded the \"superalignment\" team focused on AI risks that they jointly led.\n\nLeike said Tuesday he's joining rival AI company Anthropic, founded by ex-OpenAI leaders, to \"continue the superalignment mission\" there.\n\nOpenAI said it has \"recently begun training its next frontier model\" and its AI models lead the industry on capability and safety, though it made no mention of the controversy. \"We welcome a robust debate at this important moment,\" the company said.\n\nAI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting edge AI systems.\n\nThe safety committee is filled with company insiders, including OpenAI CEO Sam Altman and Chairman Bret Taylor, and four OpenAI technical and policy experts. It also includes board members Adam D'Angelo, who's the CEO of Quora, and Nicole Seligman, a former Sony general counsel.\n\nThe committee's first job will be to evaluate and further develop OpenAI's processes and safeguards and make its recommendations to the board in 90 days. The company said it will then publicly release the recommendations it's adopting \"in a manner that is consistent with safety and security.\"\n\n-- --\n\nThe Associated Press and OpenAI have a licensing and technology agreement that allows OpenAI access to part of the AP's text archives.", "source": {"uri": "oneidadispatch.com", "dataType": "news", "title": "Oneida Dispatch"}, "authors": [{"uri": "associated_press@oneidadispatch.com", "name": "Associated Press", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 3, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Anthropic", "type": "wiki", "score": 2, "label": {"eng": "Anthropic"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Associated_Press", "type": "org", "score": 1, "label": {"eng": "Associated Press"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 28}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 32}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 28}, {"uri": "news/Business", "label": "news/Business", "wgt": 56}], "image": "https://www.oneidadispatch.com/wp-content/uploads/2024/05/OpenAI_New_AI_Model_13983.jpg?w=640", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3176470588235294, "wgt": 216, "relevance": 1}
{"uri": "2024-05-370872392", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "12:56:11", "dateTime": "2024-05-28T12:56:11Z", "dateTimePub": "2024-05-28T11:36:56Z", "dataType": "news", "sim": 0.843137264251709, "url": "https://tribtown.com/2024/05/28/openai-forms-safety-committee-as-it-starts-training-latest-artificial-intelligence-model/", "title": "OpenAI forms safety committee as it starts training latest artificial intelligence model", "body": "FILE - The OpenAI logo is seen displayed on a cell phone with an image on a computer monitor generated by ChatGPT's Dall-E text-to-image model, Friday, Dec. 8, 2023, in Boston. OpenAI says it's setting up a new safety and security committee and has begun training a new artificial intelligence model to supplant the GPT-4 [...]\n\nOpenAI says it's setting up a safety and security committee and has begun training a new AI model to supplant the GPT-4 system that underpins its ChatGPT chatbot.\n\nThe San Francisco startup said in a blog post Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations.\n\nThe safety committee arrives as debate swirls around AI safety at the company, which was thrust into the spotlight after a researcher, Jan Leike, resigned and leveled criticism at OpenAI for letting safety \"take a backseat to shiny products.\" OpenAI co-founder and chief scientist Ilya Sutskever also resigned, and the company disbanded the \"superalignment\" team focused on AI risks that they jointly led.\n\nOpenAI said it has \"recently begun training its next frontier model\" and its AI models lead the industry on capability and safety, though it made no mention of the controversy. \"We welcome a robust debate at this important moment,\" the company said.\n\nAI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting edge AI systems.\n\nThe safety committee is filled with company insiders, including OpenAI CEO Sam Altman and Chairman Bret Taylor, and four OpenAI technical and policy experts. It also includes board members Adam D'Angelo, who's the CEO of Quora, and Nicole Seligman, a former Sony general counsel.\n\nThe committee's first job will be to evaluate and further develop OpenAI's processes and safeguards and make its recommendations to the board in 90 days. The company said it will then publicly release the recommendations it's adopting \"in a manner that is consistent with safety and security.\"\n\n-- --\n\nThe Associated Press and OpenAI have a licensing and technology agreement that allows OpenAI access to part of the AP's text archives.", "source": {"uri": "tribtown.com", "dataType": "news", "title": "The Tribune"}, "authors": [{"uri": "associated_press@tribtown.com", "name": "Associated Press", "type": "author", "isAgency": true}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 4, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Text-to-image_model", "type": "wiki", "score": 3, "label": {"eng": "Text-to-image model"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Boston", "type": "loc", "score": 3, "label": {"eng": "Boston"}, "location": {"type": "place", "label": {"eng": "Boston"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 2, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 2, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 2, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 2, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Associated_Press", "type": "org", "score": 1, "label": {"eng": "Associated Press"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 26}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 30}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 34}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 29}, {"uri": "news/Business", "label": "news/Business", "wgt": 54}], "image": "https://tribtown.com/wp-content/uploads/2024/05/preview-2446.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.388235294117647, "wgt": 215, "relevance": 1}
{"uri": "8150003651", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:26:39", "dateTime": "2024-05-28T14:26:39Z", "dateTimePub": "2024-05-28T14:26:07Z", "dataType": "news", "sim": 0.843137264251709, "url": "https://www.expressandstar.com/news/world-news/2024/05/28/openai-forms-safety-committee-as-it-starts-training-latest-ai-model/", "title": "OpenAI forms safety committee as it starts training latest AI model", "body": "The safety committee arrives as debate swirls around AI safety at the company.\n\nOpenAI said it is setting up a safety and security committee and has begun training a new AI model to supplant the GPT-4 system that underpins its ChatGPT chatbot.\n\nThe San Francisco startup said in a blog post on Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations.\n\nThe safety committee arrives as debate swirls around AI safety at the company, which was thrust into the spotlight after a researcher, Jan Leike, resigned and levelled criticism at OpenAI for letting safety \"take a backseat to shiny products\".\n\nOpenAI co-founder and chief scientist Ilya Sutskever also resigned, and the company disbanded the \"superalignment\" team focused on AI risks that they jointly led.\n\nOpenAI said it has \"recently begun training its next frontier model\" and its AI models lead the industry on capability and safety, though it made no mention of the controversy.\n\n\"We welcome a robust debate at this important moment,\" the company said.\n\nAI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting-edge AI systems.\n\nThe safety committee is filled with company insiders, including OpenAI CEO Sam Altman and chairman Bret Taylor, and four OpenAI technical and policy experts. It also includes board members Adam D'Angelo, who is the CEO of Quora, and Nicole Seligman, a former Sony general counsel.\n\nThe committee's first job will be to evaluate and further develop OpenAI's processes and safeguards and make its recommendations to the board in 90 days.\n\nThe company said it will then publicly release the recommendations it is adopting \"in a manner that is consistent with safety and security\".", "source": {"uri": "expressandstar.com", "dataType": "news", "title": "Express & Star"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 4, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 28}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 32}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 35}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 28}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 31}, {"uri": "news/Business", "label": "news/Business", "wgt": 46}], "image": "https://www.expressandstar.com/resizer/uq4tKF_1PhGTaF3Q8fjMLjxK3Nw=/1200x900/cloudfront-us-east-1.images.arcpublishing.com/mna/M4NMHH5TVBFOTBWFGVUFN2CDXA.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3960784313725489, "wgt": 215, "relevance": 1}
{"uri": "8149981475", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:12:22", "dateTime": "2024-05-28T14:12:22Z", "dateTimePub": "2024-05-28T14:11:44Z", "dataType": "news", "sim": 0.8274509906768799, "url": "https://www.theguardian.com/technology/article/2024/may/28/openai-safety-council-chatgpt", "title": "OpenAI forms safety council as it trains latest artificial intelligence model", "body": "US tech startup says committee will advise on 'critical safety and security decisions'\n\nOpenAI says it is setting up a safety and security committee and has begun training a new AI model to supplant the GPT-4 system that underpins its ChatGPT chatbot.\n\nThe San Francisco startup said in a blogpost on Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations.\n\nThe safety committee arrives as debate swirls around AI safety at the company, which was thrust into the spotlight after a researcher, Jan Leike, resigned and leveled criticism at OpenAI for letting safety \"take a backseat to shiny products\". The OpenAI co-founder and chief scientist Ilya Sutskever also resigned, and the company disbanded the \"superalignment\" team focused on AI risks that they jointly led.\n\nOpenAI said it had \"recently begun training its next frontier model\" and its AI models led the industry on capability and safety, though it made no mention of the controversy. \"We welcome a robust debate at this important moment,\" the company said.\n\nAI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting-edge AI systems.\n\nThe safety committee is filled with company insiders, including the OpenAI CEO, Sam Altman, and its chairman, Bret Taylor, and four OpenAI technical and policy experts. It also includes the board members Adam D'Angelo, who is the CEO of Quora, and Nicole Seligman, a former Sony general counsel.\n\nThe committee's first job will be to evaluate and further develop OpenAI's processes and safeguards and make its recommendations to the board in 90 days. The company said it will then publicly release the recommendations it is adopting \"in a manner that is consistent with safety and security\".", "source": {"uri": "theguardian.com", "dataType": "news", "title": "The Guardian"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 5, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 2, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 28}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 31}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 35}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 28}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 31}, {"uri": "news/Business", "label": "news/Business", "wgt": 49}], "image": "https://i.guim.co.uk/img/media/1a02bc0214b3bace10508c6e07b43e2a1f532547/0_133_4000_2401/master/4000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&s=5ba70aa6fb6ddc153569be1b2086d162", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3490196078431373, "wgt": 211, "relevance": 1}
{"uri": "8150004237", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:27:29", "dateTime": "2024-05-28T14:27:29Z", "dateTimePub": "2024-05-28T14:26:30Z", "dataType": "news", "sim": 0.8156862854957581, "url": "https://www.irishexaminer.com/world/arid-41404652.html", "title": "OpenAI forms safety committee as it starts training latest AI model", "body": "The San Francisco startup said in a blog post on Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations.\n\nThe safety committee arrives as debate swirls around AI safety at the company, which was thrust into the spotlight after a researcher, Jan Leike, resigned and levelled criticism at OpenAI for letting safety \"take a backseat to shiny products\".\n\nOpenAI co-founder and chief scientist Ilya Sutskever also resigned, and the company disbanded the \"superalignment\" team focused on AI risks that they jointly led.\n\nOpenAI said it has \"recently begun training its next frontier model\" and its AI models lead the industry on capability and safety, though it made no mention of the controversy.\n\n\"We welcome a robust debate at this important moment,\" the company said.\n\nAI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting-edge AI systems.\n\nThe safety committee is filled with company insiders, including OpenAI CEO Sam Altman and chairman Bret Taylor, and four OpenAI technical and policy experts. It also includes board members Adam D'Angelo, who is the CEO of Quora, and Nicole Seligman, a former Sony general counsel.\n\nThe committee's first job will be to evaluate and further develop OpenAI's processes and safeguards and make its recommendations to the board in 90 days.\n\nThe company said it will then publicly release the recommendations it is adopting \"in a manner that is consistent with safety and security\".", "source": {"uri": "irishexaminer.com", "dataType": "news", "title": "Irish Examiner"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 3, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 26}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 29}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 32}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 28}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 52}], "image": "https://www.irishexaminer.com/cms_media/module_img/8271/4135715_3_articlelarge_ae7dab0bf3144de8a63e2f146a664d4c.jpg.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3019607843137255, "wgt": 208, "relevance": 1}
{"uri": "8150469688", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "20:28:35", "dateTime": "2024-05-28T20:28:35Z", "dateTimePub": "2024-05-28T20:27:42Z", "dataType": "news", "sim": 0.8156862854957581, "url": "https://www.investopedia.com/microsoft-backed-openai-forms-new-safety-committee-as-it-trains-next-ai-model-here-is-why-8654771", "title": "Microsoft-Backed OpenAI Forms New Safety Committee as It Trains Next AI Model -- Here's Why", "body": "Concerns around AI safety could affect OpenAI, and in turn, Microsoft, as AI tech evolves.\n\nMicrosoft-backed (MSFT) OpenAI announced Tuesday it formed a new safety committee and has started training its next artificial intelligence (AI) model, amid safety concerns surrounding the emerging tech's quickly evolving capabilities.\n\nThe new committee could help boost perceptions of OpenAI leadership by easing concerns about AI safety, as well as worries about internal upheaval following the departures of several senior scientists and the dissolution of OpenAI's former \"Superalignment\" team.\n\nOpenAI said the company's board created the Safety and Security Committee, directed by OpenAI CEO Sam Altman, board chair Bret Taylor, and board members Adam D'Angelo and Nicole Seligman.\n\nThe committee \"is responsible for making recommendations on critical safety and security decisions for all OpenAI projects\" with recommendations made in 90 days, the company said in a release.\n\nThe company also reported that it has \"recently begun training its next frontier model\" and \"anticipate[s] the resulting systems to bring [OpenAI] to the next level of capabilities.\"\n\nThe formation of the new committee could help ease AI safety concerns following reports that OpenAI dissolved its \"Superalignment\" team, which focused on aligning AI systems to ensure safety.\n\nOpenAI introduced the Superalignment team in July of 2023, saying it would dedicate 20% of its computing power to managing risks and addressing superintelligence alignment problems.\n\nThe team was co-led by OpenAI co-founder and chief scientist Ilya Sutskever and alignment researcher Jan Leike, who both announced earlier this month they were leaving OpenAI.\n\nLeike announced his resignation on Elon Musk's X (formerly Twitter), saying that \"OpenAI must become a safety-first AGI company\" as \"over the past years, safety culture and processes have taken a backseat to shiny products.\"\n\nFollowing his OpenAI departure, Leike announced that he is joining Amazon-backed (AMZN) Anthropic to \"work on scalable oversight, weak-to-strong generalization, and automated alignment research.\" Leike's quick move from OpenAI to Anthropic also underlined the AI talent shortage the emerging tech industry faces.\n\nThe recent resignations contributed to speculation of internal upheaval at OpenAI and concerns around AI safety that could threaten to undermine OpenAI's position as an early AI leader.\n\nPerceptions of the ChatGPT maker could also affect its largest investor, Microsoft. The big tech company has staked its claim in the AI era through its investment in OpenAI as it also works on its own AI initiatives.\n\nThe latest news comes about six months after OpenAI ousted and rehired CEO Sam Altman, raising concerns around OpenAI's governance and Microsoft's involvement.", "source": {"uri": "investopedia.com", "dataType": "news", "title": "Investopedia"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 5, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Superintelligence", "type": "wiki", "score": 2, "label": {"eng": "Superintelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 2, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Anthropic", "type": "wiki", "score": 1, "label": {"eng": "Anthropic"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 1, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Big_Tech", "type": "wiki", "score": 1, "label": {"eng": "Big Tech"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Elon_Musk", "type": "person", "score": 1, "label": {"eng": "Elon Musk"}}, {"uri": "http://en.wikipedia.org/wiki/Twitter", "type": "org", "score": 1, "label": {"eng": "Twitter"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 23}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 26}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 23}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 26}], "image": "https://www.investopedia.com/thmb/zrJrTepKsfRrStXajVNlAaII1TY=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/GettyImages-2153471578-174bb4ee2450403c805eabfb8ee98041.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.5137254901960784, "wgt": 208, "relevance": 1}
{"uri": "8150020075", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:37:05", "dateTime": "2024-05-28T14:37:05Z", "dateTimePub": "2024-05-28T14:36:21Z", "dataType": "news", "sim": 0.8078431487083435, "url": "https://thecyberexpress.com/openai-safety-and-security-committee-announcement/", "title": "OpenAI Announces Safety And Security Committee Amid New Model Development", "body": "The Safety and Security Committee's first task will be to evaluate and further develop OpenAI's processes and safeguards over the next 90 days.\"\n\nOpenAI announced a new safety and security committee as it begins training a new AI model intended to replace the GPT-4 system that currently powers its ChatGPT chatbot.\n\nThe San Francisco-based startup announced the formation of this committee in a blog post on Tuesday, highlighting its role in advising the board on crucial safety and security decisions related to OpenAI's projects and operations.\n\nThe creation of this committee comes amid ongoing debates about AI safety at OpenAI. The company faced scrutiny after Jan Leike, a researcher, resigned, criticizing OpenAI for prioritizing product development over safety. Following this, co-founder and chief scientist Ilya Sutskever also resigned, leading to the disbandment of the \"superalignment\" team that he and Leike co-led, which was focused on addressing AI risks.\n\nDespite these controversies, OpenAI emphasized that its AI models are industry leaders in both capability and safety. The company expressed openness to robust debate during this critical period.\n\nThe safety committee comprises company insiders, including OpenAI CEO Sam Altman, Chairman Bret Taylor, and four OpenAI technical and policy experts. It also features board members Adam D'Angelo, CEO of Quora, and Nicole Seligman, a former general counsel for Sony.\n\n\"A first task of the Safety and Security Committee will be to evaluate and further develop OpenAI's processes and safeguards over the next 90 days.\"\n\nThe committee's initial task is to evaluate and further develop OpenAI's existing processes and safeguards. They are expected to make recommendations to the board within 90 days. OpenAI has committed to publicly releasing the recommendations it adopts in a manner that aligns with safety and security considerations.\n\nThe establishment of the safety and security committee is a significant step by OpenAI to address concerns about AI safety and maintain its leadership in AI innovation. By integrating a diverse group of experts and stakeholders into the decision-making process, OpenAI aims to ensure that safety and security remain paramount as it continues to develop cutting-edge AI technologies.\n\nOpenAI also announced that it has recently started training a new AI model, described as a \"frontier model.\" These frontier models represent the most advanced AI systems, capable of generating text, images, video, and human-like conversations based on extensive datasets.\n\nThe company recently also launched its newest flagship model GPT-4o ('o' stands for omni), which is a multilingual, multimodal generative pre-trained transformer designed by OpenAI.\n\nIt was announced by OpenAI's CTO Mira Murati during a live-streamed demo on May 13 and released the same day. GPT-4o is free, but with a usage limit that is five times higher for ChatGPT Plus subscribers. GPT-4o has a context window supporting up to 128,000 tokens, which helps it maintain coherence over longer conversations or documents, making it suitable for detailed analysis.", "source": {"uri": "thecyberexpress.com", "dataType": "news", "title": "The Cyber Express"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 3, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 2, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 2, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 2, "label": {"eng": "Sony"}}, {"uri": "http://en.wikipedia.org/wiki/Mira_Murati", "type": "wiki", "score": 1, "label": {"eng": "Mira Murati"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_pre-trained_transformer", "type": "wiki", "score": 1, "label": {"eng": "Generative pre-trained transformer"}}, {"uri": "http://en.wikipedia.org/wiki/Multimodal_learning", "type": "wiki", "score": 1, "label": {"eng": "Multimodal learning"}}, {"uri": "http://en.wikipedia.org/wiki/Lexical_analysis", "type": "wiki", "score": 1, "label": {"eng": "Lexical analysis"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_technology_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief technology officer"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 26}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 28}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 30}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 28}, {"uri": "news/Business", "label": "news/Business", "wgt": 52}], "image": "https://cf276dd8.rocketcdn.me/wp-content/uploads/shutterstock_2447360015.webp", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-05-13", "textStart": 2820, "textEnd": 2826}], "sentiment": 0.3490196078431373, "wgt": 206, "relevance": 1}
{"uri": "8149984031", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:13:56", "dateTime": "2024-05-28T14:13:56Z", "dateTimePub": "2024-05-28T14:13:23Z", "dataType": "news", "sim": 0.8078431487083435, "url": "https://www.mirror.co.uk/money/openai-starts-training-new-ai-32909857", "title": "OpenAI starts training new AI model as it sets up safety and security committee", "body": "The San Francisco startup said that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations\n\nOpenAI has announced the establishment of a safety and security committee, as well as the development of a new AI model to replace its current GPT-4 system that powers its ChatGPT chatbot\n\nThe San Francisco-based startup revealed in a blog post on Tuesday that the committee will provide advice to the full board on \"critical safety and security decisions\" related to its projects and operations. This move comes amid ongoing discussions about AI safety at OpenAI, which came under scrutiny after researcher Jan Leike resigned, accusing the company for letting safety \"take a backseat to shiny products.\"\n\nOpenAI co-founder and chief scientist Ilya Sutskever also stepped down, and the \"superalignment\" team they jointly led, which focused on AI risks, was disbanded. Despite not addressing the controversy directly, OpenAI stated it has \"recently begun training its next frontier model\" and maintains that its AI models are industry leaders in terms of capability and safety. \"We welcome a robust debate at this important moment,\" the company added.\n\nAI models are prediction systems trained on extensive datasets to produce text, images, video, and human-like conversation on demand. Frontier models represent the most advanced and powerful AI systems.\n\nThe safety committee comprises company insiders, including OpenAI chief executive Sam Altman and chairman Bret Taylor, four technical and policy experts from OpenAI, and board members Adam D'Angelo, chief executive of Quora, and Nicole Seligman, former Sony general counsel.\n\nThe committee's first task is to scrutinise and enhance OpenAI's procedures and safety measures, with plans to present its advice to the board within 90 days. OpenAI has committed to publicly disclosing the recommendations it decides to implement \"in a manner that is consistent with safety and security.\"", "source": {"uri": "mirror.co.uk", "dataType": "news", "title": "Mirror"}, "authors": [{"uri": "lawrence_matheson@mirror.co.uk", "name": "Lawrence Matheson", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 5, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 2, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 31}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 33}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 31}], "image": "https://i2-prod.mirror.co.uk/money/article32909855.ece/ALTERNATES/s1200/0_openai-new-ai-model.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.4509803921568627, "wgt": 206, "relevance": 1}
{"uri": "8149740001", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "11:46:09", "dateTime": "2024-05-28T11:46:09Z", "dateTimePub": "2024-05-28T11:45:20Z", "dataType": "news", "sim": 0.8039215803146362, "url": "https://www.nbcnewyork.com/news/business/money-report/openai-creates-oversight-team-with-sam-altman-on-board-begins-training-new-model/5452893/", "title": "OpenAI creates oversight team with Sam Altman on board, begins training new model", "body": "The formation of a new oversight team comes after OpenAI dissolved a previous team that was focused on the long-term risks of AI.\n\nOpenAI on Tuesday said it created a Safety and Security Committee led by senior executives, after disbanding its previous oversight board in mid-May.\n\nThe new committee will be responsible for making recommendations to OpenAI's board \"on critical safety and security decisions for OpenAI projects and operations,\" the company said.\n\nIt comes as the developer of the ChatGPT virtual assistant announced it has begun training its \"next frontier model.\"\n\nThe firm said in a blog post that it anticipates the \"resulting systems to bring us to the next level of capabilities on our path to AGI,\" or artificial general intelligence -- which relates to AI that is as smart or smarter than humans.\n\nThe formation of a new oversight team comes after OpenAI dissolved a previous team that was focused on the long-term risks of AI. Prior to that, both team leaders, OpenAI co-founder Ilya Sutskever and Jan Leike, announced their departures from the Microsoft-backed startup.\n\nAI safety has been at the forefront of a larger debate, as the huge models that underpin applications like ChatGPT get more advanced. AI product developers are also wondering when AGI will arrive and what risks will come with it.\n\nBret Taylor, Adam D'Angelo, Nicole Seligman, who are all on OpenAI's board of directors, now sit on the new safety committee alongside Altman.\n\nLeike this month wrote that OpenAI's \"safety culture and processes have taken a backseat to shiny products.\" In response to his departure, Altman said on social media platform X that he was sad to see Leike leave, adding that OpenAI has \"a lot more to do\"\n\nOver the next 90 days, the safety group will evaluate OpenAI's processes and safeguards and share their recommendations with the company's board. OpenAI will provide an update on the recommendations that it has adopted at a later date.", "source": {"uri": "nbcnewyork.com", "dataType": "news", "title": "NBC New York"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 2, "label": {"eng": "Virtual assistant"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 1, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 1, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Social_media", "type": "wiki", "score": 1, "label": {"eng": "Social media"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 19}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 20}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 22}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 20}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 17}], "image": "https://media.nbcnewyork.com/2024/05/107418094-1716321352537-gettyimages-2153474140-AFP_34TH9TC.jpeg?quality=85&strip=all&resize=1200%2C675", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3411764705882352, "wgt": 205, "relevance": 1}
{"uri": "8149785180", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "12:13:12", "dateTime": "2024-05-28T12:13:12Z", "dateTimePub": "2024-05-28T12:11:50Z", "dataType": "news", "sim": 0.800000011920929, "url": "https://www.chinadailyasia.com/hk/article/584309", "title": "OpenAI sets up safety committee as it starts training new model", "body": "OpenAI has formed a Safety and Security Committee which will be led by CEO Sam Altman as it begins training its next artificial intelligence model, the AI startup said on Tuesday.\n\nDirectors Bret Taylor, Adam D'Angelo and Nicole Seligman, will also lead the committee, OpenAI said on a company blog.\n\nREAD MORE: OpenAI unveils new AI model as competition heats up\n\nFormer Chief Scientist Ilya Sutskever and Jan Leike, who were leaders of Microsoft-backed OpenAI's Superalignment team, which ensured AI stays aligned to the intended objectives, left the firm earlier this month.\n\nThe committee will be responsible for making recommendations to the board on safety and security decisions for OpenAI's projects and operations\n\nOpenAI had disbanded the Superalignment team earlier in May, less than a year after the company created it, with some team members being reassigned to other groups, CNBC reported days after the high-profile departures.\n\nThe committee will be responsible for making recommendations to the board on safety and security decisions for OpenAI's projects and operations.\n\nIts first task will be to evaluate and further develop OpenAI's existing safety practices over the next 90 days, following which it will share recommendations with the board.\n\nAfter the board's review, OpenAI will publicly share an update on adopted recommendations, the company said.\n\nALSO READ: OpenAI strikes deal to bring Reddit content to ChatGPT\n\nOther committee members include the company's technical and policy experts Aleksander Madry, Lilian Weng and head of alignment sciences John Schulman. Newly appointed Chief Scientist Jakub Pachocki and head of security Matt Knight will also be on the committee.", "source": {"uri": "chinadailyasia.com", "dataType": "news", "title": "China Daily Asia"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 3, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_scientific_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief scientific officer"}}, {"uri": "http://en.wikipedia.org/wiki/CNBC", "type": "org", "score": 2, "label": {"eng": "CNBC"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 1, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Reddit", "type": "org", "score": 1, "label": {"eng": "Reddit"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 17}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 20}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 22}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 20}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 27}], "image": "https://www.chinadailyhk.com/upload/main/image/2024/05/28/f8b332fdb061ecc143653a13a2d70940.png", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3647058823529412, "wgt": 204, "relevance": 1}
{"uri": "2024-05-370789666", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "11:45:56", "dateTime": "2024-05-28T11:45:56Z", "dateTimePub": "2024-05-28T07:36:00Z", "dataType": "news", "sim": 0.7960784435272217, "url": "https://www.usnews.com/news/us/articles/2024-05-28/openai-forms-safety-committee-as-it-starts-training-latest-artificial-intelligence-model", "title": "OpenAI Forms Safety Committee as It Starts Training Latest Artificial Intelligence Model", "body": "OpenAI says it's setting up a new safety and security committee and has begun training a new artificial intelligence model to supplant the GPT-4 system that underpins its ChatGPT chatbot.\n\nThe San Francisco startup said in a blog post Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations.\n\nThe safety committee arrives as debate swirls around AI safety at the company, which was thrust into the spotlight after a researcher, Jan Leike, resigned and leveled criticism at OpenAI for letting safety \"take a backseat to shiny products.\"\n\nOpenAI said it has \"recently begun training its next frontier model\" and its AI models lead the industry on capability and safety, though it made no mention of the controversy. \"We welcome a robust debate at this important moment,\" the company said.\n\nAI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting edge AI systems.\n\nMembers of the the safety committee include OpenAI CEO Sam Altman and Chairman Bret Taylor, along with two other board members, Adam D'Angelo, who's the CEO of Quora, and Nicole Seligman, a former Sony general counsel. OpenAI said four company technical and policy experts are also members.\n\nThe committee's first job will be to evaluate and further develop OpenAI's processes and safeguards and make its recommendations to the board in 90 days. The company said it will then publicly release the recommendations it's adopting \"in a manner that is consistent with safety and security.\"\n\nCopyright 2024 The Associated Press. All rights reserved. This material may not be published, broadcast, rewritten or redistributed.", "source": {"uri": "usnews.com", "dataType": "news", "title": "U.S. News & World Report"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 2, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Associated_Press", "type": "org", "score": 1, "label": {"eng": "Associated Press"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 31}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 35}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 28}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 31}, {"uri": "news/Business", "label": "news/Business", "wgt": 51}], "image": "https://www.usnews.com/dims4/USNEWS/a566f19/2147483647/thumbnail/970x647/quality/85/?url=https%3A%2F%2Fwww.usnews.com%2Fcmsmedia%2F70%2Fa2938964cc65a315f257a5cdd1a08d%2Fae7dab0bf3144de8a63e2f146a664d4cOpenAI_New_AI_Model_13983.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.4274509803921569, "wgt": 203, "relevance": 1}
{"uri": "8149937457", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "13:45:11", "dateTime": "2024-05-28T13:45:11Z", "dateTimePub": "2024-05-28T13:44:27Z", "dataType": "news", "sim": 0.7843137383460999, "url": "https://www.businesstelegraph.co.uk/openai-creates-oversight-team-with-sam-altman-on-board-begins-training-new-model/", "title": "OpenAI creates oversight team with Sam Altman on board, begins training new model - Business Telegraph", "body": "OpenAI CEO Sam Altman speaks during the Microsoft Build conference at Microsoft headquarters in Redmond, Washington, on May 21, 2024.\n\nJason Redmond | AFP | Getty Images\n\nOpenAI on Tuesday said it created a safety and security committee led by senior executives, after disbanding its previous oversight board in mid-May.\n\nThe new committee will be responsible for recommending to OpenAI's board \"critical safety and security decisions for OpenAI projects and operations,\" the company said.\n\nNews of the new committee comes as the developer of the ChatGPT virtual assistant announced that it has begun training its \"next frontier model.\"\n\nThe firm said in a blog post that it anticipates the \"resulting systems to bring us to the next level of capabilities on our path to AGI,\" or artificial general intelligence, a kind of AI that is as smart or smarter than humans.\n\nIn addition to Altman, the safety committee will consist of Bret Taylor, Adam D'Angelo and Nicole Seligman, all members of OpenAI's board of directors, according to the blog post.\n\nThe formation of a new oversight team comes after OpenAI dissolved a previous team that focused on the long-term risks of AI. Before that, both team leaders, OpenAI co-founder Ilya Sutskever and key researcher Jan Leike, announced their departures from the Microsoft-backed startup.\n\nLeike earlier this month wrote that OpenAI's \"safety culture and processes have taken a backseat to shiny products.\" In response to his departure, Altman said on social media platform X that he was sad to see Leike leave, adding that OpenAI has \"a lot more to do.\"\n\nOver the next 90 days, the safety group will evaluate OpenAI's processes and safeguards and share their recommendations with the company's board, the blog post said. OpenAI will provide an update on the recommendations that it has adopted at a later date.\n\nAI safety has been at the forefront of a larger debate, as the huge models that underpin applications like ChatGPT get more advanced. AI product developers also wonder when AGI will arrive and what risks will accompany it.\n\n-- CNBC's Hayden Field contributed to this report.\n\nDon't miss these exclusives from CNBC PRO\n\nREAD SOURCE", "source": {"uri": "businesstelegraph.co.uk", "dataType": "news", "title": "Business Telegraph"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 5, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Redmond,_Washington", "type": "loc", "score": 5, "label": {"eng": "Redmond, Washington"}, "location": {"type": "place", "label": {"eng": "Redmond, Washington"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 2, "label": {"eng": "Virtual assistant"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 1, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 1, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/CNBC", "type": "org", "score": 1, "label": {"eng": "CNBC"}}, {"uri": "http://en.wikipedia.org/wiki/Agence_France-Presse", "type": "wiki", "score": 1, "label": {"eng": "Agence France-Presse"}}, {"uri": "http://en.wikipedia.org/wiki/Social_media", "type": "wiki", "score": 1, "label": {"eng": "Social media"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 18}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 20}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 21}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 16}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 19}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 57}], "image": "https://www.businesstelegraph.co.uk/wp-content/uploads/2024/05/OpenAI-creates-oversight-team-with-Sam-Altman-on-board-begins.jpeg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3176470588235294, "wgt": 200, "relevance": 1}
{"uri": "8150087518", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "15:21:51", "dateTime": "2024-05-28T15:21:51Z", "dateTimePub": "2024-05-28T15:21:20Z", "dataType": "news", "sim": 0.7843137383460999, "url": "https://www.nbcnews.com/tech/tech-news/openai-training-new-model-surpass-gpt-4-pursues-artificial-general-int-rcna154301", "title": "OpenAI is training a new model to surpass GPT-4 as it pursues 'artificial general intelligence'", "body": "Sam Altman during the Microsoft Build conference in Redmond, Wash., on May 21, 2024.Jason Redmond / AFP - Getty Images\n\nOpenAI on Tuesday said it created a safety and security committee led by senior executives, after disbanding its previous oversight board in mid-May.\n\nThe new committee will be responsible for recommending to OpenAI's board \"critical safety and security decisions for OpenAI projects and operations,\" the company said.\n\nNews of the new committee comes as the developer of the ChatGPT virtual assistant announced that it has begun training its \"next frontier model.\"\n\nThe firm said in a blog post that it anticipates the \"resulting systems to bring us to the next level of capabilities on our path to AGI,\" or artificial general intelligence, a kind of AI that is as smart or smarter than humans.\n\nIn addition to CEO Sam Altman, the safety committee will consist of Bret Taylor, Adam D'Angelo and Nicole Seligman, all members of OpenAI's board of directors, according to the blog post.\n\nThe formation of a new oversight team comes after OpenAI dissolved a previous team that focused on the long-term risks of AI. Before that, both team leaders, OpenAI co-founder Ilya Sutskever and key researcher Jan Leike, announced their departures from the Microsoft-backed startup.\n\nLeike earlier this month wrote that OpenAI's \"safety culture and processes have taken a backseat to shiny products.\" In response to his departure, Altman said on social media platform X that he was sad to see Leike leave, adding that OpenAI has \"a lot more to do.\"\n\nOver the next 90 days, the safety group will evaluate OpenAI's processes and safeguards and share their recommendations with the company's board, the blog post said. OpenAI will provide an update on the recommendations that it has adopted at a later date.\n\nAI safety has been at the forefront of a larger debate, as the huge models that underpin applications like ChatGPT get more advanced. AI product developers also wonder when AGI will arrive and what risks will accompany it.", "source": {"uri": "nbcnews.com", "dataType": "news", "title": "NBC News"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Redmond,_Washington", "type": "loc", "score": 5, "label": {"eng": "Redmond, Washington"}, "location": {"type": "place", "label": {"eng": "Redmond, Washington"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 4, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 3, "label": {"eng": "Virtual assistant"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 3, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Washington_(state)", "type": "loc", "score": 3, "label": {"eng": "Washington (state)"}, "location": {"type": "place", "label": {"eng": "Washington (state)"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 1, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 1, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Agence_France-Presse", "type": "wiki", "score": 1, "label": {"eng": "Agence France-Presse"}}, {"uri": "http://en.wikipedia.org/wiki/Social_media", "type": "wiki", "score": 1, "label": {"eng": "Social media"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 19}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 21}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 23}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 21}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 18}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 57}], "image": "https://media-cldnry.s-nbcnews.com/image/upload/t_nbcnews-fp-1024-512,f_auto,q_auto:best/rockcms/2024-05/240528-sam-altman-al-1105-538fb9.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3019607843137255, "wgt": 200, "relevance": 1}
{"uri": "8150494381", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "20:52:47", "dateTime": "2024-05-28T20:52:47Z", "dateTimePub": "2024-05-28T20:52:02Z", "dataType": "news", "sim": 0.7843137383460999, "url": "https://www.unite.ai/openai-forms-safety-council-trains-next-gen-ai-model-amid-controversies/", "title": "OpenAI Forms Safety Council, Trains Next-Gen AI Model Amid Controversies", "body": "OpenAI has made significant strides in advancing artificial intelligence technologies, with its most recent achievement being the GPT-4o system that powers the popular ChatGPT chatbot. Today, OpenAI announced the establishment of a new safety committee, the OpenAI Safety Council, and revealed that it has begun training a new AI model.\n\nThe newly formed OpenAI Safety Council aims to provide guidance and oversight on critical safety and security decisions related to the company's projects and operations. The council's primary objective is to ensure that OpenAI's AI development practices prioritize safety and align with ethical principles. The safety committee comprises a diverse group of individuals, including OpenAI executives, board members, and technical and policy experts.\n\nNotable members of the OpenAI Safety Council include:\n\nIn its initial phase, the new safety and security committee will focus on evaluating and strengthening OpenAI's existing safety processes and safeguards. The OpenAI Safety Council has set a 90-day timeline to provide recommendations to the board on how to enhance the company's AI development practices and safety systems. Once the recommendations are adopted, OpenAI plans to publicly release them in a manner consistent with safety and security considerations.\n\nIn parallel with the establishment of the OpenAI Safety Council, OpenAI has announced that it has begun training its next frontier model. This latest artificial intelligence model is expected to surpass the capabilities of the GPT-4 system currently underpinning ChatGPT. While details about the new AI model remain scarce, OpenAI has said that it will lead the industry in both capability and safety.\n\nThe development of this new AI model underscores the rapid pace of innovation in the field of artificial intelligence and the potential for artificial general intelligence (AGI). As AI systems become more advanced and powerful, it is crucial to prioritize safety and ensure that these technologies are developed responsibly.\n\nOpenAI's renewed focus on safety comes amidst a period of internal turmoil and public scrutiny. In recent weeks, the company has faced criticism from within its own ranks, with researcher Jan Leike resigning and expressing concerns that safety had taken a backseat to the development of \"shiny products.\" Leike's resignation was followed by the departure of Ilya Sutskever, OpenAI's co-founder and chief scientist.\n\nThe departures of Leike and Sutskever have raised questions about the company's priorities and its approach to AI safety. The two researchers jointly led OpenAI's \"superalignment\" team, which was dedicated to addressing long-term AI risks. Following their resignations, the superalignment team was disbanded, further fueling concerns about the company's commitment to safety.\n\nIn addition to the internal upheaval, OpenAI has also faced allegations of voice impersonation in its ChatGPT chatbot. Some users have claimed that the chatbot's voice bears a striking resemblance to that of actress Scarlett Johansson. While OpenAI has denied intentionally impersonating Johansson, the incident has sparked a broader conversation about the ethical implications of AI-generated content and the potential for misuse.\n\nAs the field of artificial intelligence continues to evolve rapidly, it is crucial for companies like OpenAI to engage in ongoing dialogue and collaboration with researchers, policymakers, and the public to ensure that AI technologies are developed responsibly and with robust safeguards in place. The recommendations put forth by the OpenAI Safety Council and OpenAI's commitment to transparency will contribute to the broader conversation on AI governance and help shape the future of this transformative technology, but only time will tell what will come out of it.", "source": {"uri": "unite.ai", "dataType": "news", "title": "Unite.AI"}, "authors": [{"uri": "alex_mcfarland@unite.ai", "name": "Alex McFarland", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 2, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 1, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 33}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 37}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 38}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 34}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 40}], "image": "https://www.unite.ai/wp-content/uploads/2024/05/Alex_Mc_a_safety_council_sitting_around_a_table_with_technolo_f6e2b178-43ff-4f38-bc36-4e448328c4f5_1.png", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.6549019607843136, "wgt": 200, "relevance": 1}
{"uri": "8149949025", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "13:52:18", "dateTime": "2024-05-28T13:52:18Z", "dateTimePub": "2024-05-28T13:51:38Z", "dataType": "news", "sim": 0.7803921699523926, "url": "https://www.mediapost.com/publications/article/396371/openai-trains-new-ai-model-in-quest-to-reach-agi.html", "title": "OpenAI Trains New AI Model In Quest To Reach AGI, Develops Safety Board", "body": "OpenAI said Tuesday it has begun training its next AI model to succeed the one powering ChatGPT, and anticipates that the systems will bring the company to the next level of capabilities in artificial general intelligence (AGI).\n\nAGI follows the path of supercomputing -- something that OpenAI at one time was not interested in creating. The software aims to perform any intellectual task that a human can, including tasks it was not trained to do.\n\nThe company also formed a committee to make recommendations to the company's board about safety and security, just weeks after dissolving a team focused on AI safety.\n\n\"A first task of the Safety and Security Committee will be to evaluate and further develop OpenAI's processes and safeguards over the next 90 days,\" the blog post said.\n\nOpenAI said that at the end of the 90 days, the Safety and Security Committee will share their recommendations with the full Board.\n\n\"Following the full Board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security,\" the post explained.\n\nOpenAI CEO Sam Altman will lead the new committee with board chair Bret Taylor, and board member Nicole Seligman, the company said in a blog post.\n\nThe announcement follows the announcement in May by Jan Leike, an OpenAI executive focused on safety, that he would leave the company. Leike criticized and resigned from OpenAI for underinvested in AI safety.\n\n\"To all OpenAI employees, I want to say: Learn to feel the AGI. Act with the gravitas appropriate for what you're building,\" Leike wrote on X. \"I believe you can 'ship' the cultural change that's needed. I am counting on you.\"\n\nA new safety board also comes after the departure of Ilya Sutskever who focused on ensuring that AI development serves human needs. Sutskever was part of ousting Altman last year, before reversing his support for his return.", "source": {"uri": "mediapost.com", "dataType": "news", "title": "MediaPost"}, "authors": [{"uri": "laurie_sullivan@mediapost.com", "name": "Laurie Sullivan", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Supercomputer", "type": "wiki", "score": 3, "label": {"eng": "Supercomputer"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 2, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 24}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 29}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 32}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 29}], "image": "https://s3.amazonaws.com/media.mediapost.com/dam/cropped/2023/11/20/samaltman-600_C2AIlR9.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.419607843137255, "wgt": 199, "relevance": 1}
{"uri": "8149643235", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "10:47:14", "dateTime": "2024-05-28T10:47:14Z", "dateTimePub": "2024-05-28T10:46:02Z", "dataType": "news", "sim": 0.7803921699523926, "url": "https://www.hindustantimes.com/business/openai-sets-up-safety-and-security-committee-featuring-sam-altman-after-row-101716892104702.html", "title": "OpenAI sets up Safety and Security Committee featuring Sam Altman after row", "body": "Read more: Scarlett Johansson vs OpenAI: Actor hired lawyers to push back against Sam Altman company. Here's why\n\n\"Following the full board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security,\" the company said in a blog post.\n\nWorries around how OpenAI's technology could have potential dangers intensified when company's CEO Sam Altman was briefly ousted after clashing with co-founder and chief scientist Ilya Sutskever over how quickly to develop AI products.\n\nIlya Sutskever and a key deputy, Jan Leike, left the company this month. Both of them ran OpenAI's so-called superalignment team- focused on long-term threats of AI. Jan Leike said that his division was \"struggling\" for computing resources within OpenAI.\n\nOpenAI's new safety committee will consist of three board members -- Chairman Bret Taylor, Quora CEO Adam D'Angelo and ex-Sony Entertainment executive Nicole Seligman -- along with six employees, including Sam Altman. The company said it would continue to consult two outside experts,: Rob Joyce, a Homeland Security adviser to Donald Trump and John Carlin, a former Justice Department official under President Joe Biden.", "source": {"uri": "hindustantimes.com", "dataType": "news", "title": "Hindustan Times"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 4, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 3, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Scarlett_Johansson", "type": "person", "score": 3, "label": {"eng": "Scarlett Johansson"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Joe_Biden", "type": "person", "score": 1, "label": {"eng": "Joe Biden"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Homeland_Security", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Homeland Security"}}, {"uri": "http://en.wikipedia.org/wiki/Donald_Trump", "type": "person", "score": 1, "label": {"eng": "Donald Trump"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 14}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 13}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 14}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 13}, {"uri": "dmoz/Computers/Security/Advisories_and_Patches", "label": "dmoz/Computers/Security/Advisories and Patches", "wgt": 13}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 51}], "image": "https://www.hindustantimes.com/ht-img/img/2024/05/28/1600x900/TOPSHOT-US-TECHNOLOGY-AI-MICROSOFT-COMPUTERS-1_1716523916049_1716892452976.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.1058823529411765, "wgt": 199, "relevance": 1}
{"uri": "8149784178", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "12:12:00", "dateTime": "2024-05-28T12:12:00Z", "dateTimePub": "2024-05-28T12:11:12Z", "dataType": "news", "sim": 0.7803921699523926, "url": "https://www.dailymail.co.uk/wires/ap/article-13467377/OpenAI-forms-safety-committee-starts-training-latest-artificial-intelligence-model.html", "title": "OpenAI forms safety committee as it starts training latest...", "body": "OpenAI says it's setting up a new safety and security committee and has begun training a new artificial intelligence model to supplant the GPT-4 system that underpins its ChatGPT chatbot.\n\nThe San Francisco startup said in a blog post Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations.\n\nThe safety committee arrives as debate swirls around AI safety at the company, which was thrust into the spotlight after a researcher, Jan Leike, resigned and leveled criticism at OpenAI for letting safety \"take a backseat to shiny products.\"\n\nOpenAI said it has \"recently begun training its next frontier model\" and its AI models lead the industry on capability and safety, though it made no mention of the controversy. \"We welcome a robust debate at this important moment,\" the company said.\n\nAI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting edge AI systems.\n\nMembers of the the safety committee include OpenAI CEO Sam Altman and Chairman Bret Taylor, along with two other board members, Adam D'Angelo, who's the CEO of Quora, and Nicole Seligman, a former Sony general counsel. OpenAI said four company technical and policy experts are also members.\n\nFILE - The OpenAI logo is seen displayed on a cell phone with an image on a computer monitor generated by ChatGPT's Dall-E text-to-image model, Friday, Dec. 8, 2023, in Boston. OpenAI says it's setting up a new safety and security committee and has begun training a new artificial intelligence model to supplant the GPT-4 system that underpins its ChatGPT chatbot. The San Francisco startup said in a blog post Tuesday May 28, 2024 that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations. (AP Photo/Michael Dwyer, File)\n\nThe committee's first job will be to evaluate and further develop OpenAI\u00b4s processes and safeguards and make its recommendations to the board in 90 days. The company said it will then publicly release the recommendations it's adopting \"in a manner that is consistent with safety and security.\"", "source": {"uri": "dailymail.co.uk", "dataType": "news", "title": "Daily Mail Online"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 3, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 2, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 2, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Text-to-image_model", "type": "wiki", "score": 1, "label": {"eng": "Text-to-image model"}}, {"uri": "http://en.wikipedia.org/wiki/Associated_Press", "type": "org", "score": 1, "label": {"eng": "Associated Press"}}, {"uri": "http://en.wikipedia.org/wiki/Mobile_phone", "type": "wiki", "score": 1, "label": {"eng": "Mobile phone"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}, {"uri": "http://en.wikipedia.org/wiki/Boston", "type": "loc", "score": 1, "label": {"eng": "Boston"}, "location": {"type": "place", "label": {"eng": "Boston"}, "country": {"type": "country", "label": {"eng": "United States"}}}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 31}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 34}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 30}, {"uri": "news/Business", "label": "news/Business", "wgt": 51}], "image": "https://i.dailymail.co.uk/1s/2024/05/28/12/wire-85419183-1716896452-416_636x382.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3411764705882352, "wgt": 199, "relevance": 1}
{"uri": "2024-05-371228244", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "18:44:15", "dateTime": "2024-05-28T18:44:15Z", "dateTimePub": "2024-05-28T16:18:00Z", "dataType": "news", "sim": 0.7764706015586853, "url": "https://ca.finance.yahoo.com/news/openai-announces-safety-board-angering-161800754.html", "title": "OpenAI announces new safety board after angering employees by dismantling the old one", "body": "Weeks after he dismantled the OpenAI team focused on AI safety, CEO Sam Altman says he will lead a new team with the same charge.\n\nThe company, in a blog post Monday, announced the formation of the Safety and Security Committee, which it says will be responsible for making recommendations on critical safety and security decisions for all OpenAI projects.\n\nThe announcement follows the exit earlier this month of several key members of the safety committee, including cofounder Ilya Sutskever and Jan Leike. Leike was especially critical of OpenAI in his departure, accusing the company of neglecting \"safety culture and processes\" in favor of \"shiny products.\" He chose to depart the company, he said, because he has \"been disagreeing with OpenAI leadership about the company's core priorities for quite some time, until we finally reached a breaking point.\"\n\nGiven those criticisms, Altman's oversight of the safety committee could be scrutinized. Joining him will be directors Bret Taylor (who is chairman of the board), Adam D'Angelo, and Nicole Seligman.\n\n\"A first task of the Safety and Security Committee will be to evaluate and further develop OpenAI's processes and safeguards over the next 90 days,\" the company wrote. \"At the conclusion of the 90 days, the Safety and Security Committee will share their recommendations with the full Board. Following the full Board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security.\"\n\nThe blog post also revealed OpenAI is in the process of training its \"next frontier model,\" a successor to the one that currently drives ChatGPT, saying \"we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI.\"\n\nNews of the new safety committee comes less than 10 days after OpenAI dissolved the \"Superalignment\" team, folding remaining members into broader research efforts at the company. Leike and Sutskever were the lead members of that superalignment team.", "source": {"uri": "ca.finance.yahoo.com", "dataType": "news", "title": "Yahoo! Finance"}, "authors": [{"uri": "chris_morris@ca.finance.yahoo.com", "name": "Chris Morris", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 3, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 2, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 1, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 28}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 33}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 33}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 30}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 34}], "image": "https://s.yimg.com/ny/api/res/1.2/yDK6o_RiC0BKwHq2YVqAtw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/fortune_175/a5e2b987d5d9bbac3c86d7bc69346a1a", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.2078431372549019, "wgt": 198, "relevance": 1}
{"uri": "8150067416", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "15:08:32", "dateTime": "2024-05-28T15:08:32Z", "dateTimePub": "2024-05-28T15:08:07Z", "dataType": "news", "sim": 0.7764706015586853, "url": "https://www.businesslive.co.za/bd/companies/2024-05-28-openai-sets-up-safety-committee-as-it-starts-training-new-model/", "title": "OpenAI sets up safety committee as it starts training new model", "body": "OpenAI has formed a safety and security committee that will be led by board members, including CEO Sam Altman, as it begins training its next artificial intelligence model, the AI start-up says.\n\nDirectors Bret Taylor, Adam D'Angelo and Nicole Seligman will also lead the committee, OpenAI said on a company blog.\n\nMicrosoft-backed OpenAI's chatbots with generative AI capabilities, such as engaging in human-like conversations and creating images based on text prompts, have stirred safety concerns as AI models become powerful.\n\nFormer chief scientist Ilya Sutskever and Jan Leike, who were leaders of OpenAI's Superalignment team, which ensured AI stays aligned to the intended objectives, left the firm earlier this month.\n\nOpenAI had disbanded the Superalignment team earlier in May, less than a year after the company created it, with some team members being reassigned to other groups, CNBC reported days after the high-profile departures.\n\nThe new committee will be responsible for making recommendations to the board on safety and security decisions for OpenAI's projects and operations. Its first task will be to evaluate and further develop OpenAI's existing safety practices over the next 90 days, after which it will share recommendations with the board.\n\nAfter the board's review, OpenAI would publicly share an update on adopted recommendations, the company said.\n\nOthers on the committee include newly appointed chief scientist Jakub Pachocki and Matt Knight, head of security.\n\nThe company will consult other experts, including Rob Joyce, a former US national security agency cybersecurity director and John Carlin, a former department of justice official.\n\nOpenAI did not provide further details on the new \"frontier\" model it is training, except that it would bring its systems to the \"next level of capabilities on our path to AGI\".\n\nEarlier in May, it announced a new AI model capable of realistic voice conversation and interaction across text and images.", "source": {"uri": "businesslive.co.za", "dataType": "news", "title": "BusinessLIVE"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Nicole_Seligman", "type": "person", "score": 3, "label": {"eng": "Nicole Seligman"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/CNBC", "type": "org", "score": 2, "label": {"eng": "CNBC"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 1, "label": {"eng": "Computer security"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 21}, {"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 20}, {"uri": "dmoz/Recreation/Models/Scale", "label": "dmoz/Recreation/Models/Scale", "wgt": 19}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 24}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 20}], "image": "https://lh3.googleusercontent.com/bDpcV7YLL5k8luILd5O3e6curNfHlfjvUSjsyNTcpMz36bdOnolR782mFZT74zo3ahJyFrRcCAYl9dNUV8umqeYJpv6aa42wUSpzx6X1kdIPiQ=s1000", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.388235294117647, "wgt": 198, "relevance": 1}
{"uri": "8149857536", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "12:57:01", "dateTime": "2024-05-28T12:57:01Z", "dateTimePub": "2024-05-28T12:56:13Z", "dataType": "news", "sim": 0.7764706015586853, "url": "https://sg.news.yahoo.com/openai-sets-safety-security-committee-101035488.html", "title": "OpenAI sets up safety committee as it starts training new model", "body": "(Reuters) -OpenAI has formed a Safety and Security Committee that will be led by board members, including CEO Sam Altman, as it begins training its next artificial intelligence model, the AI startup said on Tuesday.\n\nDirectors Bret Taylor, Adam D'Angelo and Nicole Seligman will also lead the committee, OpenAI said on a company blog.\n\nMicrosoft-backed OpenAI's chatbots with generative AI capabilities, such as engaging in human-like conversations and creating images based on text prompts, have stirred safety concerns as AI models become powerful.\n\nFormer Chief Scientist Ilya Sutskever and Jan Leike, who were leaders of OpenAI's Superalignment team, which ensured AI stays aligned to the intended objectives, left the firm earlier this month.\n\nOpenAI had disbanded the Superalignment team earlier in May, less than a year after the company created it, with some team members being reassigned to other groups, CNBC reported days after the high-profile departures.\n\nThe new committee will be responsible for making recommendations to the board on safety and security decisions for OpenAI's projects and operations.\n\nIts first task will be to evaluate and further develop OpenAI's existing safety practices over the next 90 days, following which it will share recommendations with the board.\n\nAfter the board's review, OpenAI will publicly share an update on adopted recommendations, the company said.\n\nOthers on the committee include newly appointed Chief Scientist Jakub Pachocki and Matt Knight, head of security.\n\nThe company will also consult other experts, including Rob Joyce, a former U.S. National Security Agency cybersecurity director and John Carlin, a former Department of Justice official.\n\nOpenAI did not provide further details on the new \"frontier\" model it is training, except that it would bring its systems to the \"next level of capabilities on our path to AGI.\"\n\nEarlier in May, it announced a new AI model capable of realistic voice conversation and interaction across text and image.", "source": {"uri": "sg.news.yahoo.com", "dataType": "news", "title": "Yahoo News"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/CNBC", "type": "org", "score": 2, "label": {"eng": "CNBC"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/National_Security_Agency", "type": "wiki", "score": 1, "label": {"eng": "National Security Agency"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 1, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Reuters", "type": "wiki", "score": 1, "label": {"eng": "Reuters"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 21}, {"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 19}, {"uri": "dmoz/Recreation/Models/Scale", "label": "dmoz/Recreation/Models/Scale", "wgt": 19}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 24}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 20}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 56}], "image": "https://media.zenfs.com/en/reuters.com/d131c5dcfe2f5518b10e7360853a22ad", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3960784313725489, "wgt": 198, "relevance": 1}
{"uri": "8149932729", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "13:42:03", "dateTime": "2024-05-28T13:42:03Z", "dateTimePub": "2024-05-28T13:41:29Z", "dataType": "news", "sim": 0.7764706015586853, "url": "https://beebom.com/openai-training-next-frontier-model-gpt-5/", "title": "OpenAI Starts Training Its Next Frontier Model; Is GPT-5 Coming?", "body": "In view of this, the company has formed a Safety and Security committee that will look into critical safety and security decisions.\n\nOpenAI has been mired in controversies recently. After Ilya Sutskever, chief scientist at OpenAI left the company, Jan Leike, the superalignment head at OpenAI, also resigned after reaching a \"breaking point\" with the leadership over compute for safety research. Now, to allay the fear over safety concerns, OpenAI has formed a Safety and Security committee.\n\n\"This new committee is responsible for making recommendations on critical safety and security decisions for all OpenAI projects\", says OpenAI in its blog. Along with that, OpenAI reveals that it \"has recently begun training its next frontier model.\"\n\nOpenAI says that the next frontier model (unlikely to be called GPT-5) will redefine the boundary of AI capabilities and the company is anticipating that \"the resulting systems to bring us to the next level of capabilities on our path to AGI.\"\n\nPrior to this announcement, during the ChatGPT 4o launch, OpenAI CTO, Mira Murati said that the next big thing is coming, at the tail end of the event. And it seems OpenAI is looking to release its next frontier model sometime in 2024 itself.\n\nAs for the Safety and Security committee, it includes Sam Altman, Bret Taylor, Adam D'Angelo, and Nicole Seligman. Besides that, technical members from OpenAI will also be part of the committee. Over the next 90 days, the committee shall evaluate the upcoming models and share the recommendations with the OpenAI board.\n\nBesides that, it must be noted that OpenAI recently removed the 'Sky' voice from ChatGPT which sounded eerily similar to Scarlett Johansson's voice in the movie 'Her'. OpenAI might be looking into a potential lawsuit amid growing concerns over the company's ethical practices, led by CEO Sam Altman.", "source": {"uri": "beebom.com", "dataType": "news", "title": "Beebom"}, "authors": [{"uri": "arjun_sha@beebom.com", "name": "Arjun Sha", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 3, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Mira_Murati", "type": "wiki", "score": 1, "label": {"eng": "Mira Murati"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 1, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_technology_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief technology officer"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 1, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 24}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 26}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 22}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 24}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 22}], "image": "https://beebom.com/wp-content/uploads/2024/03/openai-gpt-4.5-turbo.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3019607843137255, "wgt": 198, "relevance": 1}
{"uri": "8149741955", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "11:47:23", "dateTime": "2024-05-28T11:47:23Z", "dateTimePub": "2024-05-28T11:46:37Z", "dataType": "news", "sim": 0.772549033164978, "url": "https://abcnews.go.com/Business/wireStory/openai-forms-safety-committee-starts-training-latest-artificial-110604354", "title": "OpenAI forms safety committee as it starts training latest artificial intelligence model", "body": "OpenAI says it's setting up a new safety and security committee and has begun training a new artificial intelligence model to supplant the GPT-4 system that underpins its ChatGPT chatbot\n\nOpenAI says it's setting up a new safety and security committee and has begun training a new artificial intelligence model to supplant the GPT-4 system that underpins its ChatGPT chatbot.\n\nThe San Francisco startup said in a blog post Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations.\n\nThe safety committee arrives as debate swirls around AI safety at the company, which was thrust into the spotlight after a researcher, Jan Leike, resigned and leveled criticism at OpenAI for letting safety \"take a backseat to shiny products.\"\n\nOpenAI said it has \"recently begun training its next frontier model\" and its AI models lead the industry on capability and safety, though it made no mention of the controversy. \"We welcome a robust debate at this important moment,\" the company said.\n\nAI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting edge AI systems.\n\nMembers of the the safety committee include OpenAI CEO Sam Altman and Chairman Bret Taylor, along with two other board members, Adam D'Angelo, who's the CEO of Quora, and Nicole Seligman, a former Sony general counsel. OpenAI said four company technical and policy experts are also members.\n\nThe committee's first job will be to evaluate and further develop OpenAI's processes and safeguards and make its recommendations to the board in 90 days. The company said it will then publicly release the recommendations it's adopting \"in a manner that is consistent with safety and security.\"", "source": {"uri": "abcnews.go.com", "dataType": "news", "title": "ABC News"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 4, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 4, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 2, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 31}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 35}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 30}, {"uri": "news/Business", "label": "news/Business", "wgt": 46}], "image": "https://i.abcnewsfe.com/a/b4e00292-324e-4f80-aa37-907860887b1e/wirestory_6c5e6d6cae4db45c45cf9f6788fd8901_16x9.jpg?w=1600", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3960784313725489, "wgt": 197, "relevance": 1}
{"uri": "8150166658", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "16:17:38", "dateTime": "2024-05-28T16:17:38Z", "dateTimePub": "2024-05-28T16:14:39Z", "dataType": "news", "sim": 0.772549033164978, "url": "https://exbulletin.com/tech/2718835/", "title": "OpenAI forms new surveillance team, begins training next generation models - ExBulletin", "body": "OpenAI CEO Sam Altman speaks at the Microsoft Build conference at Microsoft headquarters in Redmond, Washington on May 21, 2024.\n\nJason Redmond | AFP | Getty Images\n\nOpenAI said on Tuesday it had established a safety and security committee led by senior executives after dissolving its previous oversight committee in mid-May.\n\nAccording to the company, the new committee will be responsible for recommending to OpenAI's board of directors \"significant safety and security decisions regarding OpenAI's projects and operations.\"\n\nNews of the new committee comes at the same time that the developers of the ChatGPT virtual assistant announced they have begun training their \"next frontier model.\"\n\n\"The resulting system will take us to the next level on the journey towards AGI (artificial general intelligence), a type of AI with intelligence equal to or greater than that of humans,\" the company said in a blog post.\n\nAccording to the blog post, the safety committee will be made up of Altman, as well as OpenAI board members Brett Taylor, Adam D'Angelo and Nicole Seligman.\n\nThe formation of the new oversight team comes after OpenAI disbanded a previous team focused on long-term risks to AI after both team leaders, OpenAI co-founder Ilya Sutskever and principal researcher Jan Reicke, announced they were leaving the Microsoft-backed startup.\n\nReicke wrote earlier this month that OpenAI's \"safety culture and process have taken a back seat to a flashy product.\" Following Reicke's resignation, Altman said on social media platform X that he was sad to see Reicke leave, adding that OpenAI \"still has a lot of work to do.\"\n\nOver the next 90 days, the safety group will evaluate OpenAI's processes and safety measures and share its recommendations with the company's board of directors, according to the blog post. OpenAI will provide an update on which recommendations it has adopted at a later date.\n\nAs the massive models that underpin applications like ChatGPT evolve, AI safety has come to the forefront of a major debate, with developers of AI products also wondering when AGI will arrive and what the risks are.\n\nWhat Are The Main Benefits Of Comparing Car Insurance Quotes Online", "source": {"uri": "exbulletin.com", "dataType": "news", "title": "ExBulletin"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 5, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Redmond,_Washington", "type": "loc", "score": 5, "label": {"eng": "Redmond, Washington"}, "location": {"type": "place", "label": {"eng": "Redmond, Washington"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 2, "label": {"eng": "Virtual assistant"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 1, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 1, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Research", "type": "wiki", "score": 1, "label": {"eng": "Research"}}, {"uri": "http://en.wikipedia.org/wiki/Agence_France-Presse", "type": "wiki", "score": 1, "label": {"eng": "Agence France-Presse"}}, {"uri": "http://en.wikipedia.org/wiki/Social_media", "type": "wiki", "score": 1, "label": {"eng": "Social media"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 22}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 25}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 21}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 24}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 55}], "image": "https://image.cnbcfm.com/api/v1/image/107418094-1716321352537-gettyimages-2153474140-AFP_34TH9TC.jpeg?v=1716321508&w=1920&h=1080", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3333333333333333, "wgt": 197, "relevance": 1}
{"uri": "2024-05-371078695", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "15:57:59", "dateTime": "2024-05-28T15:57:59Z", "dateTimePub": "2024-05-28T15:57:54Z", "dataType": "news", "sim": 0.772549033164978, "url": "https://www.carriermanagement.com/news/2024/05/28/262521.htm", "title": "OpenAI Forms New Safety Committee", "body": "OpenAI has formed a Safety and Security Committee that will be led by board members, including CEO Sam Altman, as it begins training its next artificial intelligence model, the AI startup said on Tuesday.\n\nDirectors Bret Taylor, Adam D'Angelo and Nicole Seligman will also lead the committee, OpenAI said on a company blog.\n\nMicrosoft-backed OpenAI's chatbots with generative AI capabilities, such as engaging in human-like conversations and creating images based on text prompts, have stirred safety concerns as AI models become powerful.\n\nThe new committee will be responsible for making recommendations to the board on safety and security decisions for OpenAI's projects and operations.\n\n\"A new safety committee signifies OpenAI completing a move to becoming a commercial entity, from a more undefined non-profit-like entity,\" said D.A. Davidson managing director Gil Luria.\n\n\"That should help streamline product development while maintaining accountability.\"\n\nFormer Chief Scientist Ilya Sutskever and Jan Leike, who were leaders of OpenAI's Superalignment team, which ensured AI stays aligned to the intended objectives, left the firm earlier this month.\n\nOpenAI had disbanded the Superalignment team, earlier in May, less than a year after the company created it, with some team members being reassigned to other groups, CNBC reported days after the high-profile departures.\n\nThe committee's first task will be to evaluate and further develop OpenAI's existing safety practices over the next 90 days, following which it will share recommendations with the board.\n\nAfter the board's review, OpenAI will publicly share an update on adopted recommendations, the company said.\n\nOthers on the committee include newly appointed Chief Scientist Jakub Pachocki and Matt Knight, head of security.\n\nThe company will also consult other experts, including Rob Joyce, a former U.S. National Security Agency cybersecurity director and John Carlin, a former Department of Justice official.\n\nOpenAI did not provide further details on the new \"frontier\" model it is training, except that it would bring its systems to the \"next level of capabilities on our path to AGI.\"\n\nEarlier in May, it announced a new AI model capable of realistic voice conversation and interaction across text and image.", "source": {"uri": "carriermanagement.com", "dataType": "news", "title": "Carrier Management"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 4, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/CNBC", "type": "org", "score": 1, "label": {"eng": "CNBC"}}, {"uri": "http://en.wikipedia.org/wiki/National_Security_Agency", "type": "wiki", "score": 1, "label": {"eng": "National Security Agency"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 1, "label": {"eng": "Computer security"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 19}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 22}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 24}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 21}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 23}], "image": "https://www.carriermanagement.com/assets/OpenAI-Bloomberg-scaled.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.4039215686274509, "wgt": 197, "relevance": 1}
{"uri": "8149964670", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:02:44", "dateTime": "2024-05-28T14:02:44Z", "dateTimePub": "2024-05-28T14:01:51Z", "dataType": "news", "sim": 0.7686274647712708, "url": "https://www.euronews.com/next/2024/05/28/openai-forms-safety-committee-as-it-starts-training-next-ai-model", "title": "OpenAI forms safety committee as it starts training next AI model", "body": "Sam Altman, OpenAI's CEO, will lead a new safety committee as training starts on their latest model.\n\nOpenAI has formed a new safety committee as training starts on their latest artificial intelligence (AI) model.\n\nThe committee will make recommendations to the company's board on \"critical and security decisions\" for OpenAI.\n\nCEO Sam Altman, Bret Taylor, Adam D'Angelo and Nicole Seligman will lead the committee, OpenAI said in a blog post.\n\nThe first thing on their agenda is to update the company's current safety practices in 90 days and then share their recommendations with the board. Then, the adopted recommendations will be shared with the public.\n\n\"We view safety as something we have to invest in and succeed at,\" OpenAI's current safety procedures say.\n\nThe announcement comes a few weeks after OpenAI disbanded its Superalignment Team, a research team that was supposed to mitigate AI risks, like rogue behaviour, after the co-chairs quit the firm. It was running for less than a year.\n\nOpenAI produced a \"safety update\" last week in the wake of the AI Seoul Summit. It says, among other things, that it will not release a new AI model if it crosses a \"medium\" threat level.\n\nThat assessment is based on internal \"scorecards\" that the company keeps on their models based on how they perform during training runs, but OpenAI does not share more specific information about how they evaluate the models.\n\nOpenAI said in their AI Seoul Summit statement that they are also working on additional protections for flagging harmful content for children on their platforms as well as introducing a new tool to identify AI-generated images by DALL-E 3, ChatGPT's image generator.\n\nOn May 13, OpenAI announced GPT-4 Omni, the latest model that can \"reason across audio, vision and text in real-time\".\n\nThe company says the new model is a step towards \"more natural human-computer interaction,\" because it can respond to inputs in as little as 232 milliseconds.\n\nOpenAI's tech and policy experts Aleksander Madry and Lilian Weng along with Jakub Pachocki, the newly appointed chief scientist, are also on the committee.\n\nThe safety committee is going to get the advice of former cybersecurity officials, Rob Joyce, who advises OpenAI on security, and John Carlin.", "source": {"uri": "euronews.com", "dataType": "news", "title": "Euronews English"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 5, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 5, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Summit_(supercomputer)", "type": "wiki", "score": 2, "label": {"eng": "Summit (supercomputer)"}}, {"uri": "http://en.wikipedia.org/wiki/Media_(communication)", "type": "wiki", "score": 2, "label": {"eng": "Media (communication)"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 1, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/DALL-E", "type": "wiki", "score": 1, "label": {"eng": "DALL-E"}}, {"uri": "http://en.wikipedia.org/wiki/Human\u2013computer_interaction", "type": "wiki", "score": 1, "label": {"eng": "Human\u2013computer interaction"}}, {"uri": "http://en.wikipedia.org/wiki/Real-time_computing", "type": "wiki", "score": 1, "label": {"eng": "Real-time computing"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 1, "label": {"eng": "Computer security"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 25}, {"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 23}, {"uri": "dmoz/Recreation/Models/Scale", "label": "dmoz/Recreation/Models/Scale", "wgt": 24}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 28}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 25}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 49}], "image": "https://static.euronews.com/articles/stories/08/46/42/58/1200x675_cmsv2_896f51f5-56b4-5dab-ac9e-b4a59b30fa1c-8464258.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-05-13", "textStart": 1688, "textEnd": 1694}], "sentiment": 0.3490196078431373, "wgt": 196, "relevance": 1}
{"uri": "8149612314", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "10:27:06", "dateTime": "2024-05-28T10:27:06Z", "dateTimePub": "2024-05-28T10:26:34Z", "dataType": "news", "sim": 0.7686274647712708, "url": "https://www.channelnewsasia.com/business/openai-sets-safety-and-security-committee-headed-senior-executives-4368341", "title": "OpenAI sets up Safety and Security Committee headed by senior executives", "body": ":OpenAI has formed a Safety and Security Committee which will include CEO Sam Altman as it begins training its next artificial intelligence model, the AI startup said on Tuesday.\n\nDirectors Bret Taylor, Adam D'Angelo and Nicole Seligman, will also be on the committee, OpenAI said on a company blog.\n\nThe committee will be responsible for making recommendations to the board on safety and security decisions for OpenAI's projects and operations.", "source": {"uri": "channelnewsasia.com", "dataType": "news", "title": "CNA"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 3, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Nicole_Seligman", "type": "person", "score": 2, "label": {"eng": "Nicole Seligman"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 2, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 1, "label": {"eng": "Blog"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 23}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 24}, {"uri": "dmoz/Computers/Security/Advisories_and_Patches", "label": "dmoz/Computers/Security/Advisories and Patches", "wgt": 23}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 31}, {"uri": "dmoz/Computers/Security/FAQs,_Help,_and_Tutorials", "label": "dmoz/Computers/Security/FAQs, Help, and Tutorials", "wgt": 23}], "image": "https://onecms-res.cloudinary.com/image/upload/s--zQO_Cewy--/fl_relative,g_south_east,l_mediacorp:cna:watermark:2024-04:reuters_1,w_0.1/f_auto,q_auto/c_fill,g_auto,h_676,w_1200/v1/one-cms/core/2024-05-28t101629z_1_lynxmpek4r0bc_rtroptp_3_openai-ai.jpg?itok=V04CTyyB", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.5215686274509803, "wgt": 196, "relevance": 1}
{"uri": "8149898207", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "13:22:01", "dateTime": "2024-05-28T13:22:01Z", "dateTimePub": "2024-05-28T13:20:03Z", "dataType": "news", "sim": 0.7686274647712708, "url": "https://www.latestly.com/agency-news/world-news-openai-forms-safety-committee-as-it-starts-training-latest-artificial-intelligence-model-5996400.html", "title": "World News | OpenAI Forms Safety Committee as It Starts Training Latest Artificial Intelligence Model | LatestLY", "body": "San Francisco, May 28 (AP) OpenAI says it's setting up a safety and security committee and has begun training a new AI model to supplant the GPT-4 system that underpins its ChatGPT chatbot.\n\nThe San Francisco startup said in a blog post Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations.\n\nAlso Read | Pakistan Road Accident: Eight Members of Family Killed After Jeep Falls Into Deep Ravine in Khyber Pakhtunkhwa.\n\nThe safety committee arrives as debate swirls around AI safety at the company, which was thrust into the spotlight after a researcher, Jan Leike, resigned and levelled criticism at OpenAI for letting safety \"take a backseat to shiny products.\"\n\nOpenAI co-founder and chief scientist Ilya Sutskever also resigned, and the company disbanded the \"superalignment\" team focused on AI risks that they jointly led.\n\nAlso Read | Papua New Guinea Landslide: India Announces Aide of USD 1 Million for Landslide-Hit Nation.\n\nOpenAI said it has \"recently begun training its next frontier model\" and its AI models lead the industry on capability and safety, though it made no mention of the controversy. \"We welcome a robust debate at this important moment,\" the company said.\n\nAI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting edge AI systems.\n\nThe safety committee is filled with company insiders, including OpenAI CEO Sam Altman and Chairman Bret Taylor, and four OpenAI technical and policy experts. It also includes board members Adam D'Angelo, who's the CEO of Quora, and Nicole Seligman, a former Sony general counsel.\n\nThe committee's first job will be to evaluate and further develop OpenAI's processes and safeguards and make its recommendations to the board in 90 days. The company said it will then publicly release the recommendations it's adopting \"in a manner that is consistent with safety and security.\" (AP)\n\n(This is an unedited and auto-generated story from Syndicated News feed, LatestLY Staff may not have modified or edited the content body)", "source": {"uri": "latestly.com", "dataType": "news", "title": "LatestLY"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 5, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 3, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Jeep", "type": "org", "score": 3, "label": {"eng": "Jeep"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Khyber_Pakhtunkhwa", "type": "loc", "score": 3, "label": {"eng": "Khyber Pakhtunkhwa"}, "location": {"type": "place", "label": {"eng": "Khyber Pakhtunkhwa"}, "country": {"type": "country", "label": {"eng": "Pakistan"}}}}, {"uri": "http://en.wikipedia.org/wiki/Pakistan", "type": "loc", "score": 3, "label": {"eng": "Pakistan"}, "location": {"type": "country", "label": {"eng": "Pakistan"}}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_dollar", "type": "wiki", "score": 2, "label": {"eng": "United States dollar"}}, {"uri": "http://en.wikipedia.org/wiki/Papua_New_Guinea", "type": "loc", "score": 2, "label": {"eng": "Papua New Guinea"}, "location": {"type": "country", "label": {"eng": "Papua New Guinea"}}}, {"uri": "http://en.wikipedia.org/wiki/India", "type": "loc", "score": 2, "label": {"eng": "India"}, "location": {"type": "country", "label": {"eng": "India"}}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Video_on_demand", "type": "wiki", "score": 1, "label": {"eng": "Video on demand"}}, {"uri": "http://en.wikipedia.org/wiki/Associated_Press", "type": "org", "score": 1, "label": {"eng": "Associated Press"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 28}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 32}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 24}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 28}, {"uri": "news/Business", "label": "news/Business", "wgt": 68}], "image": "https://st1.latestly.com/wp-content/uploads/2020/10/Latestly-World-News-784x441.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}, "extractedDates": [{"amb": false, "imp": true, "date": "2024-05-28", "textStart": 15, "textEnd": 21}], "sentiment": 0.192156862745098, "wgt": 196, "relevance": 1}
{"uri": "2024-05-370980686", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:27:54", "dateTime": "2024-05-28T14:27:54Z", "dateTimePub": "2024-05-28T14:24:24Z", "dataType": "news", "sim": 0.7686274647712708, "url": "https://www.pcmag.com/news/gpt-5-openai-starts-training-next-frontier-model", "title": "GPT-5? OpenAI Starts Training 'Next Frontier Model'", "body": "OpenAI is training a new cutting-edge AI model that promises to replace its current flagship product, GPT-4o.\n\n\"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI,\" or artificial general intelligence, the company says.\n\nOpenAI executives have been teasing the next generation ChatGPT as a major advancement, but for now, the company is declining to reveal more, including what the AI model will be called and whether it's the long-awaited GPT-5.\n\nIts announcement mainly concerns a new \"Safety and Security Committee\" meant to rein in future AI projects. That comes shortly after the leaders of OpenAI's Superalignment team resigned. One of them, Jan Leike, said he left because OpenAI isn't taking AI safety seriously.\n\nIn response, OpenAI CEO Sam Altman acknowledged that Leike is \"right [that] we have a lot more to do [and] we are committed to doing it.\" Today he then announced the Safety and Security Committee, which Altman will lead alongside OpenAI Board Chairman Bret Taylor, co-creator of Google Maps, and Nicole Seligman, general counsel for Sony.\n\nThe committee will also include at least five technical and policy experts and tap outside experts, including former NSA Cybersecurity Director Rob Joyce and former US Assistant Attorney General for National Security John Carlin, for input.\n\n\"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment,\" the company says.\n\nStill, it doesn't look like the debate will be open to the public. Instead, the committee's first task \"will be to evaluate and further develop OpenAI's processes and safeguards over the next 90 days,\" the company says. OpenAI will then publicly share an update on the \"adopted recommendations\" following a board review.\n\nThe timeline suggests OpenAI could release its next-generation model in the fall.", "source": {"uri": "pcmag.com", "dataType": "news", "title": "PC Magazine"}, "authors": [{"uri": "michael_kan@pcmag.com", "name": "Michael Kan", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Assistant_Attorney_General", "type": "wiki", "score": 1, "label": {"eng": "United States Assistant Attorney General"}}, {"uri": "http://en.wikipedia.org/wiki/General_counsel", "type": "wiki", "score": 1, "label": {"eng": "General counsel"}}, {"uri": "http://en.wikipedia.org/wiki/National_Security_Agency", "type": "wiki", "score": 1, "label": {"eng": "National Security Agency"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 1, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 1, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}], "categories": [{"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 21}, {"uri": "dmoz/Recreation/Models/Scale", "label": "dmoz/Recreation/Models/Scale", "wgt": 22}, {"uri": "dmoz/Recreation/Collecting/Models", "label": "dmoz/Recreation/Collecting/Models", "wgt": 19}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 20}, {"uri": "dmoz/Recreation/Models/Boats_and_Ships", "label": "dmoz/Recreation/Models/Boats and Ships", "wgt": 20}], "image": "https://i.pcmag.com/imagery/articles/07sulBF2vct6CtoGgUhUiPC-1.fit_lim.size_1200x630.v1716902590.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.1529411764705881, "wgt": 196, "relevance": 1}
{"uri": "2024-05-370937634", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "13:51:02", "dateTime": "2024-05-28T13:51:02Z", "dateTimePub": "2024-05-28T13:50:02Z", "dataType": "news", "sim": 0.7647058963775635, "url": "https://venturebeat.com/ai/openai-begins-training-new-frontier-model-but-gpt-5-wont-come-for-at-least-90-days/", "title": "OpenAI begins training new frontier model  --  but GPT-5 won't come for at least 90 days", "body": "Join us in returning to NYC on June 5th to collaborate with executive leaders in exploring comprehensive methods for auditing AI models regarding bias, performance, and ethical compliance across diverse organizations. Find out how you can attend here.\n\nChatGPT-maker OpenAI this morning announced it has begun training its new \"frontier model\" and formed a new Safety and Security Committee led by current board members Bret Taylor (OpenAI board chair and co-founder of customer service startup Sierra AI, former Google Maps lead and former Facebook CTO), Adam D'Angelo (CEO of Quora and AI model aggregator app Poe), Nicole Seligman (former Executive Vice President and global General Counsel of Sony Corporation), and Sam Altman (current OpenAI CEO and one of its co-founders).\n\nAs OpenAI writes in a company blog post:\n\n\"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI. While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment.\"\n\n90 day timer starts now\n\nNotably, the company outlines the role this new committee will play in steering the development of the new frontier AI model, stating:\n\n\"A first task of the Safety and Security Committee will be to evaluate and further develop OpenAI's processes and safeguards over the next 90 days. At the conclusion of the 90 days, the Safety and Security Committee will share their recommendations with the full Board. Following the full Board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security.\"\n\nTherefore, it is reasonable to conclude that whatever the new frontier model is -- be it called GPT-5 or something else -- it won't be released for at least 90 days, to give the new Safety and Security Committee the time necessary to \"evaluate and further develop OpenAI's processes and safeguards\" and to issue the recommendations to the \"full Board\" of directors.\n\nThat means OpenAI's board should receive the new Safety and Security Committee's recommendations by no later than August 26, 2024.\n\nWhy 90 days as opposed to longer, shorter, or some other time? OpenAI doesn't really specify, but the metric is a common one used in business to evaluate and provide feedback on processes, and seems to be about as good as any other -- not too short, not too long.\n\nThe new safety board isn't independent\n\nThe news was immediately criticized, with some noting the fact that the new committee was comprised entirely of OpenAI's \"own executives,\" meaning the evaluation of the company's safety measures will not be independent.\n\nOpenAI's board of directors, many of which are now on the new Safety and Security Committee, has been a source of controversy before.\n\nThe old board of directors of OpenAI's nonprofit holding company fired Altman as CEO and from all duties at the company back on November 17, 2023, just five days prior to the 1-year-anniversary of ChatGPT, citing that he was \"not consistently candid\" with them, only to face a staunch revolt by employees and major pushback by OpenAI investors including big backer Microsoft.\n\nAltman was ultimately reinstated as OpenAI CEO on November 21, 2024, and that board stepped down to be replaced by Taylor, Larry Summers, and Adam D'Angelo, with Microsoft joining as a non-voting observer. At the time, the board was criticized for being entirely male dominated.\n\nOn March 8 of this year, additional members Sue Desmond-Hellmann (former CEO of the Bill and Melinda Gates Foundation), Fidji Simo (CEO and Chair of Instacart), Seligman and Altman were also named to the new board.\n\nA bumpy time for OpenAI (and the AI industry)\n\nOpenAI released its latest AI model -- GPT-4o -- earlier this month and has been on a bit of a public relations meltdown since then.\n\nDespite the new model being the first of its kind from OpenAI (and possibly the world) to be trained on multimodal inputs and outputs from the get-go, rather than stringing together several models trained on text and media (as with the prior GPT-4), the company was criticized by actor Scarlett Johansson who accused it of approaching her about voicing its new assistant and showcasing a voice she and others sounded like hers (specifically, her AI assistant character from the sci-fi movie Her). OpenAI countered it commissioned a voice separately and did not ever intend or instruct the voice actor to imitate Johansson.\n\nOpenAI's chief scientist and co-founder Ilya Sutskever resigned along with the co-leader of its superalignment team dedicated to safeguarding against superintelligences, and the latter criticized OpenAI on his way out the door for prioritizing \"shiny products\" over safety. The entire superalignment team was disbanded.\n\nIn addition, OpenAI was criticized for having a restrictive non-disparagement separation agreement for outgoing employees and clawback provision for equity in the event it and other terms were violated, but the company has since said it will not enforce and release employees from that terminology (it is also, I might add, not actually unusual from my experience working in tech at Xerox and a self-driving startup Argo AI).\n\nHowever, it has also found success signing up new partners in mainstream media for training data and authoritative journalism to be surfaced in ChatGPT, and has seen interest among musicians and filmmakers in its Sora video generation model -- as Hollywood reportedly eyes AI to streamline and reduce costs in film and TV production.\n\nMeanwhile, rival Google took heat for its AI Overview answers in search, suggesting a wider backlash among regular users to the entire gen AI field.\n\nWe shall see if OpenAI's new safety committee can placate or at least assuage some critics and, perhaps more importantly, regulators and potential business partners, ahead of the launch of whatever it is cooking up.", "source": {"uri": "venturebeat.com", "dataType": "news", "title": "VentureBeat"}, "authors": [{"uri": "carl_franzen@venturebeat.com", "name": "Carl Franzen", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 5, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Edgar_Allan_Poe", "type": "person", "score": 3, "label": {"eng": "Edgar Allan Poe"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 3, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_technology_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief technology officer"}}, {"uri": "http://en.wikipedia.org/wiki/General_counsel", "type": "wiki", "score": 3, "label": {"eng": "General counsel"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Vice_president", "type": "wiki", "score": 3, "label": {"eng": "Vice president"}}, {"uri": "http://en.wikipedia.org/wiki/Customer_service", "type": "wiki", "score": 3, "label": {"eng": "Customer service"}}, {"uri": "http://en.wikipedia.org/wiki/Board_of_directors", "type": "wiki", "score": 3, "label": {"eng": "Board of directors"}}, {"uri": "http://en.wikipedia.org/wiki/Bias", "type": "wiki", "score": 3, "label": {"eng": "Bias"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Audit", "type": "wiki", "score": 3, "label": {"eng": "Audit"}}, {"uri": "http://en.wikipedia.org/wiki/Mobile_app", "type": "wiki", "score": 3, "label": {"eng": "Mobile app"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 3, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 3, "label": {"eng": "Sony"}}, {"uri": "http://en.wikipedia.org/wiki/New_York_City", "type": "loc", "score": 3, "label": {"eng": "New York City"}, "location": {"type": "place", "label": {"eng": "New York City"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Nonprofit_organization", "type": "wiki", "score": 2, "label": {"eng": "Nonprofit organization"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 2, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Holding_company", "type": "wiki", "score": 2, "label": {"eng": "Holding company"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 2, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 1, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 1, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Self-driving_car", "type": "wiki", "score": 1, "label": {"eng": "Self-driving car"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Instacart", "type": "org", "score": 1, "label": {"eng": "Instacart"}}, {"uri": "http://en.wikipedia.org/wiki/Lawrence_Summers", "type": "person", "score": 1, "label": {"eng": "Lawrence Summers"}}, {"uri": "http://en.wikipedia.org/wiki/Xerox", "type": "org", "score": 1, "label": {"eng": "Xerox"}}, {"uri": "http://en.wikipedia.org/wiki/Cinema_of_the_United_States", "type": "loc", "score": 1, "label": {"eng": "Cinema of the United States"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Scarlett_Johansson", "type": "person", "score": 1, "label": {"eng": "Scarlett Johansson"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 22}, {"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 21}, {"uri": "dmoz/Recreation/Models/Scale", "label": "dmoz/Recreation/Models/Scale", "wgt": 21}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 26}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 22}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 69}], "image": "https://venturebeat.com/wp-content/uploads/2024/05/cfr0z3n_vector_art_line_art_graphic_novel_style_synthwave_cyber_b350d74d-110d-40f1-bc30-302c4cfc2d75.png?w=1024?w=1200&strip=all", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-06-05", "textStart": 31, "textEnd": 39}, {"amb": false, "date": "-03-08", "textStart": 3559, "textEnd": 3566}, {"amb": false, "date": "2017-11-", "textStart": 3027, "textEnd": 3038}], "sentiment": 0.223529411764706, "wgt": 195, "relevance": 1}
{"uri": "8150379960", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "19:04:46", "dateTime": "2024-05-28T19:04:46Z", "dateTimePub": "2024-05-28T19:03:19Z", "dataType": "news", "sim": 0.7647058963775635, "url": "https://securityboulevard.com/2024/05/openai-launches-security-committee-amid-ongoing-criticism/", "title": "OpenAI Launches Security Committee Amid Ongoing Criticism", "body": "OpenAI has a new Safety and Security Committee in place fewer than two weeks after disbanding its \"superalignment\" team, a year-old unit that was tasked with focusing on the long-term effects of AI.\n\nIn a blog post Tuesday, the Microsoft-backed company said the new committee will comprise CEO Sam Altman and board of director members Bret Taylor - the board's chair - Adam D'Angelo, and Nicole Seligman. The group \"will be responsible for making recommendations to the full Board on critical safety and security decisions for OpenAI projects and operations,\" OpenAI wrote.\n\nThe new committee comes in the wake of two key members of the Superalignment team - OpenAI co-founder Ilya Sutskever and AI researcher Jan Leike - left the company. Leike on X (formerly Twitter) announced Tuesday that he was joining OpenAI rival Anthropic to join another \"superalignment\" committee.\n\n\"My new team will work on scalable oversight, weak-to-strong generalization, and automated alignment research,\" wrote Leike, who recently criticized OpenAI, reportedly writing that OpenAI's \"safety culture and processes have taken a backseat to shiny products.\"\n\nThe shutting down of the superalignment team and the departure of Sutskever and Leike - and now the creation of an executive-led safety and security group - are only the latest moments in an ongoing in-house drama that burst into public view with Altman's firing as CEO by members of the board at the time saying he had not been open with them and reports that some in the company - including Sutskever - were pushing the development of OpenAI's technologies too quickly, with the innovation outpacing the development of controls necessary to ensure that AI can be used safely.\n\nHowever, less than a week later, Altman was back as CEO, with a revamped board in place and some executives being let go. Two of the former board members, speaking to The Economist, said they were concerned that OpenAI - as well as high-profile AI companies like Microsoft and Google - is innovating to rapidly to take into account adverse effects that could come with the technology.\n\nHelen Toner, with Georgetown University's Center for Security and Emerging Technology, and tech entrepreneur Tasha McCauley argued that AI companies can't self-govern and that government oversight is needed.\n\nThe rollout of AI can't be controlled only by private companies, Toner and McCauley said.\n\nAI - particularly in this relatively new era of generative AI - has generated almost as much security and safety concerns as it has excitement about its potential. Those concerns span everything from bias and discrimination in their outputs to hallucinations - made-up answers that are wrong - data security leaks and sovereignty compliance worries, and the use of the technology by threat groups.\n\nIt's unclear whether the new Safety and Security Committee will ease any of those concerns. Ilia Kolochenko, co-founder and CEO of IT security firm ImmuniWeb, called OpenAI's move welcome but questioned its societal benefits.\n\n\"Making AI models safe, for instance, to prevent their misuse or dangerous hallucinations, is obviously essential,\" Kolochenko wrote in an email to Security Boulevard. \"However, safety is just one of many facets of risks that GenAI vendors have to address.\"\n\nOne area that needs even more attention than the safety of AI concerns the unauthorized collection of data from across the internet for training LLMs and the \"unfair monopolization of human-created knowledge,\" he argued.\n\n\"Likewise, being safe does not necessarily imply being accurate, reliable, fair, transparent, explainable and non-discriminative - the absolutely crucial characteristics of GenAI solutions,\" Kolochenko noted. \"In view of the past turbulence at OpenAI, I am not sure that the new committee will make a radical improvement.\"\n\nOpenAI said the new committee's first step will be evaluating and improving OpenAI's processes and safeguard over 90 days and then bring recommendations back to the full board, with OpenAI publicly sharing the recommendations that were approved.\n\nThe company noted that the committee comes in just as OpenAI begins to train its next frontier model that will succeed GPT-4 and bring the company even closer to achieved artificial general intelligence (AGI), the point where AI systems can learn, understand, and perform as well as humans, only much faster.\n\nReaching that point has been a destination for Altman and OpenAI, though it brings up myriad concerns about what it could mean for societies and humanity itself. In a blog post last year, Altman wrote that AGI \"help us elevate humanity by increasing abundance, turbocharging the global economy, and aiding in the discovery of new scientific knowledge that changes the limits of possibility.\"\n\nHe added that it also \"would also come with serious risks of misuse, drastic accidents and societal disruption. Because the upside of AGI is so great, we do not believe it is possible or desirable for society to stop its development forever; instead, society and the developers of AGI have to figure out how to get it right.\"\n\nLeike reportedly earlier this month said that creating \"smarter-than-human machines is an inherently dangerous endeavor,\" adding that OpenAI is \"shouldering an enormous responsibility on behalf of all of humanity.\"\n\nFrontier models are the most cutting edge in AI that are designed push the evolution of AI systems forward. OpenAI in its blog post said that \"while we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment.\"", "source": {"uri": "securityboulevard.com", "dataType": "news", "title": "Security Boulevard"}, "authors": [{"uri": "jeffrey_burt@securityboulevard.com", "name": "Jeffrey Burt", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 5, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Anthropic", "type": "wiki", "score": 3, "label": {"eng": "Anthropic"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 3, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Hallucination", "type": "wiki", "score": 3, "label": {"eng": "Hallucination"}}, {"uri": "http://en.wikipedia.org/wiki/Twitter", "type": "org", "score": 3, "label": {"eng": "Twitter"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Center_for_Security_and_Emerging_Technology", "type": "wiki", "score": 2, "label": {"eng": "Center for Security and Emerging Technology"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Georgetown_University", "type": "org", "score": 2, "label": {"eng": "Georgetown University"}}, {"uri": "http://en.wikipedia.org/wiki/Entrepreneurship", "type": "wiki", "score": 2, "label": {"eng": "Entrepreneurship"}}, {"uri": "http://en.wikipedia.org/wiki/Discrimination", "type": "wiki", "score": 2, "label": {"eng": "Discrimination"}}, {"uri": "http://en.wikipedia.org/wiki/Bias", "type": "wiki", "score": 2, "label": {"eng": "Bias"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 2, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/The_Economist", "type": "wiki", "score": 2, "label": {"eng": "The Economist"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 2, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 2, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 1, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Evolution", "type": "wiki", "score": 1, "label": {"eng": "Evolution"}}, {"uri": "http://en.wikipedia.org/wiki/Monopoly", "type": "wiki", "score": 1, "label": {"eng": "Monopoly"}}, {"uri": "http://en.wikipedia.org/wiki/Internet", "type": "wiki", "score": 1, "label": {"eng": "Internet"}}], "categories": [{"uri": "dmoz/Business/Business_Services/Fire_and_Security", "label": "dmoz/Business/Business Services/Fire and Security", "wgt": 19}, {"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 21}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 20}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 20}, {"uri": "dmoz/Computers/Security/Advisories_and_Patches", "label": "dmoz/Computers/Security/Advisories and Patches", "wgt": 19}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 67}], "image": "https://securityboulevard.com/wp-content/uploads/2024/04/AIOps.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3176470588235294, "wgt": 195, "relevance": 1}
{"uri": "8149923894", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "13:36:48", "dateTime": "2024-05-28T13:36:48Z", "dateTimePub": "2024-05-28T13:36:19Z", "dataType": "news", "sim": 0.7647058963775635, "url": "https://www.siliconrepublic.com/machines/openai-safety-security-committee-next-ai-model-gpt-5-sam-altman", "title": "OpenAI forms safety committee and starts building next AI model", "body": "The committee will evaluate and develop OpenAI's processes and safeguards over the next 90 days, after which it will share its recommendations with the board.\n\nOpenAI has announced the formation of a new safety and security committee today (28 May) co-led by CEO Sam Altman as it begins training its next frontier AI model.\n\nOther than Altman, the safety and security committee will be led by directors Bret Taylor, Adam D'Angelo and Nicole Seligman.\n\nThe company said the committee's role will be to make recommendations to its board on \"critical safety and security decisions\" for OpenAI projects and operations.\n\nOpenAI said it anticipates the new frontier AI model - presumably GPT-5, although the company hasn't called it that yet - to \"bring us to the next level of capabilities on our path\" towards artificial general intelligence.\n\n\"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment,\" the company said in a statement.\n\nThe committee is set to evaluate and further develop OpenAI's processes and safeguards over the next 90 days, after which it will share its recommendations with the full board.\n\n\"Following the full board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security,\" the company said.\n\nSome of the technical and policy experts who are members of the committee include Aleksander Madry (head of preparedness), Lilian Weng (head of safety systems), John Schulman (head of alignment science), Matt Knight (head of security) and Jakub Pachocki (who recently replaced Ilya Sutskever as chief scientist).\n\nOpenAI said it will also consult other experts to support its work, including former cybersecurity officials Rob Joyce (who advises OpenAI on security) and John Carlin.\n\nJust last week, the San Francisco-based AI start-up announced a global partnership with News Corp, the multibillion-dollar news media organisation, that will allow it to access content from the likes of The Wall Street Journal and The Sunday Times.\n\nIt was also one of 16 leading tech companies that agreed to an expanded set of safety commitments relating to the development of AI at a global summit in Seoul, South Korea.\n\nFind out how emerging tech trends are transforming tomorrow with our new podcast, Future Human: The Series. Listen now on Spotify, on Apple or wherever you get your podcasts.", "source": {"uri": "siliconrepublic.com", "dataType": "news", "title": "Silicon Republic"}, "authors": [{"uri": "vish_gain@siliconrepublic.com", "name": "Vish Gain", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/The_Sunday_Times", "type": "wiki", "score": 1, "label": {"eng": "The Sunday Times"}}, {"uri": "http://en.wikipedia.org/wiki/Podcast", "type": "wiki", "score": 1, "label": {"eng": "Podcast"}}, {"uri": "http://en.wikipedia.org/wiki/The_Wall_Street_Journal", "type": "wiki", "score": 1, "label": {"eng": "The Wall Street Journal"}}, {"uri": "http://en.wikipedia.org/wiki/Spotify", "type": "wiki", "score": 1, "label": {"eng": "Spotify"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 1, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/News_media", "type": "wiki", "score": 1, "label": {"eng": "News media"}}, {"uri": "http://en.wikipedia.org/wiki/Apple_Inc.", "type": "org", "score": 1, "label": {"eng": "Apple Inc."}}, {"uri": "http://en.wikipedia.org/wiki/Seoul", "type": "loc", "score": 1, "label": {"eng": "Seoul"}, "location": {"type": "place", "label": {"eng": "Seoul"}, "country": {"type": "country", "label": {"eng": "South Korea"}}}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 22}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 25}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 26}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 25}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 23}, {"uri": "news/Business", "label": "news/Business", "wgt": 49}], "image": "https://www.siliconrepublic.com/wp-content/uploads/2023/11/a-2.jpeg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-05-28", "textStart": 241, "textEnd": 247}], "sentiment": 0.5372549019607844, "wgt": 195, "relevance": 1}
{"uri": "8150160877", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "16:11:30", "dateTime": "2024-05-28T16:11:30Z", "dateTimePub": "2024-05-28T16:11:03Z", "dataType": "news", "sim": 0.7607843279838562, "url": "https://techcrunch.com/2024/05/28/openais-new-safety-committee-is-made-up-of-all-insiders/", "title": "OpenAI's new safety committee is made up of all insiders | TechCrunch", "body": "In light of criticism over its approach to AI safety, OpenAI has formed a new committee to oversee \"critical\" safety and security decisions related to the company's projects and operations. But, in a move that's sure to raise the ire of some ethicists, OpenAI's chosen to staff the committee exclusively with company insiders -- including Sam Altman, OpenAI's CEO -- rather than outside observers.\n\nAltman and the rest of the Safety and Security Committee -- OpenAI board members Bret Taylor, Adam D'Angelo and Nicole Seligman as well as chief scientist Jakub Pachocki, Aleksander Madry (who leads OpenAI's \"preparedness\" team), Lilian Weng (head of safety systems), Matt Knight (head of security) and John Schulman (head of \"alignment science\") -- will be responsible for evaluating OpenAI's processes and safeguards over the next 90 days, according to a post on the company's official blog. The committee will then share its findings and recommendations with the full OpenAI board of directors for review, at which point it'll publish an update on any adopted suggestions \"in a manner that is consistent with safety and security.\"\n\n\"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to [artificial general intelligence,],\" OpenAI writes. \"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment.\"\n\nOpenAI has over the past few months seen several high-profile departures from the safety side of its technical team -- and some of these ex-staffers have voiced concerns about what they see as an intentional de-prioritization of AI safety.\n\nDaniel Kokotajlo, who worked on OpenAI's governance team, quit in April after losing confidence that OpenAI would \"behave responsibly\" around the release of increasingly capable AI, as he wrote on a post in his personal blog. And Ilya Sutskever, an OpenAI co-founder and formerly the company's chief scientist, left in May after a protracted battle with Altman and Altman's allies -- reportedly in part over Altman's rush to launch AI-powered products at the expense of safety work.\n\nMore recently, Jan Leike, a former DeepMind researcher who while at OpenAI was involved with the development of ChatGPT and ChatGPT's predecessor, InstructGPT, resigned from his safety research role, saying in a series of posts on X that he believed OpenAI \"wasn't on the trajectory\" to get issues pertaining to AI security and safety \"right.\" AI policy researcher Gretchen Krueger, who left OpenAI last week, echoed Leike's statements, calling on the company to improve its accountability and transparency and \"the care with which [it uses its] own technology.\"\n\nQuartz notes that, besides Sutskever, Kokotajlo, Leike and Krueger, at least five of OpenAI's most safety-conscious employees have either quit or been pushed out since late last year, including former OpenAI board members Helen Toner and Tasha McCauley. In an op-ed for The Economist published Sunday, Toner and McCauley wrote that -- with Altman at the helm -- they don't believe that OpenAI can be trusted to hold itself accountable.\n\n\"[B]ased on our experience, we believe that self-governance cannot reliably withstand the pressure of profit incentives,\" Toner and McCauley said.\n\nTo Toner and McCauley's point, TechCrunch reported earlier this month that OpenAI's Superalignment team, responsible for developing ways to govern and steer \"superintelligent\" AI systems, was promised 20% of the company's compute resources -- but rarely received a fraction of that. The Superalignment team has since been dissolved, and much of its work placed under the purview of Schulman and a safety advisory group OpenAI formed in December.\n\nOpenAI has advocated for AI regulation. At the same time, it's made efforts to shape that regulation, hiring an in-house lobbyist and lobbyists at an expanding number of law firms and spending hundreds of thousands on U.S. lobbying in Q4 2023 alone. Recently, the U.S. Department of Homeland Security announced that Altman would be among the members of its newly formed Artificial Intelligence Safety and Security Board, which will provide recommendations for \"safe and secure development and deployment of AI\" throughout the U.S.' critical infrastructures.\n\nIn an effort to avoid the appearance of ethical fig-leafing with the exec-dominated Safety and Security Committee, OpenAI has pledged to retain third-party \"safety, security and technical\" experts to support the committee's work, including cybersecurity veteran Rob Joyce and former U.S. Department of Justice official John Carlin. However, beyond Joyce and Carlin, the company hasn't detailed the size or makeup of this outside expert group -- nor has it shed light on the limits of the group's power and influence over the committee.\n\nIn a post on X, Bloomberg columnist Parmy Olson notes that corporate oversight boards like the Safety and Security Committee, similar to Google's AI oversight boards like its Advanced Technology External Advisory Council, \"[do] virtually nothing in the way of actual oversight.\" Tellingly, OpenAI says it's looking to address \"valid criticisms\" of its work via the committee -- \"valid criticisms\" being in the eye of the beholder, of course.\n\nAltman once promised that outsiders would play an important role in OpenAI's governance. In a 2016 piece in the New Yorker, he said that OpenAI would \"[plan] a way to allow wide swaths of the world to elect representatives to a ... governance board.\" That never came to pass -- and it seems very highly unlikely it will, at this point.", "source": {"uri": "techcrunch.com", "dataType": "news", "title": "TechCrunch"}, "authors": [{"uri": "kyle_wiggers@techcrunch.com", "name": "Kyle Wiggers", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 4, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 4, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Board_of_directors", "type": "wiki", "score": 3, "label": {"eng": "Board of directors"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Quartz_(publication)", "type": "wiki", "score": 2, "label": {"eng": "Quartz (publication)"}}, {"uri": "http://en.wikipedia.org/wiki/DeepMind", "type": "org", "score": 2, "label": {"eng": "DeepMind"}}, {"uri": "http://en.wikipedia.org/wiki/Op-ed", "type": "wiki", "score": 2, "label": {"eng": "Op-ed"}}, {"uri": "http://en.wikipedia.org/wiki/Lobbying", "type": "wiki", "score": 2, "label": {"eng": "Lobbying"}}, {"uri": "http://en.wikipedia.org/wiki/The_Economist", "type": "wiki", "score": 2, "label": {"eng": "The Economist"}}, {"uri": "http://en.wikipedia.org/wiki/Superintelligence", "type": "wiki", "score": 1, "label": {"eng": "Superintelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Bloomberg_News", "type": "org", "score": 1, "label": {"eng": "Bloomberg News"}}, {"uri": "http://en.wikipedia.org/wiki/TechCrunch", "type": "wiki", "score": 1, "label": {"eng": "TechCrunch"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 1, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Homeland_Security", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Homeland Security"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 1, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/New_York_City", "type": "loc", "score": 1, "label": {"eng": "New York City"}, "location": {"type": "place", "label": {"eng": "New York City"}, "country": {"type": "country", "label": {"eng": "United States"}}}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 29}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 29}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 26}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 30}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 79}], "image": "https://techcrunch.com/wp-content/uploads/2024/05/openAI-spiral-color.jpg?resize=1200,675", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.5607843137254902, "wgt": 194, "relevance": 1}
{"uri": "2024-05-371188492", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "17:54:32", "dateTime": "2024-05-28T17:54:32Z", "dateTimePub": "2024-05-28T17:51:01Z", "dataType": "news", "sim": 0.7607843279838562, "url": "https://www.financialexpress.com/life/technology-openai-creates-new-safety-team-and-sam-altman-is-its-head-is-it-a-safe-zone-3505383/", "title": "OpenAI creates new safety team and Sam Altman is its head  --  is it a safe zone?", "body": "OpenAI seems to go a step ahead for self governance, after announcing a revamped safety and security team. The news comes after OpenAI went through several public resignations and the dissolution of its former oversight body.\n\nThe new safety committee is named 'Safety and Security Committee'. The new team will be led by board members and directors Bret Taylor, Adam D'Angelo, Nicole Seligman. However, the irony comes in that it will even have OpenAI CEO Sam Altman.\n\nOther members of the new committee include internal \"OpenAI technical and policy experts,\" including heads of \"Preparedness,\" \"Safety Systems,\" and \"Alignment Science.\"\n\nThe 'Safety Net'!\n\n\"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI,\" OpenAI says. Furthermore, \"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment\" OpenAI added.\n\nDuring the announcement, OpenAI explained that the initial task of the new team is to \"evaluate and further develop OpenAI's processes and safeguards over the next 90 days.\"\n\nOther members of OpenAI's new safety team include head of preparedness Aleksander Madry, safety head Lilian Weng, head of alignment science John Schulman, security head Matt Knight, and chief scientist Jakub Pachocki.\n\nThe safe road ahead!\n\nA few days back OpenAI revealed its new voice for ChatGPT, called Sky, which sounded similar to Scarlett Johansson. Johansson then confirmed that she had denied Altman's offers to provide a voice for ChatGPT. Later Altman explained that \"Open AI never intended to make Sky sound like Johansson and that he reached out to Johansson after the company cast the voice actor.\"\n\nFrom what it is understood, after this incident critics argued that with two board members and Altman himself heading up the new safety board, it doesn't seem like OpenAI is actually addressing its former workers' concerns.\n\nFurthermore, apart from the 'safety team' OpenAI seems to be testing a new AI model. However, OpenAI didn't confirm whether it's GPT-5 or not.", "source": {"uri": "financialexpress.com", "dataType": "news", "title": "The Financial Express"}, "authors": [{"uri": "poulami_saha@financialexpress.com", "name": "Poulami Saha", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 4, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 1, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial intelligence"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 29}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 26}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 30}], "image": "https://www.financialexpress.com/wp-content/uploads/2024/02/sam-altman.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3647058823529412, "wgt": 194, "relevance": 1}
{"uri": "8150113104", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "15:39:12", "dateTime": "2024-05-28T15:39:12Z", "dateTimePub": "2024-05-28T15:38:24Z", "dataType": "news", "sim": 0.7568627595901489, "url": "https://coingape.com/?p=199247", "title": "Breaking: OpenAI Forms New Committee for Safety and Security", "body": "Committee response to AI safety debates and internal critiques.\n\nOpenAI has announced the establishment of a new Safety and Security Committee. This strategic move is aimed at positioning the organization to make key safety and security decisions about its projects and operations.\n\nThe committee will be instrumental in recommending procedures to the full board as well as putting in place efficient processes within OpenAI's developmental frameworks especially as the company moves to train its next frontier model.\n\nThis new committee is led by Bret Taylor and members include Sam Altman who is the CEO of OpenAI, Adam D'Angelo, and Nicole Seligman. This team will first be tasked with assessing and improving the safety and security of OpenAI.\n\nThey are expected to come up with their first report in the next 90 days, which will be vital in determining the safety measures of OpenAI projects. The formation of this committee is a sign that OpenAI is keen on ensuring high safety levels as it seeks to achieve better artificial intelligence technologies.\n\nThis comes after the recent commencement of training on the latest OpenAI AI model that seeks to replace the GPT-4 system that is currently in use in its ChatGPT chatbot. The organization has stated its commitment to being at the forefront not only in capability but in safety, which shows a positive outlook towards the potential dangers of AI creation.\n\nThe formation of the Safety and Security Committee is rather timely given that the safety of AI is now emerging as a major topic of discussion among the technological fraternity.\n\nSome have interpreted OpenAI's decision to make this committee official as a reaction to the ongoing controversies and discussions on AI safety standards, particularly after some of its employees resigned or publicly criticized the organization.\n\nJan Leike, an ex-employee at OpenAI, has previously expressed his concerns regarding the company, pointing out that product development seems to be valued more than the safety measures.\n\nThis new committee is a part of the steps OpenAI is taking to maintain the innovative character of the project while keeping safety as one of the main priorities in the project development process.", "source": {"uri": "coingape.com", "dataType": "news", "title": "Coingape"}, "authors": [{"uri": "kelvin_munene_murithi@coingape.com", "name": "Kelvin Munene Murithi", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 3, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 2, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 2, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 33}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 39}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 39}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 35}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 39}], "image": "https://coingape.com/wp-content/uploads/2023/12/OpenAI.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.5450980392156863, "wgt": 193, "relevance": 1}
{"uri": "8150316849", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "18:09:31", "dateTime": "2024-05-28T18:09:31Z", "dateTimePub": "2024-05-28T18:09:03Z", "dataType": "news", "sim": 0.7568627595901489, "url": "https://www.voanews.com/a/openai-unveils-new-safety-committee/7630202.html", "title": "OpenAI unveils new safety committee", "body": "ChatGPT developer OpenAI announced Tuesday it is establishing a safety committee as it trains its latest artificial intelligence model, the GPT-4 system of its chatbot.\n\nThe committee will include OpenAI CEO Sam Altman, board members and other executives. The company said the body will spend the next 90 days strengthening OpenAI's processes and safeguarding advanced AI development from potential misuse and exploitation.\n\nThe committee will make recommendations to the full board on \"critical safety and security decisions for OpenAI projects and operations,\" the company said in a statement.\n\nThe announcement comes weeks after key executives departed the company.\n\nResearcher Jan Leike, who resigned from OpenAI earlier this month, said the company's \"safety culture and processes have taken a back seat to shiny products.\"\n\nIlya Sutskever, OpenAI co-founder and chief scientist, also resigned. \"I'm confident that OpenAI will build AGI [artificial general intelligence] that is both safe and beneficial,\" he said on the social media site X, formerly Twitter.\n\nLeike and Sutskever jointly led the company's \"superalignment\" team, dedicated to reducing long-term AI risks, which disbanded after their departures.\n\nOpenAI has faced backlash over allegations that a voice for ChatGPT copied that of actress Scarlett Johansson. The company denied trying to impersonate Johansson.\n\nThe new committee will publicly release its recommendations for the company following its meeting with the full board in the fall.\n\n\"We welcome a robust debate at this important juncture,\" OpenAI's statement said.", "source": {"uri": "voanews.com", "dataType": "news", "title": "VOA Voice of America"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Twitter", "type": "org", "score": 1, "label": {"eng": "Twitter"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 18}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 22}, {"uri": "dmoz/Computers/Artificial_Intelligence/Associations", "label": "dmoz/Computers/Artificial Intelligence/Associations", "wgt": 18}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 18}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 23}], "image": "https://gdb.voanews.com/21479E2E-682E-4AC5-BE04-26A39CF4941C.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.2784313725490195, "wgt": 193, "relevance": 1}
{"uri": "8149737033", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "11:44:48", "dateTime": "2024-05-28T11:44:48Z", "dateTimePub": "2024-05-28T11:43:23Z", "dataType": "news", "sim": 0.7529411911964417, "url": "https://wtop.com/national/2024/05/openai-forms-safety-committee-as-it-starts-training-latest-artificial-intelligence-model/", "title": "OpenAI forms safety committee as it starts training latest artificial intelligence model - WTOP News", "body": "OpenAI says it's setting up a new safety and security committee and has begun training a new artificial intelligence model...\n\nOpenAI says it's setting up a new safety and security committee and has begun training a new artificial intelligence model to supplant the GPT-4 system that underpins its ChatGPT chatbot.\n\nThe San Francisco startup said in a blog post Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations.\n\nThe safety committee arrives as debate swirls around AI safety at the company, which was thrust into the spotlight after a researcher, Jan Leike, resigned and leveled criticism at OpenAI for letting safety \"take a backseat to shiny products.\"\n\nOpenAI said it has \"recently begun training its next frontier model\" and its AI models lead the industry on capability and safety, though it made no mention of the controversy. \"We welcome a robust debate at this important moment,\" the company said.\n\nAI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting edge AI systems.\n\nMembers of the the safety committee include OpenAI CEO Sam Altman and Chairman Bret Taylor, along with two other board members, Adam D'Angelo, who's the CEO of Quora, and Nicole Seligman, a former Sony general counsel. OpenAI said four company technical and policy experts are also members.\n\nThe committee's first job will be to evaluate and further develop OpenAI's processes and safeguards and make its recommendations to the board in 90 days. The company said it will then publicly release the recommendations it's adopting \"in a manner that is consistent with safety and security.\"\n\nCopyright \u00a9 2024 The Associated Press. All rights reserved. This material may not be published, broadcast, written or redistributed.", "source": {"uri": "wtop.com", "dataType": "news", "title": "WTOP"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 2, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Associated_Press", "type": "org", "score": 1, "label": {"eng": "Associated Press"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 32}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 36}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 28}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 31}, {"uri": "news/Business", "label": "news/Business", "wgt": 51}], "image": null, "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3568627450980393, "wgt": 192, "relevance": 1}
{"uri": "8149820537", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "12:33:56", "dateTime": "2024-05-28T12:33:56Z", "dateTimePub": "2024-05-28T12:33:33Z", "dataType": "news", "sim": 0.7529411911964417, "url": "https://techcentral.co.za/openais-new-safety-board-ceo-sam-altman/245465/", "title": "OpenAI's new safety board includes CEO Sam Altman - TechCentral", "body": "OpenAI has created a board committee to evaluate the safety and security of its artificial intelligence models, a governance change made weeks after its top executive on the subject resigned and the company effectively disbanded his internal team.\n\nThe new committee will spend 90 days evaluating the safeguards in OpenAI's technology before giving a report. \"Following the full board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security,\" the company said in a blog post on Tuesday.\n\nOpenAI also said that it has recently started to train its latest AI model.\n\nThe private firm's recent rapid advances in AI have raised concerns about how it manages the technology's potential dangers. Those worries intensified last year when CEO Sam Altman was briefly ousted in a boardroom coup after clashing with co-founder and chief scientist Ilya Sutskever over how quickly to develop AI products and the steps to limit harms.\n\nThose concerns returned this month after Sutskever and a key deputy, Jan Leike, left the company. The scientists ran OpenAI's so-called super-alignment team, which focused on long-term threats of superhuman AI. Leike, who resigned, wrote afterwards that his division was \"struggling\" for computing resources within OpenAI. Other departing employees echoed his criticism.\n\nFollowing Sutskever's departure, OpenAI dissolved his team. The company said on Tuesday that this particular work would continue under its research unit and John Schulman, a co-founder with the new title of head of alignment science.\n\nThe start-up has at times struggled to manage staff departures. Last week, OpenAI nixed a policy that cancelled the equity from former staffers if they spoke out against the company. A spokesman said OpenAI was aware of criticism from ex-employees and anticipated more, adding that the company was working to address concerns.\n\nOpenAI's new safety committee will consist of three board members -- chairman Bret Taylor, Quora CEO Adam D'Angelo and ex-Sony Entertainment executive Nicole Seligman -- along with six employees, including Schulman and Altman. The company said it would continue to consult outside experts, naming two of them: Rob Joyce, a homeland security adviser to Donald Trump, and John Carlin, a former justice department official under President Joe Biden. -- Mark Bergen, (c) 2024 Bloomberg LP", "source": {"uri": "techcentral.co.za", "dataType": "news", "title": "TechCentral"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Coup_d'\u00e9tat", "type": "wiki", "score": 2, "label": {"eng": "Coup d'\u00e9tat"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Homeland_security", "type": "wiki", "score": 1, "label": {"eng": "Homeland security"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Joe_Biden", "type": "person", "score": 1, "label": {"eng": "Joe Biden"}}, {"uri": "http://en.wikipedia.org/wiki/Bloomberg_L.P.", "type": "org", "score": 1, "label": {"eng": "Bloomberg L.P."}}, {"uri": "http://en.wikipedia.org/wiki/Equity_(finance)", "type": "wiki", "score": 1, "label": {"eng": "Equity (finance)"}}, {"uri": "http://en.wikipedia.org/wiki/Donald_Trump", "type": "person", "score": 1, "label": {"eng": "Donald Trump"}}], "categories": [{"uri": "dmoz/Business/Human_Resources", "label": "dmoz/Business/Human Resources", "wgt": 16}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 16}, {"uri": "dmoz/Business/Human_Resources/Employee_Relations", "label": "dmoz/Business/Human Resources/Employee Relations", "wgt": 15}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 19}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 15}], "image": "https://techcentral.co.za/wp-content/uploads/2023/10/sam-altman-1500-800.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.0117647058823529, "wgt": 192, "relevance": 1}
{"uri": "8149731699", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "11:41:08", "dateTime": "2024-05-28T11:41:08Z", "dateTimePub": "2024-05-28T11:40:14Z", "dataType": "news", "sim": 0.7490196228027344, "url": "https://gazette.com/news/us-world/openai-sets-up-safety-committee-as-it-starts-training-new-model/article_6f47c584-9295-590a-835c-7d7963fef026.html", "title": "OpenAI sets up safety committee as it starts training new model", "body": "(Reuters) -OpenAI has formed a Safety and Security Committee which will be led by CEO Sam Altman as it begins training its next artificial intelligence model, the AI startup said on Tuesday.\n\nDirectors Bret Taylor, Adam D'Angelo and Nicole Seligman, will also lead the committee, OpenAI said on a company blog.\n\nFormer Chief Scientist Ilya Sutskever and Jan Leike, who were leaders of Microsoft-backed OpenAI's Superalignment team, which ensured AI stays aligned to the intended objectives, left the firm earlier this month.\n\nOpenAI had disbanded the Superalignment team earlier in May, less than a year after the company created it, with some team members being reassigned to other groups, CNBC reported days after the high-profile departures.\n\nThe committee will be responsible for making recommendations to the board on safety and security decisions for OpenAI's projects and operations.\n\nIts first task will be to evaluate and further develop OpenAI's existing safety practices over the next 90 days, following which it will share recommendations with the board.\n\nAfter the board's review, OpenAI will publicly share an update on adopted recommendations, the company said.\n\nOther committee members include the company's technical and policy experts Aleksander Madry, Lilian Weng and head of alignment sciences John Schulman. Newly appointed Chief Scientist Jakub Pachocki and head of security Matt Knight will also be on the committee.\n\n(Reporting by Arsheeya Bajwa and Akash Sriram in Bengaluru; Editing by Tasim Zahid and Vijay Kishore)\n\nSign Up for Springs AM Update Your morning rundown of the latest news from Colorado Springs and around the country\n\nSign Up View all of our newsletters. Success! Thank you for subscribing to our newsletter. View all of our newsletters. CLICK HERE TO READ MORE FROM THE GAZETTE", "source": {"uri": "gazette.com", "dataType": "news", "title": "Colorado Springs Gazette"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 3, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_scientific_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief scientific officer"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/CNBC", "type": "org", "score": 2, "label": {"eng": "CNBC"}}, {"uri": "http://en.wikipedia.org/wiki/Reuters", "type": "wiki", "score": 1, "label": {"eng": "Reuters"}}, {"uri": "http://en.wikipedia.org/wiki/Colorado_Springs,_Colorado", "type": "loc", "score": 1, "label": {"eng": "Colorado Springs, Colorado"}, "location": {"type": "place", "label": {"eng": "Colorado Springs, Colorado"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Bangalore", "type": "loc", "score": 1, "label": {"eng": "Bangalore"}, "location": {"type": "place", "label": {"eng": "Bangalore"}, "country": {"type": "country", "label": {"eng": "India"}}}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 17}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 20}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Publications", "label": "dmoz/Health/Occupational Health and Safety/Publications", "wgt": 15}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 17}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 25}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 54}], "image": "https://bloximages.newyork1.vip.townnews.com/gazette.com/content/tncms/assets/v3/editorial/d/fa/dfadc7bc-2bc8-56c9-a7b0-00e48e43741c/6655b03d30e78.image.jpg?crop=800%2C420%2C0%2C34&resize=438%2C230&order=crop%2Cresize", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3098039215686275, "wgt": 191, "relevance": 1}
{"uri": "8150362368", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "18:48:59", "dateTime": "2024-05-28T18:48:59Z", "dateTimePub": "2024-05-28T18:48:15Z", "dataType": "news", "sim": 0.7490196228027344, "url": "https://www.latimes.com/entertainment-arts/business/story/2024-05-28/openai-forms-safety-and-security-committee", "title": "OpenAI forms safety and security committee as concerns mount about AI", "body": "ChatGPT creator OpenAI on Tuesday said it formed a safety and security committee to evaluate the company's processes and safeguards as concerns mount over the use of rapidly developing artificial intelligence technology.\n\nThe committee is expected to take 90 days to finish its evaluation. After that, it will present the company's full board with recommendations on critical safety and security decisions for OpenAI projects and operations, the firm said in a blog post.\n\nThe announcement comes after two high-level leaders, co-founder Ilya Sutskever and fellow executive Jan Leike, resigned from the company. Their departures raised concerns about the company's priorities, because both had been focused on the importance of ensuring a safe future for humanity amid the rise of AI.\n\nSutskever and Leike led OpenAI's so-called superalignment team, which was meant to create systems to curb the tech's longterm risks. The group was tasked with \"scientific and technical breakthroughs to steer and control AI systems much smarter than us.\" Upon his departure, Leike said OpenAI's \"safety culture and processes have taken a backseat to shiny products.\"\n\nOpenAI's new safety and security committee is led by board chair Bret Taylor, directors Adam D'Angelo and Nicole Seligman and Chief Executive Sam Altman. Multiple OpenAI technical and policy leaders are on the committee as well. OpenAI said that it will \"retain and consult with other safety, security and technical experts to support this work.\"\n\nThe committee's formation arrives as the company begins work on training what it calls its \"next frontier model\" for artificial intelligence.\n\n\"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment,\" OpenAI said in its blog post.\n\nControversies about use of AI have dogged the San Francisco-based company, including in the entertainment business, which is worried about the technology's implications for intellectual property and the potential displacement of jobs.\n\nActor Scarlett Johansson criticized the company last week over its handling of a ChatGPT voice feature that she and others said sounded eerily like her. Johansson, who voiced an AI program in the Oscar-winning Spike Jonze movie \"Her,\" said she was approached by Altman with a request to provide her voice, but she declined, only to later hear what sounded like her voice in an OpenAI demo.\n\nOpenAI said that the voice featured in the demo was not Johansson's, but another actor's. After Johansson raised the alarm, OpenAI put a pause on its voice option, \"Sky,\" one of many human voices available on the app. An OpenAI spokesperson said the formation of the safety committee was not related to the issues involving Johansson.\n\nOpenAI is best known for ChatGPT and Sora, a text to video tool that has major potential ramifications for filmmakers and studios.\n\nOpenAI and other tech companies have been holding discussions with Hollywood, as the entertainment industry grapples with the long-term effects of AI on employment and creativity.\n\nSome film and TV directors have said AI allows them to think more boldly, testing ideas without having the constraints of limited visual effects and travel budgets. Others worry that increased efficiency through AI tools could whittle away jobs in areas like makeup, production and animation.\n\nAs it faced safety questions, OpenAI's business, which is backed by Microsoft, also must deal with competition from other companies that are building their own artificial intelligence tools and funding.\n\nSan Francisco-based Anthropic has received billions of dollars from Amazon and Google. On Sunday, xAI, which is led by Elon Musk, announced it closed on a $6-billion funding round that goes toward research and development, building its infrastructure and bringing its first products to market.", "source": {"uri": "latimes.com", "dataType": "news", "title": "Los Angeles Times"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 4, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 3, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Scarlett_Johansson", "type": "person", "score": 3, "label": {"eng": "Scarlett Johansson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 2, "label": {"eng": "Intellectual property"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Anthropic", "type": "wiki", "score": 1, "label": {"eng": "Anthropic"}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_(company)", "type": "org", "score": 1, "label": {"eng": "Amazon (company)"}}, {"uri": "http://en.wikipedia.org/wiki/Academy_Awards", "type": "wiki", "score": 1, "label": {"eng": "Academy Awards"}}, {"uri": "http://en.wikipedia.org/wiki/Spike_Jonze", "type": "person", "score": 1, "label": {"eng": "Spike Jonze"}}, {"uri": "http://en.wikipedia.org/wiki/Visual_effects", "type": "wiki", "score": 1, "label": {"eng": "Visual effects"}}, {"uri": "http://en.wikipedia.org/wiki/Cinema_of_the_United_States", "type": "loc", "score": 1, "label": {"eng": "Cinema of the United States"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Creativity", "type": "wiki", "score": 1, "label": {"eng": "Creativity"}}, {"uri": "http://en.wikipedia.org/wiki/Voice_acting", "type": "wiki", "score": 1, "label": {"eng": "Voice acting"}}, {"uri": "http://en.wikipedia.org/wiki/Animation", "type": "wiki", "score": 1, "label": {"eng": "Animation"}}, {"uri": "http://en.wikipedia.org/wiki/Elon_Musk", "type": "person", "score": 1, "label": {"eng": "Elon Musk"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 1, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Entertainment", "type": "wiki", "score": 1, "label": {"eng": "Entertainment"}}, {"uri": "http://en.wikipedia.org/wiki/Mobile_app", "type": "wiki", "score": 1, "label": {"eng": "Mobile app"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 1, "label": {"eng": "Google"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 22}, {"uri": "dmoz/Arts/Animation/Voice_Actors", "label": "dmoz/Arts/Animation/Voice Actors", "wgt": 26}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 25}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 22}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 21}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 83}], "image": "https://ca-times.brightspotcdn.com/dims4/default/e5dd2d1/2147483647/strip/true/crop/4338x2440+0+452/resize/1200x675!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fdf%2Ffa%2Ff8ca91bb40109203c9484c39ac01%2Fartificial-intelligence-audits-66775.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3725490196078431, "wgt": 191, "relevance": 1}
{"uri": "2024-05-370782133", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "11:38:59", "dateTime": "2024-05-28T11:38:59Z", "dateTimePub": "2024-05-28T11:31:14Z", "dataType": "news", "sim": 0.7490196228027344, "url": "https://www.cnn.com/2024/05/28/tech/openai-announces-new-safety-board-after-employee-revolt/index.html", "title": "OpenAI announces new safety board after employee revolt", "body": "Washington CNN --\n\nOpenAI said Tuesday it has established a new committee to make recommendations to the company's board about safety and security, weeks after dissolving a team focused on AI safety.\n\nIn a blog post, OpenAI said the new committee would be led by CEO Sam Altman as well as Bret Taylor, the company's board chair, and board member Nicole Seligman.\n\nThe announcement follows the high-profile exit this month of an OpenAI executive focused on safety, Jan Leike. Leike resigned from OpenAI leveling criticisms that the company had underinvested in AI safety work and that tensions with OpenAI's leadership had \"reached a breaking point.\"\n\nIt also comes after the departure of Ilya Sutskever, another leader of OpenAI's so-called \"superalignment\" team focused on ensuring that AI development serves human needs and priorities. Sutskever played a key role in Altman's surprise ouster as CEO last year, only to reverse course and later throw his support behind Altman's return.\n\nEarlier this month, an OpenAI spokesperson told CNN that dismantling the superalignment team and reassigning those employees across the company would help it better achieve its superalignment goals.\n\nIn its blog post Tuesday, OpenAI also said it has begun training a new AI model to succeed the one currently powering ChatGPT. The company said the new AI model succeeding GPT-4 would be another step along the way to artificial general intelligence.\n\n\"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment,\" the company said.\n\n\"A first task of the Safety and Security Committee will be to evaluate and further develop OpenAI's processes and safeguards over the next 90 days,\" the blog post added. \"At the conclusion of the 90 days, the Safety and Security Committee will share their recommendations with the full Board. Following the full Board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security.\"", "source": {"uri": "cnn.com", "dataType": "news", "title": "CNN"}, "authors": [{"uri": "brian_fung@cnn.com", "name": "Brian Fung", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 4, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/CNN", "type": "org", "score": 4, "label": {"eng": "CNN"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 4, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 1, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 1, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 23}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 28}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 30}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 29}], "image": "https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-2153474140.jpg?c=16x9&q=w_800,c_fill", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3960784313725489, "wgt": 191, "relevance": 1}
{"uri": "8149857545", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "12:57:36", "dateTime": "2024-05-28T12:57:36Z", "dateTimePub": "2024-05-28T12:56:13Z", "dataType": "news", "sim": 0.7411764860153198, "url": "https://www.neowin.net/news/openai-launches-a-safety-and-security-committee-confirms-it-is-training-new-frontier-model/", "title": "OpenAI launches a Safety and Security committee; confirms it is training new frontier model", "body": "OpenAI says it is making a new effort to keep its generative AI systems safe to use, even as it also admits it is training its next AI model. This morning, the company announced that its Board of Directors had formed a Safety and Security committee that will examine the company's safety procedures in regard to its product development.\n\nIn a blog post, Open AI said its CEO Sam Altman will be part of that committee, along with board members Bret Taylor, Adam D'Angelo, and Nicole Seligman. Other OpenAI employees include its chief scientist, Jakub Pachocki, and its head of security, Matt Knight. The committee will also contact other outside safety and security experts to serve as its consultants.\n\nThe blog post stated:\n\nA first task of the Safety and Security Committee will be to evaluate and further develop OpenAI's processes and safeguards over the next 90 days. At the conclusion of the 90 days, the Safety and Security Committee will share their recommendations with the full Board. Following the full Board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security.\n\nThe new committee has been formed in the wake of reports that OpenAI shut down its superalignment team earlier in May. That team was previously formed to find ways to keep humans in control of generative AI services that could, in theory, become smarter than humans one day.\n\nSpeaking of which, the same OpenAi blog today confirmed that the company had \"recently begun training its next frontier model.\" It didn't name that model, but it's likely to be called ChatGPT-5. OpenAI said it will \"bring us to the next level of capabilities on our path to AGI.\" However, it added that it also wants \"a robust debate at this important moment\" about keeping systems safe to use.\n\nEarlier this month, OpenAI announced ChatGPT-4o, the latest version of its GPT-4 AI model with more realistic voice interactions. It is available to use for both free and paid ChatGPT users.", "source": {"uri": "neowin.net", "dataType": "news", "title": "Neowin"}, "authors": [{"uri": "john_callaham@neowin.net", "name": "John Callaham", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 1, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 1, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 26}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 26}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 29}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 25}, {"uri": "dmoz/Computers/Security/Advisories_and_Patches", "label": "dmoz/Computers/Security/Advisories and Patches", "wgt": 24}], "image": "https://cdn.neowin.com/news/images/uploaded/2021/01/1609914495_openai-cover_story.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.5137254901960784, "wgt": 189, "relevance": 1}
{"uri": "8149943323", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "13:49:15", "dateTime": "2024-05-28T13:49:15Z", "dateTimePub": "2024-05-28T13:48:07Z", "dataType": "news", "sim": 0.7372549176216125, "url": "https://gizmodo.com/openai-agi-chatgpt-gpt5-sam-altman-safety-group-1851503318", "title": "OpenAI Is Pushing Towards AGI With New Sam Altman Led Safety Group", "body": "OpenAI says it's training the next frontier model, according to a press release on Tuesday, and anticipates it will bring the startup one step closer to artificial intelligence systems that are generally smarter than humans. The company also announced a new Safety and Security Committee to guide critical safety and security decisions, led by CEO Sam Altman and other OpenAI board members.\n\n\"While we are proud to build and release models that are industry-leading on both capabilities and safety,\" OpenAI said in a press release. \"We welcome a robust debate at this important moment.\"\n\nThe announcement follows a tumultuous month for OpenAI, where a group led by Ilya Sutskever and Jan Leike that researched AI risks existential to humanity was disbanded. Former OpenAI board members Helen Toner and Tasha McCauley wrote in The Economist on Sunday these developments and others following the return of Altman \"bode ill for the OpenAI experiment in self-governance.\" Several employees concerned with safety also exited the company in recent months, many of which called for greater attention to the dangers of AI systems.\n\nThis new group seems to be OpenAI's attempt at addressing those fears, and the group's first task will be to evaluate OpenAI's processes and safeguards over the next 90 days. However, including Altman in this group is unlikely to appease OpenAI's critics. Toner and McCauley write that senior leaders told them Altman cultivated \"a toxic culture of lying\" at OpenAI. Just last week, Scarlett Johansson seemed to call Altman's trustworthiness into question as the company created a voice that sounded just like her.\n\nAltman, Chair Bret Taylor, and board members Adam D'Angelo and Nicole Seligman will lead the Safety and Security Committee. The company's new chief scientist, Jakub Pachocki, will also sit on the committee alongside department heads Matt Knight, John Sculman, Lilian Weng, and Aleksander Madry. The group will also consult with outside experts and make recommendations to the larger OpenAI board on safety procedures.\n\nDuring May, the company also released GPT-4 Omni, which showcased a new frontier in human interaction with AI models. This model shocked many in the AI community with its real-time multimodal interactions, and it seems OpenAI is already pushing ahead with training the next one. Altman's startup is facing pressure to compete with Google to win an AI chatbot partnership with Apple, largely expected to be unveiled during the June WWDC. The partnership could be one of the most important business deals in tech.\n\nThat said, OpenAI's new safety team is largely made up of board members brought on after Altman's return to OpenAI, and new department heads who were granted more power as a result of recent departures. The new safety group is a small step towards addressing the safety concerns plaguing OpenAI, but the collection of insiders does not seem sufficient to silence these worries.", "source": {"uri": "gizmodo.com", "dataType": "news", "title": "Gizmodo"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 3, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/The_Economist", "type": "wiki", "score": 2, "label": {"eng": "The Economist"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 1, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 1, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Multimodal_interaction", "type": "wiki", "score": 1, "label": {"eng": "Multimodal interaction"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Human\u2013computer_interaction", "type": "wiki", "score": 1, "label": {"eng": "Human\u2013computer interaction"}}, {"uri": "http://en.wikipedia.org/wiki/Real-time_computing", "type": "wiki", "score": 1, "label": {"eng": "Real-time computing"}}, {"uri": "http://en.wikipedia.org/wiki/Apple_Inc.", "type": "org", "score": 1, "label": {"eng": "Apple Inc."}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 1, "label": {"eng": "Google"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 20}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 24}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 20}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 24}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 55}], "image": "https://i.kinja-img.com/image/upload/c_fill,h_675,pg_1,q_80,w_1200/7d9e91a55434dd1bff89e25ecad5d0a2.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.1686274509803922, "wgt": 188, "relevance": 1}
{"uri": "8150356945", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "18:44:44", "dateTime": "2024-05-28T18:44:44Z", "dateTimePub": "2024-05-28T18:44:07Z", "dataType": "news", "sim": 0.7333333492279053, "url": "https://siliconangle.com/2024/05/28/openai-forms-safety-security-committee-oversee-ai-projects/", "title": "OpenAI forms safety and security committee to oversee its AI projects - SiliconANGLE", "body": "OpenAI forms safety and security committee to oversee its AI projects\n\nOpenAI today announced the formation of a committee that will be tasked with ensuring its machine learning research is carried out safely.\n\nThe Safety and Security Committee, as the panel is called, comprises nine members. It will be led by OpenAI Chief Executive Officer Sam Altman and three other directors including board chair Bret Taylor. The committee's five other members are OpenAI engineering executives Aleksander Madry, Lilian Weng, John Schulman, Matt Knight and Jakub Pachocki.\n\nThe panel's formation comes a few days after word emerged that the GPT-4 developer had disbanded an internal team dedicated to AI safety. The Superalignment team, as it was known, was established last July under the leadership of OpenAI co-founder Ilya Sutskever and then-head of alignment Jan Leike. It focused on mitigating the risks that could be posed by the company's future AI systems.\n\nSutskever and Leike left OpenAI earlier this month. Leike wrote in a post on X following his resignation that \"over the past few months my team has been sailing against the wind.\" The Superalignment group's members have reportedly either resigned or joined other teams within OpenAI.\n\nAccording to the company, the new safety and security committee's first priority will be to identify ways that its AI risk mitigation workflows can be improved. The panel will submit its recommendations to OpenAI's full board within 90 days. Afterwards, the company plans to publicly disclose which of the recommendations it will adopt.\n\nOpenAI announced the launch of the committee today alongside another update: its engineers recently began training its next frontier model. \"We anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI,\" the company detailed. AGI or, or artificial general intelligence, is a term for hypothetical future AI models that can perform a wide variety of tasks with human-like accuracy.\n\nOpenAI Chief Technology Officer Mira Murati recently told Axios that a \"major update\" to GPT-4 is set to debut later this year. The update is described as more significant than GPT-4o, an enhanced version of the large language model that OpenAI detailed about two weeks ago. It's unclear if the product launch will see the company release an upgraded edition of GPT-4 or an entirely new AI system.\n\nOpenAI relies on graphics cards hosted in Microsoft Corp.'s public cloud for much of its AI research. Last week, Microsoft Chief Technology Officer Kevin Scott reportedly likened GPT-4 to an orca and OpenAI's next-generation model to a whale. This implies the upcoming LLM will feature more parameters, AI configuration settings that play a central role in determining how a neural network processes data.", "source": {"uri": "siliconangle.com", "dataType": "news", "title": "SiliconANGLE"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 3, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 3, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Mira_Murati", "type": "wiki", "score": 1, "label": {"eng": "Mira Murati"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 1, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_technology_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief technology officer"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_neural_network", "type": "wiki", "score": 1, "label": {"eng": "Artificial neural network"}}, {"uri": "http://en.wikipedia.org/wiki/Cloud_computing", "type": "wiki", "score": 1, "label": {"eng": "Cloud computing"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 1, "label": {"eng": "Microsoft"}}], "categories": [{"uri": "dmoz/Computers/Artificial_Intelligence", "label": "dmoz/Computers/Artificial Intelligence", "wgt": 18}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 18}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 21}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 17}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 20}, {"uri": "news/Business", "label": "news/Business", "wgt": 50}], "image": "https://d15shllkswkct0.cloudfront.net/wp-content/blogs.dir/1/files/2024/05/OpenAI.png", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.1764705882352942, "wgt": 187, "relevance": 1}
{"uri": "2024-05-371031469", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "15:14:09", "dateTime": "2024-05-28T15:14:09Z", "dateTimePub": "2024-05-28T13:47:20Z", "dataType": "news", "sim": 0.7333333492279053, "url": "https://www.reuters.com/technology/openai-sets-up-safety-security-committee-2024-05-28/", "title": "OpenAI sets up safety committee as it starts training new model", "body": "May 28 (Reuters) - OpenAI has formed a Safety and Security Committee that will be led by board members, including CEO Sam Altman, as it begins training its next artificial intelligence model, the AI startup said on Tuesday.\n\nDirectors Bret Taylor, Adam D'Angelo and Nicole Seligman will also lead the committee, OpenAI said on a company blog.\n\nMicrosoft-backed (MSFT.O)New Tab, opens new tab OpenAI's chatbots with generative AI capabilities, such as engaging in human-like conversations and creating images based on text prompts, have stirred safety concerns as AI models become powerful.\n\nThe new committee will be responsible for making recommendations to the board on safety and security decisions for OpenAI's projects and operations.\n\n\"A new safety committee signifies OpenAI completing a move to becoming a commercial entity, from a more undefined non-profit-like entity,\" said D.A. Davidson managing director Gil Luria.\n\n\"That should help streamline product development while maintaining accountability.\"\n\nFormer Chief Scientist Ilya Sutskever and Jan Leike, who were leaders of OpenAI's Superalignment team, which ensured AI stays aligned to the intended objectives, left the firm earlier this month.\n\nOpenAI had disbanded the Superalignment team, earlier in May, less than a year after the company created it, with some team members being reassigned to other groups, CNBC reported days after the high-profile departures.\n\nThe committee's first task will be to evaluate and further develop OpenAI's existing safety practices over the next 90 days, following which it will share recommendations with the board.\n\nAfter the board's review, OpenAI will publicly share an update on adopted recommendations, the company said.\n\nOthers on the committee include newly appointed Chief Scientist Jakub Pachocki and Matt Knight, head of security.\n\nThe company will also consult other experts, including Rob Joyce, a former U.S. National Security Agency cybersecurity director and John Carlin, a former Department of Justice official.\n\nOpenAI did not provide further details on the new \"frontier\" model it is training, except that it would bring its systems to the \"next level of capabilities on our path to AGI.\"\n\nEarlier in May, it announced a new AI model capable of realistic voice conversation and interaction across text and image.\n\nReporting by Arsheeya Bajwa and Akash Sriram in Bengaluru; Editing by Muhammad Tasim Zahid and Vijay Kishore", "source": {"uri": "reuters.com", "dataType": "news", "title": "Reuters"}, "authors": [{"uri": "arsheeya_bajwa@reuters.com", "name": "Arsheeya Bajwa", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 4, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Reuters", "type": "wiki", "score": 3, "label": {"eng": "Reuters"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_scientific_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief scientific officer"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/CNBC", "type": "org", "score": 1, "label": {"eng": "CNBC"}}, {"uri": "http://en.wikipedia.org/wiki/National_Security_Agency", "type": "wiki", "score": 1, "label": {"eng": "National Security Agency"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 1, "label": {"eng": "Computer security"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 18}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 22}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 24}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 21}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 22}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 56}], "image": "https://www.reuters.com/resizer/v2/DM2CJP4R4JK6XELRZP7SDHV4L4.jpg?auth=6b04de28b39ae49ef8925c9555e2b3020fe62c27854ab2fd26a494b9434fcae9&height=1005&width=1920&quality=80&smart=true", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-05-28", "textStart": 0, "textEnd": 6}], "sentiment": 0.4588235294117646, "wgt": 187, "relevance": 1}
{"uri": "8150451834", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "20:11:11", "dateTime": "2024-05-28T20:11:11Z", "dateTimePub": "2024-05-28T20:10:10Z", "dataType": "news", "sim": 0.7254902124404907, "url": "https://www.ciodive.com/news/openai-safety-security-team-new-AI-model-development/717279/", "title": "OpenAI forms safety committee as it pushes next model development", "body": "Over the next 90 days, the committee will offer guidance on the company's safeguards and security processes. Following a board review, OpenAI will publicly share details regarding the adopted recommendations, the company said.\n\nOpenAI is working to solidify its security and safety ahead of releasing its next model. It's a push that could help earn enterprise customer buy-in, too.\n\n\"OpenAI's initiative to form this committee underscores the growing recognition within the industry of the importance of safety and ethical responsibility in AI development,\" Alon Yamin, co-founder and CEO of AI-based text analysis platform Copyleaks, said in an email. \"This approach is crucial for maintaining public trust and ensuring that AI advancements benefit society while minimizing potential risks.\"\n\nOpenAI said it recently started training its \"next frontier model,\" in a blog post Tuesday. \"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment.\"\n\nThe company said it will lean on safety recommendations from the new committee to inform critical security decisions for all OpenAI projects. OpenAI plans to also consult with other safety, security and technical experts to support the efforts.\n\nThe safety push follows multiple key departures, including Ilya Sutskever, co-founder and chief scientist, and Jan Leike, senior researcher and leader of OpenAI's superalignment team. The two led OpenAI's team focused on long-term risks, or superalignment, to prevent rogue AI. OpenAI dedicated 20% of the compute it had secured in July to the effort and launched a $10 million grant program.\n\nIn a post on X, formerly Twitter, earlier this month, Leike said he believed much more of the company's bandwidth should have been spent getting ready for next-generation models, security, monitoring, adversarial robustness, and safety among others.\n\n\"These problems are quite hard to get right, and I am concerned we aren't on a trajectory to get there,\" Leike said in the post. The researcher announced Tuesday he joined rival AI startup Anthropic.\n\nAn OpenAI spokesperson said co-founder John Schulman has taken on an expanded role as head of alignment science, in an email to CIO Dive Tuesday.\n\n\"This work will be coordinated within research instead of as a separate effort, and we believe this structure will be more effective for long-term safety research,\" the spokesperson said. \"This is a priority for OpenAI and the company expects its investment to increase over time.\"", "source": {"uri": "ciodive.com", "dataType": "news", "title": "CIO Dive"}, "authors": [{"uri": "lindsey_wilkinson@ciodive.com", "name": "Lindsey Wilkinson", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 2, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Email", "type": "wiki", "score": 2, "label": {"eng": "Email"}}, {"uri": "http://en.wikipedia.org/wiki/Anthropic", "type": "wiki", "score": 1, "label": {"eng": "Anthropic"}}, {"uri": "http://en.wikipedia.org/wiki/Robustness_(computer_science)", "type": "wiki", "score": 1, "label": {"eng": "Robustness (computer science)"}}, {"uri": "http://en.wikipedia.org/wiki/Bandwidth_(computing)", "type": "wiki", "score": 1, "label": {"eng": "Bandwidth (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 1, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Twitter", "type": "org", "score": 1, "label": {"eng": "Twitter"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 26}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 28}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 30}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 24}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 27}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 62}], "image": "https://www.ciodive.com/imgproxy/xqOKsCnXkbsjtEV-dGYH33zI9onjBYudHzBi0zvhRSE/g:ce/rs:fit:770:435/bG9jYWw6Ly8vZGl2ZWltYWdlL0dldHR5SW1hZ2VzLTE0OTE0NTgzNDEuanBn.webp", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.5686274509803921, "wgt": 185, "relevance": 1}
{"uri": "8150000425", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:24:27", "dateTime": "2024-05-28T14:24:27Z", "dateTimePub": "2024-05-28T14:23:49Z", "dataType": "news", "sim": 0.7254902124404907, "url": "https://www.foxbusiness.com/technology/openai-starts-training-next-frontier-artificial-intelligence-model-forms-safety-committee", "title": "OpenAI starts training 'next frontier' artificial intelligence model, forms safety committee", "body": "News Corp CEO Robert Thomson and OpenAI CEO Sam Altman join 'Kudlow' to discuss a new partnership that will give OpenAI access to current and archived content from News Corp's publications.\n\nOpenAI said on Tuesday that it has begun training an advanced artificial intelligence model that will succeed the San Francisco start-up's own GPT-4 system that currently serves its ChatGPT chatbot.\n\nThe Microsoft-backed company said in a blog post that it expects its \"next frontier model\" to bring \"the next level of capabilities\" as it works toward building artificial general intelligence, the advanced technology with similar capabilities to that of humans.\n\nOpenAI also announced that it is setting up a new safety and security committee that will advise the full board on critical safety and security decisions for its projects and operations.\n\n\"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment,\" the company said.\n\nOPENAI ACCUSED OF MIMICKING SCARLETT JOHANSSON, TECH COMPANY PAUSES CHATGPT VOICE\n\nThe committee's first task will be to evaluate and further develop OpenAI's processes and safeguards and share their recommendations at the end of the 90-day assessment period, according to the AI startup.\n\nThe company said it will then share any adopted recommendations \"in a manner that is consistent with safety and security.\"\n\nWHAT IS ARTIFICIAL INTELLIGENCE (AI)?\n\nThose who will serve on the safety committee include OpenAI CEO Sam Altman and Chairman Bret Taylor, and board members Adam D'Angelo and Nicole Seligman. Four of the company's technical and policy experts are also members.\n\nEarlier this month, OpenAI introduced its new GPT-40 model with features including real-time conversation skills.\n\nGET FOX BUSINESS ON THE GO BY CLICKING HERE\n\nOpenAI is under pressure to expand the user base of ChatGPT, its popular chatbot product that wowed the world with its ability to produce human-like written content and top-notch software code. Shortly after launching in late 2022, ChatGPT was called the fastest application to ever reach 100 million monthly active users.", "source": {"uri": "foxbusiness.com", "dataType": "news", "title": "Fox Business"}, "authors": [{"uri": "stephen_sorace@foxbusiness.com", "name": "Stephen Sorace", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 5, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 2, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Fox_Business", "type": "wiki", "score": 1, "label": {"eng": "Fox Business"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Real-time_computing", "type": "wiki", "score": 1, "label": {"eng": "Real-time computing"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 1, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_program", "type": "wiki", "score": 1, "label": {"eng": "Computer program"}}], "categories": [{"uri": "dmoz/Computers/Artificial_Intelligence", "label": "dmoz/Computers/Artificial Intelligence", "wgt": 22}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 24}, {"uri": "dmoz/Computers/Artificial_Intelligence/Associations", "label": "dmoz/Computers/Artificial Intelligence/Associations", "wgt": 24}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 26}, {"uri": "dmoz/Computers/Artificial_Intelligence/Academic_Departments", "label": "dmoz/Computers/Artificial Intelligence/Academic Departments", "wgt": 22}], "image": "https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2024/05/1024/512/openAI.jpg?ve=1&tl=1", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.5215686274509803, "wgt": 185, "relevance": 1}
{"uri": "8150059940", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "15:04:15", "dateTime": "2024-05-28T15:04:15Z", "dateTimePub": "2024-05-28T15:03:34Z", "dataType": "news", "sim": 0.7176470756530762, "url": "https://winbuzzer.com/2024/05/28/openai-prioritizes-ai-safety-with-new-committee-xcxwbn/", "title": "OpenAI Forms Safety Committee Amid New AI Model Training - WinBuzzer", "body": "The new Open AI Safety and Security Committee effectively replaces the previous Superalignment team that closed this year.\n\nOpenAI has announced the creation of a Safety and Security Committee within its Board of Directors to oversee the safety of its generative AI systems. This move coincides with the company's confirmation that it is training its next AI model, which is likely to be GPT-5.\n\nThe committee includes OpenAI's CEO Sam Altman, board members Bret Taylor, Adam D'Angelo, and Nicole Seligman, along with chief scientist Jakub Pachocki and head of security Matt Knight. The committee will also consult with external safety and security experts. According to a blog post by OpenAI, the committee's initial task is to review and improve the company's safety protocols over the next 90 days. At the end of this period, the committee will present its recommendations to the full Board, which will then review and publicly share an update on the adopted measures.\n\nThe establishment of the committee follows reports that OpenAI disbanded its superalignment team earlier in May. The superalignment team was initially created to explore methods for maintaining human control over generative AI systems, especially those that might surpass human intelligence in the future.\n\nIn the same blog post, OpenAI confirmed that it has begun training its next major AI model, expected to be named GPT-5. The company stated that this model aims to advance capabilities on the path to achieving Artificial General Intelligence (AGI). OpenAI emphasized the importance of a \"robust debate\" regarding the safety of these systems at this critical juncture.\n\nEarlier this month, OpenAI introduced GPT-4o, an enhanced version of its GPT-4 model, which features more realistic voice interactions. This version is available to both free and paid users of GPT-4.", "source": {"uri": "winbuzzer.com", "dataType": "news", "title": "WinBuzzer"}, "authors": [{"uri": "luke_jones@winbuzzer.com", "name": "Luke Jones", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 1, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Intelligence", "type": "wiki", "score": 1, "label": {"eng": "Intelligence"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 22}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 24}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 19}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 21}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 24}], "image": "https://winbuzzer.com/wp-content/uploads/2023/02/openai-logo.png", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.419607843137255, "wgt": 183, "relevance": 1}
{"uri": "8150149937", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "16:04:06", "dateTime": "2024-05-28T16:04:06Z", "dateTimePub": "2024-05-28T16:03:31Z", "dataType": "news", "sim": 0.7176470756530762, "url": "https://news.abplive.com/technology/openai-chatgpt-safety-and-security-committee-sam-altman-ai-model-training-phase-1690921", "title": "ChatGPT Maker OpenAI Has A New Safety And Security Committee With Sam Altman Onboard", "body": "ChatGPT maker OpenAI has set up a \"Safety and Security Committee\". ( Image Source :Getty )\n\nChatGPT maker OpenAI has set up a \"Safety and Security Committee\", in a bid to evaluate its artificial intelligence (AI) models, with company CEO Sam Altman playing a key role as the company gears up for its next AI model training phase. In a blog post dated May 28, OpenAI stated that the committee would provide recommendations on safety and security measures for its AI initiatives.\n\nThe newly formed committee will three board members. Their primary objective is to enhance and develop OpenAI's safety protocols.\n\nAlso read: Apple Mulling To Change The Logo On The Back Of iPads In Future\n\n\"Following the full board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security,\" the company said in a blog post.\n\nThe committee's work will involve a detailed evaluation over the next 90 days, and prepare a report based on their findings. OpenAI has committed to publicly sharing an update on the recommendations adopted after the full board's review, ensuring transparency and alignment with safety and security standards.\n\nAlso read: CMF Phone 1 May Get An iPhone SE 2-Like Design: Reports\n\nThe committee will include three board members -- Chairman Bret Taylor, Quora CEO Adam D'Angelo, and former Sony Entertainment executive Nicole Seligman -- along with six OpenAI employees, including CEO Sam Altman. Additionally, the company will seek advice from two external experts: Rob Joyce, a Homeland Security adviser under Donald Trump, and John Carlin, a former Justice Department official under President Joe Biden.\n\nOpenAI's recent quick advancements in artificial intelligence have sparked concerns over potential risks, reaulting in significant internal disagreements.\n\nThese differences, particularly with co-founder and chief scientist Ilya Sutskever, contributed to CEO Altman's brief ouster late last year. In May 2024, both Sutskever and a key deputy, Jan Leike, departed from OpenAI, citing struggles with securing adequate computing resources.\n\nOpenAI's progress in AI technology has not been without controversy. The company's aggressive push forward raised alarms about safety and ethical considerations, leading to internal conflicts. The most notable disagreement was between CEO Sam Altman and co-founder Ilya Sutskever, ultimately resulting in Altman's ouster.", "source": {"uri": "news.abplive.com", "dataType": "news", "title": "english"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 5, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 4, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 4, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 2, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 2, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/IPhone", "type": "wiki", "score": 2, "label": {"eng": "IPhone"}}, {"uri": "http://en.wikipedia.org/wiki/IPad", "type": "wiki", "score": 2, "label": {"eng": "IPad"}}, {"uri": "http://en.wikipedia.org/wiki/Apple_Inc.", "type": "org", "score": 2, "label": {"eng": "Apple Inc."}}, {"uri": "http://en.wikipedia.org/wiki/Sweden", "type": "loc", "score": 2, "label": {"eng": "Sweden"}, "location": {"type": "country", "label": {"eng": "Sweden"}}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Computing", "type": "wiki", "score": 1, "label": {"eng": "Computing"}}, {"uri": "http://en.wikipedia.org/wiki/Joe_Biden", "type": "person", "score": 1, "label": {"eng": "Joe Biden"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 1, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Homeland_Security", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Homeland Security"}}, {"uri": "http://en.wikipedia.org/wiki/Donald_Trump", "type": "person", "score": 1, "label": {"eng": "Donald Trump"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 22}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 21}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 21}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 21}, {"uri": "dmoz/Computers/Security/FAQs,_Help,_and_Tutorials", "label": "dmoz/Computers/Security/FAQs, Help, and Tutorials", "wgt": 20}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 55}], "image": "https://feeds.abplive.com/onecms/images/uploaded-images/2024/05/28/dadbf54417455950368fa6a902b091c01716911350654295_original.png?impolicy=abp_cdn&imwidth=640", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-05-01", "textStart": 1210, "textEnd": 1215}, {"amb": false, "imp": true, "date": "2024-05-28", "textStart": 351, "textEnd": 357}], "sentiment": 0.4431372549019608, "wgt": 183, "relevance": 1}
{"uri": "2024-05-371137477", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "16:57:17", "dateTime": "2024-05-28T16:57:17Z", "dateTimePub": "2024-05-28T14:14:53Z", "dataType": "news", "sim": 0.7176470756530762, "url": "https://finance.yahoo.com/news/openai-starts-training-next-frontier-141453655.html", "title": "OpenAI starts training 'next frontier' artificial intelligence model, forms safety committee", "body": "OpenAI said on Tuesday that it has begun training an advanced artificial intelligence model that will succeed the San Francisco start-up's own GPT-4 system that currently serves its ChatGPT chatbot.\n\nThe Microsoft-backed company said in a blog post that it expects its \"next frontier model\" to bring \"the next level of capabilities\" as it works toward building artificial general intelligence, the advanced technology with similar capabilities to that of humans.\n\nOpenAI also announced that it is setting up a new safety and security committee that will advise the full board on critical safety and security decisions for its projects and operations.\n\n\"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment,\" the company said.\n\nOPENAI ACCUSED OF MIMICKING SCARLETT JOHANSSON, TECH COMPANY PAUSES CHATGPT VOICE\n\nThe committee's first task will be to evaluate and further develop OpenAI's processes and safeguards and share their recommendations at the end of the 90-day assessment period, according to the AI startup.\n\nREAD ON THE FOX BUSINESS APP\n\nThe company said it will then share any adopted recommendations \"in a manner that is consistent with safety and security.\"\n\nWHAT IS ARTIFICIAL INTELLIGENCE (AI)?\n\nThose who will serve on the safety committee include OpenAI CEO Sam Altman and Chairman Bret Taylor, and board members Adam D'Angelo and Nicole Seligman. Four of the company's technical and policy experts are also members.\n\nEarlier this month, OpenAI introduced its new GPT-40 model with features including real-time conversation skills.\n\nOpenAI is under pressure to expand the user base of ChatGPT, its popular chatbot product that wowed the world with its ability to produce human-like written content and top-notch software code. Shortly after launching in late 2022, ChatGPT was called the fastest application to ever reach 100 million monthly active users.\n\nOriginal article source: OpenAI starts training 'next frontier' artificial intelligence model, forms safety committee", "source": {"uri": "finance.yahoo.com", "dataType": "news", "title": "Yahoo! Finance"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Fox_Business", "type": "wiki", "score": 1, "label": {"eng": "Fox Business"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Real-time_computing", "type": "wiki", "score": 1, "label": {"eng": "Real-time computing"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 1, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_program", "type": "wiki", "score": 1, "label": {"eng": "Computer program"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 27}, {"uri": "dmoz/Computers/Artificial_Life/Artificial_Worlds", "label": "dmoz/Computers/Artificial Life/Artificial Worlds", "wgt": 25}, {"uri": "dmoz/Computers/Artificial_Intelligence/Associations", "label": "dmoz/Computers/Artificial Intelligence/Associations", "wgt": 29}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 29}, {"uri": "dmoz/Computers/Artificial_Intelligence/Academic_Departments", "label": "dmoz/Computers/Artificial Intelligence/Academic Departments", "wgt": 25}], "image": "https://s.yimg.com/ny/api/res/1.2/NpCbs2o.QKm7AxdoWxJhng--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://media.zenfs.com/en/fox_business_text_367/a1a7b155322ac2d7cf9611d3c78f8638", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.5686274509803921, "wgt": 183, "relevance": 1}
{"uri": "2024-05-370991273", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:37:57", "dateTime": "2024-05-28T14:37:57Z", "dateTimePub": "2024-05-28T14:25:11Z", "dataType": "news", "sim": 0.7137255072593689, "url": "https://www.france24.com/en/live-news/20240528-openai-forms-ai-safety-committee-after-key-departures", "title": "OpenAI forms AI safety committee after key departures", "body": "San Francisco (AFP) - OpenAI, the company behind ChatGPT, announced the formation of a new safety committee on Tuesday, weeks after the departures of key executives raised questions about the firm's commitment to mitigating the dangers of artificial intelligence.\n\nThe company said the committee, which will include CEO Sam Altman, is being established as OpenAI begins training its next AI model, expected to surpass the capabilities of the GPT-4 system powering ChatGPT.\n\n\"While we are proud to build and release industry-leading models on both capabilities and safety, we welcome a robust debate at this important juncture,\" OpenAI stated.\n\nComprised of board members and executives, the committee will spend the next 90 days comprehensively evaluating and bolstering OpenAI's processes and safeguards around advanced AI development.\n\nOpenAI stated it will also consult outside experts during this review period, including former US cybersecurity officials Rob Joyce, who previously led efforts at the National Security Agency, and John Carlin, a former senior Justice Department official.\n\nOver the three-month span, the group will scrutinize OpenAI's current AI safety protocols and develop recommendations for potential enhancements or additions.\n\nAfter this 90-day review, the committee's findings will be presented to the full OpenAI board before being publicly released.\n\nThe committee's formation comes on the heels of recent executive departures that stoked concerns about OpenAI's AI safety priorities.\n\nEarlier this month, the company dissolved its \"superalignment\" team dedicated to mitigating long-term AI risks.\n\nIn announcing his exit, team co-lead Jan Leike criticized OpenAI for prioritizing \"shiny new products\" over vital safety work in a series of posts on X, the platform previously known as Twitter.\n\n\"Over the past few months, my team has been sailing against the wind,\" Leike said.\n\nOpenAI has also faced controversy over an AI voice some claimed closely mimicked actress Scarlett Johansson, though the company denied attempting to impersonate the Hollywood star.", "source": {"uri": "france24.com", "dataType": "news", "title": "France 24"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 4, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/National_Security_Agency", "type": "wiki", "score": 2, "label": {"eng": "National Security Agency"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 2, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 2, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Hollywood,_Los_Angeles", "type": "wiki", "score": 1, "label": {"eng": "Hollywood, Los Angeles"}}, {"uri": "http://en.wikipedia.org/wiki/Twitter", "type": "org", "score": 1, "label": {"eng": "Twitter"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 21}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 21}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 20}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 21}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 21}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 48}], "image": "https://s.france24.com/media/display/459ba0b0-1897-11ef-b181-005056bfb2b6/w:1280/p:16x9/62cf020708896193c71006f802c5eac69a553244.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3254901960784313, "wgt": 182, "relevance": 1}
{"uri": "8150365889", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "18:52:19", "dateTime": "2024-05-28T18:52:19Z", "dateTimePub": "2024-05-28T18:51:37Z", "dataType": "news", "sim": 0.7137255072593689, "url": "https://siliconangle.com/2024/05/28/openai-forms-safety-security-committee-oversee-ai-projects-trains-next-model/", "title": "OpenAI forms safety and security committee to oversee AI projects as it trains next model - SiliconANGLE", "body": "OpenAI forms safety and security committee to oversee AI projects as it trains next model\n\nOpenAI today announced the formation of a committee that will be tasked with ensuring its machine learning research is carried out safely.\n\nThe Safety and Security Committee, as the panel is called, comprises nine members. It will be led by OpenAI Chief Executive Officer Sam Altman and three other directors, including board Chair Bret Taylor. The committee's five other members are OpenAI engineering executives Aleksander Madry, Lilian Weng, John Schulman, Matt Knight and Jakub Pachocki.\n\nThe panel's formation comes a few days after word emerged that the GPT-4 developer had disbanded an internal team dedicated to AI safety. The Superalignment team, as it was known, was established last July under the leadership of OpenAI co-founder Ilya Sutskever and then-head of alignment Jan Leike. It focused on mitigating the risks that could be posed by the company's future AI systems.\n\nSutskever and Leike left OpenAI earlier this month. Leike wrote in a post on X following his resignation that \"over the past few months my team has been sailing against the wind.\" The Superalignment group's members have reportedly either resigned or joined other teams within OpenAI. Leike today joined Anthropic PBC.\n\nAccording to the company, the new safety and security committee's first priority will be to identify ways that its AI risk mitigation workflows can be improved. The panel will submit its recommendations to OpenAI's full board within 90 days. Afterwards, the company plans to publicly disclose which of the recommendations it will adopt.\n\nOpenAI announced the launch of the committee today alongside another update: Its engineers recently began training its next frontier model. \"We anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI,\" the company detailed. AGI or, or artificial general intelligence, is a term for hypothetical future AI models that can perform a wide variety of tasks with human-like accuracy.\n\nChief Technology Officer Mira Murati recently told Axios that a \"major update\" to GPT-4 is set to debut later this year. The update is described as more significant than GPT-4o, an enhanced version of the large language model that OpenAI detailed about two weeks ago. It's unclear if the product launch will see the company release an upgraded edition of GPT-4 or an entirely new AI system.\n\nOpenAI relies on graphics cards hosted in Microsoft Corp.'s public cloud for much of its AI research. Last week, Microsoft Chief Technology Officer Kevin Scott reportedly likened GPT-4 to an orca and OpenAI's next-generation model to a whale. This implies the upcoming LLM will feature more parameters, AI configuration settings that play a central role in determining how a neural network processes data.\n\nRecent reports suggest OpenAI may have already developed a prototype version of its next-generation language model. In March, Business Insider reported that the company had made a version of GPT-5 available to a limited number of users. The LLM was described by one user as \"materially better\" than GPT-4.", "source": {"uri": "siliconangle.com", "dataType": "news", "title": "SiliconANGLE"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 3, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 3, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Engineering", "type": "wiki", "score": 3, "label": {"eng": "Engineering"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Anthropic", "type": "wiki", "score": 2, "label": {"eng": "Anthropic"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Mira_Murati", "type": "wiki", "score": 1, "label": {"eng": "Mira Murati"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 1, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Language_model", "type": "wiki", "score": 1, "label": {"eng": "Language model"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_technology_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief technology officer"}}, {"uri": "http://en.wikipedia.org/wiki/Business_Insider", "type": "wiki", "score": 1, "label": {"eng": "Business Insider"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_neural_network", "type": "wiki", "score": 1, "label": {"eng": "Artificial neural network"}}, {"uri": "http://en.wikipedia.org/wiki/Cloud_computing", "type": "wiki", "score": 1, "label": {"eng": "Cloud computing"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 1, "label": {"eng": "Microsoft"}}], "categories": [{"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 16}, {"uri": "dmoz/Computers/Artificial_Intelligence", "label": "dmoz/Computers/Artificial Intelligence", "wgt": 18}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 19}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 16}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 18}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 75}], "image": "https://d15shllkswkct0.cloudfront.net/wp-content/blogs.dir/1/files/2024/05/OpenAI.png", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.1764705882352942, "wgt": 182, "relevance": 1}
{"uri": "8150048974", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:56:38", "dateTime": "2024-05-28T14:56:38Z", "dateTimePub": "2024-05-28T14:56:06Z", "dataType": "news", "sim": 0.7137255072593689, "url": "https://www.pymnts.com/news/artificial-intelligence/2024/openai-overhauls-ai-safety-efforts-races-develop-chatgpt-successor/", "title": "OpenAI Overhauls AI Safety Efforts, Races to Develop ChatGPT Successor", "body": "The company formed a new Safety and Security Committee to guide its board on AI safety and security and announced a forthcoming souped-up version of its current chatbot.\n\nThe moves come on the heels of key departures from OpenAI's safety team. It's a tricky balancing act for the company as it navigates the challenges of responsible AI development in a competitive industry.\n\nOpenAI also announced in a Tuesday (May 28) blog post that it has started training a new AI model to replace the one behind ChatGPT. The company said this new model, which will succeed GPT-4, would bring it closer to achieving artificial general intelligence (AGI), the hypothetical ability of an AI system to understand or learn any intellectual task that a human can.\n\n\"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment,\" the post said.\n\n\"A first task of the Safety and Security Committee will be to evaluate and further develop OpenAI's processes and safeguards over the next 90 days,\" the post added. \"At the conclusion of the 90 days, the Safety and Security Committee will share their recommendations with the full board. Following the full board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security.\"\n\nThe new committee, led by CEO Sam Altman and board members Bret Taylor and Nicole Seligman, has 90 days to evaluate and strengthen OpenAI's safety processes. It will present its recommendations to the board and share an update with the public.\n\nHowever, the committee's formation follows the exits of Jan Leike and Ilya Sutskever, two key figures in OpenAI's AI safety efforts. Leike resigned, criticizing the company for underinvesting in safety and citing tensions with leadership. Sutskever, who briefly ousted Altman as CEO last year, also departed.\n\nThe overhaul comes as OpenAI and its competitors race to develop powerful AI systems. AI has potential benefits, from healthcare to productivity. However, it also raises ethical concerns, like bias and job displacement.\n\nThe new committee shows that OpenAI recognizes the importance of responsible AI development. The 90-day timeline suggests urgency and commitment. However, the departures raise questions about internal dynamics and the ability to retain AI safety talent.\n\nOpenAI will need to address these challenges and ensure AI safety remains a top priority. This means allocating resources and fostering a culture that values responsibility alongside innovation.\n\nThe overhaul also highlights broader challenges in the AI industry. As AI becomes more powerful, robust safety measures and ethical guidelines are crucial. The race to achieve AGI must be balanced with mitigating risks and ensuring AI benefits society.\n\nOpenAI's new committee will need to navigate these complex issues. It must work to restore confidence in the company's commitment to AI safety and contribute to the broader conversation about responsible AI development in a fast-paced industry.", "source": {"uri": "pymnts.com", "dataType": "news", "title": "PYMNTS.com"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 4, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 1, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Bias", "type": "wiki", "score": 1, "label": {"eng": "Bias"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 1, "label": {"eng": "Ethics"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 29}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 29}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 26}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 30}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 27}], "image": "https://www.pymnts.com/wp-content/uploads/2024/04/AI-artificial-intelligence.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-05-28", "textStart": 413, "textEnd": 419}], "sentiment": 0.5921568627450979, "wgt": 182, "relevance": 1}
{"uri": "2024-05-370797883", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "11:53:21", "dateTime": "2024-05-28T11:53:21Z", "dateTimePub": "2024-05-28T11:11:26Z", "dataType": "news", "sim": 0.7137255072593689, "url": "https://ca.finance.yahoo.com/news/openai-sets-safety-security-committee-101035008.html", "title": "OpenAI sets up safety committee as it starts training new model", "body": "(Reuters) -OpenAI has formed a Safety and Security Committee which will be led by CEO Sam Altman as it begins training its next artificial intelligence model, the AI startup said on Tuesday.\n\nDirectors Bret Taylor, Adam D'Angelo and Nicole Seligman, will also lead the committee, OpenAI said on a company blog.\n\nFormer Chief Scientist Ilya Sutskever and Jan Leike, who were leaders of Microsoft-backed OpenAI's Superalignment team, which ensured AI stays aligned to the intended objectives, left the firm earlier this month.\n\nOpenAI had disbanded the Superalignment team earlier in May, less than a year after the company created it, with some team members being reassigned to other groups, CNBC reported days after the high-profile departures.\n\nThe committee will be responsible for making recommendations to the board on safety and security decisions for OpenAI's projects and operations.\n\nIts first task will be to evaluate and further develop OpenAI's existing safety practices over the next 90 days, following which it will share recommendations with the board.\n\nAfter the board's review, OpenAI will publicly share an update on adopted recommendations, the company said.\n\nOther committee members include the company's technical and policy experts Aleksander Madry, Lilian Weng and head of alignment sciences John Schulman. Newly appointed Chief Scientist Jakub Pachocki and head of security Matt Knight will also be on the committee.\n\n(Reporting by Arsheeya Bajwa and Akash Sriram in Bengaluru; Editing by Tasim Zahid and Vijay Kishore)", "source": {"uri": "ca.finance.yahoo.com", "dataType": "news", "title": "Yahoo! Finance"}, "authors": [{"uri": "reuters@ca.finance.yahoo.com", "name": "Reuters", "type": "author", "isAgency": true}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 3, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Nicole_Seligman", "type": "person", "score": 3, "label": {"eng": "Nicole Seligman"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Reuters", "type": "wiki", "score": 3, "label": {"eng": "Reuters"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_scientific_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief scientific officer"}}, {"uri": "http://en.wikipedia.org/wiki/CNBC", "type": "org", "score": 2, "label": {"eng": "CNBC"}}, {"uri": "http://en.wikipedia.org/wiki/Bangalore", "type": "loc", "score": 1, "label": {"eng": "Bangalore"}, "location": {"type": "place", "label": {"eng": "Bangalore"}, "country": {"type": "country", "label": {"eng": "India"}}}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 15}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 18}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 21}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 18}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 26}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 55}], "image": "https://media.zenfs.com/en/reuters.ca/d131c5dcfe2f5518b10e7360853a22ad", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3803921568627451, "wgt": 182, "relevance": 1}
{"uri": "8149769150", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "12:04:09", "dateTime": "2024-05-28T12:04:09Z", "dateTimePub": "2024-05-28T12:03:38Z", "dataType": "news", "sim": 0.7098039388656616, "url": "https://sea.mashable.com/tech/32788/openai-confirms-gpt-4-successor-in-training-stage", "title": "OpenAI confirms GPT-4 successor in training stage", "body": "OpenAI is training a new prime AI model to succeed its current GPT-4.\n\nFirst reported by The New York Times and announced in a blog post, the company is working on a successor to the artificial intelligence model that fuels its well-known chatbot, ChatGPT.\n\n\"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI,\" reads the post, published Tuesday.\n\nOpenAI's GPT-4 was released in March 2023, a powerful update to GPT-3 which powered its successful ChatGPT chatbot launched in November 2022.\n\nMashable reached out to OpenAI for further information on the new AI model, and we were pointed to the blog.\n\nIn the same post, OpenAI also announced it has formed a Safety and Security Committee that \"will be responsible for making recommendations to the full Board on critical safety and security decisions for OpenAI projects and operations.\"\n\nThe committee will be comprised of directors Bret Taylor, Nicole Seligman, Adam D'Angelo, and OpenAI CEO Sam Altman.\n\n\"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment,\" OpenAI's post reads.\n\nThe news comes weeks after OpenAI unveiled GPT-4o, a multimodal AI voice assistant that combines text, vision, and audio, in April. The announcement put a new spotlight on the existing \"Sky\" option for ChatGPT's Voice Mode, which some had likened to actor Scarlett Johansson's fictional digital assistant in the 2013 film Her -- and yes, Johansson heard it too. The voice has been paused on ChatGPT for now.\n\nMeanwhile, in-company politics have reached boiling point for OpenAI, following a leadership crisis, a wave of high profile resignations and former executives calling out the company's lack of transparency.", "source": {"uri": "sea.mashable.com", "dataType": "news", "title": "Mashable SEA"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 4, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 4, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/The_New_York_Times", "type": "wiki", "score": 3, "label": {"eng": "The New York Times"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-3", "type": "wiki", "score": 2, "label": {"eng": "GPT-3"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Mashable", "type": "wiki", "score": 2, "label": {"eng": "Mashable"}}, {"uri": "http://en.wikipedia.org/wiki/Multimodal_learning", "type": "wiki", "score": 1, "label": {"eng": "Multimodal learning"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 1, "label": {"eng": "Virtual assistant"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 17}, {"uri": "dmoz/Recreation/Models/Scale", "label": "dmoz/Recreation/Models/Scale", "wgt": 17}, {"uri": "dmoz/Arts/Animation/Voice_Actors", "label": "dmoz/Arts/Animation/Voice Actors", "wgt": 16}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 15}, {"uri": "dmoz/Recreation/Models/Boats_and_Ships", "label": "dmoz/Recreation/Models/Boats and Ships", "wgt": 15}], "image": "https://sm.mashable.com/t/mashable_sea/article/o/openai-con/openai-confirms-gpt-4-successor-in-training-stage_3edx.1200.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.4039215686274509, "wgt": 181, "relevance": 1}
{"uri": "8149867334", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "13:03:02", "dateTime": "2024-05-28T13:03:02Z", "dateTimePub": "2024-05-28T13:02:22Z", "dataType": "news", "sim": 0.7098039388656616, "url": "https://www.techtimes.com/articles/305072/20240528/openai-assembles-new-safety-team-sam-altman-starts-training-next-ai-model.htm", "title": "OpenAI Assembles New Safety Team Led by CEO Sam Altman, Starts Training on Next AI Model", "body": "OpenAI has announced the formation of a new Safety and Security Committee following the departure of top executives earlier this month.\n\nThis move comes as the company begins training its next flagship AI model, designed to succeed the widely used GPT-4 technology.\n\nThe new committee is led by CEO Sam Altman and includes several high-profile directors and experts.\n\nOpenAI's announcement on Tuesday, May 28, introduced the Safety and Security Committee, which will oversee the company's safety practices and address the risks associated with its AI models, Reuters reports.\n\nAlongside CEO Sam Altman, the committee includes directors Bret Taylor, Adam D'Angelo, and Nicole Seligman. Technical and policy experts Aleksander Madry, Lilian Weng, and John Schulman are also part of the team, along with newly appointed Chief Scientist Jakub Pachocki and head of security Matt Knight.\n\nThe primary task of this committee over the next 90 days is to evaluate and develop OpenAI's existing safety protocols. After this period, the committee will share its recommendations with the board, which will then publicly disclose the adopted measures.\n\nRead Also: ChatGPT Answers to Computer Programming Questions More Than 50% Inaccurate, Study Shows\n\nThe formation of the new committee follows major leadership changes within OpenAI.\n\nEarlier this month, Ilya Sutskever, the former Chief Scientist and co-leader of the disbanded Superalignment team, left the company.\n\nThe Superalignment team, established to ensure AI models align with intended objectives, was also dissolved in May, and its members were reassigned to other projects.\n\nJan Leike, who also co-led the Superalignment team, resigned alongside Sutskever, raising concerns about OpenAI's approach to safety.\n\nJohn Schulman, a co-founder of OpenAI who previously headed the team that developed ChatGPT, will now lead the company's long-term safety research. His work will be overseen by the new Safety and Security Committee, ensuring a cohesive strategy for managing AI risks.\n\nIn addition to forming the new safety committee, OpenAI has started training its next AI model, aimed at succeeding GPT-4.\n\nAs reported by the New York Times, this new model is expected to bring \"the next level of capabilities,\" according to OpenAI. It represents a significant step towards developing artificial general intelligence (AGI), a machine that can perform any intellectual task that a human can.\n\nThe upcoming model is intended to power several of AI products, including chatbots, digital assistants, search engines, and image generators.\n\nReports tell us that the new model may not be available for another nine months to a year or more.\n\n\"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment,\" the company stated in a recent blog post.\n\nRecently, the company was accused of ripping off Hollywood actress Scarlett Johansson's voice to power ChatGPT's Sky voice.\n\nStay posted here at Tech Times.", "source": {"uri": "techtimes.com", "dataType": "news", "title": "Tech Times"}, "authors": [{"uri": "john_lopez@techtimes.com", "name": "John Lopez", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 4, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 4, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_scientific_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief scientific officer"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_programming", "type": "wiki", "score": 2, "label": {"eng": "Computer programming"}}, {"uri": "http://en.wikipedia.org/wiki/Search_engine", "type": "wiki", "score": 1, "label": {"eng": "Search engine"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 1, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/The_New_York_Times", "type": "wiki", "score": 1, "label": {"eng": "The New York Times"}}, {"uri": "http://en.wikipedia.org/wiki/Reuters", "type": "wiki", "score": 1, "label": {"eng": "Reuters"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 23}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 25}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 24}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 24}], "image": "https://1734811051.rsc.cdn77.org/data/thumbs/full/447727/820/0/0/0/us-technology-ai-altman.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-05-28", "textStart": 402, "textEnd": 408}], "sentiment": 0.3019607843137255, "wgt": 181, "relevance": 1}
{"uri": "2024-05-371058263", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "15:38:26", "dateTime": "2024-05-28T15:38:26Z", "dateTimePub": "2024-05-28T15:38:17Z", "dataType": "news", "sim": 0.7058823704719543, "url": "http://english.ahram.org.eg/NewsContent/3/1239/524402/Business/Tech/OpenAI-forms-AI-safety-committee-after-key-departu.aspx", "title": "OpenAI forms AI safety committee after key departures - Tech - Business", "body": "The company said the committee, which will include CEO Sam Altman, is being established as OpenAI begins training its next AI model, expected to surpass the capabilities of the GPT-4 system powering ChatGPT.\n\n\"While we are proud to build and release industry-leading models on both capabilities and safety, we welcome a robust debate at this important juncture,\" OpenAI stated.\n\nComprised of board members and executives, the committee will spend the next 90 days comprehensively evaluating and bolstering OpenAI's processes and safeguards around advanced AI development.\n\nOpenAI stated it will also consult outside experts during this review period, including former US cybersecurity officials Rob Joyce, who previously led efforts at the National Security Agency, and John Carlin, a former senior Justice Department official.\n\nOver the three months, the group will scrutinize OpenAI's current AI safety protocols and develop recommendations for potential enhancements or additions.\n\nAfter this 90-day review, the committee's findings will be presented to the full OpenAI board before being publicly released.\n\nThe committee's formation comes on the heels of recent executive departures that stoked concerns about OpenAI's AI safety priorities.\n\nEarlier this month, the company dissolved its \"superalignment\" team dedicated to mitigating long-term AI risks.\n\nIn announcing his exit, team co-lead Jan Leike criticized OpenAI for prioritizing \"shiny new products\" over vital safety work in a series of posts on X, the platform previously known as Twitter.\n\n\"Over the past few months, my team has been sailing against the wind,\" Leike said.\n\nOpenAI has also faced controversy over an AI voice some claimed closely mimicked actress Scarlett Johansson, though the company denied attempting to impersonate the Hollywood star.", "source": {"uri": "english.ahram.org.eg", "dataType": "news", "title": "\u062c\u0631\u064a\u062f\u0629 \u0627\u0644\u0623\u0647\u0631\u0627\u0645"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 4, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/National_Security_Agency", "type": "wiki", "score": 2, "label": {"eng": "National Security Agency"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 2, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 2, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Scarlett_Johansson", "type": "person", "score": 1, "label": {"eng": "Scarlett Johansson"}}, {"uri": "http://en.wikipedia.org/wiki/Twitter", "type": "org", "score": 1, "label": {"eng": "Twitter"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 20}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 20}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 19}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 20}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 18}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 60}], "image": "https://english.ahram.org.eg/Media/News/2024/5/28/41_2024-638525158911872298-187.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3647058823529412, "wgt": 180, "relevance": 1}
{"uri": "8150019628", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:36:45", "dateTime": "2024-05-28T14:36:45Z", "dateTimePub": "2024-05-28T14:36:07Z", "dataType": "news", "sim": 0.7058823704719543, "url": "https://www.digitaljournal.com/business/openai-forms-ai-safety-committee-after-key-departures/article", "title": "OpenAI forms AI safety committee after key departures", "body": "OpenAI CEO Sam Altman speaks during the Microsoft Build conference in Seattle on May 21, 2024 - Copyright AFP/File Jason Redmond\n\nOpenAI, the company behind ChatGPT, announced the formation of a new safety committee on Tuesday, weeks after the departures of key executives raised questions about the firm's commitment to mitigating the dangers of artificial intelligence.\n\nThe company said the committee, which will include CEO Sam Altman, is being established as OpenAI begins training its next AI model, expected to surpass the capabilities of the GPT-4 system powering ChatGPT.\n\n\"While we are proud to build and release industry-leading models on both capabilities and safety, we welcome a robust debate at this important juncture,\" OpenAI stated.\n\nComprised of board members and executives, the committee will spend the next 90 days comprehensively evaluating and bolstering OpenAI's processes and safeguards around advanced AI development.\n\nOpenAI stated it will also consult outside experts during this review period, including former US cybersecurity officials Rob Joyce, who previously led efforts at the National Security Agency, and John Carlin, a former senior Justice Department official.\n\nOver the three-month span, the group will scrutinize OpenAI's current AI safety protocols and develop recommendations for potential enhancements or additions.\n\nAfter this 90-day review, the committee's findings will be presented to the full OpenAI board before being publicly released.\n\nThe committee's formation comes on the heels of recent executive departures that stoked concerns about OpenAI's AI safety priorities.\n\nEarlier this month, the company dissolved its \"superalignment\" team dedicated to mitigating long-term AI risks.\n\nIn announcing his exit, team co-lead Jan Leike criticized OpenAI for prioritizing \"shiny new products\" over vital safety work in a series of posts on X, the platform previously known as Twitter.\n\n\"Over the past few months, my team has been sailing against the wind,\" Leike said.\n\nOpenAI has also faced controversy over an AI voice some claimed closely mimicked actress Scarlett Johansson, though the company denied attempting to impersonate the Hollywood star.", "source": {"uri": "digitaljournal.com", "dataType": "news", "title": "Digital Journal"}, "authors": [{"uri": "agence_france_presse@digitaljournal.com", "name": "Agence France-Presse", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 5, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 5, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 3, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Seattle", "type": "loc", "score": 3, "label": {"eng": "Seattle"}, "location": {"type": "place", "label": {"eng": "Seattle"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Redmond,_Washington", "type": "loc", "score": 3, "label": {"eng": "Redmond, Washington"}, "location": {"type": "place", "label": {"eng": "Redmond, Washington"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 2, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/National_Security_Agency", "type": "wiki", "score": 2, "label": {"eng": "National Security Agency"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 2, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 2, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Scarlett_Johansson", "type": "person", "score": 1, "label": {"eng": "Scarlett Johansson"}}, {"uri": "http://en.wikipedia.org/wiki/Agence_France-Presse", "type": "wiki", "score": 1, "label": {"eng": "Agence France-Presse"}}, {"uri": "http://en.wikipedia.org/wiki/Twitter", "type": "org", "score": 1, "label": {"eng": "Twitter"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 20}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 21}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 20}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 21}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 20}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 84}], "image": "https://www.digitaljournal.com/wp-content/uploads/2024/05/cbda240667364fa2cdcf0bff0ce3f41651fc342f-1.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3490196078431373, "wgt": 180, "relevance": 1}
{"uri": "8150019513", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:37:14", "dateTime": "2024-05-28T14:37:14Z", "dateTimePub": "2024-05-28T14:36:04Z", "dataType": "news", "sim": 0.7058823704719543, "url": "https://timesofindia.indiatimes.com/technology/tech-news/chatgpt-maker-openai-forms-safety-and-security-committee-members-and-what-it-will-do/articleshow/110502945.cms", "title": "ChatGPT-maker OpenAI forms Safety and Security Committee: Members and what it will do - Times of India", "body": "ChatGPT-maker OpenAI, which recently disbanded its \"superalignment team\" focused on long-term AI risks, has formed a committee to make recommendations on the safety and security of OpenAI's projects and operations.\n\nThe committee, formed by OpenAI Board, is led by directors Bret Taylor (Chair), Adam D'Angelo, Nicole Seligman, and Sam Altman (CEO), the company announced.OpenAI technical and policy experts Aleksander Madry (Head of Preparedness), Lilian Weng (Head of Safety Systems), John Schulman (Head of Alignment Science), Matt Knight (Head of Security), and Jakub Pachocki (Chief Scientist) will also be on the committee.\n\nThis team will evaluate and further develop the microsoft-backed company's processes and safeguards over the next 90 days. Following the review, OpenAI will share an update on adopted recommendations in a manner that is consistent with safety and security.\n\nThe team also includes other safety, security, and technical experts, including former cybersecurity officials, Rob Joyce, who advises OpenAI on security, and John Carlin.\n\nThe move coincides with the high-profile departures of key leaders, including co-founder and chief scientist Ilya Sutskever and superalignment team co-lead Jan Leike.\n\nOpenAI starts testing \"its next frontier model\"\n\nThe company also said it had recently started training \"its next frontier model\" and that the model would bring the company to the \"next level of capabilities on our path to AGI,\" or artificial general intelligence.\n\n\"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI. While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment,\" OpenAI announced.\n\nEarlier this month, OpenAI demoed GPT-4o, an AI model that is multimodal - which means it lets people talk to ChatGPT on their smartphones similar to the way they would speak to other voice assistants.\n\nThe TOI Tech Desk is a dedicated team of journalists committed to delivering the latest and most relevant news from the world of technology to readers of The Times of India. TOI Tech Desk's news coverage spans a wide spectrum across gadget launches, gadget reviews, trends, in-depth analysis, exclusive reports and breaking stories that impact technology and the digital universe. Be it how-tos or the latest happenings in AI, cybersecurity, personal gadgets, platforms like WhatsApp, Instagram, Facebook and more; TOI Tech Desk brings the news with accuracy and authenticity.", "source": {"uri": "timesofindia.indiatimes.com", "dataType": "news", "title": "The Times of India"}, "authors": [{"uri": "toi_tech_desk@timesofindia.indiatimes.com", "name": "Toi Tech Desk", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_scientific_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief scientific officer"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 2, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 1, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 1, "label": {"eng": "Virtual assistant"}}, {"uri": "http://en.wikipedia.org/wiki/The_Times_of_India", "type": "wiki", "score": 1, "label": {"eng": "The Times of India"}}, {"uri": "http://en.wikipedia.org/wiki/WhatsApp", "type": "org", "score": 1, "label": {"eng": "WhatsApp"}}, {"uri": "http://en.wikipedia.org/wiki/Instagram", "type": "org", "score": 1, "label": {"eng": "Instagram"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 1, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Smartphone", "type": "wiki", "score": 1, "label": {"eng": "Smartphone"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 22}, {"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 20}, {"uri": "dmoz/Recreation/Models/Scale", "label": "dmoz/Recreation/Models/Scale", "wgt": 20}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 21}, {"uri": "dmoz/Computers/Security/Advisories_and_Patches", "label": "dmoz/Computers/Security/Advisories and Patches", "wgt": 19}, {"uri": "news/Business", "label": "news/Business", "wgt": 81}], "image": "https://static.toiimg.com/thumb/msid-110503165,width-1070,height-580,imgsize-38076,resizemode-75,overlay-toi_sw,pt-32,y_pad-40/photo.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3960784313725489, "wgt": 180, "relevance": 1}
{"uri": "8149622403", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "10:33:51", "dateTime": "2024-05-28T10:33:51Z", "dateTimePub": "2024-05-28T10:33:10Z", "dataType": "news", "sim": 0.7058823704719543, "url": "https://news.bloomberglaw.com/artificial-intelligence/openai-creates-oversight-board-after-dissolving-safety-team", "title": "OpenAI Creates Oversight Board After Dissolving Safety Team", "body": "OpenAI-bsp-bb-link> has created a board committee to evaluate the safety and security of its artificial intelligence models, a governance change made weeks after its top executive on the the subject resigned and the company effectively disbanded his internal team.\n\nThe new committee will spend 90 days evaluating the safeguards in OpenAI's technology before giving a report. \"Following the full board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security,\" the company said in a blog post on Tuesday.\n\nOpenAI also said that it has recently started to train ...", "source": {"uri": "news.bloomberglaw.com", "dataType": "news", "title": "news.bloomberglaw.com"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 2, "label": {"eng": "OpenAI"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 19}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 23}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 19}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 24}], "image": "https://db0ip7zd23b50.cloudfront.net/dims4/default/b50077b/2147483647/crop/4893x1886%2B0%2B119/resize/1920x740%3E/quality/90/?url=http%3A%2F%2Fbloomberg-bna-brightspot.s3.amazonaws.com%2Fe8%2Fcc%2F9846ccb0424a8cd5244b67b8c3ca%2Fgettyimages-1797580651.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.5215686274509803, "wgt": 180, "relevance": 1}
{"uri": "2024-05-371108543", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "16:25:56", "dateTime": "2024-05-28T16:25:56Z", "dateTimePub": "2024-05-28T14:24:26Z", "dataType": "news", "sim": 0.7019608020782471, "url": "https://www.kulr8.com/news/national/openai-forms-ai-safety-committee-after-key-departures/article_a83c21fa-b2ab-5ba5-a2d1-e601ba2b191f.html", "title": "OpenAI forms AI safety committee after key departures", "body": "OpenAI, the company behind ChatGPT, announced the formation of a new safety committee on Tuesday, weeks after the departures of key executives raised questions about the firm's commitment to mitigating the dangers of artificial intelligence.\n\nThe company said the committee, which will include CEO Sam Altman, is being established as OpenAI begins training its next AI model, expected to surpass the capabilities of the GPT-4 system powering ChatGPT.\n\n\"While we are proud to build and release industry-leading models on both capabilities and safety, we welcome a robust debate at this important juncture,\" OpenAI stated.\n\nComprised of board members and executives, the committee will spend the next 90 days comprehensively evaluating and bolstering OpenAI's processes and safeguards around advanced AI development.\n\nOpenAI stated it will also consult outside experts during this review period, including former US cybersecurity officials Rob Joyce, who previously led efforts at the National Security Agency, and John Carlin, a former senior Justice Department official.\n\nOver the three-month span, the group will scrutinize OpenAI's current AI safety protocols and develop recommendations for potential enhancements or additions.\n\nAfter this 90-day review, the committee's findings will be presented to the full OpenAI board before being publicly released.\n\nThe committee's formation comes on the heels of recent executive departures that stoked concerns about OpenAI's AI safety priorities.\n\nEarlier this month, the company dissolved its \"superalignment\" team dedicated to mitigating long-term AI risks.\n\nIn announcing his exit, team co-lead Jan Leike criticized OpenAI for prioritizing \"shiny new products\" over vital safety work in a series of posts on X, the platform previously known as Twitter.\n\n\"Over the past few months, my team has been sailing against the wind,\" Leike said.\n\nOpenAI has also faced controversy over an AI voice some claimed closely mimicked actress Scarlett Johansson, though the company denied attempting to impersonate the Hollywood star.\n\narp/bfm\n\nMore from this section\n\nClosing arguments, jury instructions and maybe a verdict? Major week looms in Trump hush money trial\n\nBill Walton, Hall of Fame player who became a star broadcaster, dies of cancer at 71\n\nAt least 22 dead in Memorial Day weekend storms that devastated several US states", "source": {"uri": "kulr8.com", "dataType": "news", "title": "KULR-8 Local News"}, "authors": [{"uri": "agence_france_presse@kulr8.com", "name": "Agence France-Presse", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 5, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 4, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/National_Security_Agency", "type": "wiki", "score": 2, "label": {"eng": "National Security Agency"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 2, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 2, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Hollywood,_Los_Angeles", "type": "wiki", "score": 1, "label": {"eng": "Hollywood, Los Angeles"}}, {"uri": "http://en.wikipedia.org/wiki/Pro_Football_Hall_of_Fame", "type": "wiki", "score": 1, "label": {"eng": "Pro Football Hall of Fame"}}, {"uri": "http://en.wikipedia.org/wiki/Scarlett_Johansson", "type": "person", "score": 1, "label": {"eng": "Scarlett Johansson"}}, {"uri": "http://en.wikipedia.org/wiki/Memorial_Day", "type": "wiki", "score": 1, "label": {"eng": "Memorial Day"}}, {"uri": "http://en.wikipedia.org/wiki/Cancer", "type": "wiki", "score": 1, "label": {"eng": "Cancer"}}, {"uri": "http://en.wikipedia.org/wiki/Donald_Trump", "type": "person", "score": 1, "label": {"eng": "Donald Trump"}}, {"uri": "http://en.wikipedia.org/wiki/Twitter", "type": "org", "score": 1, "label": {"eng": "Twitter"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 20}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 20}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 19}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 20}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 19}], "image": "https://bloximages.newyork1.vip.townnews.com/kulr8.com/content/tncms/assets/v3/editorial/6/02/602d274e-9258-52ac-9efb-cc93690048d1/664e8a9441d1f.image.jpg?crop=512%2C269%2C0%2C36&resize=438%2C230&order=crop%2Cresize", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3647058823529412, "wgt": 179, "relevance": 1}
{"uri": "2024-05-370694156", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "10:25:45", "dateTime": "2024-05-28T10:25:45Z", "dateTimePub": "2024-05-28T10:00:00Z", "dataType": "news", "sim": 0.7019608020782471, "url": "https://www.axios.com/2024/05/28/openai-safety-new-model", "title": "OpenAI announces new safety committee and successor to GPT-4", "body": "Driving the news: OpenAI says it has established a new safety and security committee to be led by outside chairman Bret Taylor along with board members Adam D'Angelo, Nicole Seligman, and Sam Altman.\n\nOpenAI also used Tuesday's announcement to officially confirm that it has started training its next big large language model, although recent comments from both Microsoft and OpenAI suggested this was already taking place.\n\nContext: OpenAI's moves come after the resignations of co-founder Ilya Sutskever and Jan Leike, who together led the company's long-term safety work, dubbed \"superalignment.\" Leike criticized OpenAI for not supporting the work of his superalignment team in a thread he posted announcing his departure.\n\nBetween the lines: OpenAI is clearly trying to reassure the world that it's taking its security responsibilities seriously and not ignoring recent criticism.", "source": {"uri": "axios.com", "dataType": "news", "title": "Axios"}, "authors": [{"uri": "ina_fried@axios.com", "name": "Ina Fried", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 2, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 17}, {"uri": "dmoz/Recreation/Autos/Driving_and_Safety", "label": "dmoz/Recreation/Autos/Driving and Safety", "wgt": 16}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 18}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 15}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 18}], "image": "https://images.axios.com/oaaOisGhLTT6ZpVJpEu_UcFghM4=/0x0:1920x1080/1366x768/2024/05/28/1716860189679.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.2470588235294118, "wgt": 179, "relevance": 1}
{"uri": "2024-05-371038804", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "15:20:40", "dateTime": "2024-05-28T15:20:40Z", "dateTimePub": "2024-05-28T12:49:38Z", "dataType": "news", "sim": 0.7019608020782471, "url": "https://tulsaworld.com/ap/business/openai-forms-safety-committee-as-it-starts-training-latest-artificial-intelligence-model/article_c1a47c33-1396-5be1-bdcb-85be82c34e29.html", "title": "OpenAI forms safety committee as it starts training latest artificial intelligence model", "body": "OpenAI says it's setting up a new safety and security committee and has begun training a new artificial intelligence model to supplant the GPT-4 system that underpins its ChatGPT chatbot\n\nAssociated Press\n\nOpenAI says it's setting up a safety and security committee and has begun training a new AI model to supplant the GPT-4 system that underpins its ChatGPT chatbot.\n\nThe San Francisco startup said in a blog post Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations.\n\nThe safety committee arrives as debate swirls around AI safety at the company, which was thrust into the spotlight after a researcher, Jan Leike, resigned and leveled criticism at OpenAI for letting safety \"take a backseat to shiny products.\" OpenAI co-founder and chief scientist Ilya Sutskever also resigned, and the company disbanded the \"superalignment\" team focused on AI risks that they jointly led.\n\nOpenAI said it has \"recently begun training its next frontier model\" and its AI models lead the industry on capability and safety, though it made no mention of the controversy. \"We welcome a robust debate at this important moment,\" the company said.\n\nPeople are also reading...\n\n'Four out of 6 survived it when it should have been zero' near Pryor Storms leave two dead in Pryor, tornado damage in Rogers, Mayes counties Update: Tornado confirmed just west of Claremore at 11:27 p.m. Patty Gasso has OU softball on brink of championship four-peat 33 years after last attempt by UCLA Trooper fired amid criminal case was disciplined before, agency records show Berry Tramel joining the Tulsa World After 'bittersweet' OU-Oregon regional, Melyssa Lombardi rooting for Sooners softball to four-peat as champions Things to do around Tulsa for Memorial Day weekend including festivals, rodeos and more Bedlam schools learn opening opponents, times for Thursday's WCWS first-round games Viral video of attack on Jenks school bus prompts inquiry amid online criticism Bill Haisten: A double-digit win total for OU or OSU? Not with these schedules Tulsa police chief search narrowed to five candidates Barons on 1st earns rare five-star review for its exceptional fine dining experience | Review City Councilor Jayme Fowler drops out of Tulsa mayor's race At least 15 dead in Oklahoma, Texas, Arkansas after severe weather roars across region\n\nAI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting edge AI systems.\n\nThe safety committee is filled with company insiders, including OpenAI CEO Sam Altman and Chairman Bret Taylor, and four OpenAI technical and policy experts. It also includes board members Adam D'Angelo, who's the CEO of Quora, and Nicole Seligman, a former Sony general counsel.\n\nThe committee's first job will be to evaluate and further develop OpenAI's processes and safeguards and make its recommendations to the board in 90 days. The company said it will then publicly release the recommendations it's adopting \"in a manner that is consistent with safety and security.\"\n\n-- --\n\nThe Associated Press and OpenAI have a licensing and technology agreement that allows OpenAI access to part of the AP's text archives.\n\nCopyright 2024 The Associated Press. All rights reserved. This material may not be published, broadcast, rewritten or redistributed without permission.\n\nThe business news you need\n\nGet the latest local business news delivered FREE to your inbox weekly.\n\nSign up!\n\n* I understand and agree that registration on or use of this site constitutes agreement to its user agreement and privacy policy.", "source": {"uri": "tulsaworld.com", "dataType": "news", "title": "Tulsa World"}, "authors": [{"uri": "associated_press@tulsaworld.com", "name": "Associated Press", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 5, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 5, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 5, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 3, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 3, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Tornado", "type": "wiki", "score": 3, "label": {"eng": "Tornado"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Associated_Press", "type": "org", "score": 3, "label": {"eng": "Associated Press"}}, {"uri": "http://en.wikipedia.org/wiki/Softball", "type": "wiki", "score": 3, "label": {"eng": "Softball"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Tulsa,_Oklahoma", "type": "loc", "score": 3, "label": {"eng": "Tulsa, Oklahoma"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Oklahoma_Sooners", "type": "wiki", "score": 2, "label": {"eng": "Oklahoma Sooners"}}, {"uri": "http://en.wikipedia.org/wiki/University_of_California,_Los_Angeles", "type": "org", "score": 2, "label": {"eng": "University of California, Los Angeles"}}, {"uri": "http://en.wikipedia.org/wiki/Rodeo", "type": "wiki", "score": 2, "label": {"eng": "Rodeo"}}, {"uri": "http://en.wikipedia.org/wiki/Tulsa_World", "type": "wiki", "score": 2, "label": {"eng": "Tulsa World"}}, {"uri": "http://en.wikipedia.org/wiki/Memorial_Day", "type": "wiki", "score": 2, "label": {"eng": "Memorial Day"}}, {"uri": "http://en.wikipedia.org/wiki/Viral_video", "type": "wiki", "score": 2, "label": {"eng": "Viral video"}}, {"uri": "http://en.wikipedia.org/wiki/County_(United_States)", "type": "wiki", "score": 2, "label": {"eng": "County (United States)"}}, {"uri": "http://en.wikipedia.org/wiki/Jenks,_Oklahoma", "type": "loc", "score": 2, "label": {"eng": "Jenks, Oklahoma"}, "location": {"type": "place", "label": {"eng": "Jenks, Oklahoma"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/New_York_City_Council", "type": "org", "score": 1, "label": {"eng": "New York City Council"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Video_on_demand", "type": "wiki", "score": 1, "label": {"eng": "Video on demand"}}, {"uri": "http://en.wikipedia.org/wiki/General_counsel", "type": "wiki", "score": 1, "label": {"eng": "General counsel"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy_policy", "type": "wiki", "score": 1, "label": {"eng": "Privacy policy"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}, {"uri": "http://en.wikipedia.org/wiki/Texas", "type": "loc", "score": 1, "label": {"eng": "Texas"}, "location": {"type": "place", "label": {"eng": "Texas"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Oklahoma", "type": "loc", "score": 1, "label": {"eng": "Oklahoma"}, "location": {"type": "place", "label": {"eng": "Oklahoma"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Arkansas", "type": "loc", "score": 1, "label": {"eng": "Arkansas"}, "location": {"type": "place", "label": {"eng": "Arkansas"}, "country": {"type": "country", "label": {"eng": "United States"}}}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 23}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 24}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 28}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 21}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 23}, {"uri": "news/Business", "label": "news/Business", "wgt": 98}], "image": "https://bloximages.newyork1.vip.townnews.com/tulsaworld.com/content/tncms/assets/v3/editorial/d/3a/d3a0e613-6811-52c9-8de6-bb496c0e9148/6655c207a991a.image.jpg?crop=1763%2C926%2C0%2C124&resize=438%2C230&order=crop%2Cresize", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.411764705882353, "wgt": 179, "relevance": 1}
{"uri": "8150052623", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:59:22", "dateTime": "2024-05-28T14:59:22Z", "dateTimePub": "2024-05-28T14:58:42Z", "dataType": "news", "sim": 0.7019608020782471, "url": "https://finance.yahoo.com/news/openai-announces-committee-focused-safety-101244622.html", "title": "OpenAI announces new committee focused on \"safety and security\"", "body": "Investing.com -- OpenAI has announced that it has formed a new committee focused on \"safety and security\" as the ChatGPT-maker said it has begun to train a next-generation artificial intelligence model.\n\nIn a statement, the Microsoft-backed group said the committee will be \"responsible for making recommendations to the full Board on critical safety and security decisions for OpenAI projects and operations.\"\n\nOpenAI Chief Executive Sam Altman and Chair Bret Taylor are both serving on the committee, along with directors Adam D'Angelo and Nicole Seligman.\n\nThe company said the committee members will be tasked with evaluating and \"further develop[ing]\" OpenAI's processes and safeguards over the next 90 days. At the end of this period, the members will share their recommendations with the full board.\n\nOpenAI, which faces intensifying competition from the likes of Alphabet-owned Google (NASDAQ:GOOGL) and Elon Musk's xAI, is also moving to reassure lawmakers that it pursuing the responsible development of AI.\n\nFormer chief Scientist Ilya Sutskever and Jan Leike, a leader on OpenaI's Superalignment team aimed at ensuring that AI performs only its intended objectives, both stepped down from their roles earlier this month. The Superalignment team has also been disbanded, according to CNBC.\n\nSan Francisco-based OpenAI, which on Tuesday also said that its latest AI systems will \"bring us to the next level of capabilities,\" noted that it \"welcomes a robust debate\" around the safety of the nascent technology.\n\nOpenAI announces new committee focused on \"safety and security\"\n\nWall Street firms start coverage of Viking Holdings after post-IPO gains", "source": {"uri": "finance.yahoo.com", "dataType": "news", "title": "Yahoo! Finance"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Bret_Taylor", "type": "person", "score": 2, "label": {"eng": "Bret Taylor"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Elon_Musk", "type": "person", "score": 2, "label": {"eng": "Elon Musk"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 2, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Wall_Street", "type": "wiki", "score": 1, "label": {"eng": "Wall Street"}}, {"uri": "http://en.wikipedia.org/wiki/CNBC", "type": "org", "score": 1, "label": {"eng": "CNBC"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 19}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 21}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 22}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 21}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 26}, {"uri": "news/Business", "label": "news/Business", "wgt": 53}], "image": "https://s.yimg.com/cv/apiv2/social/images/yahoo_default_logo-1200x1200.png", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.4431372549019608, "wgt": 179, "relevance": 1}
{"uri": "8150198728", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "16:38:50", "dateTime": "2024-05-28T16:38:50Z", "dateTimePub": "2024-05-28T16:38:07Z", "dataType": "news", "sim": 0.6980392336845398, "url": "https://the-decoder.com/openai-begins-training-of-new-flagship-model/", "title": "OpenAI says it has \"recently begun training its next frontier model\"", "body": "Online journalist Matthias is the co-founder and publisher of THE DECODER. He believes that artificial intelligence will fundamentally change the relationship between humans and computers.\n\nOpenAI has announced the start of training for a new flagship model and introduced new safety measures.\n\nThe OpenAI Board of Directors has formed a new Safety and Security Committee, led by directors Bret Taylor, Adam D'Angelo, Nicole Seligman, and CEO Sam Altman. Over the next 90 days, the committee will develop recommendations on critical security decisions for all OpenAI projects, the company announced today.\n\nOpenAI also revealed that it has \"recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI.\"\n\nOnce the discussions are complete, OpenAI plans to make the committee's recommendations public, to the extent permitted by security requirements. The committee includes OpenAI experts from the technology and policy communities, such as former Cyber Commissioner Rob Joyce, and other outside security experts.\n\nThe announcement of a new safety and security unit is likely a response to criticism over the past two weeks, during which many AGI security researchers turned their backs on OpenAI, accusing the company of allegedly careless safety practices. OpenAI has dissolved the team responsible for developing a super AI and integrated the measures into existing security teams.\n\nRumor has it that OpenAI plans to release an intermediate step like GPT-4.5 this summer. GPT-5 is more likely planned for the end of the year.\n\nAt Microsoft's Build developer conference, Microsoft CTO Kevin Scott showed a slide with an OpenAI model to be released in 2024. Although the axes are not labeled, the image suggests a big jump compared to GPT-4.\n\nAn OpenAI researcher showed a similar graph at the Viva Technology tech festival in Paris. Here, the model to be released in 2024 was called \"GPT-Next\" and also ranked well above GPT-4 in terms of capabilities.\n\n\"Recently\" is a rather flexible term, so the new flagship model could even be the successor to GPT-5. The training phase is likely to take several months, followed by functional and safety testing, which could also take months. A training start in May or April might be too late for a fall launch.", "source": {"uri": "the-decoder.com", "dataType": "news", "title": "THE DECODER"}, "authors": [{"uri": "matthias_bastian@the-decoder.com", "name": "Matthias Bastian", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Computer", "type": "wiki", "score": 3, "label": {"eng": "Computer"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 2, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 1, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Graph_(discrete_mathematics)", "type": "wiki", "score": 1, "label": {"eng": "Graph (discrete mathematics)"}}, {"uri": "http://en.wikipedia.org/wiki/Google_I/O", "type": "wiki", "score": 1, "label": {"eng": "O"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_technology_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief technology officer"}}, {"uri": "http://en.wikipedia.org/wiki/Paris", "type": "loc", "score": 1, "label": {"eng": "Paris"}, "location": {"type": "place", "label": {"eng": "Paris"}, "country": {"type": "country", "label": {"eng": "France"}}}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 23}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 21}, {"uri": "dmoz/Computers/Security/Advisories_and_Patches", "label": "dmoz/Computers/Security/Advisories and Patches", "wgt": 22}, {"uri": "dmoz/Computers/Hacking/Conventions", "label": "dmoz/Computers/Hacking/Conventions", "wgt": 19}, {"uri": "dmoz/Computers/Security/FAQs,_Help,_and_Tutorials", "label": "dmoz/Computers/Security/FAQs, Help, and Tutorials", "wgt": 21}, {"uri": "news/Business", "label": "news/Business", "wgt": 59}], "image": "https://the-decoder.com/wp-content/uploads/2024/05/openai_chatgpt_present.png", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.2941176470588236, "wgt": 178, "relevance": 1}
{"uri": "8149989895", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:18:01", "dateTime": "2024-05-28T14:18:01Z", "dateTimePub": "2024-05-28T14:17:12Z", "dataType": "news", "sim": 0.6941176652908325, "url": "https://www.investing.com/news/stock-market-news/openai-announces-new-committee-focused-on-safety-and-security-3459190", "title": "OpenAI announces new committee focused on \"safety and security\" By Investing.com", "body": "Investing.com -- OpenAI has announced that it has formed a new committee focused on \"safety and security\" as the ChatGPT-maker said it has begun to train a next-generation artificial intelligence model.\n\nIn a statement, the Microsoft-backed group said the committee will be \"responsible for making recommendations to the full Board on critical safety and security decisions for OpenAI projects and operations.\"\n\nOpenAI Chief Executive Sam Altman and Chair Bret Taylor are both serving on the committee, along with directors Adam D'Angelo and Nicole Seligman.\n\nThe company said the committee members will be tasked with evaluating and \"further develop[ing]\" OpenAI's processes and safeguards over the next 90 days. At the end of this period, the members will share their recommendations with the full board.\n\nOpenAI, which faces intensifying competition from the likes of Alphabet-owned Google (NASDAQ:GOOGL) and Elon Musk's xAI, is also moving to reassure lawmakers that it pursuing the responsible development of AI.\n\nFormer chief Scientist Ilya Sutskever and Jan Leike, a leader on OpenaI's Superalignment team aimed at ensuring that AI performs only its intended objectives, both stepped down from their roles earlier this month. The Superalignment team has also been disbanded, according to CNBC.\n\nSan Francisco-based OpenAI, which on Tuesday also said that its latest AI systems will \"bring us to the next level of capabilities,\" noted that it \"welcomes a robust debate\" around the safety of the nascent technology.", "source": {"uri": "investing.com", "dataType": "news", "title": "Investing.com"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/CNBC", "type": "org", "score": 1, "label": {"eng": "CNBC"}}, {"uri": "http://en.wikipedia.org/wiki/Elon_Musk", "type": "person", "score": 1, "label": {"eng": "Elon Musk"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 1, "label": {"eng": "Google"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 16}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 19}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 20}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 19}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 25}], "image": "https://i-invdn-com.investing.com/news/moved_LYNXMPEJAJ08W_L.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.4431372549019608, "wgt": 177, "relevance": 1}
{"uri": "8150351650", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "18:40:07", "dateTime": "2024-05-28T18:40:07Z", "dateTimePub": "2024-05-28T18:39:18Z", "dataType": "news", "sim": 0.6901960968971252, "url": "https://techbullion.com/openai-establishes-a-safety-and-security-committee-for-all-openai-projects/", "title": "OpenAI Establishes a Safety and Security Committee for all OpenAI projects.", "body": "OpenAI has established a Safety and Security Committee for all OpenAI projects.\n\nTakeaway Points\n\nOpenAI establishes a Safety and Security Committee for all OpenAI projects. This committee will be responsible for making recommendations on critical safety and security decisions for all OpenAI projects. The Safety and Security Committee is led by directors Bret Taylor (chair), Adam D'Angelo, Nicole Seligman, and Sam Altman (CEO). On May 22, 2024, OpenAI partnered with News Corp. to bring News Corp. news content to OpenAI. Why did OpenAI establish a Safety and Security Committee?\n\nThe AI research and deployment company OpenAI, announced on Tuesday that its board has established a Safety and Security Committee. This committee will be responsible for making recommendations on critical safety and security decisions for all OpenAI projects within 90 days.\n\n\"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI. While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment. A first task of the Safety and Security Committee will be to evaluate and further develop OpenAI's processes and safeguards over the next 90 days. At the conclusion of the 90 days, the Safety and Security Committee will share their recommendations with the full Board. Following the full Board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security,\" OpenAI said.\n\nThe firm said that the Safety and Security Committee is led by directors Bret Taylor (Chair), Adam D'Angelo, Nicole Seligman, and Sam Altman (CEO). Other members include OpenAI technical and policy experts Aleksander Madry (Head of Preparedness), Lilian Weng (Head of Safety Systems), John Schulman (Head of Alignment Science), Matt Knight (Head of Security), Jakub Pachocki (Chief Scientist), and former cybersecurity officials Rob Joyce, who advises OpenAI on security, and John Carlin.\n\nOpenAI partners with News Corp.\n\nOn May 22, 2024, OpenAI announced that it had partnered with News Corp. to bring News Corp. news content to OpenAI. According to the report, OpenAI has the authority to display content from News Corp mastheads in response to user questions.\n\nRobert Thomson, Chief Executive of News Corp., said in a comment, \"We believe an historic agreement will set new standards for veracity, for virtue and for value in the digital age. We are delighted to have found principled partners in Sam Altman and his trusty, talented team who understand the commercial and social significance of journalists and journalism. This landmark accord is not an end, but the beginning of a beautiful friendship in which we are jointly committed to creating and delivering insight and integrity instantaneously.\"\n\nSam Altman, CEO of OpenAI, said, \"Our partnership with News Corp is a proud moment for journalism and technology. We greatly value News Corp's history as a leader in reporting breaking news around the world, and are excited to enhance our users' access to its high quality reporting. Together, we are setting the foundation for a future where AI deeply respects, enhances, and upholds the standards of world-class journalism.\"\n\nOpenAI said that through this partnership it will receive access to current and archived content from News Corp's major news and information publications, including The Wall Street Journal, Barron's, MarketWatch, Investor's Business Daily, FN, and New York Post; The Times, The Sunday Times, and The Sun; The Australian, news.com.au, The Daily Telegraph, The Courier Mail, The Advertiser, and Herald Sun; and others.\n\nRelated Items:News Corp, OpenAI, safety Recommended for you OpenAI Withdraws Controversial Decision Elon Musk And Baidu's CEO Predict Smarter-than-humans AI What is Openai and How to use Chat Gpt in 2024?", "source": {"uri": "techbullion.com", "dataType": "news", "title": "TechBullion"}, "authors": [{"uri": "angela_scott_briggs@techbullion.com", "name": "Angela Scott-Briggs", "type": "author", "isAgency": false}, {"uri": "sandy_wincefort@techbullion.com", "name": "Sandy Wincefort", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/News_Corp", "type": "wiki", "score": 5, "label": {"eng": "News Corp"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 4, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 4, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 4, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 2, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Journalism", "type": "wiki", "score": 2, "label": {"eng": "Journalism"}}, {"uri": "http://en.wikipedia.org/wiki/News.com.au", "type": "wiki", "score": 1, "label": {"eng": "News.com.au"}}, {"uri": "http://en.wikipedia.org/wiki/The_Advertiser_(Adelaide)", "type": "wiki", "score": 1, "label": {"eng": "The Advertiser (Adelaide)"}}, {"uri": "http://en.wikipedia.org/wiki/MarketWatch", "type": "wiki", "score": 1, "label": {"eng": "MarketWatch"}}, {"uri": "http://en.wikipedia.org/wiki/The_Sunday_Times", "type": "wiki", "score": 1, "label": {"eng": "The Sunday Times"}}, {"uri": "http://en.wikipedia.org/wiki/Barron's_(newspaper)", "type": "wiki", "score": 1, "label": {"eng": "Barron's (newspaper)"}}, {"uri": "http://en.wikipedia.org/wiki/The_Courier-Mail", "type": "wiki", "score": 1, "label": {"eng": "The Courier-Mail"}}, {"uri": "http://en.wikipedia.org/wiki/Investor's_Business_Daily", "type": "wiki", "score": 1, "label": {"eng": "Investor's Business Daily"}}, {"uri": "http://en.wikipedia.org/wiki/Herald_Sun", "type": "wiki", "score": 1, "label": {"eng": "Herald Sun"}}, {"uri": "http://en.wikipedia.org/wiki/The_Daily_Telegraph", "type": "wiki", "score": 1, "label": {"eng": "The Daily Telegraph"}}, {"uri": "http://en.wikipedia.org/wiki/Baidu", "type": "org", "score": 1, "label": {"eng": "Baidu"}}, {"uri": "http://en.wikipedia.org/wiki/The_Australian", "type": "wiki", "score": 1, "label": {"eng": "The Australian"}}, {"uri": "http://en.wikipedia.org/wiki/The_Wall_Street_Journal", "type": "wiki", "score": 1, "label": {"eng": "The Wall Street Journal"}}, {"uri": "http://en.wikipedia.org/wiki/New_York_Post", "type": "wiki", "score": 1, "label": {"eng": "New York Post"}}, {"uri": "http://en.wikipedia.org/wiki/The_Sun_(United_Kingdom)", "type": "wiki", "score": 1, "label": {"eng": "The Sun (United Kingdom)"}}, {"uri": "http://en.wikipedia.org/wiki/Elon_Musk", "type": "person", "score": 1, "label": {"eng": "Elon Musk"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 28}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 27}, {"uri": "dmoz/Computers/Security/Advisories_and_Patches", "label": "dmoz/Computers/Security/Advisories and Patches", "wgt": 27}, {"uri": "dmoz/Computers/Security/FAQs,_Help,_and_Tutorials", "label": "dmoz/Computers/Security/FAQs, Help, and Tutorials", "wgt": 27}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 80}], "image": "https://techbullion.com/wp-content/uploads/2024/05/OpenAI-2.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.5372549019607844, "wgt": 176, "relevance": 1}
{"uri": "8150148268", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "16:02:48", "dateTime": "2024-05-28T16:02:48Z", "dateTimePub": "2024-05-28T16:02:24Z", "dataType": "news", "sim": 0.686274528503418, "url": "https://www.theregister.com/2024/05/28/openai_establishes_new_safety_group/", "title": "OpenAI sets up safety group in wake of high-profile exits", "body": "AI biz forms Safety and Security Committee to succeed Superalignment team as it trains latest GPT model\n\nOpenAI has created a new safety group as it works on the successor to GPT-4 while grappling with the recent departure of high-profile members who criticized its commercial intent.\n\nTermed the Safety and Security Committee (SSC), the team's leadership includes OpenAI CEO Sam Altman, Bret Taylor (who is set to be the chair), Adam D'Angelo, and Nicole Seligman, all of whom also sit on the board of directors.\n\nOther SSC members include various team leaders at OpenAI, including Jakub Pachocki, who has been chief scientist for just 13 days after he replaced co-founder Ilya Sutskever.\n\nOpenAI says the safety team will advise the board of directors on \"critical safety and security decisions\" from now on. Those decisions will, presumably, impact the development of the successor to GPT-4, which OpenAI briefly mentions in its announcement as its \"next frontier model.\"\n\n\"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment,\" the company said, without specifying what it expects to be discussed.\n\nFirst on the docket is a 90-day period of developing safety recommendations for the board's consideration, though the implication is that Altman and other directors have the final say as they get to review the recommendations. Naturally, the OpenAI CEO and the four other leads will also have their chance to influence the recommendations before they even reach the board of directors.\n\nThe formation of the new security board is likely wrapped up with two high-profile departures that happened earlier this month: that of Sutskever and Jan Leike. Their exits from OpenAI were immediately followed by the dissolution of the company's Superalignment group, which existed to evaluate AI safety concerns over the long term. Leike had been the leader of the Superalignment team up until his departure.\n\nOpenAI also lost Daniel Kokotajlo, who worked on OpenAI's governance team, earlier this month, and in February co-founder Andrej Karpathy quit as well.\n\nWhile Sutskever and Karpathy have declined to delve too deeply into the reasoning behind their departures, Leike and Kokotajlo have made it clear that they resigned over disagreements on AI safety.\n\n\"Over the past years, safety culture and processes have taken a backseat to shiny products,\" Leike said the day before the Superalignment team was abolished. \"We are long overdue in getting incredibly serious about the implications of AGI... OpenAI must become a safety-first AGI company.\"\n\nSimilarly, Kokotajlo said he \"quit OpenAI due to losing confidence that it would behave responsibly around the time of AGI.\"\n\nAI safety is undoubtedly a contentious issue at OpenAI, and that's probably a key reason why the new Safety and Security Committee was created. Although whether the new group will actually satisfy safety advocates is an open question. \u00ae", "source": {"uri": "theregister.com", "dataType": "news", "title": "theregister.com"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 4, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 4, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 3, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 2, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Andrej_Karpathy", "type": "person", "score": 1, "label": {"eng": "Andrej Karpathy"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 32}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 31}, {"uri": "dmoz/Home/Cooking/Safety", "label": "dmoz/Home/Cooking/Safety", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 29}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 34}], "image": "https://regmedia.co.uk/2024/01/29/openai.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.4745098039215687, "wgt": 175, "relevance": 1}
{"uri": "8149687544", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "11:12:55", "dateTime": "2024-05-28T11:12:55Z", "dateTimePub": "2024-05-28T11:12:21Z", "dataType": "news", "sim": 0.686274528503418, "url": "https://www.yahoo.com/tech/openai-sets-safety-security-committee-102511837.html", "title": "OpenAI sets up safety and security committee and starts training 'next frontier model'", "body": "The move comes amid scrutiny over OpenAI's commitment to AI safety.\n\nOpenAI said it has set up a safety and security committee to make recommendations to the board on \"critical safety and security decisions.\"\n\nThe committee will be chaired by Bret Taylor, and include fellow directors Adam D'Angelo and Nicole Seligman as well as CEO Sam Altman.\n\nThe company also said it had begun training a new flagship AI model to succeed GPT-4.\n\nIt said in a Tuesday blogpost: \"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI.\"\n\nOpenAI recently launched its updated GPT-4o model, which uses native audio inputs and outputs. When integrated into ChatGPT, users can have human-like conversations with the bot, speaking to it and showing it things.", "source": {"uri": "yahoo.com", "dataType": "news", "title": "Yahoo"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 3, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 2, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 1, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 21}, {"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 21}, {"uri": "dmoz/Recreation/Models/Scale", "label": "dmoz/Recreation/Models/Scale", "wgt": 20}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 20}], "image": "https://s.yimg.com/ny/api/res/1.2/IMrRVuenHHur511Xp4yLhg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD05MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/business_insider_articles_888/d2ea6faf68cbeaf941b4849c0f7b6aa1", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3411764705882352, "wgt": 175, "relevance": 1}
{"uri": "8149757823", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "11:56:53", "dateTime": "2024-05-28T11:56:53Z", "dateTimePub": "2024-05-28T11:56:17Z", "dataType": "news", "sim": 0.686274528503418, "url": "https://www.punjabnewsexpress.com/business/news/openai-board-forms-safety-and-security-committee-led-by-altman-others-251003", "title": "OpenAI Board forms Safety and Security Committee led by Altman, others", "body": "SAN FRANCISCO: ChatGPT maker OpenAI Board has formed a Safety and Security Committee led by directors Sam Altman (CEO), Bret Taylor (Chair), Adam D'Angelo, and Nicole Seligman, the company said on Tuesday.\n\nAccording to the AI startup, this committee will be responsible for making suggestions to the full Board on critical safety and security decisions for the company's projects and operations.\n\n\"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI, \" OpenAI said in a blogpost.\n\n\"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment, \" it added.\n\nThe first task of this committee will be to evaluate and further develop OpenAI's processes and safeguards over the next 90 days.\n\nAfter 90 days, the committee will share its suggestions with the full Board.\n\n\"Following the full Board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security, \" the company mentioned.\n\nIn addition, the ChatGPT maker said that OpenAI technical and policy experts Aleksander Madry (Head of Preparedness), Lilian Weng (Head of Safety Systems), John Schulman (Head of Alignment Science), Matt Knight (Head of Security), and Jakub Pachocki (Chief Scientist) will also be on the committee.", "source": {"uri": "punjabnewsexpress.com", "dataType": "news", "title": "punjabnewsexpress.com"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_scientific_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief scientific officer"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 21}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 24}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 24}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 25}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 25}], "image": "https://www.punjabnewsexpress.com/images/article/article251003.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}, "extractedDates": null, "sentiment": 0.4980392156862745, "wgt": 175, "relevance": 1}
{"uri": "8150162471", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "16:12:16", "dateTime": "2024-05-28T16:12:16Z", "dateTimePub": "2024-05-28T16:11:52Z", "dataType": "news", "sim": 0.6823529601097107, "url": "https://arstechnica.com/information-technology/2024/05/openai-training-its-next-major-ai-model-forms-new-safety-committee/", "title": "OpenAI training its next major AI model, forms new safety committee", "body": "GPT-5 might be farther off than we thought, but OpenAI wants to make sure it is safe.\n\nOn Monday, OpenAI announced the formation of a new \"Safety and Security Committee\" to oversee risk management for its projects and operations. The announcement comes as the company says it has \"recently begun\" training its next frontier model, which it expects to bring the company closer to its goal of achieving artificial general intelligence (AGI), though some critics say AGI is farther off than we might think. It also comes as a reaction to a terrible two weeks in the press for the company.\n\nFurther Reading\n\nWhether the aforementioned new frontier model is intended to be GPT-5 or a step beyond that is currently unknown. In the AI industry, \"frontier model\" is a term for a new AI system designed to push the boundaries of current capabilities. And \"AGI\" refers to a hypothetical AI system with human-level abilities to perform novel, general tasks beyond its training data (unlike narrow AI, which is trained for specific tasks).\n\nMeanwhile, the new Safety and Security Committee, led by OpenAI directors Bret Taylor (chair), Adam D'Angelo, Nicole Seligman, and Sam Altman (CEO), will be responsible for making recommendations about AI safety to the full company board of directors. In this case, \"safety\" partially means the usual \"we won't let the AI go rogue and take over the world,\" but it also includes a broader set of \"processes and safeguards\" that the company spelled out in a May 21 safety update related to alignment research, protecting children, upholding election integrity, assessing societal impacts, and implementing security measures.\n\nOpenAI says the committee's first task will be to evaluate and further develop those processes and safeguards over the next 90 days. At the end of this period, the committee will share its recommendations with the full board, and OpenAI will publicly share an update on adopted recommendations.\n\nOpenAI says that multiple technical and policy experts, including Aleksander Madry (head of preparedness), Lilian Weng (head of safety systems), John Schulman (head of alignment science), Matt Knight (head of security), and Jakub Pachocki (chief scientist), will also serve on its new committee.\n\nThe announcement is notable in a few ways. First, it's a reaction to negative press that came from OpenAI Superalignment team members Ilya Sutskever and Jan Leike resigning two weeks ago. That team was tasked with \"steer[ing] and control[ling] AI systems much smarter than us,\" and their departure has led to criticism from some within the AI community (and Leike himself) that OpenAI lacks a commitment to developing highly capable AI safely. Other critics, like Meta Chief AI Scientist Yann LeCun, think the company is nowhere near developing AGI, so the concern over a lack of safety for superintelligent AI may be overblown.\n\nFurther Reading\n\nSecond, there have been persistent rumors that progress in large language models (LLMs) has plateaued recently around capabilities similar to GPT-4. Two major competing models, Anthropic's Claude Opus and Google's Gemini 1.5 Pro, are roughly equivalent to the GPT-4 family in capability despite every competitive incentive to surpass it. And recently, when many expected OpenAI to release a new AI model that would clearly surpass GPT-4 Turbo, it instead released GPT-4o, which is roughly equivalent in ability but faster. During that launch, the company relied on a flashy new conversational interface rather than a major under-the-hood upgrade.\n\nWe've previously reported on a rumor of GPT-5 coming this summer, but with this recent announcement, it seems the rumors may have been referring to GPT-4o instead. It's quite possible that OpenAI is nowhere near releasing a model that can significantly surpass GPT-4. But with the company quiet on the details, we'll have to wait and see.", "source": {"uri": "arstechnica.com", "dataType": "news", "title": "Ars Technica"}, "authors": [{"uri": "benj_edwards@arstechnica.com", "name": "Benj Edwards", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 2, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 1, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 1, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 1, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Yann_LeCun", "type": "person", "score": 1, "label": {"eng": "Yann LeCun"}}, {"uri": "http://en.wikipedia.org/wiki/Superintelligence", "type": "wiki", "score": 1, "label": {"eng": "Superintelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 1, "label": {"eng": "Google"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 16}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 19}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 17}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 20}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 15}, {"uri": "news/Business", "label": "news/Business", "wgt": 63}], "image": "https://cdn.arstechnica.net/wp-content/uploads/2024/05/boulder_header-760x380.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-05-21", "textStart": 1485, "textEnd": 1491}], "sentiment": 0.3490196078431373, "wgt": 174, "relevance": 1}
{"uri": "8149957688", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "13:57:53", "dateTime": "2024-05-28T13:57:53Z", "dateTimePub": "2024-05-28T13:57:07Z", "dataType": "news", "sim": 0.6823529601097107, "url": "https://www.sandiegouniontribune.com/business/technology/story/2024-05-28/openai-starts-training-a-new-ai-model-to-power-chatgpt", "title": "OpenAI starts training a new AI model to power ChatGPT", "body": "Artificial intelligence company OpenAI said Tuesday that it has started training its newest AI model that will fuel the popular ChatGPT chatbot.\n\nIn a statement released on its website, OpenAI said this new model, which would replace GPT-4 technology, will bring the company closer to achieving \"AGI,\" or artificial general intelligence, a hotly contested idea that refers to computers matching the power of human brains.\n\nOpenAI also announced that it is forming a new committee, including CEO Sam Altman, to evaluate the safety and security of its products, and pledged to release recommendations sometime after a 90-day review of its technology.\n\n\"We welcome a robust debate at this important moment,\" the company said.\n\nThe San Francisco-based company is one of the leading players in artificial intelligence, with widely used tools such as ChatGPT and image creator Dall-E. The technology behind them has been adopted by large companies such as Microsoft, one of OpenAI's biggest financial backers.\n\nTuesday's announcements come amid turmoil for the San Francisco-based company as it faces mounting lawsuits, high-profile staff departures and concerns that AI technology will spread election disinformation, eliminate jobs and infringe on copyrights.\n\nEarlier this month, the company released an update to its latest AI technology, called GPT-4o or \"GPT-4 omni,\" that enhances ChatGPT's ability to listen and respond by voice. Actress Scarlett Johansson said one of the voices OpenAI released, called \"Sky,\" was \"eerily similar\" to hers, and that after declining overtures by Altman to voice the assistant, she was \"shocked, angered and in disbelief\" to find it sounding nearly identical to her speech.\n\nOpenAI said the voice was not hers, and documents shared with The Washington Post show the company hired a voice actor. Johansson has threatened to file legal action against OpenAI.\n\nThe company already faces lawsuits from news organizations, including local papers and the New York Times, saying that the way OpenAI trains its chatbot technology - by ingesting vast amounts of online data such as news stories, Wikipedia articles and even Reddit forums - is infringing on the copyrights of news organizations.\n\nOpenAI co-founder Ilya Sutskever, who co-led a team focused on the societal threats of AI, resigned from the company in May amid concern from critics that OpenAI was dismissing the dangers of its technology while chasing profit. His team co-lead, Jan Leike, also departed this month.\n\nSutskever was one of the board members who voted to oust co-founder Altman in November. Altman was reinstated a few days later, and Sutskever and the other directors who voted against him resigned from the board.\n\nThe new safety committee will be led by board Chairman Bret Taylor, Quora CEO Adam D'Angelo, former Sony Entertainment executive Nicole Seligman and Altman, OpenAI said.\n\nThe announcement of its formation comes just days after two former OpenAI board members said in an Economist article Sunday that more regulation of AI is needed because companies like OpenAI can't be trusted to govern themselves.", "source": {"uri": "sandiegouniontribune.com", "dataType": "news", "title": "San Diego Union-Tribune"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 4, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Human_brain", "type": "wiki", "score": 3, "label": {"eng": "Human brain"}}, {"uri": "http://en.wikipedia.org/wiki/Computer", "type": "wiki", "score": 3, "label": {"eng": "Computer"}}, {"uri": "http://en.wikipedia.org/wiki/Disinformation", "type": "wiki", "score": 2, "label": {"eng": "Disinformation"}}, {"uri": "http://en.wikipedia.org/wiki/Scarlett_Johansson", "type": "person", "score": 2, "label": {"eng": "Scarlett Johansson"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 2, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Wikipedia", "type": "wiki", "score": 1, "label": {"eng": "Wikipedia"}}, {"uri": "http://en.wikipedia.org/wiki/Reddit", "type": "org", "score": 1, "label": {"eng": "Reddit"}}, {"uri": "http://en.wikipedia.org/wiki/The_Economist", "type": "wiki", "score": 1, "label": {"eng": "The Economist"}}, {"uri": "http://en.wikipedia.org/wiki/The_Washington_Post", "type": "org", "score": 1, "label": {"eng": "The Washington Post"}}, {"uri": "http://en.wikipedia.org/wiki/The_New_York_Times", "type": "wiki", "score": 1, "label": {"eng": "The New York Times"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}], "categories": [{"uri": "dmoz/Arts/Animation/Voice_Actors", "label": "dmoz/Arts/Animation/Voice Actors", "wgt": 20}, {"uri": "dmoz/Business/Information_Technology", "label": "dmoz/Business/Information Technology", "wgt": 17}, {"uri": "dmoz/Computers/Speech_Technology/Telephony", "label": "dmoz/Computers/Speech Technology/Telephony", "wgt": 19}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 20}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 19}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 73}], "image": "https://ca-times.brightspotcdn.com/dims4/default/c26ca38/2147483647/strip/true/crop/1920x1008+0+36/resize/1200x630!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F18%2F87%2Fad2789124ebea11f3459aa4c4d66%2Fsdut-desktop-black.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3176470588235294, "wgt": 174, "relevance": 1}
{"uri": "8149764497", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "12:00:59", "dateTime": "2024-05-28T12:00:59Z", "dateTimePub": "2024-05-28T12:00:31Z", "dataType": "news", "sim": 0.6784313917160034, "url": "https://mashable.com/article/openai-training-new-gpt", "title": "OpenAI confirms GPT-4 successor in training stage", "body": "\"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI,\" reads the post, published Tuesday.\n\nOpenAI's GPT-4 was released in March 2023, a powerful update to GPT-3 which powered its successful ChatGPT chatbot launched in November 2022.\n\nMashable reached out to OpenAI for further information on the new AI model, and we were pointed to the blog.\n\nIn the same post, OpenAI also announced it has formed a Safety and Security Committee that \"will be responsible for making recommendations to the full Board on critical safety and security decisions for OpenAI projects and operations.\"\n\nThe committee will be comprised of directors Bret Taylor, Nicole Seligman, Adam D'Angelo, and OpenAI CEO Sam Altman.\n\n\"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment,\" OpenAI's post reads.\n\nThe news comes weeks after OpenAI unveiled GPT-4o, a multimodal AI voice assistant that combines text, vision, and audio, in April. The announcement put a new spotlight on the existing \"Sky\" option for ChatGPT's Voice Mode, which some had likened to actor Scarlett Johansson's fictional digital assistant in the 2013 film Her -- and yes, Johansson heard it too. The voice has been paused on ChatGPT for now.", "source": {"uri": "mashable.com", "dataType": "news", "title": "Mashable"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-3", "type": "wiki", "score": 3, "label": {"eng": "GPT-3"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Mashable", "type": "wiki", "score": 3, "label": {"eng": "Mashable"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Nicole_Seligman", "type": "person", "score": 2, "label": {"eng": "Nicole Seligman"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 1, "label": {"eng": "Virtual assistant"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 13}, {"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 13}, {"uri": "dmoz/Recreation/Models/Scale", "label": "dmoz/Recreation/Models/Scale", "wgt": 13}, {"uri": "dmoz/Arts/Animation/Voice_Actors", "label": "dmoz/Arts/Animation/Voice Actors", "wgt": 19}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 15}], "image": "https://helios-i.mashable.com/imagery/articles/05STTeXNN2K2eXzMf0OmXZS/hero-image.fill.size_1200x675.v1716892635.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3647058823529412, "wgt": 173, "relevance": 1}
{"uri": "8149911590", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "13:29:56", "dateTime": "2024-05-28T13:29:56Z", "dateTimePub": "2024-05-28T13:28:47Z", "dataType": "news", "sim": 0.6745098233222961, "url": "https://english.jagran.com/technology/openai-sets-up-safety-committee-as-it-starts-training-new-ai-model-details-10163533", "title": "OpenAI Sets Up Safety Committee As It Starts Training New AI Model; Details", "body": "OpenAI has established a Safety and Security Committee, which will be chaired by board members, including CEO Sam Altman, the AI startup announced on Tuesday. The committee will be led by directors Bret Taylor, Adam D'Angelo, and Nicole Seligman as well, OpenAI announced in a corporate blog.\n\nThe new committee will be in charge of advising the board on matters pertaining to security and safety for OpenAI's initiatives and activities.\n\nREAD: iPhone 16 Launch Date: Apple To Launch iPhone 16 In September? Production Likely To Begin Next Month\n\nOver the next ninety days, its first assignment will be to assess and refine OpenAI's current safety procedures. After that, it will present its recommendations to the board.\n\nOpenAI added that following the board's study, it will make available to the public an update on the recommendations that were implemented.\n\nJakub Pachocki, the recently hired Chief Scientist, and Matt Knight, the head of security, are among the other committee members.\n\nThe business will also confer with other specialists, such as John Carlin, a former officer of the Department of Justice, and Rob Joyce, a former head of cybersecurity for the United States National Security Agency.\n\nEarlier, Ilya Sutskever, the former chief scientist, and Jan Leike, the head of OpenAI's Super Alignment team, which made sure AI stayed in line with the goals, departed the company earlier this month.\n\nREAD: Centre Flags Vulnerabilities In Microsoft Windows, Office And Bing Users; 5 Tips To Be Safe\n\nDays after the high-profile departures, CNBC reported that OpenAI had dissolved the Superalignment team earlier in May, less than a year after the company established it, with some team members being relocated to other groups.\n\nThe only information provided by OpenAI about the new \"frontier\" model it is training is that it will advance its systems to the \"next level of capabilities on our path to AGI.\"\n\nMeanwhile, the company unveiled GPT-4o, a new AI model earlier in May that can engage in realistic voice communication and text-to-image interaction.", "source": {"uri": "english.jagran.com", "dataType": "news", "title": "Jagran English"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/IPhone", "type": "wiki", "score": 4, "label": {"eng": "IPhone"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Apple_Inc.", "type": "org", "score": 3, "label": {"eng": "Apple Inc."}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_scientific_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief scientific officer"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 2, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft_Bing", "type": "wiki", "score": 1, "label": {"eng": "Microsoft Bing"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/CNBC", "type": "org", "score": 1, "label": {"eng": "CNBC"}}, {"uri": "http://en.wikipedia.org/wiki/National_Security_Agency", "type": "wiki", "score": 1, "label": {"eng": "National Security Agency"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft_Windows", "type": "wiki", "score": 1, "label": {"eng": "Microsoft Windows"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 1, "label": {"eng": "Computer security"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 18}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 17}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 19}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 17}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 19}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 56}], "image": "https://imgeng.jagran.com/images/2024/05/28/article/image/OpenAI (5)-1716902385584.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3647058823529412, "wgt": 172, "relevance": 1}
{"uri": "8149876947", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "13:07:55", "dateTime": "2024-05-28T13:07:55Z", "dateTimePub": "2024-05-28T13:07:24Z", "dataType": "news", "sim": 0.6705882549285889, "url": "https://qz.com/openai-sam-altman-safety-security-committee-ai-1851503241", "title": "OpenAI has a new safety committee --  and of course it includes Sam Altman", "body": "The new oversight team will be led by board chair Bret Taylor, directors Adam D'Angelo and Nicole Seligman, and OpenAI's chief executive Sam Altman, the artificial intelligence company announced Tuesday. The committee's first task will be to evaluate and develop OpenAI's processes and safeguards over the next 90 days, the company said.\n\nAt the end of the three-month period, the committee will share its recommendations with the full board and, following review, the company will publicly share an update on adopted recommendations.\n\nThe company also confirmed that it has begun training its \"next frontier\" AI model that will succeed the GPT-4 model that powers its chatbot, ChatGPT, and will help it advance towards artificial general intelligence (AGI).\n\nThe safety committee will also include OpenAI technical and policy experts, including head of preparedness Aleksander Madry, head of safety systems Lilian Weng, head of alignment science John Schulman, head of security Matt Knight, and chief scientist Jakub Pachocki.\n\nThis comes after the company shuttered the team responsible for AI's existential dangers after the two co-leads of the company's so-called \"superalignment\" team -- co-founder and chief scientist Ilya Sutskever and Jan Leike -- resigned on May 14.\n\nUpon his departure, Leike wrote in a thread on X that he had reached a \"breaking point\" over disagreements with the company's core priorities, adding that \"safety culture and processes have taken a backseat to shiny products\" in the last few years.\n\nSutskever -- who helped briefly oust Altman from OpenAI's leadership late last year -- and Leike joined the ranks of several other OpenAI employees who have exited the company in recent months, including others from the superalignment team and researchers working on AI policy and governance who have felt that the company has strayed from its original mission.\n\nIn response to the high-profile departures, Altman and OpenAI President Greg Brockman said in a co-signed post on X that they are continuing to lay the groundwork for deploying increasingly capable AI models in a safe way. \"We need to keep elevating our safety work to match the stakes of each new model,\" they said.\n\nThat includes a \"very tight feedback loop, rigorous testing, careful consideration at every step, world-class security, and harmony of safety and capabilities,\" the pair wrote.", "source": {"uri": "qz.com", "dataType": "news", "title": "Quartz"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 2, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 2, "label": {"eng": "Chatbot"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 17}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 19}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 21}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 19}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 16}], "image": "https://i.kinja-img.com/image/upload/c_fill,h_675,pg_1,q_80,w_1200/915bc7badb2ebb17d6d7cd88a736a33c.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-05-14", "textStart": 1268, "textEnd": 1274}], "sentiment": 0.3803921568627451, "wgt": 171, "relevance": 1}
{"uri": "8150060231", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "15:04:14", "dateTime": "2024-05-28T15:04:14Z", "dateTimePub": "2024-05-28T15:03:45Z", "dataType": "news", "sim": 0.6705882549285889, "url": "https://www.democraticunderground.com/10143247331", "title": "OpenAI has a new safety team -- it's run by Sam Altman", "body": "Source: The Verge\n\nOpenAI is forming a new safety team, and it's led by CEO Sam Altman, along with board members Adam D'Angelo and Nicole Seligman. The committee will make recommendations on \"critical safety and security decisions for OpenAI projects and operations\" -- a concern several key AI researchers shared when leaving the company this month.\n\nFor its first task, the new team will \"evaluate and further develop OpenAI's processes and safeguards.\" It will then present its findings to OpenAI's board, which all three of the safety team's leaders have a seat on. The board will then decide how to implement the safety team's recommendations.\n\nIts formation follows the departure of OpenAI co-founder and chief scientist Ilya Sutskever, who supported the board's attempted coup to dethrone Altman last year. He also co-led OpenAI's Superalignment team, which was created to \"steer and control AI systems much smarter than us.\"\n\nThe Superalignment team's other co-leader, Jan Leike, announced his departure shortly after Sutskever left. In a post on X, Leike said safety at OpenAI has \"taken a backseat to shiny products.\" OpenAI has since dissolved the Superalignment team, according to Wired. Last week, OpenAI policy researcher Gretchen Krueger announced her resignation, citing similar safety concerns.\n\n-snip-\n\nRead more: https://www.theverge.com/2024/5/28/24166105/openai-safety-team-sam-altman", "source": {"uri": "democraticunderground.com", "dataType": "news", "title": "Democratic Underground"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/The_Verge", "type": "wiki", "score": 3, "label": {"eng": "The Verge"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Wired_(magazine)", "type": "wiki", "score": 1, "label": {"eng": "Wired (magazine)"}}], "categories": [{"uri": "dmoz/Computers/Robotics/Competitions", "label": "dmoz/Computers/Robotics/Competitions", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 27}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 28}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 69}], "image": null, "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3254901960784313, "wgt": 171, "relevance": 1}
{"uri": "8150312371", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "18:06:15", "dateTime": "2024-05-28T18:06:15Z", "dateTimePub": "2024-05-28T18:05:23Z", "dataType": "news", "sim": 0.6666666865348816, "url": "https://www.maginative.com/article/openai-forms-safety-and-security-committee/", "title": "OpenAI Forms Safety and Security Committee", "body": "OpenAI has established a Safety and Security Committee to evaluate its AI practices and advise its board on critical decisions, according to a blog post on Tuesday. This move comes amid scrutiny and high-profile concerns about the company's commitment to AI safety, especially following the recent departures of key personnel involved in AI safety and \"superalignment\" work.\n\nThe new committee will be led by chairman Bret Taylor and include board members Adam D'Angelo, Nicole Seligman, and CEO Sam Altman. It will also include several OpenAI technical and policy experts, such as Head of Preparedness Aleksander M\u0105dry, Head of Safety Systems Lilian Weng, co-founder and Head of Alignment Science John Schulman, Security Chief Matt Knight, and Chief Scientist Jakub Pachocki.\n\nOpenAI's recent rapid advancements in AI have raised concerns about the management of the technology's potential dangers. These worries intensified last fall when CEO Sam Altman briefly faced a boardroom coup after clashing with co-founder and chief scientist Ilya Sutskever over the pace of AI product development and steps to limit harms.\n\nThe concerns resurfaced this month following the departure of Sutskever and key deputy Jan Leike, who ran OpenAI's \"superalignment\" team. Leike, who resigned, later wrote on X that his division was \"struggling\" for computing resources within the company, a criticism echoed by other departing employees. Leike has now joined Anthropic to work on \"scalable oversight, weak-to-strong generalization, and automated alignment research.\"\n\nIn the wake of these events, OpenAI has stated that the work previously undertaken by the \"superalignment\" team will continue under its research unit and John Schulman, a co-founder now serving as Head of Alignment Science. The company has also announced that it has recently begun training its next frontier model, anticipating that the resulting systems will bring them to the next level of capabilities on their path to artificial general intelligence.\n\nTo support the work of the Safety and Security Committee, OpenAI will retain and consult with additional safety, security, and technical experts, including former cybersecurity officials Rob Joyce and John Carlin.\n\nAt the conclusion of the 90-day evaluation period, the committee will share its recommendations with the full board. Following the board's review, OpenAI has committed to publicly sharing an update on adopted recommendations in a manner consistent with safety and security.", "source": {"uri": "maginative.com", "dataType": "news", "title": "Maginative"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 5, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 4, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 4, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Nicole_Seligman", "type": "person", "score": 3, "label": {"eng": "Nicole Seligman"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Computing", "type": "wiki", "score": 2, "label": {"eng": "Computing"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_scientific_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief scientific officer"}}, {"uri": "http://en.wikipedia.org/wiki/Anthropic", "type": "wiki", "score": 1, "label": {"eng": "Anthropic"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 1, "label": {"eng": "Computer security"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 21}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 24}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 24}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 21}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 23}, {"uri": "news/Business", "label": "news/Business", "wgt": 45}], "image": "https://www.maginative.com/content/images/size/w1200/2024/05/ssc-oai.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.003921568627450966, "wgt": 170, "relevance": 1}
{"uri": "8150095248", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "15:27:14", "dateTime": "2024-05-28T15:27:14Z", "dateTimePub": "2024-05-28T15:26:29Z", "dataType": "news", "sim": 0.6666666865348816, "url": "https://www.reformer.com/news/national/openai-forms-ai-safety-committee-after-key-departures/article_3ca7d227-b5bc-5785-b811-7f547ab7a0b0.html", "title": "OpenAI forms AI safety committee after key departures", "body": "OpenAI, the company behind ChatGPT, announced the formation of a new safety committee on Tuesday, weeks after the departures of key executives raised questions about the firm's commitment to mitigating the dangers of artificial intelligence.\n\nThe company said the committee, which will include CEO Sam Altman, is being established as OpenAI begins training its next AI model, expected to surpass the capabilities of the GPT-4 system powering ChatGPT.\n\n\"While we are proud to build and release industry-leading models on both capabilities and safety, we welcome a robust debate at this important juncture,\" OpenAI stated.\n\nComprised of board members and executives, the committee will spend the next 90 days comprehensively evaluating and bolstering OpenAI's processes and safeguards around advanced AI development.\n\nOpenAI stated it will also consult outside experts during this review period, including former US cybersecurity officials Rob Joyce, who previously led efforts at the National Security Agency, and John Carlin, a former senior Justice Department official.\n\nOver the three-month span, the group will scrutinize OpenAI's current AI safety protocols and develop recommendations for potential enhancements or additions.\n\nAfter this 90-day review, the committee's findings will be presented to the full OpenAI board before being publicly released.\n\nMore from this section Chaotic Memorial Day weekend at the Jersey Shore leads to stabbing, curfew Grayson Murray dies aged 30 just 24 hours after withdrawing from Charles Schwab Challenge Bronx Historical Society offers Mott Haven walking tour, screening of 'Up Jump The Boogie'\n\nThe committee's formation comes on the heels of recent executive departures that stoked concerns about OpenAI's AI safety priorities.\n\nEarlier this month, the company dissolved its \"superalignment\" team dedicated to mitigating long-term AI risks.\n\nIn announcing his exit, team co-lead Jan Leike criticized OpenAI for prioritizing \"shiny new products\" over vital safety work in a series of posts on X, the platform previously known as Twitter.\n\n\"Over the past few months, my team has been sailing against the wind,\" Leike said.\n\nOpenAI has also faced controversy over an AI voice some claimed closely mimicked actress Scarlett Johansson, though the company denied attempting to impersonate the Hollywood star.\n\narp/bfm", "source": {"uri": "reformer.com", "dataType": "news", "title": "Brattleboro Reformer"}, "authors": [{"uri": "agence_france_presse@reformer.com", "name": "Agence France-Presse", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 5, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 2, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/National_Security_Agency", "type": "wiki", "score": 2, "label": {"eng": "National Security Agency"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 2, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 2, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Hollywood,_Los_Angeles", "type": "wiki", "score": 1, "label": {"eng": "Hollywood, Los Angeles"}}, {"uri": "http://en.wikipedia.org/wiki/Colonial_National_Invitation", "type": "wiki", "score": 1, "label": {"eng": "Colonial National Invitation"}}, {"uri": "http://en.wikipedia.org/wiki/Jersey_Shore", "type": "loc", "score": 1, "label": {"eng": "Jersey Shore"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Scarlett_Johansson", "type": "person", "score": 1, "label": {"eng": "Scarlett Johansson"}}, {"uri": "http://en.wikipedia.org/wiki/Memorial_Day", "type": "wiki", "score": 1, "label": {"eng": "Memorial Day"}}, {"uri": "http://en.wikipedia.org/wiki/Twitter", "type": "org", "score": 1, "label": {"eng": "Twitter"}}, {"uri": "http://en.wikipedia.org/wiki/The_Bronx", "type": "loc", "score": 1, "label": {"eng": "The Bronx"}, "location": {"type": "place", "label": {"eng": "The Bronx"}, "country": {"type": "country", "label": {"eng": "United States"}}}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 20}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 20}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 19}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 21}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 19}, {"uri": "news/Arts_and_Entertainment", "label": "news/Arts and Entertainment", "wgt": 51}], "image": "https://bloximages.newyork1.vip.townnews.com/reformer.com/content/tncms/assets/v3/editorial/f/16/f1645006-5824-514f-9858-aaf2ba674331/664e8ab665dd9.image.jpg?crop=512%2C269%2C0%2C36&resize=438%2C230&order=crop%2Cresize", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.2862745098039217, "wgt": 170, "relevance": 1}
{"uri": "8149716613", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "11:31:18", "dateTime": "2024-05-28T11:31:18Z", "dateTimePub": "2024-05-28T11:30:57Z", "dataType": "news", "sim": 0.6666666865348816, "url": "https://www.nbcmiami.com/news/national-international/openai-creates-oversight-team-with-sam-altman-on-board-begins-training-new-model/3321370/", "title": "OpenAI creates oversight team with Sam Altman on board, begins training new model", "body": "The formation of a new oversight team comes after OpenAI dissolved a previous team that was focused on the long-term risks of AI.\n\nOpenAI on Tuesday said it created a Safety and Security Committee led by senior executives, after disbanding its previous oversight board in mid-May.\n\nThe new committee will be responsible for making recommendations to OpenAI's board \"on critical safety and security decisions for OpenAI projects and operations,\" the company said.\n\nIt comes as the developer of the ChatGPT virtual assistant announced it has begun training its \"next frontier model.\"\n\nThe firm said in a blog post that it anticipates the \"resulting systems to bring us to the next level of capabilities on our path to AGI,\" or artificial general intelligence -- which relates to AI that is as smart or smarter than humans.\n\nThe formation of a new oversight team comes after OpenAI dissolved a previous team that was focused on the long-term risks of AI. Prior to that, both team leaders, OpenAI co-founder Ilya Sutskever and Jan Leike, announced their departures from the Microsoft-backed startup.\n\n- CNBC's Hayden Fielde contributed to this report.", "source": {"uri": "nbcmiami.com", "dataType": "news", "title": "NBC 6 South Florida"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 2, "label": {"eng": "Virtual assistant"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 1, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/CNBC", "type": "org", "score": 1, "label": {"eng": "CNBC"}}], "categories": [{"uri": "dmoz/Sports/Paintball/Teams", "label": "dmoz/Sports/Paintball/Teams", "wgt": 21}, {"uri": "dmoz/Computers/Robotics/Competitions", "label": "dmoz/Computers/Robotics/Competitions", "wgt": 22}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 17}, {"uri": "dmoz/Sports/Adventure_Racing/Teams", "label": "dmoz/Sports/Adventure Racing/Teams", "wgt": 17}, {"uri": "dmoz/Business/Education_and_Training/Team_Building", "label": "dmoz/Business/Education and Training/Team Building", "wgt": 19}], "image": "https://media.nbcmiami.com/2024/05/107418094-1716321352537-gettyimages-2153474140-AFP_34TH9TC.jpeg?quality=85&strip=all&resize=1200%2C675", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3098039215686275, "wgt": 170, "relevance": 1}
{"uri": "8150003363", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:26:28", "dateTime": "2024-05-28T14:26:28Z", "dateTimePub": "2024-05-28T14:25:58Z", "dataType": "news", "sim": 0.6666666865348816, "url": "https://www.legit.ng/business-economy/technology/1594578-openai-forms-ai-safety-committee-key-departures/", "title": "OpenAI forms AI safety committee after key departures", "body": "PAY ATTENTION: Legit.ng Entertainment Awards 2024 Voting Is Alive. Choose the best entertainer in 15 categories for FREE.\n\nOpenAI, the company behind ChatGPT, announced the formation of a new safety committee on Tuesday, weeks after the departures of key executives raised questions about the firm's commitment to mitigating the dangers of artificial intelligence.\n\nThe company said the committee, which will include CEO Sam Altman, is being established as OpenAI begins training its next AI model, expected to surpass the capabilities of the GPT-4 system powering ChatGPT.\n\n\"While we are proud to build and release industry-leading models on both capabilities and safety, we welcome a robust debate at this important juncture,\" OpenAI stated.\n\nComprised of board members and executives, the committee will spend the next 90 days comprehensively evaluating and bolstering OpenAI's processes and safeguards around advanced AI development.\n\nOpenAI stated it will also consult outside experts during this review period, including former US cybersecurity officials Rob Joyce, who previously led efforts at the National Security Agency, and John Carlin, a former senior Justice Department official.\n\nOver the three-month span, the group will scrutinize OpenAI's current AI safety protocols and develop recommendations for potential enhancements or additions.\n\nAfter this 90-day review, the committee's findings will be presented to the full OpenAI board before being publicly released.\n\nThe committee's formation comes on the heels of recent executive departures that stoked concerns about OpenAI's AI safety priorities.\n\nEarlier this month, the company dissolved its \"superalignment\" team dedicated to mitigating long-term AI risks.\n\nIn announcing his exit, team co-lead Jan Leike criticized OpenAI for prioritizing \"shiny new products\" over vital safety work in a series of posts on X, the platform previously known as Twitter.\n\n\"Over the past few months, my team has been sailing against the wind,\" Leike said.\n\nOpenAI has also faced controversy over an AI voice some claimed closely mimicked actress Scarlett Johansson, though the company denied attempting to impersonate the Hollywood star.", "source": {"uri": "legit.ng", "dataType": "news", "title": "Legit.ng - Nigeria news."}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 2, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/National_Security_Agency", "type": "wiki", "score": 2, "label": {"eng": "National Security Agency"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 2, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 2, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Hollywood,_Los_Angeles", "type": "wiki", "score": 1, "label": {"eng": "Hollywood, Los Angeles"}}, {"uri": "http://en.wikipedia.org/wiki/Twitter", "type": "org", "score": 1, "label": {"eng": "Twitter"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 21}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 21}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 20}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 21}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 20}], "image": "https://netstorage-legit.akamaized.net/images/df69057e48105795.jpg?imwidth=1200", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.4431372549019608, "wgt": 170, "relevance": 1}
{"uri": "8149739903", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "11:45:52", "dateTime": "2024-05-28T11:45:52Z", "dateTimePub": "2024-05-28T11:45:16Z", "dataType": "news", "sim": 0.6666666865348816, "url": "https://financialpost.com/pmn/business-pmn/openai-forms-safety-committee-as-it-starts-training-latest-artificial-intelligence-model", "title": "OpenAI forms safety committee as it starts training latest artificial intelligence model", "body": "If you are a Home delivery print subscriber, unlimited online access is included in your subscription. Activate your Online Access Now\n\nOpenAI said it has \"recently begun training its next frontier model\" and its AI models lead the industry on capability and safety, though it made no mention of the controversy. \"We welcome a robust debate at this important moment,\" the company said.\n\nAI models are prediction systems that are trained on vast datasets to generate on-demand text, images, video and human-like conversation. Frontier models are the most powerful, cutting edge AI systems.\n\nMembers of the the safety committee include OpenAI CEO Sam Altman and Chairman Bret Taylor, along with two other board members, Adam D'Angelo, who's the CEO of Quora, and Nicole Seligman, a former Sony general counsel. OpenAI said four company technical and policy experts are also members.\n\nThe committee's first job will be to evaluate and further develop OpenAI's processes and safeguards and make its recommendations to the board in 90 days. The company said it will then publicly release the recommendations it's adopting \"in a manner that is consistent with safety and security.\"", "source": {"uri": "financialpost.com", "dataType": "news", "title": "Financial Post"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 4, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Video_on_demand", "type": "wiki", "score": 2, "label": {"eng": "Video on demand"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Chairperson", "type": "wiki", "score": 1, "label": {"eng": "Chairperson"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 1, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/General_counsel", "type": "wiki", "score": 1, "label": {"eng": "General counsel"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 1, "label": {"eng": "Sony"}}], "categories": [{"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 26}, {"uri": "dmoz/Recreation/Models/Scale", "label": "dmoz/Recreation/Models/Scale", "wgt": 25}, {"uri": "dmoz/Recreation/Collecting/Models", "label": "dmoz/Recreation/Collecting/Models", "wgt": 23}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 27}, {"uri": "dmoz/Recreation/Models/Boats_and_Ships", "label": "dmoz/Recreation/Models/Boats and Ships", "wgt": 23}, {"uri": "news/Business", "label": "news/Business", "wgt": 53}], "image": null, "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.2705882352941176, "wgt": 170, "relevance": 1}
{"uri": "8149871092", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "13:05:05", "dateTime": "2024-05-28T13:05:05Z", "dateTimePub": "2024-05-28T13:04:23Z", "dataType": "news", "sim": 0.6627451181411743, "url": "https://www.latestly.com/technology/openai-board-forms-safety-and-security-committee-for-making-suggestions-on-critical-safety-and-security-decisions-for-projects-operations-5996309.html", "title": "OpenAI Board Forms 'Safety and Security Committee' for Making Suggestions on Critical Safety and Security Decisions for Projects, Operations | \ud83d\udcf2 LatestLY", "body": "San Francisco, May 28: ChatGPT maker OpenAI Board has formed a Safety and Security Committee led by directors Sam Altman (CEO), Bret Taylor (Chair), Adam D'Angelo, and Nicole Seligman, the company said on Tuesday. According to the AI startup, this committee will be responsible for making suggestions to the full Board on critical safety and security decisions for the company's projects and operations.\n\n\"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI,\" OpenAI said in a blogpost. \"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment,\" it added. OpenAI Begins Testing Its Next Frontier Model Expecting To Bring New Capabilities on Path to AGI, Forms Safety and Security Committee for Company's Projects and Operations.\n\nThe first task of this committee will be to evaluate and further develop OpenAI's processes and safeguards over the next 90 days. After 90 days, the committee will share its suggestions with the full Board. \"Following the full Board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security,\" the company mentioned. DoT Imposes Penalty on Airtel for Violating Subscriber Verification Norms in Punjab.\n\nIn addition, the ChatGPT maker said that OpenAI technical and policy experts Aleksander Madry (Head of Preparedness), Lilian Weng (Head of Safety Systems), John Schulman (Head of Alignment Science), Matt Knight (Head of Security), and Jakub Pachocki (Chief Scientist) will also be on the committee.", "source": {"uri": "latestly.com", "dataType": "news", "title": "LatestLY"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/San_Francisco", "type": "loc", "score": 3, "label": {"eng": "San Francisco"}, "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Chief_scientific_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief scientific officer"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 24}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 26}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 26}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 26}, {"uri": "dmoz/Computers/Security/FAQs,_Help,_and_Tutorials", "label": "dmoz/Computers/Security/FAQs, Help, and Tutorials", "wgt": 24}], "image": "https://st1.latestly.com/wp-content/uploads/2024/02/Sam-Altman-784x441.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": {"type": "place", "label": {"eng": "San Francisco"}, "country": {"type": "country", "label": {"eng": "United States"}}}, "extractedDates": [{"amb": false, "imp": true, "date": "2024-05-28", "textStart": 15, "textEnd": 21}], "sentiment": 0.3254901960784313, "wgt": 169, "relevance": 1}
{"uri": "8149623812", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "10:34:27", "dateTime": "2024-05-28T10:34:27Z", "dateTimePub": "2024-05-28T10:33:52Z", "dataType": "news", "sim": 0.658823549747467, "url": "https://www.businessinsider.com/openai-sets-up-safety-committee-starts-training-next-frontier-model-2024-5", "title": "OpenAI sets up safety and security committee and starts training 'next frontier model'", "body": "This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now. Have an account? Log in.\n\nOpenAI said it has set up a safety and security committee to make recommendations to the board on \"critical safety and security decisions.\"\n\nThe committee will be chaired by Bret Taylor, and include fellow directors Adam D'Angelo and Nicole Seligman as well as CEO Sam Altman.\n\nThe company also said it had begun training a new flagship AI model.\n\nIt said in a Tuesday blogpost: \"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI.\"", "source": {"uri": "businessinsider.com", "dataType": "news", "title": "Business Insider"}, "authors": [{"uri": "beatrice_nolan@businessinsider.com", "name": "Beatrice Nolan", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 3, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Business_Insider", "type": "wiki", "score": 3, "label": {"eng": "Business Insider"}}, {"uri": "http://en.wikipedia.org/wiki/Nicole_Seligman", "type": "person", "score": 2, "label": {"eng": "Nicole Seligman"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 19}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 20}, {"uri": "dmoz/Business/Education_and_Training/Health_and_Safety", "label": "dmoz/Business/Education and Training/Health and Safety", "wgt": 19}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 19}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 47}], "image": "https://i.insider.com/6655aefc239fda2da6cbf393?width=1200&format=jpeg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.1450980392156862, "wgt": 168, "relevance": 1}
{"uri": "8150427313", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "19:47:41", "dateTime": "2024-05-28T19:47:41Z", "dateTimePub": "2024-05-28T19:46:53Z", "dataType": "news", "sim": 0.658823549747467, "url": "https://www.databreachtoday.com/openai-sets-up-new-security-oversight-team-a-25339", "title": "OpenAI Sets Up New Security Oversight Team", "body": "Artificial Intelligence & Machine Learning , Next-Generation Technologies & Secure Development\n\nOpenAI on Tuesday set up a committee to make \"critical\" safety and security decisions for all of its projects, as the technology giant begins to train its next artificial intelligence model.\n\nSee Also: Secure Your Applications: Learn How to Prevent AI Generated Code Risks\n\nCEO Sam Altman and board members Adam D'Angelo, Nicole Seligman and Bret Taylor will lead the committee, the company said. Over the next three months, the team will evaluate OpenAI's processes and safeguards and recommend improvements. OpenAI will share an update on which recommendations it chooses to adopt \"in a manner that is consistent with safety and security.\"\n\nThe committee will also comprise technical and policy leads at the company, including Aleksander M\u0105dry, head of preparedness; Lilian Weng, head of safety systems; John Schulman, head of alignment science; Matt Knight, head of security; and Jakub Pachocki, chief scientist. The company plans to consult external security and technical experts including former White House cybersecurity official Rob Joyce.\n\nThe committee's formation comes after OpenAI reportedly disbanded its \"superalignment\" security team dedicated to preventing AI systems from going rogue.\n\nThe superalignment safety team's leaders - OpenAI co-founder Ilya Sutskever and Jan Leike - quit the company over their misalignment on the approach to security, as did policy researcher Gretchen Kreuger.\n\nBoth Sutskever and Leike worked on addressing the long-term safety risks facing the company and the technology, and Leike criticized OpenAI's lack of support for the superalignment security team in a social media post. \"Over the past years, safety culture and processes have taken a backseat to shiny products,\" Leike said. Sutskever was among the board members who in November removed Altman from OpenAI only to see him reinstated as CEO five days later. Krueger said she decided to resign a few hours before her other two colleagues did, as she shared their security concerns.", "source": {"uri": "databreachtoday.com", "dataType": "news", "title": "DataBreachToday"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 3, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/White_House", "type": "wiki", "score": 2, "label": {"eng": "White House"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Social_media", "type": "wiki", "score": 1, "label": {"eng": "Social media"}}], "categories": [{"uri": "dmoz/Business/Business_Services/Fire_and_Security", "label": "dmoz/Business/Business Services/Fire and Security", "wgt": 29}, {"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 36}, {"uri": "dmoz/Computers/Security/Policy", "label": "dmoz/Computers/Security/Policy", "wgt": 29}, {"uri": "dmoz/Computers/Security/Advisories_and_Patches", "label": "dmoz/Computers/Security/Advisories and Patches", "wgt": 34}, {"uri": "dmoz/Computers/Security/FAQs,_Help,_and_Tutorials", "label": "dmoz/Computers/Security/FAQs, Help, and Tutorials", "wgt": 33}], "image": "https://130e178e8f8ba617604b-8aedd782b7d22cfe0d1146da69a52436.ssl.cf1.rackcdn.com/openai-sets-up-new-security-oversight-team-showcase_image-1-a-25339.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.4509803921568627, "wgt": 168, "relevance": 1}
{"uri": "8149841983", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "12:47:39", "dateTime": "2024-05-28T12:47:39Z", "dateTimePub": "2024-05-28T12:46:25Z", "dataType": "news", "sim": 0.658823549747467, "url": "https://www.newsbytesapp.com/news/science/openai-establishes-committee-for-ai-model-evaluation/story", "title": "OpenAI sets up safety committee to evaluate AI models", "body": "OpenAI has announced the formation of a 'Safety and Security Committee' today. Its primary role is to provide safety and security recommendations for OpenAI's projects to the board. Over next 90 days, this committee will assess the safeguards in place within OpenAI's architecture. A report based on their findings will be submitted for board review. \"Following the board's review, OpenAI will share an update on adopted recommendations in a manner that is consistent with safety and security,\" said the company.\n\nThe Safety and Security Committee will be led by OpenAI's CEO, Sam Altman, and includes Directors Bret Taylor, Adam D'Angelo, and Nicole Seligman. In line with its commitment to safety and security, OpenAI will also seek advice from external experts. Among these consultants are Rob Joyce, a Homeland Security adviser to former President Donald Trump, as well as John Carlin, a Justice Department official under President Joe Biden.", "source": {"uri": "newsbytesapp.com", "dataType": "news", "title": "NewsBytes"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/John_W._Carlin", "type": "person", "score": 1, "label": {"eng": "John W. Carlin"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Joe_Biden", "type": "person", "score": 1, "label": {"eng": "Joe Biden"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Homeland_Security", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Homeland Security"}}, {"uri": "http://en.wikipedia.org/wiki/Donald_Trump", "type": "person", "score": 1, "label": {"eng": "Donald Trump"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 30}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 30}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 30}, {"uri": "dmoz/Computers/Security/Advisories_and_Patches", "label": "dmoz/Computers/Security/Advisories and Patches", "wgt": 31}, {"uri": "dmoz/Computers/Security/FAQs,_Help,_and_Tutorials", "label": "dmoz/Computers/Security/FAQs, Help, and Tutorials", "wgt": 30}, {"uri": "news/Politics", "label": "news/Politics", "wgt": 62}], "image": "https://i.cdn.newsbytesapp.com/images/l28520240528180921.png", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.5215686274509803, "wgt": 168, "relevance": 1}
{"uri": "8149705817", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "11:24:52", "dateTime": "2024-05-28T11:24:52Z", "dateTimePub": "2024-05-28T11:24:03Z", "dataType": "news", "sim": 0.6509804129600525, "url": "https://www.cnbc.com/2024/05/28/openai-creates-new-oversight-team-begins-training-next-model.html", "title": "OpenAI creates oversight team with Sam Altman on board, begins training new model", "body": "OpenAI CEO Sam Altman speaks during the Microsoft Build conference at Microsoft headquarters in Redmond, Washington, on May 21, 2024.\n\nOpenAI on Tuesday said it created a Safety and Security Committee led by senior executives, after disbanding its previous oversight board in mid-May.\n\nThe new committee will be responsible for making recommendations to OpenAI's board \"on critical safety and security decisions for OpenAI projects and operations,\" the company said.\n\nIt comes as the developer of the ChatGPT virtual assistant announced it has begun training its \"next frontier model.\"\n\nThe firm said in a blog post that it anticipates the \"resulting systems to bring us to the next level of capabilities on our path to AGI,\" or artificial general intelligence -- which relates to AI that is as smart or smarter than humans.\n\nThe formation of a new oversight team comes after OpenAI dissolved a previous team that was focused on the long-term risks of AI. Prior to that, both team leaders, OpenAI co-founder Ilya Sutskever and Jan Leike, announced their departures from the Microsoft-backed startup.\n\n- CNBC's Hayden Field contributed to this report.", "source": {"uri": "cnbc.com", "dataType": "news", "title": "CNBC"}, "authors": [{"uri": "arjun_kharpal@cnbc.com", "name": "Arjun Kharpal", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 5, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Redmond,_Washington", "type": "loc", "score": 3, "label": {"eng": "Redmond, Washington"}, "location": {"type": "place", "label": {"eng": "Redmond, Washington"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 2, "label": {"eng": "Virtual assistant"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 1, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/CNBC", "type": "org", "score": 1, "label": {"eng": "CNBC"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial intelligence"}}], "categories": [{"uri": "dmoz/Sports/Paintball/Teams", "label": "dmoz/Sports/Paintball/Teams", "wgt": 15}, {"uri": "dmoz/Computers/Robotics/Competitions", "label": "dmoz/Computers/Robotics/Competitions", "wgt": 16}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 16}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 15}, {"uri": "dmoz/Business/Education_and_Training/Team_Building", "label": "dmoz/Business/Education and Training/Team Building", "wgt": 17}, {"uri": "news/Business", "label": "news/Business", "wgt": 65}], "image": "https://image.cnbcfm.com/api/v1/image/107418094-1716321352537-gettyimages-2153474140-AFP_34TH9TC.jpeg?v=1716321508&w=1920&h=1080", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.2941176470588236, "wgt": 166, "relevance": 1}
{"uri": "8150130700", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "15:51:10", "dateTime": "2024-05-28T15:51:10Z", "dateTimePub": "2024-05-28T15:50:05Z", "dataType": "news", "sim": 0.6509804129600525, "url": "https://mashable.com/article/openai-new-ai-safety-security-committee-sam-altman", "title": "OpenAI launches new internal safety team with Sam Altman in control", "body": "OpenAI's new committee has a 90 day turnaround for its first safeguard evaluation. Credit: Omer Taha Cetin / Anadolu via Getty Images\n\nOpenAI is digging its heels deeper into industry self governance as the company announces a revamped safety and security team, following several public resignations and the dissolution of its former oversight body.\n\nThe Safety and Security Committee, as its been renamed, is led by board members and directors Bret Taylor (Sierra), Adam D'Angelo (Quora), Nicole Seligman, and -- of course -- OpenAI CEO Sam Altman. Other members include internal \"OpenAI technical and policy experts,\" including heads of \"Preparedness,\" \"Safety Systems,\" and \"Alignment Science.\"\n\n\"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI,\" wrote OpenAI. \"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment.\"\n\nThe committee's first task is to \"evaluate and further develop OpenAI's processes and safeguards over the next 90 days,\" the company wrote in its announcement, with feedback from outside experts who are already on OpenAI's external oversight roster, like former NSA cybersecurity director Rob Joyce.\n\nThe announcement is a timely response to a swirling management controversy at OpenAI, although it may do little to reassure watchful eyes and advocates for external oversight. This week, former OpenAI board members called for more intense government regulation of the AI sector, specifically calling out the poor management decisions and toxic culture fostered by Altman in the role of OpenAI's leader.\n\n\"Even with the best of intentions, without external oversight, this kind of self-regulation will end up unenforceable, especially under the pressure of immense profit incentives,\" they argued.\n\nOpenAI's new committee is being thrown straight into the fire, with an immediate mandate to evaluate the company's AI safeguards. But even those might not be enough.", "source": {"uri": "mashable.com", "dataType": "news", "title": "Mashable"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 3, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Getty_Images", "type": "org", "score": 3, "label": {"eng": "Getty Images"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/National_Security_Agency", "type": "wiki", "score": 1, "label": {"eng": "National Security Agency"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 1, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Regulation", "type": "wiki", "score": 1, "label": {"eng": "Regulation"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 19}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 19}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 19}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 16}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 19}], "image": "https://helios-i.mashable.com/imagery/articles/07Jfp7ArOZ6XFkxq99z4beW/hero-image.fill.size_1200x675.v1716910498.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.419607843137255, "wgt": 166, "relevance": 1}
{"uri": "2024-05-370774186", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "11:32:54", "dateTime": "2024-05-28T11:32:54Z", "dateTimePub": "2024-05-28T11:28:17Z", "dataType": "news", "sim": 0.6431372761726379, "url": "https://www.latestly.com/socially/technology/openai-begins-testing-its-next-frontier-model-expecting-to-bring-new-capabilities-on-path-to-agi-forms-safety-and-security-committee-for-companys-projects-and-operations-5996077.html", "title": "OpenAI Begins Testing Its Next Frontier Model Expecting To Bring New Capabilities on Path to AGI, Forms Safety and Security Committee for Company's Projects and Operations", "body": "OpenAI starts training its next frontier model, anticipates the resulting systems would bring company to the advanced level on the path of AGI (artificial general intelligence). The Sam Altman-run company also forms Safety and Security Committee for decisions and recommends over the safety and security of OpenAI projects and operations.\n\nOpenAI has begun testing its \"next frontier model\" to bring the advanced level of capabilities on the path of 'artificial general intelligence' or AGI. The Sam Altman-run AI company said, \"While we are proud to build and release models that are industry-leading in both capabilities and safety, we welcome a robust debate at this important moment.\" In its official post, the company said that the OpenAI Board formed a \"Safety and Security Committee\", which will be led by Chair Bret Taylor, CEO Sam Altman, Adam D'Angelo and Nicole Seligman. The committee would be responsible for critical safety and security decisions and providing recommendations to the entire Board related to the OpenAI projects and operations. Elon Musk's AI Company xAI Raises USD 6 Billion To Boost Research and Development of Future Technology.", "source": {"uri": "latestly.com", "dataType": "news", "title": "LatestLY"}, "authors": [{"uri": "team_latestly@latestly.com", "name": "Team Latestly", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Elon_Musk", "type": "person", "score": 1, "label": {"eng": "Elon Musk"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 20}, {"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 20}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 22}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 24}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 22}], "image": "https://st1.latestly.com/wp-content/uploads/2024/04/MicrosoftTeams-image-50-784x441.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.7098039215686274, "wgt": 164, "relevance": 1}
{"uri": "8150034562", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:46:37", "dateTime": "2024-05-28T14:46:37Z", "dateTimePub": "2024-05-28T14:46:08Z", "dataType": "news", "sim": 0.6392157077789307, "url": "https://readwrite.com/openai-confirms-gpt-4-successor-in-training-stage/", "title": "OpenAI confirms GPT-4 successor in training stage", "body": "Rumors suggest GPT-5 may focus on improved task automation, accuracy, and in-built safety protocols.\n\nOpenAI has announced plans to create a successor to its current AI model, GPT-4.\n\nGPT-4 underpins OpenAI's current products, such as the early face of generative AI ChatGPT, but in a blog post on May 28, the company confirmed that a new model is on the way.\n\nSpecifically, the OpenAI Board has formed a Safety and Security Committee, led by directors Bret Taylor, Adam D'Angelo, Nicole Seligman, and CEO Sam Altman. This committee will be \"responsible for making recommendations to the full Board on critical safety and security decisions for OpenAI projects and operations\".\n\nThe first task of the committee will be to evaluate and develop OpenAI's safety processes over the next 90 days, with the development of the new model in mind.\n\n\"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI,\" the statement reads. \"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment.\"\n\nIt's been just over a year since GPT-4 was released in March 2023 and comes just a few weeks after the company launched GPT-4o, a multiformat AI assistant across text, video, and audio.\n\nWhile nothing is yet known officially about what GPT-5 could bring, it's thought that automation would be a central part of it. Rumors are circulating about improved ability in task delegation and greater accuracy in both paid and free versions.\n\nWith greater emphasis being placed on the importance of safety in data training, as evidenced by the formation of the committee at OpenAI as well, it's likely that GPT-5 will have in-built safety protocols and frameworks too.\n\nSpeaking about future models in March, Altman previously refused to be drawn on what the model could entail or even what it would be called, only that it would be 'smarter'.", "source": {"uri": "readwrite.com", "dataType": "news", "title": "ReadWrite"}, "authors": [{"uri": "rachael_davies@readwrite.com", "name": "Rachael Davies", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 5, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Automation", "type": "wiki", "score": 3, "label": {"eng": "Automation"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 1, "label": {"eng": "Virtual assistant"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 19}, {"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 19}, {"uri": "dmoz/Recreation/Models/Scale", "label": "dmoz/Recreation/Models/Scale", "wgt": 19}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 21}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 19}], "image": "https://readwrite.com/wp-content/uploads/2024/05/ChatGPT-Successor.jpeg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-05-05", "textStart": 19, "textEnd": 24}, {"amb": false, "imp": true, "date": "2024-05-28", "textStart": 298, "textEnd": 304}], "sentiment": 0.388235294117647, "wgt": 163, "relevance": 1}
{"uri": "8149696874", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "11:19:21", "dateTime": "2024-05-28T11:19:21Z", "dateTimePub": "2024-05-28T11:18:17Z", "dataType": "news", "sim": 0.6352941393852234, "url": "https://gazette.com/news/us-world/openai-sets-up-safety-and-security-committee-headed-by-senior-executives/article_6f47c584-9295-590a-835c-7d7963fef026.html", "title": "OpenAI sets up Safety and Security Committee headed by senior executives", "body": "(Reuters) -OpenAI has formed a Safety and Security Committee which will include CEO Sam Altman as it begins training its next artificial intelligence model, the AI startup said on Tuesday.\n\nDirectors Bret Taylor, Adam D'Angelo and Nicole Seligman, will also be on the committee, OpenAI said on a company blog.\n\nThe committee will be responsible for making recommendations to the board on safety and security decisions for OpenAI's projects and operations.\n\n(Reporting by Arsheeya Bajwa in Bengaluru; Editing by Tasim Zahid)\n\nSign Up for Springs AM Update Your morning rundown of the latest news from Colorado Springs and around the country\n\nSign Up View all of our newsletters. Success! Thank you for subscribing to our newsletter. View all of our newsletters. CLICK HERE TO READ MORE FROM THE GAZETTE", "source": {"uri": "gazette.com", "dataType": "news", "title": "Colorado Springs Gazette"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Bret_Taylor", "type": "person", "score": 3, "label": {"eng": "Bret Taylor"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 2, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Newsletter", "type": "wiki", "score": 1, "label": {"eng": "Newsletter"}}, {"uri": "http://en.wikipedia.org/wiki/Reuters", "type": "wiki", "score": 1, "label": {"eng": "Reuters"}}, {"uri": "http://en.wikipedia.org/wiki/Colorado_Springs,_Colorado", "type": "loc", "score": 1, "label": {"eng": "Colorado Springs, Colorado"}, "location": {"type": "place", "label": {"eng": "Colorado Springs, Colorado"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Bangalore", "type": "loc", "score": 1, "label": {"eng": "Bangalore"}, "location": {"type": "place", "label": {"eng": "Bangalore"}, "country": {"type": "country", "label": {"eng": "India"}}}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 20}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 20}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 19}, {"uri": "dmoz/Computers/Security/Advisories_and_Patches", "label": "dmoz/Computers/Security/Advisories and Patches", "wgt": 20}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 26}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 57}], "image": "https://bloximages.newyork1.vip.townnews.com/gazette.com/content/tncms/assets/v3/editorial/d/fa/dfadc7bc-2bc8-56c9-a7b0-00e48e43741c/6655b03d30e78.image.jpg?crop=800%2C420%2C0%2C34&resize=438%2C230&order=crop%2Cresize", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.2392156862745098, "wgt": 162, "relevance": 1}
{"uri": "8150104456", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "15:34:07", "dateTime": "2024-05-28T15:34:07Z", "dateTimePub": "2024-05-28T15:32:40Z", "dataType": "news", "sim": 0.6352941393852234, "url": "https://en.haberler.com/openai-forms-safety-security-committee-responsible-1957509/?utm_source=facebook&utm_campaign=tavsiye_et", "title": "Openai Forms Safety Security Committee Responsible For Making Recommendations On Projects, Operations", "body": "Committee to share first recommendations after 90 day evaluation, OpenAI says.\n\nUS-based technology firm, OpenAI, the owner of ChatGPT, said Tuesday it formed a safety and security committee responsible for making recommendations on the company's projects and operations.\n\n\"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI (artificial general intelligence),\" it said.\n\nThe first task will be to evaluate and further develop OpenAI's processes and safeguards during the next 90 days.\n\n\"At the conclusion of the 90 days, the Safety and Security Committee will share their recommendations with the full Board,\" it noted. \"Following the full Board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security.\"\n\nOpenAI is the developer of ChatGPT, which recently released version 4.0, as well as image creator Dall-E and video creator Sora. -", "source": {"uri": "en.haberler.com", "dataType": "news", "title": "Haberler.com"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial general intelligence"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 22}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 21}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 22}, {"uri": "dmoz/Computers/Security/Advisories_and_Patches", "label": "dmoz/Computers/Security/Advisories and Patches", "wgt": 21}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 21}], "image": null, "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3803921568627451, "wgt": 162, "relevance": 1}
{"uri": "8149695332", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "11:17:44", "dateTime": "2024-05-28T11:17:44Z", "dateTimePub": "2024-05-28T11:17:09Z", "dataType": "news", "sim": 0.6313725709915161, "url": "https://www.ft.com/content/34a7a082-e685-4e02-bca7-61ff89d99ed2", "title": "OpenAI begins training next AI model as it battles safety concerns", "body": "OpenAI said it has begun training its next-generation artificial intelligence software, even as the start-up backtracked on earlier claims that it wants to build \"superintelligent\" systems that are smarter than humans.\n\nThe San Francisco-based company said on Tuesday that it had started producing a new AI system \"to bring us to the next level of capabilities\" and that its development would be overseen by a new safety and security committee.\n\nBut while OpenAI is racing ahead with AI development, a senior OpenAI executive seemed to backtrack on previous comments by its chief executive Sam Altman that it was ultimately aiming to build a \"superintelligence\" far more advanced than humans.\n\nAnna Makanju, OpenAI's vice-president of global affairs, told the Financial Times in an interview that its \"mission\" was to build artificial general intelligence capable of \"cognitive tasks that are what a human could do today\".\n\n\"Our mission is to build AGI; I would not say our mission is to build superintelligence,\" Makanju said. \"Superintelligence is a technology that is going to be orders of magnitude more intelligent than human beings on Earth.\"\n\nAltman told the FT in November that he spent half of his time researching \"how to build superintelligence\".\n\nAt the same time as fending off competition from Google's Gemini and Elon Musk's start-up xAI, OpenAI is attempting to reassure policymakers that it is prioritising responsible AI development after several senior safety researchers quit this month.\n\nIts new committee will be led by Altman and board directors Bret Taylor, Adam D'Angelo, and Nicole Seligman, and will report back to the remaining three members of the board.\n\nThe company did not say what the follow-up to GPT-4, which powers its ChatGPT app and received a major upgrade two weeks ago, could do or when it would launch.\n\nEarlier this month, OpenAI disbanded its so-called superalignment team -- tasked with focusing on the safety of potentially superintelligent systems -- after Ilya Sutskever, the team's leader and a co-founder of the company, quit.\n\nSutskever's departure came months after he led a shock coup against Altman in November that ultimately proved unsuccessful.\n\nClosing down the superalignment team has resulted in several employees leaving the company, including Jan Leike, another senior AI safety researcher.\n\nMakanju emphasised that work on the \"long-term possibilities\" of AI was still being done \"even if they are theoretical\".\n\n\"AGI does not yet exist,\" Makanju added, and said such a technology would not be released until it was safe.\n\nTraining is the primary step in how an artificial intelligence model learns, drawing on a huge volume of data and information given to it. After it has digested the data and its performance has improved, the model is then validated and tested before being deployed into products or applications.\n\nThis lengthy and highly technical process means OpenAI's new model may not become a tangible product for many months.", "source": {"uri": "ft.com", "dataType": "news", "title": "Financial Times News"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Superintelligence", "type": "wiki", "score": 5, "label": {"eng": "Superintelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 3, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Cognition", "type": "wiki", "score": 2, "label": {"eng": "Cognition"}}, {"uri": "http://en.wikipedia.org/wiki/Financial_Times", "type": "wiki", "score": 2, "label": {"eng": "Financial Times"}}, {"uri": "http://en.wikipedia.org/wiki/Elon_Musk", "type": "person", "score": 2, "label": {"eng": "Elon Musk"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 2, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 1, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 1, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 1, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Mobile_app", "type": "wiki", "score": 1, "label": {"eng": "Mobile app"}}], "categories": [{"uri": "dmoz/Computers/Artificial_Intelligence", "label": "dmoz/Computers/Artificial Intelligence", "wgt": 21}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 24}, {"uri": "dmoz/Computers/Artificial_Intelligence/Academic_Departments", "label": "dmoz/Computers/Artificial Intelligence/Academic Departments", "wgt": 21}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 20}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 22}], "image": "https://www.ft.com/__origami/service/image/v2/images/raw/https%3A%2F%2Fwww.ft.com%2F__origami%2Fservice%2Fimage%2Fv2%2Fimages%2Fraw%2Fhttps%253A%252F%252Fd1e00ek4ebabms.cloudfront.net%252Fproduction%252F28ea88b8-929d-484b-a4ba-37e38434a51a.jpg%3Fsource%3Dnext-article%26fit%3Dscale-down%26quality%3Dhighest%26width%3D700%26dpr%3D1?source=next-opengraph&fit=scale-down&width=900&overlay=https://www.ft.com/__assets/creatives/x/ft-overlay.png&overlay_height=0.15&overlay_y=30&overlay_gravity=south_east", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.4509803921568627, "wgt": 161, "relevance": 1}
{"uri": "8150401498", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "19:24:06", "dateTime": "2024-05-28T19:24:06Z", "dateTimePub": "2024-05-28T19:22:56Z", "dataType": "news", "sim": 0.6274510025978088, "url": "https://economictimes.indiatimes.com/news/international/world-news/openai-sets-up-safety-committee/articleshow/110509227.cms", "title": "OpenAI sets up safety committee", "body": "Microsoft-backed OpenAI's chatbots with generative AI capabilities, such as engaging in human-like conversations and creating images based on text prompts, have stirred safety concerns as AI models become more powerful.OpenAI has formed a Safety and Security Committee that will be led by board members, including chief operating officer Sam Altman, as it begins training its next artificial intelligence model, the artificial intelligence startup said Tuesday.\n\nDirectors Bret Taylor, Adam D'Angelo and Nicole Seligman will also lead the committee, OpenAI said on a company blog.\n\nMicrosoft-backed OpenAI's chatbots with generative AI capabilities, such as engaging in human-like conversations and creating images based on text prompts, have stirred safety concerns as AI models become more powerful.\n\nThe new committee will be responsible for making recommendations to the board on safety and security decisions for OpenAI's projects and operations.\n\n\"A new safety committee signifies OpenAI completing a move to becoming a commercial entity, from a more undefined non-profit-like entity,\" said D.A. Davidson managing director Gil Luria.\n\n\"That should help streamline product development while maintaining accountability.\"\n\nFormer Chief Scientist Ilya Sutskever and Jan Leike, who were leaders of OpenAI's Superalignment team, which ensured AI stays aligned to the intended objectives, left the firm earlier this month.\n\nOpenAI had disbanded the Superalignment team, earlier in May, less than a year after the company created it, with some team members being reassigned to other groups, CNBC reported days after the high-profile departures. The committee's first task will be to evaluate and further develop OpenAI's existing safety practices over the next 90 days, following which it will share recommendations with the company's board.", "source": {"uri": "economictimes.indiatimes.com", "dataType": "news", "title": "Economic Times"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 4, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_operating_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief operating officer"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 2, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_scientific_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief scientific officer"}}, {"uri": "http://en.wikipedia.org/wiki/CNBC", "type": "org", "score": 1, "label": {"eng": "CNBC"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 24}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 25}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 21}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 24}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 22}, {"uri": "news/Business", "label": "news/Business", "wgt": 48}], "image": "https://img.etimg.com/thumb/msid-110509311,width-1200,height-630,imgsize-5142,overlay-economictimes/photo.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3803921568627451, "wgt": 160, "relevance": 1}
{"uri": "8150047136", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:55:09", "dateTime": "2024-05-28T14:55:09Z", "dateTimePub": "2024-05-28T14:54:44Z", "dataType": "news", "sim": 0.6274510025978088, "url": "https://www.verdict.co.uk/openai-forms-safety-committee-as-it-begins-training-new-ai-model/", "title": "OpenAI forms safety committee as it begins training new AI model", "body": "The startup behind ChatGPT, OpenAI, has formed a safety committee ahead of training its biggest AI model yet.\n\nOpenAI announced today (28 May) via a blog post that its CEO Sam Altman and Chair Bret Taylor would form a Safety and Security Committee alongside Adam D'Angelo and Nicole Seligman.\n\nSeligman joined OpenAI's board in March 2024 and serves as the director of Intuitive Machines, a space exploration company.\n\nOpenAI's in-house safety and policy specialists, such as chief scientist Jakub Pachocki and head of safety systems Lilian Weng, will also be part of the committee.\n\nOpenAI stated that its committee would help inform safety and ethical decisions ahead of its progress towards artificial general intelligence (AGI).\n\nAGI is a theoretical form of AI where its knowledge surpasses that of a human.\n\nThe Safety and Security Committee's first task will be to expand OpenAI's safeguarding procedures. Over the next 90 days, it will be required to make amendments to OpenAI's current procedures, which will then be posted publicly.\n\nOpenAI clarified that it would continue consultations with external cybersecurity experts.\n\nIt currently works with Rob Joyce, who previously acted as the cybersecurity director of the US National Security Agency, and John Carlin who has worked at the US' Department of Justice.\n\nAccording to research and analysis company GlobalData's executive briefing on AI, the global AI market is set to exceed $1,037bn by 2030, achieving a CAGR of 39% from 2023.\n\nIn its 2024 tech sentiment polls, over 20% of businesses answered that they already had a high adoption rate of AI into their workloads.\n\nAs AI becomes ubiquitous online and in business, countries around the world have rushed to regulate its usage.", "source": {"uri": "verdict.co.uk", "dataType": "news", "title": "Verdict"}, "authors": [{"uri": "alice_nunwick@verdict.co.uk", "name": "Alice Nunwick", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Space_exploration", "type": "wiki", "score": 3, "label": {"eng": "Space exploration"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 2, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 2, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/National_Security_Agency", "type": "wiki", "score": 1, "label": {"eng": "National Security Agency"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Justice"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 26}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 26}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 23}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 25}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 22}], "image": "https://www.verdict.co.uk/wp-content/uploads/2024/05/Shutterstock_2366323225.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-05-28", "textStart": 135, "textEnd": 141}], "sentiment": 0.4039215686274509, "wgt": 160, "relevance": 1}
{"uri": "8150336367", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "18:26:38", "dateTime": "2024-05-28T18:26:38Z", "dateTimePub": "2024-05-28T18:26:00Z", "dataType": "news", "sim": 0.6274510025978088, "url": "https://www.thesun.co.uk/tech/28177771/open-ai-agi-advanced-chatgpt-safety-security-committee/", "title": "OpenAI working on 'next level' of creating intelligence 'smarter than humans'", "body": "OPENAI has created a Safety and Security Committee as it works to make its artificial intelligence platform more advanced than ever, alongside concerns.\n\nThe move to add a safety committee comes as OpenAI recently announced it is working to create AGI which will be \"the next level\" of AI systems.\n\nIt is unclear when AGI would be released and OpenAI is only on the path of its creation at this time.\n\n\"If AGI is successfully created, this technology could help us elevate humanity by increasing abundance, turbocharging the global economy, and aiding in the discovery of new scientific knowledge that changes the limits of possibility,\" OpenAI said in a release in February.\n\n\"AGI has the potential to give everyone incredible new capabilities; we can imagine a world where all of us have access to help with almost any cognitive task, providing a great force multiplier for human ingenuity and creativity.\"\n\nHowever, OpenAI highlighted how if AGI is successfully created there could possibly be the issue of \"serious misuse, drastic accidents, and societal disruption.\"\n\nThe advancements that would come with AGI would be so great that OpenAI does not want to delay its creation over fear but rather tackle it responsibly.\n\n\"Because the upside of AGI is so great, we do not believe it is possible or desirable for society to stop its development forever; instead, society and the developers of AGI have to figure out how to get it right,\" OpenAI added.\n\nOpenAI is also currently training a new upgraded version of its AI - GPT-4o - it also runs ChatGPT.\n\nThe AI research and deployment company has four Titans as its safety board including CEO Sam Altman, chair director Bret Taylor, director Adam D'Angelo, and lawyer Nicole Seligman, OpenAI said in a release on Tuesday.\n\n\"This committee will be responsible for making recommendations to the full Board on critical safety and security decisions for OpenAI projects and operations,\" the release said.\n\n\"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI.\"\n\nThe AI giant wants to open a discussion about any current concerns with AI so the committee can discuss and assist.\n\n\"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment,\" the release continued.\n\n\"A first task of the Safety and Security Committee will be to evaluate and further develop OpenAI's processes and safeguards over the next 90 days.\"\n\nOnce the committee has all the considerations, it will create a new outline to maintain the safety of the platform.\n\n\"At the conclusion of the 90 days, the Safety and Security Committee will share their recommendations with the full Board,\" the release said.\n\n\"Following the full Board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security.\"\n\nOpenaAI is dedicated to consistently improving AI to empower humanity.\n\nIn the announcement about AGI, OpenAI went over key points as to why it believes it is important to keep working at AI in terms of upgrades and safety.\n\nThe goal is to make the universe thrive and flourish with the help of technology.\n\nOpenAI said it doesn't expect a perfect utopia but that it wants to maximize positive outcomes and minimize negative ones, making AGI an enhancer of human potential.\n\nIt aims for the benefits, access, and governance of AGI to be widely and fairly distributed.\n\nThe company insisted it is working to successfully navigate significant risks.", "source": {"uri": "thesun.co.uk", "dataType": "news", "title": "The Sun"}, "authors": [{"uri": "ashley_palya@thesun.co.uk", "name": "Ashley Palya", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Creativity", "type": "wiki", "score": 3, "label": {"eng": "Creativity"}}, {"uri": "http://en.wikipedia.org/wiki/Cognition", "type": "wiki", "score": 3, "label": {"eng": "Cognition"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Outline_(list)", "type": "wiki", "score": 1, "label": {"eng": "Outline (list)"}}, {"uri": "http://en.wikipedia.org/wiki/Utopia", "type": "wiki", "score": 1, "label": {"eng": "Utopia"}}, {"uri": "http://en.wikipedia.org/wiki/Universe", "type": "wiki", "score": 1, "label": {"eng": "Universe"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 18}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 20}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 21}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 17}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 20}], "image": "https://www.thesun.co.uk/wp-content/uploads/2024/05/AK_CHATGPT_OP.jpg?strip=all&quality=100&w=1920&h=1080&crop=1", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.5137254901960784, "wgt": 160, "relevance": 1}
{"uri": "8150144727", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "16:00:36", "dateTime": "2024-05-28T16:00:36Z", "dateTimePub": "2024-05-28T16:00:05Z", "dataType": "news", "sim": 0.6196078658103943, "url": "https://www.mobileworldlive.com/ai-cloud/openai-forms-safety-committee/", "title": "OpenAI forms safety committee", "body": "ChatGPT-maker OpenAI created a safety and security committee made up of its board members with plans to evaluate its existing safeguards and practices in the next 90 days, as it started training a new advanced model.\n\nIn a brief statement, the company explained the committee will be led by its board including CEO Sam Altman. OpenAI's technical and policy experts will also join the advisory body, and it will continue working with external security specialists including Rob Joyce, a US official who served as security advisor under Donald Trump's administration.\n\nOpenAI's head of alignment, Jan Leike, who led safety research, recently resigned.\n\nThe committee will begin to review OpenAI's current safety and security practices in the next three months days and will then \"share their recommendations with the full board\".\n\nCreation of the committee comes as OpenAI started training its \"next frontier model\", a system it expects will bring the company closer to Artificial General Intelligence (AGI).\n\nEarlier this month, OpenAI unveiled a new flagship model GPT-4o, a system it claims is faster than GPT-4 Turbo.\n\nThe move also came on the heels of a recent controversy linked to its alleged replication of movie star Scarlett Johansson's voice for its Sky AI voice assistant, which has since been suspended from the market.", "source": {"uri": "mobileworldlive.com", "dataType": "news", "title": "Mobile World Live"}, "authors": [{"uri": "hana_anandira@mobileworldlive.com", "name": "Hana Anandira", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Donald_Trump", "type": "person", "score": 2, "label": {"eng": "Donald Trump"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 1, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Reproducibility", "type": "wiki", "score": 1, "label": {"eng": "Reproducibility"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 1, "label": {"eng": "Virtual assistant"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial intelligence"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 20}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 22}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 20}, {"uri": "dmoz/Computers/Security/Advisories_and_Patches", "label": "dmoz/Computers/Security/Advisories and Patches", "wgt": 20}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 25}], "image": "https://assets.mobileworldlive.com/wp-content/uploads/2023/05/16113736/MWL_OpenAI_650.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3019607843137255, "wgt": 158, "relevance": 1}
{"uri": "8149997712", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:22:52", "dateTime": "2024-05-28T14:22:52Z", "dateTimePub": "2024-05-28T14:22:08Z", "dataType": "news", "sim": 0.615686297416687, "url": "https://www.pymnts.com/news/artificial-intelligence/2024/openai-forms-safety-committee-it-trains-new-frontier-model/", "title": "OpenAI Forms Safety Committee as It Trains New Frontier Model", "body": "OpenAI formed a security committee following some high-profile concerns about its safety focus.\n\nThe artificial intelligence company announced in a Monday (May 28) blog post the makeup of its new Safety and Security Committee, led by board directors Bret Taylor, Adam D'Angelo, Nicole Seligman, and CEO Sam Altman.\n\nThe committee will be charged with making recommendations to the entire board on crucial safety and security decisions for OpenAI operations and projects, per the post. That includes artificial general intelligence, or AGI, a so-far unrealized version of AI with thinking/reasoning abilities that can match or exceed those of humans.\n\n\"OpenAI has recently begun training its next frontier model, and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI,\" the post said. \"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment.\"\n\nLeike wrote on social platform X earlier this month that he had reached a \"breaking point\" with OpenAI's leadership over the company's central priorities and argued that the firm did not pay enough attention to safety, especially where AGI is concerned.\n\nAltman and OpenAI President Greg Brockman responded with their own message on X, saying they were aware of the risks and potential of AGI and adding that the company had called for international AGI standards and was one of the pioneers in the practice of examining AI systems for catastrophic threats.\n\nMeanwhile, there is a new landmark agreement among AI companies to implement a \"kill switch\" that would halt the development of their most advanced AI models if certain risk thresholds are exceeded.\n\nThe decision has sparked a debate about the future of AI, with proponents seeing the kill switch as a necessary safeguard against the potential dangers of unchecked AI development.\n\nCritics, however, question the effectiveness of the solution.", "source": {"uri": "pymnts.com", "dataType": "news", "title": "PYMNTS.com"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Social_media", "type": "wiki", "score": 2, "label": {"eng": "Social media"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 20}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 23}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 20}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 21}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 21}], "image": "https://www.pymnts.com/wp-content/uploads/2023/12/OpenAI-1.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-05-28", "textStart": 156, "textEnd": 162}], "sentiment": 0.4352941176470588, "wgt": 157, "relevance": 1}
{"uri": "8150216752", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "16:52:30", "dateTime": "2024-05-28T16:52:30Z", "dateTimePub": "2024-05-28T16:51:41Z", "dataType": "news", "sim": 0.6078431606292725, "url": "https://www.engadget.com/openais-new-safety-team-is-led-by-board-members-including-ceo-sam-altman-164927745.html", "title": "OpenAI's new safety team is led by board members, including CEO Sam Altman", "body": "OpenAI has created a new Safety and Security Committee less than two weeks after the company dissolved the team tasked with protecting humanity from AI's existential threats. This latest iteration of the group responsible for OpenAI's safety guardrails will include two board members and CEO Sam Altman, raising questions about whether the move is little more than self-policing theatre amid a breakneck race for profit and dominance alongside partner Microsoft.\n\nThe Safety and Security Committee, formed by OpenAI's board, will be led by board members Bret Taylor (Chair), Nicole Seligman, Adam D'Angelo and Sam Altman (CEO). The new team follows co-founder Ilya Sutskever's and Jan Leike's high-profile resignations, which raised more than a few eyebrows. Their former \"Superalignment Team\" was only created last July.\n\nFollowing his resignation, Leike wrote in an X (Twitter) thread on May 17 that, although he believed in the company's core mission, he left because the two sides (product and safety) \"reached a breaking point.\" Leike added that he was \"concerned we aren't on a trajectory\" to adequately address safety-related issues as AI grows more intelligent. He posted that the Superalignment team had recently been \"sailing against the wind\" within the company and that \"safety culture and processes have taken a backseat to shiny products.\"\n\nA cynical take would be that a company focused primarily on \"shiny products\" -- while trying to fend off the PR blow of high-profile safety departures -- might create a new safety team led by the same people speeding toward those shiny products.\n\nThe safety departures earlier this month weren't the only concerning news from the company recently. It also launched (and quickly pulled) a new voice model that sounded remarkably like two-time Oscar Nominee Scarlett Johansson. The Jojo Rabbit actor then revealed that OpenAI Sam Altman had pursued her consent to use her voice to train an AI model but that she had refused.\n\nIn a statement to Engadget, Johansson's team said she was shocked that OpenAI would cast a voice talent that \"sounded so eerily similar\" to her after pursuing her authorization. The statement added that Johansson's \"closest friends and news outlets could not tell the difference.\"\n\nOpenAI also backtracked on nondisparagement agreements it had required from departing executives, changing its tune to say it wouldn't enforce them. Before that, the company forced exiting employees to choose between being able to speak against the company and keeping the vested equity they earned.\n\nThe Safety and Security Committee plans to \"evaluate and further develop\" the company's processes and safeguards over the next 90 days. After that, the group will share its recommendations with the entire board. After the whole leadership team reviews its conclusions, it will \"publicly share an update on adopted recommendations in a manner that is consistent with safety and security.\"\n\nIn its blog post announcing the new Safety and Security Committee, OpenAI confirmed that the company is currently training its next model, which will succeed GPT-4. \"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment,\" the company wrote.", "source": {"uri": "engadget.com", "dataType": "news", "title": "engadget"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 5, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 4, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 3, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Existentialism", "type": "wiki", "score": 3, "label": {"eng": "Existentialism"}}, {"uri": "http://en.wikipedia.org/wiki/Theatre", "type": "wiki", "score": 3, "label": {"eng": "Theatre"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 3, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Academy_Awards", "type": "wiki", "score": 2, "label": {"eng": "Academy Awards"}}, {"uri": "http://en.wikipedia.org/wiki/Scarlett_Johansson", "type": "person", "score": 2, "label": {"eng": "Scarlett Johansson"}}, {"uri": "http://en.wikipedia.org/wiki/Public_relations", "type": "wiki", "score": 2, "label": {"eng": "Public relations"}}, {"uri": "http://en.wikipedia.org/wiki/Twitter", "type": "org", "score": 2, "label": {"eng": "Twitter"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 1, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Jojo_Rabbit", "type": "wiki", "score": 1, "label": {"eng": "Jojo Rabbit"}}, {"uri": "http://en.wikipedia.org/wiki/Engadget", "type": "wiki", "score": 1, "label": {"eng": "Engadget"}}, {"uri": "http://en.wikipedia.org/wiki/Voice_acting", "type": "wiki", "score": 1, "label": {"eng": "Voice acting"}}, {"uri": "http://en.wikipedia.org/wiki/Equity_(finance)", "type": "wiki", "score": 1, "label": {"eng": "Equity (finance)"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 1, "label": {"eng": "Blog"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 26}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 31}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 33}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 28}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 32}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 58}], "image": "https://s.yimg.com/ny/api/res/1.2/86tmSCW0ryQo8BW.2GQSAQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU7Y2Y9d2VicA--/https://s.yimg.com/os/creatr-uploaded-images/2024-05/8783bc80-1d0e-11ef-bfff-52d37c1678e4", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-05-17", "textStart": 890, "textEnd": 896}], "sentiment": 0.3411764705882352, "wgt": 155, "relevance": 1}
{"uri": "8150470264", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "20:29:01", "dateTime": "2024-05-28T20:29:01Z", "dateTimePub": "2024-05-28T20:28:22Z", "dataType": "news", "sim": 0.6039215922355652, "url": "https://www.chiangraitimes.com/tech/the-openai-safety-committee-conducts/", "title": "The OpenAI Safety Committee Conducts Training For The New Model - CTN News", "body": "(CTN News) - In an announcement made on Tuesday, OpenAI, a startup company that focuses on artificial intelligence, announced that it has established a Safety and Security Committee to oversee the company's safety and security procedures.\n\nMembers of the board, including Sam Altman, who is the CEO of the company, will be in charge of supervising this committee. The company is in the process of training its next artificial intelligence model, and this revelation comes at a crucial time because the company is now dealing with the training process.\n\nFurthermore, according to a blog post OpenAI published regarding the company, directors Bret Taylor, Adam D'Angelo, and Nicole Seligman would be in charge of the committee.\n\nConcerns regarding the security of chatbots that incorporate generative artificial intelligence skills have arisen as a result of the growing strength of artificial intelligence models.\n\nIn addition to the ability to generate visuals based on text inputs, these talents include the capability to engage in conversations that are analogous to those that humans normally have. OpenAI, which has received support from Microsoft, is the company that is involved in the development of these chatbots.\n\nAt the beginning of this month, both Ilya Sutskever, who had previously held the position of Chief Scientist at OpenAI, and Jan Leike, who had been in charge of the Superalignment team, resigned from their positions at the organization.\n\nThe task of ensuring that the objectives of artificial intelligence were maintained in a manner that was congruent with the outcomes that were sought fell on their team.\n\nIt was reported by CNBC a few days after the high-profile departures that OpenAI had disbanded the Superalignment team earlier in May.\n\nThis occurred less than a year after the business had established the Superalignment organization. Following the beginning of the departure of the high-profile personnel, this news was announced. Additionally, a number of the members of the team had been moved to different departments within the firm because of promotion opportunities.\n\nThe newly formed committee will be tasked with the responsibility of presenting recommendations to the board of directors regarding choices affecting safety and security for OpenAI's operations and initiatives, respectively. This responsibility will be assigned to the committee.\n\nBy the time it has finished fulfilling its first obligation, which is to investigate and further enhance OpenAI's existing safety regulations over the course of the following ninety days, it will then present its ideas and suggestions to the board of directors. In the event that ninety days have passed, this will take place.\n\nIn accordance with the business's request, provide an update on the suggestions that have been accepted to the general public.\n\nThe group also includes Jakub Pachocki, who was just recently appointed Chief Scientist, and Matt Knight, who is the head of security. Both of these individuals are additional members of the committee. These two individuals are both represented on the committee in some capacity.\n\nThe corporation will also seek the advice of other professionals, such as Rob Joyce, who served as the head of cybersecurity for the United States National Security Agency, and John Carlin, who was a former officer with the Department of Justice. Both of these individuals have extensive experience in the IT industry.\n\nBoth of these professionals have a significant amount of experience in taking care of concerns related to cybersecurity.\n\nIn spite of the fact that OpenAI did not disclose any additional information on the new \"frontier\" model that it is going through the process of training, the business did announce that it would bring its systems to the \"next level of capabilities on our path to artificial general intelligence.\"\n\nSEE ALSO:", "source": {"uri": "chiangraitimes.com", "dataType": "news", "title": "CTN News l Chiang Rai Times"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 4, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_scientific_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief scientific officer"}}, {"uri": "http://en.wikipedia.org/wiki/CNBC", "type": "org", "score": 2, "label": {"eng": "CNBC"}}, {"uri": "http://en.wikipedia.org/wiki/Board_of_directors", "type": "wiki", "score": 2, "label": {"eng": "Board of directors"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 2, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/National_Security_Agency", "type": "wiki", "score": 1, "label": {"eng": "National Security Agency"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 1, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Information_technology", "type": "wiki", "score": 1, "label": {"eng": "Information technology"}}, {"uri": "http://en.wikipedia.org/wiki/Corporation", "type": "wiki", "score": 1, "label": {"eng": "Corporation"}}], "categories": [{"uri": "dmoz/Computers/Artificial_Intelligence/Associations", "label": "dmoz/Computers/Artificial Intelligence/Associations", "wgt": 28}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 25}, {"uri": "dmoz/Computers/Artificial_Intelligence/Academic_Departments", "label": "dmoz/Computers/Artificial Intelligence/Academic Departments", "wgt": 24}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 27}, {"uri": "dmoz/Society/Government/Intelligence", "label": "dmoz/Society/Government/Intelligence", "wgt": 24}], "image": "https://www.chiangraitimes.com/wp-content/uploads/2024/05/OpenAI-logo1715785806-0.webp", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.388235294117647, "wgt": 154, "relevance": 1}
{"uri": "8150385449", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "19:08:50", "dateTime": "2024-05-28T19:08:50Z", "dateTimePub": "2024-05-28T19:08:10Z", "dataType": "news", "sim": 0.6000000238418579, "url": "https://www.darkreading.com/cybersecurity-operations/openai-forms-another-safety-committee-after-dismantling-prior-team", "title": "OpenAI Forms Another Safety Committee After Dismantling Prior Team", "body": "Open AI is forming a safety and security committee led by company directors Bret Taylor, Adam D'Angelo, Nicole Seligman, and CEO Sam Altman.\n\nThe committee is being formed to make recommendations to the full board on safety measures and security decisions for OpenAI projects and operations.\n\nIn its announcement of the committee, OpenAI noted that it has begun training the next iteration of the large language model that underpins ChatGPT, and that it \"welcomes a robust debate at this important moment\" on AI safety.\n\nThe group is first tasked with evaluating and developing the company's processes and safeguards for the next 90 days, after which the committee will share its recommendations with the board to be reviewed before being shared with the public.\n\nThe formation of the committee comes after Jan Leike, a former OpenAI safety executive, resigned from the company due to criticisms of underinvestment in safety work, as well as tensions with leadership. It also comes after its \"superalignment\" safety oversight team was disassembled, with its members reassigned elsewhere.\n\nIlia Kolochenko, cybersecurity expert and entrepreneur, raises skepticism over how this change in the company ultimately will benefit society at large.\n\n\"While this move is certainly welcome, its eventual benefit for society is largely unclear. Making AI models safe, for instance, to prevent their misuse or dangerous hallucinations, is obviously essential,\" Kolochenko says. \"However, safety is just one of many facets of risks that GenAI vendors have to address. ... Being safe does not necessarily imply being accurate, reliable, fair, transparent, explainable and non-discriminative -- the absolutely crucial characteristics of GenAI solutions.\"", "source": {"uri": "darkreading.com", "dataType": "news", "title": "Dark Reading"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 3, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 3, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 2, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 1, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Hallucination", "type": "wiki", "score": 1, "label": {"eng": "Hallucination"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 30}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 32}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 31}], "image": "https://eu-images.contentstack.com/v3/assets/blt6d90778a997de1cd/blt76195657b1652bc8/64f170bfee3d93baafb00317/openai_SOPA_Images_Limited_Alamy.jpg?disable=upscale&width=1200&height=630&fit=crop", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.4901960784313726, "wgt": 153, "relevance": 1}
{"uri": "2024-05-370982368", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:29:35", "dateTime": "2024-05-28T14:29:35Z", "dateTimePub": "2024-05-28T12:49:00Z", "dataType": "news", "sim": 0.6000000238418579, "url": "https://www.wkow.com/news/openai-forms-safety-committee-as-it-starts-training-latest-artificial-intelligence-model/article_9d3187c0-b3b4-56ad-9eac-54145360a31d.html", "title": "OpenAI forms safety committee as it starts training latest artificial intelligence model", "body": "OpenAI says it's setting up a new safety and security committee and has begun training a new artificial intelligence model to supplant the GPT-4 system that underpins its ChatGPT chatbot. The San Francisco startup said in a blog post Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations. The safety committee is being unveiled as debate swirls around AI safety at the company, after a researcher resigned and then leveled high-profile criticism at OpenAI for letting safety \"take a backseat to shiny products.\"", "source": {"uri": "wkow.com", "dataType": "news", "title": " WKOW"}, "authors": [{"uri": "associated_press@wkow.com", "name": "Associated Press", "type": "author", "isAgency": true}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 4, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 2, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 2, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 2, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 1, "label": {"eng": "AI safety"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 29}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 34}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 36}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 31}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 34}], "image": "https://bloximages.newyork1.vip.townnews.com/wkow.com/content/tncms/assets/v3/editorial/1/27/12760a50-1cf1-11ef-b3f4-e73d87b989ad/6655d37f340b4.image.jpg?crop=640%2C336%2C0%2C72&resize=438%2C230&order=crop%2Cresize", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.6235294117647059, "wgt": 153, "relevance": 1}
{"uri": "8150323132", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "18:15:10", "dateTime": "2024-05-28T18:15:10Z", "dateTimePub": "2024-05-28T18:14:19Z", "dataType": "news", "sim": 0.6000000238418579, "url": "https://www.cnbc.com/2024/05/28/openai-safety-leader-jan-leike-joins-amazon-backed-anthropic.html", "title": "OpenAI former safety leader Jan Leike joins rival AI startup Anthropic", "body": "Leike announced his resignation from OpenAI on May 14, days before the company dissolved the superalignment group he co-led.\n\nJan Leike, one of the lead safety researchers at OpenAI who resigned from the artificial intelligence company earlier this month, said on Tuesday that he's joined rival AI startup Anthropic.\n\nLeike announced his resignation from OpenAI on May 15, days before the company dissolved the superalignment group that he co-led. That team, which formed in 2023, focused on long-term AI risks. OpenAI co-founder Ilya Sutskever announced his departure in a post on X on May 14.\n\n\"I'm excited to join @AnthropicAI to continue the superalignment mission,\" Leike wrote on X. \"My new team will work on scalable oversight, weak-to-strong generalization, and automated alignment research.\"\n\nAnthropic is backed by Amazon, which has committed up to $4 billion in funding for a minority stake in the company.\n\nIn a post following his departure from OpenAI, Leike wrote that, \"Stepping away from this job has been one of the hardest things I have ever done, because we urgently need to figure out how to steer and control AI systems much smarter than us.\"\n\nAI safety has gained rapid importance across the tech sector since OpenAI introduced ChatGPT in late 2022, ushering in a boom in generative AI products and investments. Some in the industry have expressed concern that companies are moving too quickly in releasing powerful AI products to the public without adequately considering potential societal harm.\n\nOpenAI, which is backed by Microsoft, said Tuesday that it created a new safety and security committee led by senior executives, including CEO Sam Altman. The committee will recommend \"safety and security decisions for OpenAI projects and operations\" to the company's board.\n\nAnthropic, founded in 2021 by siblings Dario Amodei and Daniela Amodei and other ex-OpenAI executives, launched its ChatGPT rival Claude 3 in March. In addition to Amazon, the company has received funding from Google, Salesforce and Zoom.", "source": {"uri": "cnbc.com", "dataType": "news", "title": "CNBC"}, "authors": [{"uri": "todd_haselton@cnbc.com", "name": "Todd Haselton", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_(company)", "type": "org", "score": 2, "label": {"eng": "Amazon (company)"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 1, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 1, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Salesforce", "type": "wiki", "score": 1, "label": {"eng": "Salesforce"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 1, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 1, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 13}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 15}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 14}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 14}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 17}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 65}], "image": "https://image.cnbcfm.com/api/v1/image/107408833-1714576860275-gettyimages-2147920483-AA_19042024_1633892.jpeg?v=1714576975&w=1920&h=1080", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-05-14", "textStart": 47, "textEnd": 53, "freq": 2}, {"amb": false, "imp": true, "date": "2024-05-15", "textStart": 365, "textEnd": 371}], "sentiment": 0.2392156862745098, "wgt": 153, "relevance": 1}
{"uri": "8150135491", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "15:55:16", "dateTime": "2024-05-28T15:55:16Z", "dateTimePub": "2024-05-28T15:53:21Z", "dataType": "news", "sim": 0.5960784554481506, "url": "https://mspoweruser.com/openai-is-training-a-new-ai-model-to-succeed-gpt-4-gpt-5-and-establish-a-safety-committee/", "title": "OpenAI is training a new AI model to succeed GPT-4 (GPT-5?) and establish a safety committee", "body": "Read our disclosure page to find out how can you help MSPoweruser sustain the editorial team Read more\n\nOpenAI announced that it has begun training a new AI model made to surpass its current GPT-4 technology. This new model is expected to bring big advancements in AI capabilities and propel the company further on its path to achieving artificial general intelligence (AGI). Could it be GPT-5, which is said to be \"materially better\" and \"better at everything\"?\n\nOn a similar note, when asked about AGI by Elon Musk, he said it'll be out next year.\n\nOpenAI is also forming a new Safety and Security Committee to address the potential risks associated with future AI developments. The committee will evaluate and refine OpenAI's safety protocols over the next three months and make recommendations to the company's board.\n\nOpenAI's announcement comes amid ongoing debates regarding the safety and ethics of AI development. The company highlighted its commitment to responsible AI advancement while acknowledging the importance of open discussion on these critical issues.\n\nThe training process for AI models can take months or even years. Following the training phase, additional time is required for testing and refinement before a model is publicly released. This is a clear example of the fact that OpenAI's new model might not be available for at least another year.\n\nThe formation of the Safety and Security Committee comes after a period of internal turmoil at OpenAI. Ilya Sutskever, a co-founder and safety leader, recently left the company. John Schulman, another co-founder, will now head the safety research efforts.", "source": {"uri": "mspoweruser.com", "dataType": "news", "title": "MSPoweruser"}, "authors": [{"uri": "devesh_beri@mspoweruser.com", "name": "Devesh Beri", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Ethics of artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Elon_Musk", "type": "person", "score": 2, "label": {"eng": "Elon Musk"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 22}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 24}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 29}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 24}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 22}], "image": null, "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3490196078431373, "wgt": 152, "relevance": 1}
{"uri": "8150121318", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "15:44:35", "dateTime": "2024-05-28T15:44:35Z", "dateTimePub": "2024-05-28T15:43:52Z", "dataType": "news", "sim": 0.5921568870544434, "url": "https://www.androidheadlines.com/2024/05/openai-new-safety-oversight-board.html", "title": "OpenAI has a new team to make sure its AI tech doesn't become dangerous", "body": "When it comes to AI, safety is one of the most important topics. As we've seen with the likes of Google and Meta, there's a bad side to this innovative technology. Well, OpenAI just established a new oversight board to ensure that it's developing AI safely.\n\nThe AI startup previously had an oversight board, but the company disbanded it for some reason. Two people on that board, Ilya Sutskever and Jan Leike have since left the company. That doesn't look good on OpenAI especially since there have been rumors floating around that there's tension growing at the company.\n\nAll AI companies should have some sort of entity charged with making sure that the companies don't go overboard. After getting rid of its old board, OpenAI just announced that it has established a new oversight board. The previous board was charged with outlining the potential long-term effects of its AI technology. One worker complained that, over time, the board was getting pushed lower on the priority list, receiving fewer resources as time went on. Let's hope that this doesn't happen with the new board.\n\nSpeaking of the new board, it consists of CEO Sam Altman, company chair Bret Taylor, Adam D'Angelo, and Nicole Seligman. Over the next 90 days, the board will \"evaluate and further develop OpenAI's processes and safeguards\". After that, it will present recommendations to the full board. Then, the full Board will publicly share an update about the recommendations.\n\nRight now, OpenAI is working on its next \"frontier model\" (we're pretty sure that it's GPT-5). As such, it's going to be faster, stronger, and more importantly, smarter than the models on the market today. As such, it's extremely important that the company exercise safety, as we still don't know the ramifications of implementing powerful AI technology into so many aspects of our lives.", "source": {"uri": "androidheadlines.com", "dataType": "news", "title": "Android Headlines"}, "authors": [{"uri": "arthur_brown@androidheadlines.com", "name": "Arthur Brown", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 3, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Nicole_Seligman", "type": "person", "score": 1, "label": {"eng": "Nicole Seligman"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Business/Electronics_and_Electrical/Contract_Manufacturing", "label": "dmoz/Business/Electronics and Electrical/Contract Manufacturing", "wgt": 15}, {"uri": "dmoz/Sports/Extreme_Sports/All-Terrain_Boarding", "label": "dmoz/Sports/Extreme Sports/All-Terrain Boarding", "wgt": 15}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 19}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 14}, {"uri": "dmoz/Games/Board_Games/Developers_and_Publishers", "label": "dmoz/Games/Board Games/Developers and Publishers", "wgt": 14}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 47}], "image": "https://www.androidheadlines.com/wp-content/uploads/2024/03/Sam-Altman-OpenAI-Logo-jpg.webp", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.05882352941176472, "wgt": 151, "relevance": 1}
{"uri": "8149974981", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "14:08:32", "dateTime": "2024-05-28T14:08:32Z", "dateTimePub": "2024-05-28T14:07:36Z", "dataType": "news", "sim": 0.5803921818733215, "url": "https://www.rocketnews.com/2024/05/openai-begins-training-new-frontier-model-but-gpt-5-wont-come-for-at-least-90-days/", "title": "OpenAI begins training new frontier model  --  but GPT-5 won't come for at least 90 days - RocketNews", "body": "Join us in returning to NYC on June 5th to collaborate with executive leaders in exploring comprehensive methods for auditing AI models regarding bias, performance, and ethical compliance across diverse organizations. Find out how you can attend here.\n\nChatGPT-maker OpenAI this morning announced it has begun training its new \"frontier model\" and formed a new Safety and Security Committee led by current board members Bret Taylor (OpenAI board chair and co-founder of customer service startup Sierra AI, former Google Maps lead and former Facebook CTO), Adam D'Angelo (CEO of Quora and AI model aggregator app Poe), Nicole Seligman (former Executive Vice President and global General Counsel of Sony Corporation), and Sam Altman (current OpenAI CEO and one of its co-founders).\n\nAs OpenAI writes in a company blog post:\n\n\"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI. While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment.\"\n\n90 day timer starts now\n\nNotably, the company outlines the role this new committee will play in steering the development of the new frontier AI model, stating:\n\nVB Event\n\nThe AI Impact Tour: The AI Audit\n\nJoin us as we return to NYC on June 5th to engage with top executive leaders, delving into strategies for auditing AI models to ensure fairness, optimal performance, and ethical compliance across diverse organizations. Secure your attendance for this exclusive invite-only event.\n\nRequest an invite\n\n\"A first task of the Safety and Security Committee will be to evaluate and further develop OpenAI's proce ...", "source": {"uri": "rocketnews.com", "dataType": "news", "title": "RocketNews | Top News Stories From Around the Globe"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Bret_Taylor", "type": "person", "score": 3, "label": {"eng": "Bret Taylor"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Audit", "type": "wiki", "score": 3, "label": {"eng": "Audit"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/New_York_City", "type": "loc", "score": 3, "label": {"eng": "New York City"}, "location": {"type": "place", "label": {"eng": "New York City"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 2, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Quora", "type": "org", "score": 2, "label": {"eng": "Quora"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_technology_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief technology officer"}}, {"uri": "http://en.wikipedia.org/wiki/General_counsel", "type": "wiki", "score": 2, "label": {"eng": "General counsel"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 2, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Vice_president", "type": "wiki", "score": 2, "label": {"eng": "Vice president"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 2, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Mobile_app", "type": "wiki", "score": 2, "label": {"eng": "Mobile app"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 2, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 2, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Sony", "type": "org", "score": 2, "label": {"eng": "Sony"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}], "categories": [{"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 25}, {"uri": "dmoz/Recreation/Models/Scale", "label": "dmoz/Recreation/Models/Scale", "wgt": 25}, {"uri": "dmoz/Recreation/Collecting/Models", "label": "dmoz/Recreation/Collecting/Models", "wgt": 23}, {"uri": "dmoz/Recreation/Models/Boats_and_Ships", "label": "dmoz/Recreation/Models/Boats and Ships", "wgt": 23}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 20}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 78}], "image": null, "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-06-05", "textStart": 31, "textEnd": 39, "freq": 2}], "sentiment": 0.5294117647058822, "wgt": 148, "relevance": 1}
{"uri": "8149729229", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "11:39:08", "dateTime": "2024-05-28T11:39:08Z", "dateTimePub": "2024-05-28T11:38:42Z", "dataType": "news", "sim": 0.5803921818733215, "url": "https://www.businesspost.ie/tech/openai-establishes-oversight-board-after-disbanding-safety-team/", "title": "OpenAI establishes oversight board after disbanding safety team", "body": "Artificial Intelligence OpenAI establishes oversight board after disbanding safety team\n\nChief executive Sam Altman included on new committee along with chairman Bret Taylor and others\n\nBusiness Post 12:20\n\nOpenAI has created a board committee to evaluate the safety and security of its artificial intelligence models, a governance change made weeks after its top executive on the the subject resigned and the company effectively disbanded his internal team.\n\nThe move also follows damning criticism of OpenAI's governance by two former board members, Helen Toner and Tasha McCauley, in The Economist on Sunday.\n\nThe new committee will spend 90 days evaluating the safeguards in OpenAI's ...", "source": {"uri": "businesspost.ie", "dataType": "news", "title": "Business Post"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 4, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/The_Economist", "type": "wiki", "score": 1, "label": {"eng": "The Economist"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 16}, {"uri": "dmoz/Computers/Artificial_Intelligence/Associations", "label": "dmoz/Computers/Artificial Intelligence/Associations", "wgt": 19}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 17}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 15}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 19}], "image": "https://imengine.public.prod.sbp.infomaker.io?uuid=875b3bd4-b3e3-57a1-8709-cd3bf2007816&function=cropresize&type=preview&source=false&q=75&crop_w=0.99999&crop_h=0.85878&width=2000&height=1125&x=1.0E-5&y=0.07061", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.2156862745098038, "wgt": 148, "relevance": 1}
{"uri": "8149763344", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "12:00:19", "dateTime": "2024-05-28T12:00:19Z", "dateTimePub": "2024-05-28T11:59:40Z", "dataType": "news", "sim": 0.5803921818733215, "url": "https://www.forbes.com/sites/roberthart/2024/05/28/openai-says-it-has-started-training-gpt-4-successor---heres-what-we-know/", "title": "OpenAI Says It Has Started Training GPT-4 Successor  --  Here's What We Know", "body": "OpenAI has created a new safety and security board and has started work training its next AI model, the company announced Tuesday in a blog post, a rare insight into the hotly anticipated successor to GPT-4, the technology powering its chatbot ChatGPT, as tech companies race to produce increasingly capable AI tools.\n\nGet Forbes Breaking News Text Alerts: We're launching text message alerts so you'll always know the biggest stories shaping the day's headlines. Text \"Alerts\" to (201) 335-0739 or sign up here.\n\nThe company has not explicitly stated this is the name of the model it is now training. To date, OpenAI has followed a clear naming sequence for its foundational models in the form of numerically ascending variations of GPT. Its latest foundational model powering the likes of ChatGPT is GPT-4 so its next flagship model will be expected to take the form of GPT-5. OpenAI is widely expected to release a major update in the form of GPT-5 in coming months, especially in the face of increasingly intense competition from rival models including Meta's Llama 3, Google's Gemini and Anthropic's Claude 3.\n\nAlthough it is \"proud to build and release models that are industry-leading on both capabilities and safety,\" OpenAI said it welcomes \"a robust debate at this important moment.\"\n\nOpenAI did not indicate when this model will be released. Training AI systems can take months or even years. The company recently released an update to GPT-4, GPT-4o, to power its flagship ChatGPT and introduce new features like voice mode, that will enable it to act as a digital assistant like Amazon's Alexa or Apple's Siri. The company has already come under fire for using a voice resembling actress Scarlett Johansson for one of its virtual assistants.\n\nWhile appearing to be transparent at first blush, there is a lot of ambiguity regarding OpenAI's willingness to share what its new committee says. OpenAI said it will \"publicly share an update on adopted recommendations in a manner that is consistent with safety and security\" once the committee has reported to the board, but did not provide a timeframe as to when it will do this after the initial 90 day period. The company's wording is also limited to sharing the recommendations it elects to adopt and it is unclear whether the company will share the committee's full report or recommendations, particularly if they clash with what it decides to, or not to, implement. The company and the committee are likely to come under intense scrutiny from the AI safety community, particularly given OpenAI's stated commitment to safety, division among directors over its approach to safety and recent criticism questioning the commitment from former staff members, as well as the departure of several key safety leaders at the company.\n\nAltman has an estimated net worth of $1 billion. He has no equity in OpenAI so he does not owe his fortune to the company's success. Instead, Altman is a prolific venture investor and his wealth stems from a series of valuable investments, including stakes in fintech darling Stripe, Reddit and nuclear fusion firm Helion. Prior to cofounding OpenAI, Altman founded social mapping company Loopt and was a partner and president at storied startup accelerator Y Combinator.", "source": {"uri": "forbes.com", "dataType": "news", "title": "Forbes"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 5, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 5, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_pre-trained_transformer", "type": "wiki", "score": 3, "label": {"eng": "Generative pre-trained transformer"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 3, "label": {"eng": "Virtual assistant"}}, {"uri": "http://en.wikipedia.org/wiki/Text_messaging", "type": "wiki", "score": 3, "label": {"eng": "Text messaging"}}, {"uri": "http://en.wikipedia.org/wiki/Forbes", "type": "org", "score": 3, "label": {"eng": "Forbes"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_Alexa", "type": "wiki", "score": 2, "label": {"eng": "Amazon Alexa"}}, {"uri": "http://en.wikipedia.org/wiki/Siri", "type": "wiki", "score": 2, "label": {"eng": "Siri"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 2, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 1, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Stripe,_Inc.", "type": "wiki", "score": 1, "label": {"eng": "Stripe, Inc."}}, {"uri": "http://en.wikipedia.org/wiki/Y_Combinator", "type": "org", "score": 1, "label": {"eng": "Y Combinator"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_accelerator", "type": "wiki", "score": 1, "label": {"eng": "Startup accelerator"}}, {"uri": "http://en.wikipedia.org/wiki/Venture_capital", "type": "wiki", "score": 1, "label": {"eng": "Venture capital"}}, {"uri": "http://en.wikipedia.org/wiki/Reddit", "type": "org", "score": 1, "label": {"eng": "Reddit"}}, {"uri": "http://en.wikipedia.org/wiki/Equity_(finance)", "type": "wiki", "score": 1, "label": {"eng": "Equity (finance)"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 17}, {"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 19}, {"uri": "dmoz/Recreation/Models/Scale", "label": "dmoz/Recreation/Models/Scale", "wgt": 19}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 21}, {"uri": "dmoz/Recreation/Models/Boats_and_Ships", "label": "dmoz/Recreation/Models/Boats and Ships", "wgt": 17}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 81}], "image": "https://imageio.forbes.com/specials-images/imageserve/6655c2558635c98814744c40/0x0.jpg?format=jpg&crop=2425,1365,x0,y36,safe&height=600&width=1200&fit=bounds", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.2705882352941176, "wgt": 148, "relevance": 1}
{"uri": "8149864507", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "13:01:24", "dateTime": "2024-05-28T13:01:24Z", "dateTimePub": "2024-05-28T13:00:52Z", "dataType": "news", "sim": 0.5764706134796143, "url": "https://windowsreport.com/openai-training-new-language-model-replace-gpt-4/", "title": "Clock is ticking for GPT-4 as OpenAI trains a new model to replace it", "body": "Read our disclosure page to find out how can you help Windows Report sustain the editorial team Read more\n\nEver since the introduction of ChatGPT, all major companies have started developing their language models to compete with it.\n\nOpenAI, creator of ChatGPT, recently stated that they are training a new language model, so let's see what that means.\n\nAs the New York Times reports, OpenAI stated that it has begun training a new AI model that will replace GPT-4.\n\nAccording to OpenAI, they expect the new model to bring the next level of capabilities while planning to build artificial general intelligence. The new model would act as an engine for various AI products.\n\nThe company is also creating a new Safety and Security Committee as Axios writes, that will assess the risk of this technology. OpenAI stated the following:\n\nWhile we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment.\n\nThe committee is advisory, and it will collaborate with an array of security experts, its first task is to enhance the OpenAI's processes and safeguards.\n\nIt's great to see that OpenAI plans to push the boundaries of artificial intelligence while seriously taking into consideration all the possible risks that come with it.\n\nDo keep in mind that training an AI model can take months or years to complete. Once the training is finished, there's a period of internal testing and tweaking before it can be released to the public.\n\nWhile this announcement has many excited, it will be months before we can see this new model available to the public.\n\nOpenAI CTO stated that a successor to GPT-4 will be unveiled later this year, so we can just sit tight and wait for the official announcement.\n\nIn case you missed it, OpenAI announced GPT-4o recently and it brings various improvements, including the ability to recognize voice input and hold conversations.\n\nIn other news, the new Copilot UI seems to take inspiration from ChatGPT, which doesn't seem like a surprise since it already runs on GPT-4 technology.", "source": {"uri": "windowsreport.com", "dataType": "news", "title": "Windows Report | Error-free Tech Life"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Language_model", "type": "wiki", "score": 5, "label": {"eng": "Language model"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/The_New_York_Times", "type": "wiki", "score": 3, "label": {"eng": "The New York Times"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 2, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_technology_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief technology officer"}}, {"uri": "http://en.wikipedia.org/wiki/User_interface", "type": "wiki", "score": 1, "label": {"eng": "User interface"}}], "categories": [{"uri": "dmoz/Business/Arts_and_Entertainment/Models", "label": "dmoz/Business/Arts and Entertainment/Models", "wgt": 25}, {"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 29}, {"uri": "dmoz/Recreation/Models/Scale", "label": "dmoz/Recreation/Models/Scale", "wgt": 30}, {"uri": "dmoz/Recreation/Collecting/Models", "label": "dmoz/Recreation/Collecting/Models", "wgt": 27}, {"uri": "dmoz/Recreation/Models/Boats_and_Ships", "label": "dmoz/Recreation/Models/Boats and Ships", "wgt": 28}], "image": "https://windowsreport.com/wp-content/uploads/2024/05/openAI-new-model.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.3647058823529412, "wgt": 147, "relevance": 1}
{"uri": "8150315339", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "18:08:26", "dateTime": "2024-05-28T18:08:26Z", "dateTimePub": "2024-05-28T18:07:48Z", "dataType": "news", "sim": 0.572549045085907, "url": "https://qz.com/jan-leike-openai-superalignment-rival-anthropic-ai-safe-1851504247", "title": "Former OpenAI safety co-lead goes to rival Anthropic", "body": "Less than two weeks after leaving OpenAI, one of the company's former artificial intelligence safety leads announced that he's landed at one of its rivals.\n\nJan Leike, who co-led OpenAI's now-disbanded \"Superalignment team,\" which was responsible for AI's existential dangers, resigned from the company earlier this month. On Tuesday, Leike said on X he was \"excited\" to join the AI company Anthropic \"to continue the superalignment mission.\" He added that his new team \"will work on scalable oversight, weak-to-strong generalization, and automated alignment research.\"\n\nAnthropic, which recently secured a $4 billion investment from Amazon, said its latest AI model family released in March, Claude 3, outperformed OpenAI's GPT-4.\n\nThe company was founded by former OpenAI employees Daniela and Dario Amodei in 2021 to develop \"safer\" chatbots. The Amodei siblings took a stab at OpenAI earlier this month, saying at Bloomberg's Technology Summit that its Claude 3 Opus model \"is the most capable and powerful AI model available anywhere in the world.\"\n\nLeike announced his departure from OpenAI after his co-lead, Ilya Sutskever, who also co-founded the company and served as its chief scientist, said he was leaving. Leike called his decision to leave \"one of the hardest things I have ever done, because we urgently need to figure out how to steer and control AI systems much smarter than us.\"\n\nLeike wrote that he joined OpenAI because he thought the company \"would be the best place in the world to do this research,\" but that he had \"been disagreeing with OpenAI leadership about the company's core priorities for quite some time, until we finally reached a breaking point.\" He continued by writing that OpenAI should prioritize safety as it pursues artificial general intelligence, or AGI.\n\nOpenAI reportedly did not keep its commitments to the Superalignment team that it announced last July. The team's requests for access to GPUs, or graphics processing units, were repeatedly turned down, and it never came close to receiving its promised computing power budget of 20%, Fortune reported, citing sources familiar with the matter.", "source": {"uri": "qz.com", "dataType": "news", "title": "Quartz"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 2, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Summit_(supercomputer)", "type": "wiki", "score": 2, "label": {"eng": "Summit (supercomputer)"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 2, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_(company)", "type": "org", "score": 2, "label": {"eng": "Amazon (company)"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Fortune_(magazine)", "type": "wiki", "score": 1, "label": {"eng": "Fortune (magazine)"}}, {"uri": "http://en.wikipedia.org/wiki/Computing", "type": "wiki", "score": 1, "label": {"eng": "Computing"}}, {"uri": "http://en.wikipedia.org/wiki/Graphics_processing_unit", "type": "wiki", "score": 1, "label": {"eng": "Graphics processing unit"}}], "categories": [{"uri": "dmoz/Computers/Artificial_Intelligence", "label": "dmoz/Computers/Artificial Intelligence", "wgt": 15}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 19}, {"uri": "dmoz/Computers/Artificial_Intelligence/Academic_Departments", "label": "dmoz/Computers/Artificial Intelligence/Academic Departments", "wgt": 15}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 18}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 16}], "image": "https://i.kinja-img.com/image/upload/c_fill,h_675,pg_1,q_80,w_1200/dd2dd81ccabe1897b6654be8accfe869.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.2470588235294118, "wgt": 146, "relevance": 1}
{"uri": "8149712525", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "11:31:56", "dateTime": "2024-05-28T11:31:56Z", "dateTimePub": "2024-05-28T11:28:04Z", "dataType": "news", "sim": 0.5647059082984924, "url": "https://theprint.in/tech/openai-sets-up-safety-committee-as-it-starts-training-new-model/2105186/", "title": "OpenAI sets up safety committee as it starts training new model", "body": "Former Chief Scientist Ilya Sutskever and Jan Leike, who were leaders of Microsoft-backed OpenAI's Superalignment team, which ensured AI stays aligned to the intended objectives, left the firm earlier this month.\n\nOpenAI had disbanded the Superalignment team earlier in May, less than a year after the company created it, with some team members being reassigned to other groups, CNBC reported days after the high-profile departures.\n\nThe committee will be responsible for making recommendations to the board on safety and security decisions for OpenAI's projects and operations.\n\nIts first task will be to evaluate and further develop OpenAI's existing safety practices over the next 90 days, following which it will share recommendations with the board.\n\nAfter the board's review, OpenAI will publicly share an update on adopted recommendations, the company said.\n\nOther committee members include the company's technical and policy experts Aleksander Madry, Lilian Weng and head of alignment sciences John Schulman. Newly appointed Chief Scientist Jakub Pachocki and head of security Matt Knight will also be on the committee.\n\n(Reporting by Arsheeya Bajwa and Akash Sriram in Bengaluru; Editing by Tasim Zahid and Vijay Kishore)", "source": {"uri": "theprint.in", "dataType": "news", "title": "ThePrint"}, "authors": [{"uri": "reuters@theprint.in", "name": "Reuters", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 3, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_scientific_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief scientific officer"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/CNBC", "type": "org", "score": 2, "label": {"eng": "CNBC"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 14}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 16}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 17}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 16}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 21}], "image": null, "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.2784313725490195, "wgt": 144, "relevance": 1}
{"uri": "8150289550", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "17:47:43", "dateTime": "2024-05-28T17:47:43Z", "dateTimePub": "2024-05-28T17:46:35Z", "dataType": "news", "sim": 0.5607843399047852, "url": "https://www.cryptotimes.io/2024/05/28/openai-forms-oversight-board-led-by-sam-altman/", "title": "OpenAI Forms Oversight Board Led by Sam Altman", "body": "The newly formed group will assess OpenAI's technology's security measures for ninety days and then provide a report.\n\nOpenAI changed its governance and established a board committee to assess the security and safety of its AI models, a few weeks after its top executive on the matter left and the business essentially dismantled his internal team.\n\nThe action comes after two former board members, Helen Toner and Tasha McCauley, published harsh critiques of OpenAI's administration in The Economist on Sunday.\n\nThe newly formed group will assess OpenAI's technology's security measures for ninety days and then provide a report. \"Following the full board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security,\" the company stated in a blog post on Tuesday.\n\nThe private company's recent, quick advancements in AI have sparked questions about how it handles the possible risks of the technology.\n\nConcerns grew last fall when CEO Sam Altman was momentarily removed in a boardroom coup following disagreements with chief scientist and co-founder Ilya Sutskever on the pace of AI product development and safety precautions.\n\nConcerns resurfaced this month following the departure of Sutskever and Jan Leike, key figures at OpenAI. They led the superalignment team, focused on superhuman AI threats. Leike, who resigned, cited resource struggles, echoed by other departing employees.\n\nAfter Sutskever's exit, OpenAI absorbed his team into broader research initiatives instead of keeping it separate. Co-founder John Schulman now leads alignment research in an expanded role, titled Head of Alignment Science.\n\nThe startup has occasionally had trouble handling employee turnover. OpenAI eliminated a provision last week that would have deprived former employees of their shares if they had spoken out against the firm.", "source": {"uri": "cryptotimes.io", "dataType": "news", "title": "The Crypto Times"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Privately_held_company", "type": "wiki", "score": 2, "label": {"eng": "Privately held company"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 2, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/The_Economist", "type": "wiki", "score": 2, "label": {"eng": "The Economist"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 1, "label": {"eng": "Startup company"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 18}, {"uri": "dmoz/Computers/Security/Internet", "label": "dmoz/Computers/Security/Internet", "wgt": 15}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 15}, {"uri": "dmoz/Science/Educational_Resources/Assessment", "label": "dmoz/Science/Educational Resources/Assessment", "wgt": 15}, {"uri": "dmoz/Computers/Security/Advisories_and_Patches", "label": "dmoz/Computers/Security/Advisories and Patches", "wgt": 16}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 46}], "image": "https://www.cryptotimes.io/wp-content/uploads/2024/05/image-800x500-10-2.png", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.07450980392156858, "wgt": 143, "relevance": 1}
{"uri": "8150303386", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "17:58:42", "dateTime": "2024-05-28T17:58:42Z", "dateTimePub": "2024-05-28T17:58:03Z", "dataType": "news", "sim": 0.5607843399047852, "url": "https://winbuzzer.com/2024/05/28/jan-leike-joins-anthropic-to-lead-new-ai-safety-team-xcxwbn/", "title": "Former OpenAI Safety Lead Jan Leike Joins Anthropic in Similar Role - WinBuzzer", "body": "Leike announced via a post on X that his new team at Anthropic will concentrate on various facets of AI safety and security. The primary areas of focus will include scalable oversight, weak-to-strong generalization, and automated alignment research.\n\nA source familiar with the matter told TechCrunch that Leike will report directly to Jared Kaplan, Anthropic's chief science officer. Researchers at Anthropic currently engaged in scalable oversight will now report to Leike as his team begins its work.\n\nLeike's new role at Anthropic bears resemblance to his previous position at OpenAI, where he co-led the Superalignment team. This team aimed to address the technical challenges of controlling superintelligent AI within four years but faced obstacles due to OpenAI's leadership decisions.\n\nAnthropic has consistently positioned itself as prioritizing safety more than OpenAI. This stance is reflected in its leadership, with CEO Dario Amodei, a former VP of research at OpenAI, having left the company due to disagreements over its commercial direction. Amodei, along with several ex-OpenAI employees, including former policy lead Jack Clark, founded Anthropic with a focus on AI safety.\n\nDario Amodei's departure from OpenAI was driven by a divergence in vision, particularly regarding the company's increasing commercial focus. This split led to the formation of Anthropic, which has since attracted several former OpenAI employees who share a commitment to prioritizing AI safety and ethical considerations.\n\nLeike's move to Anthropic underscores a growing emphasis on AI safety within the industry. By leading the new superalignment team, Leike aims to advance research in scalable oversight and alignment, ensuring that AI systems behave in predictable and desirable ways.\n\nAt OpenAI, resource allocation issues have led to the resignation of several team members, including co-lead Jan Leike, a former DeepMind researcher.\n\nLeike, who has played a significant role in the development of ChatGPT, GPT-4, and InstructGPT, publicly cited disagreements with OpenAI leadership regarding the company's core priorities. In a series of posts on X, Leike expressed concerns about the company's focus, stating that more effort should be dedicated to preparing for future AI models, emphasizing security, monitoring, safety, and societal impact.\n\nMeanwhile, OpenAI has announced the creation of a new Safety and Security Committee within its Board of Directors to oversee the safety of its generative AI systems.\n\nThe committee includes OpenAI's CEO Sam Altman, board members Bret Taylor, Adam D'Angelo, and Nicole Seligman, along with chief scientist Jakub Pachocki and head of security Matt Knight. The committee will also consult with external safety and security experts.", "source": {"uri": "winbuzzer.com", "dataType": "news", "title": "WinBuzzer"}, "authors": [{"uri": "markus_kasanmascheff@winbuzzer.com", "name": "Markus Kasanmascheff", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Anthropic", "type": "wiki", "score": 5, "label": {"eng": "Anthropic"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 5, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/TechCrunch", "type": "wiki", "score": 3, "label": {"eng": "TechCrunch"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_scientific_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief scientific officer"}}, {"uri": "http://en.wikipedia.org/wiki/Superintelligence", "type": "wiki", "score": 2, "label": {"eng": "Superintelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 1, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 1, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/DeepMind", "type": "org", "score": 1, "label": {"eng": "DeepMind"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 1, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial intelligence"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 16}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 18}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 18}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 16}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 18}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 56}], "image": "https://winbuzzer.com/wp-content/uploads/2024/03/Anthropic-Claude-3-Logo.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.1215686274509804, "wgt": 143, "relevance": 1}
{"uri": "8150288993", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "17:46:56", "dateTime": "2024-05-28T17:46:56Z", "dateTimePub": "2024-05-28T17:46:07Z", "dataType": "news", "sim": 0.5490196347236633, "url": "https://finance.yahoo.com/news/ex-openai-safety-leader-leike-171840325.html", "title": "Ex-OpenAI Safety Leader Leike to Join Rival Anthropic", "body": "(Bloomberg) -- Jan Leike, the former co-head of an OpenAI safety team focused on long-term risks, is joining its artificial intelligence rival Anthropic, Leike said in a post on X Tuesday.\n\nMost Read from Bloomberg\n\nLeike left the company earlier this month after Ilya Sutskever, the other leader of OpenAI's Superalignment team, resigned from the company. The team they once lead was subsequently dissolved.\n\nAs he departed Leike criticized OpenAI, saying that \"safety culture and processes have taken a backseat to shiny products.\" On Tuesday, OpenAI formed a new safety team featuring Chief Executive Officer Sam Altman.\n\nLeike's work at Anthropic will focus on similar topics to what he worked on at OpenAI, he said -- safety issues related to the control of so-called superhuman AI models. Such AI models do not yet exist, but companies such as OpenAI and Anthropic are conducting research into how they could be controlled if they are built in the future.\n\nAnthropic, formed by former OpenAI staffers, has billed itself as a more safety-focused AI company. Leike did not immediately respond to a request for comment.", "source": {"uri": "finance.yahoo.com", "dataType": "news", "title": "Yahoo! Finance"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Bloomberg_News", "type": "org", "score": 5, "label": {"eng": "Bloomberg News"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 3, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 15}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 17}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 17}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 16}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 17}, {"uri": "news/Business", "label": "news/Business", "wgt": 49}], "image": "https://s.yimg.com/ny/api/res/1.2/s5QRECljtg3WNtw1WoRyfA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/bloomberg_technology_68/1e5d19f908cd1e51da17ff1b10bb7b73", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.1607843137254903, "wgt": 140, "relevance": 1}
{"uri": "2024-05-371058775", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "15:39:07", "dateTime": "2024-05-28T15:39:07Z", "dateTimePub": "2024-05-28T14:24:26Z", "dataType": "news", "sim": 0.545098066329956, "url": "https://www.djournal.com/news/national/openai-forms-ai-safety-committee-after-key-departures/article_1d4c1e3d-2139-5452-a95b-235d15367961.html", "title": "OpenAI forms AI safety committee after key departures", "body": "OpenAI, the company behind ChatGPT, announced the formation of a new safety committee on Tuesday, weeks after the departures of key executives raised questions about the firm's commitment to mitigating the dangers of artificial intelligence.\n\nThe company said the committee, which will include CEO Sam Altman, is being established as OpenAI begins training its next AI model, expected to surpass the capabilities of the GPT-4 system powering ChatGPT.\n\nNewsletters", "source": {"uri": "djournal.com", "dataType": "news", "title": "Daily Journal"}, "authors": [{"uri": "agence_france_presse@djournal.com", "name": "Agence France-Presse", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 3, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 1, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}], "categories": [{"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 19}, {"uri": "dmoz/Computers/Artificial_Intelligence/Associations", "label": "dmoz/Computers/Artificial Intelligence/Associations", "wgt": 17}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 21}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 17}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 25}], "image": "https://bloximages.newyork1.vip.townnews.com/djournal.com/content/tncms/assets/v3/editorial/7/6f/76ffb17d-7ffd-58b9-b940-8ae74e124c5d/664e8a8877673.image.jpg?crop=512%2C269%2C0%2C36&resize=438%2C230&order=crop%2Cresize", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.2705882352941176, "wgt": 139, "relevance": 1}
{"uri": "8150434990", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "19:55:51", "dateTime": "2024-05-28T19:55:51Z", "dateTimePub": "2024-05-28T19:54:02Z", "dataType": "news", "sim": 0.5411764979362488, "url": "https://uk.investing.com/news/stock-market-news/sam-altmans-openai-responds-to-security-concerns-with-new-governance-team-3518953", "title": "Sam Altman's OpenAI Responds To Security Concerns With New Governance Team By Benzinga", "body": "Benzinga - by Shivani Kumaresan, Benzinga Staff Writer.\n\nMicrosoft Corp (NASDAQ:MSFT) backed OpenAI has established a new board committee dedicated to evaluating the safety and security of its artificial intelligence models.\n\nThe governance change comes shortly after the resignation of a key executive in the area and the subsequent disbanding of his internal team.\n\nOpenAI announced that the committee will spend 90 days assessing the safeguards in its technology before presenting a report, according to a report from Bloomberg.\n\nThe company plans to publicly share updates on the recommendations after the full board's review. Additionally, OpenAI revealed that it has begun training its latest AI model.\n\nSam Altman, Chief Executive Officer, was briefly ousted last fall following a clash with co-founder and chief scientist Ilya Sutskever over the pace of AI development and measures to mitigate potential harms.\n\nAlso Read: OpenAI's ChatGPT Fails To Meet EU's Data Accuracy Standards, Says Privacy Watchdog\n\nConcerns resurfaced this month when Sutskever and key deputy Jan Leike left the company. Leike, who led the superalignment team addressing long-term AI threats, cited struggles with computing resources as a reason for his resignation.\n\nAfter Sutskever's departure, OpenAI dissolved its team and reassigned its tasks to the research unit under co-founder John Schulman, now Head of Alignment Science.\n\nThe company has also revoked a policy that penalized ex-employees equity if they publicly criticized the firm.\n\nDisclaimer: This content was partially produced with the help of AI tools and was reviewed and published by Benzinga editors.\n\nRead Next: Scarlett Johansson's Feud With OpenAI' Puts A Human Face' On Hollywood's AI Fears\n\nPhoto via Shutterstock", "source": {"uri": "uk.investing.com", "dataType": "news", "title": "Investing.com UK"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 3, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Bloomberg_News", "type": "org", "score": 2, "label": {"eng": "Bloomberg News"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Scarlett_Johansson", "type": "person", "score": 1, "label": {"eng": "Scarlett Johansson"}}, {"uri": "http://en.wikipedia.org/wiki/Equity_(finance)", "type": "wiki", "score": 1, "label": {"eng": "Equity (finance)"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 14}, {"uri": "dmoz/Computers/Artificial_Intelligence", "label": "dmoz/Computers/Artificial Intelligence", "wgt": 14}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 18}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 19}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 17}], "image": "https://i-invdn-com.investing.com/news/LYNXNPEB6U08A_L.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": -0.04313725490196074, "wgt": 138, "relevance": 1}
{"uri": "2024-05-371224213", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "18:38:29", "dateTime": "2024-05-28T18:38:29Z", "dateTimePub": "2024-05-28T17:54:05Z", "dataType": "news", "sim": 0.5372549295425415, "url": "https://www.gzeromedia.com/gzero-ai/openai-announces-next-model-and-new-safety-committee", "title": "OpenAI announces next model and new safety committee", "body": "An image of OpenAI CEO Sam Altman is seen on a mobile device screen in this illustration.\n\nOpenAI announced that it is training a new generative AI model to eventually replace GPT-4, the industry-standard model that powers ChatGPT and Microsoft Copilot.\n\nBut the OpenAI board of directors also said that it's forming a new Safety and Security Committee to advise it on the risks posed by powerful AI. After the previous board of directors abruptly fired CEO Sam Altman for not being candid with them in November 2023, OpenAI staffers and lead investor Microsoft pressured the board to rehire Altman. It worked: Altman rejoined the company, and most of the old board members resigned.\n\nOpenAI has sought to be an industry leader in generative AI while staying in the good graces of regulators looking to rein in its ambitions. OpenAI took the Biden administration's voluntary pledge to mitigate AI risks in July 2023, and Altman recently joined the Department of Homeland Security's new Artificial Intelligence Safety and Security Board.\n\nThe US has done little to curb the ambitions of its most prominent AI firms, but that good grace is dependent on the appearance of being a reliable and trustworthy actor -- one that will propel Silicon Valley ahead of other global tech hubs while building AI that can help humanity, not harm it.", "source": {"uri": "gzeromedia.com", "dataType": "news", "title": "GZERO Media"}, "authors": [{"uri": "scott_nover@gzeromedia.com", "name": "Scott Nover", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 4, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 4, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 3, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Joe_Biden", "type": "person", "score": 1, "label": {"eng": "Joe Biden"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Homeland_Security", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Homeland Security"}}, {"uri": "http://en.wikipedia.org/wiki/Silicon_Valley", "type": "loc", "score": 1, "label": {"eng": "Silicon Valley"}, "location": null}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 15}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 13}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 16}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 19}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 15}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 55}], "image": "https://www.gzeromedia.com/media-library/an-image-of-openai-ceo-sam-altman-is-seen-on-a-mobile-device-screen-in-this-illustration.jpg?id=52334521&width=1245&height=700&coordinates=0%2C74%2C0%2C0", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.09019607843137245, "wgt": 137, "relevance": 1}
{"uri": "8150478304", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "20:37:04", "dateTime": "2024-05-28T20:37:04Z", "dateTimePub": "2024-05-28T20:36:20Z", "dataType": "news", "sim": 0.529411792755127, "url": "https://finance.yahoo.com/news/sam-altmans-openai-responds-security-202742606.html", "title": "Sam Altman's OpenAI Responds To Security Concerns With New Governance Team", "body": "Microsoft Corp (NASDAQ:MSFT) backed OpenAI has established a new board committee dedicated to evaluating the safety and security of its artificial intelligence models.\n\nThe governance change comes shortly after the resignation of a key executive in the area and the subsequent disbanding of his internal team.\n\nOpenAI announced that the committee will spend 90 days assessing the safeguards in its technology before presenting a report, according to a report from Bloomberg.\n\nThe company plans to publicly share updates on the recommendations after the full board's review. Additionally, OpenAI revealed that it has begun training its latest AI model.\n\nSam Altman, Chief Executive Officer, was briefly ousted last fall following a clash with co-founder and chief scientist Ilya Sutskever over the pace of AI development and measures to mitigate potential harms.\n\nAlso Read: OpenAI's ChatGPT Fails To Meet EU's Data Accuracy Standards, Says Privacy Watchdog\n\nConcerns resurfaced this month when Sutskever and key deputy Jan Leike left the company. Leike, who led the superalignment team addressing long-term AI threats, cited struggles with computing resources as a reason for his resignation.\n\nAfter Sutskever's departure, OpenAI dissolved its team and reassigned its tasks to the research unit under co-founder John Schulman, now Head of Alignment Science.\n\nThe company has also revoked a policy that penalized ex-employees equity if they publicly criticized the firm.\n\nDisclaimer: This content was partially produced with the help of AI tools and was reviewed and published by Benzinga editors.\n\nRead Next: Scarlett Johansson's Feud With OpenAI' Puts A Human Face' On Hollywood's AI Fears\n\nPhoto via Shutterstock\n\n\"ACTIVE INVESTORS' SECRET WEAPON\" Supercharge Your Stock Market Game with the #1 \"news & everything else\" trading tool: Benzinga Pro - Click here to start Your 14-Day Trial Now!\n\n\u00a9 2024 Benzinga.com. Benzinga does not provide investment advice. All rights reserved.", "source": {"uri": "finance.yahoo.com", "dataType": "news", "title": "Yahoo! Finance"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Bloomberg_L.P.", "type": "org", "score": 3, "label": {"eng": "Bloomberg L.P."}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 3, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 2, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 2, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Computing", "type": "wiki", "score": 1, "label": {"eng": "Computing"}}, {"uri": "http://en.wikipedia.org/wiki/Shutterstock", "type": "org", "score": 1, "label": {"eng": "Shutterstock"}}, {"uri": "http://en.wikipedia.org/wiki/Scarlett_Johansson", "type": "person", "score": 1, "label": {"eng": "Scarlett Johansson"}}, {"uri": "http://en.wikipedia.org/wiki/Equity_(finance)", "type": "wiki", "score": 1, "label": {"eng": "Equity (finance)"}}], "categories": [{"uri": "dmoz/Business/Investing", "label": "dmoz/Business/Investing", "wgt": 14}, {"uri": "dmoz/Computers/Artificial_Intelligence", "label": "dmoz/Computers/Artificial Intelligence", "wgt": 14}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 17}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 20}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 17}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 69}], "image": "https://media.zenfs.com/en/Benzinga/6cda6f2bd20b42ed30e222bb2b6a0e40", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": -0.08235294117647063, "wgt": 135, "relevance": 1}
{"uri": "8150291054", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "17:48:20", "dateTime": "2024-05-28T17:48:20Z", "dateTimePub": "2024-05-28T17:47:48Z", "dataType": "news", "sim": 0.501960813999176, "url": "https://www.semafor.com/article/05/28/2024/openai-forms-safety-council-led-by-sam-altman-and-trains-gpt-4-successor", "title": "OpenAI forms safety council  --  while training a powerful new AI model", "body": "Sign up for Semafor Technology: What's next in the new era of tech. Read it now.\n\nChatGPT creator OpenAI is training a powerful new model to fuel its chatbot and image generation tools, the company said Tuesday. It is also launching a new committee focused on safety, following scrutiny over its safety efforts and several high-profile resignations.\n\nThe moves follow a controversy earlier this month in which OpenAI suspended a voice chatbot after actress Scarlett Johansson accused the company of copying her AI voice character from the movie Her.\n\nOpenAI said the next model will \"bring us to the next level of capabilities on our path to AGI,\" which refers to artificial general intelligence -- AI systems that could eventually match or surpass human capabilities.", "source": {"uri": "semafor.com", "dataType": "news", "title": "semafor.com"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 4, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Semafor_(website)", "type": "wiki", "score": 3, "label": {"eng": "Semafor (website)"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Artificial intelligence"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 19}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 23}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 19}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 19}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 20}], "image": "https://img.semafor.com/380dc02b24bb658b5fe0e70f1557e6c2a04ff7f6-3500x2138.jpg?rect=0,150,3500,1838&w=1200&h=630&q=75&auto=format", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.1607843137254903, "wgt": 128, "relevance": 1}
{"uri": "2024-05-370810071", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "12:04:27", "dateTime": "2024-05-28T12:04:27Z", "dateTimePub": "2024-05-28T11:36:57Z", "dataType": "news", "sim": 0.501960813999176, "url": "https://www.bakersfield.com/ap/news/openai-forms-safety-committee-as-it-starts-training-latest-artificial-intelligence-model/article_d422eaa6-12ae-5b7e-93f6-ba825a3c62b7.html", "title": "OpenAI forms safety committee as it starts training latest artificial intelligence model", "body": "OpenAI says it's setting up a new safety and security committee and has begun training a new artificial intelligence model to supplant the GPT-4 system that underpins its ChatGPT chatbot\n\nOpenAI says it's setting up a new safety and security committee and has begun training a new artificial intelligence model to supplant the GPT-4 system that underpins its ChatGPT chatbot.\n\nThe San Francisco startup said in a blog post Tuesday that the committee will advise the full board on \"critical safety and security decisions\" for its projects and operations.", "source": {"uri": "bakersfield.com", "dataType": "news", "title": "The Bakersfield Californian"}, "authors": [{"uri": "associated_press@bakersfield.com", "name": "Associated Press", "type": "author", "isAgency": true}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 3, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 2, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 1, "label": {"eng": "Startup company"}}], "categories": [{"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 26}, {"uri": "dmoz/Computers/Artificial_Intelligence/Associations", "label": "dmoz/Computers/Artificial Intelligence/Associations", "wgt": 27}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 26}, {"uri": "dmoz/Computers/Artificial_Intelligence/Academic_Departments", "label": "dmoz/Computers/Artificial Intelligence/Academic Departments", "wgt": 25}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 25}], "image": "https://bloximages.newyork1.vip.townnews.com/bakersfield.com/content/tncms/assets/v3/editorial/a/21/a2102305-5042-5c39-a86f-43d41ffec1a6/6655c4f7b79fa.image.jpg?crop=1763%2C926%2C0%2C124&resize=1200%2C630&order=crop%2Cresize", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.6941176470588235, "wgt": 128, "relevance": 1}
{"uri": "2024-05-370833034", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "12:20:58", "dateTime": "2024-05-28T12:20:58Z", "dateTimePub": "2024-05-28T12:20:53Z", "dataType": "news", "sim": 0.4823529422283173, "url": "https://www.erienewsnow.com/story/50837217/openai-announces-new-safety-board-after-employee-revolt", "title": "OpenAI announces new safety board after employee revolt", "body": "\"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment,\" the company said.\n\n\"A first task of the Safety and Security Committee will be to evaluate and further develop OpenAI's processes and safeguards over the next 90 days,\" the blog post added. \"At the conclusion of the 90 days, the Safety and Security Committee will share their recommendations with the full Board. Following the full Board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security.\"", "source": {"uri": "erienewsnow.com", "dataType": "news", "title": "Erie News Now - Your News Team"}, "authors": [], "concepts": [], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 33}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 31}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 29}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 35}], "image": "https://CNNWIRE.images.worldnow.com/images/25934210_G.jpg?lastEditedDate=1716882471000", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.7176470588235293, "wgt": 123, "relevance": 1}
{"uri": "2024-05-370877330", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "12:59:12", "dateTime": "2024-05-28T12:59:12Z", "dateTimePub": "2024-05-28T12:49:38Z", "dataType": "news", "sim": 0.4745098054409027, "url": "https://www.timesdaily.com/ap/business/openai-forms-safety-committee-as-it-starts-training-latest-artificial-intelligence-model/article_15804f09-4719-5f0d-990c-a21b504d6601.html", "title": "OpenAI forms safety committee as it starts training latest artificial intelligence model", "body": "OpenAI says it's setting up a new safety and security committee and has begun training a new artificial intelligence model to supplant the GPT-4 system that underpins its ChatGPT chatbot\n\nOpenAI says it's setting up a safety and security committee and has begun training a new AI model to supplant the GPT-4 system that underpins its ChatGPT chatbot.", "source": {"uri": "timesdaily.com", "dataType": "news", "title": "TimesDaily"}, "authors": [{"uri": "associated_press@timesdaily.com", "name": "Associated Press", "type": "author", "isAgency": true}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 2, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 1, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 1, "label": {"eng": "Chatbot"}}], "categories": [{"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 25}, {"uri": "dmoz/Computers/Artificial_Intelligence/Associations", "label": "dmoz/Computers/Artificial Intelligence/Associations", "wgt": 22}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 24}, {"uri": "dmoz/Computers/Artificial_Intelligence/Academic_Departments", "label": "dmoz/Computers/Artificial Intelligence/Academic Departments", "wgt": 21}, {"uri": "dmoz/Computers/Organizations/Committees", "label": "dmoz/Computers/Organizations/Committees", "wgt": 22}], "image": "https://bloximages.newyork1.vip.townnews.com/timesdaily.com/content/tncms/assets/v3/editorial/8/be/8bed728e-1c6f-55f1-bd51-153c13f67379/6655c455e23c9.image.jpg?crop=1763%2C926%2C0%2C124&resize=438%2C230&order=crop%2Cresize", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.8117647058823529, "wgt": 121, "relevance": 1}
{"uri": "8150405141", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "19:26:31", "dateTime": "2024-05-28T19:26:31Z", "dateTimePub": "2024-05-28T19:26:13Z", "dataType": "news", "sim": 0.4666666686534882, "url": "https://www.cio.com/article/2128275/openai-sets-up-new-safety-body-in-wake-of-staff-departures.html", "title": "OpenAI sets up new safety body in wake of staff departures", "body": "Its first task will be to evaluate how the company is handling AI risks in its development of AI models. In 90 days, it will share its recommendations with the full board of directors. The company said it may later reveal any adopted recommendations \"in a manner that is consistent with safety and security.\"\n\nWith the committee, OpenAI signals that it recognizes the continued concerns the industry and the general public have about AI, and is taking steps internally to monitor itself even as it aims to stay ahead of competitors.\n\n\"While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment,\" it said in the blog post.\n\nOpenAI's unveiling of progress on its next version of GPT is a natural progression for the company as it aims to protect its market lead even as competition heat ups. xAI, the company founded by Tesla leader Elon Musk, recently announced a $6 billion fundraising effort with a $24 billion valuation as Musk aims to challenge the startup he once championed on AI and AGI. Meanwhile, Musk and OpenAI remain embroiled in a heated legal dispute.\n\nOpenAI also faced controversy recently when it released a virtual assistant with a voice that some said sounded eerily similar to that of Hollywood actress Scarlett Johannson, even though she did not consent to the company using her voice when asked for her permission several times. Johannson famously voiced an AI system with whom a character played by Joaquim Phoenix falls in love in the 2013 film \"Her.\"\n\n\"As the usage of generative AI increases, associated risks, and security concerns are emerging,\" observed Pareekh Jain, CEO of EIIRTrend & Pareekh Consulting. \"The Scarlett Johansson incident has heightened OpenAI's awareness of these risks.\"\n\nAI security also remains a priority for AI stakeholders at large, with various initiatives being formed at both the government and corporate levels to try to set guidelines for the future development of the technology before it evolves beyond human control.", "source": {"uri": "cio.com", "dataType": "news", "title": "CIO"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Board_of_directors", "type": "wiki", "score": 3, "label": {"eng": "Board of directors"}}, {"uri": "http://en.wikipedia.org/wiki/Elon_Musk", "type": "person", "score": 3, "label": {"eng": "Elon Musk"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_pre-trained_transformer", "type": "wiki", "score": 2, "label": {"eng": "Generative pre-trained transformer"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Tesla,_Inc.", "type": "org", "score": 2, "label": {"eng": "Tesla, Inc."}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 2, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 1, "label": {"eng": "Virtual assistant"}}, {"uri": "http://en.wikipedia.org/wiki/Cinema_of_the_United_States", "type": "loc", "score": 1, "label": {"eng": "Cinema of the United States"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Scarlett_Johansson", "type": "person", "score": 1, "label": {"eng": "Scarlett Johansson"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Phoenix,_Arizona", "type": "loc", "score": 1, "label": {"eng": "Phoenix, Arizona"}, "location": {"type": "place", "label": {"eng": "Phoenix, Arizona"}, "country": {"type": "country", "label": {"eng": "United States"}}}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 14}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 14}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 15}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 22}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 15}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 52}], "image": "https://www.cio.com/wp-content/uploads/2024/05/shutterstock_editorial_2253221991.jpg?quality=50&strip=all&w=1024", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.2, "wgt": 119, "relevance": 1}
{"uri": "8150325156", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "18:16:56", "dateTime": "2024-05-28T18:16:56Z", "dateTimePub": "2024-05-28T18:16:00Z", "dataType": "news", "sim": 0.4588235318660736, "url": "https://the-decoder.com/openais-former-head-of-super-ai-alignment-jan-leike-joins-anthropic/", "title": "OpenAI's former head of super AI alignment Jan Leike joins Anthropic", "body": "Online journalist Matthias is the co-founder and publisher of THE DECODER. He believes that artificial intelligence will fundamentally change the relationship between humans and computers.\n\nAI safety researcher Jan Leike, who recently left OpenAI over safety concerns, is joining Anthropic. When Leike left OpenAI, he made serious allegations against the company, saying its safety culture and processes fell short of its \"shiny products.\" His move to Anthropic has two notable points: First, Anthropic is probably OpenAI's strongest competitor outside of Google. Second, the AI company grew out of an OpenAI breakaway group that objected to the more commercial focus after Microsoft got involved in 2019. Anthropic co-founder Dario Amodei was head of safety at OpenAI before launching Anthropic in 2021, while his sister Daniela Amodei, also a co-founder, led safety and policy at OpenAI from May to December 2020.", "source": {"uri": "the-decoder.com", "dataType": "news", "title": "THE DECODER"}, "authors": [{"uri": "matthias_bastian@the-decoder.com", "name": "Matthias Bastian", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Anthropic", "type": "wiki", "score": 4, "label": {"eng": "Anthropic"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 4, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 3, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 1, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 1, "label": {"eng": "Google"}}], "categories": [{"uri": "dmoz/Science/Technology/Safety_Engineering", "label": "dmoz/Science/Technology/Safety Engineering", "wgt": 14}, {"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 16}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 16}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 15}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 17}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 60}], "image": "https://the-decoder.com/wp-content/uploads/2024/05/anthropic_claude_team-1200x676.png", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": [{"amb": false, "date": "2020-05-", "dateEnd": "2020-12-", "textStart": 894, "textEnd": 914}], "sentiment": 0.3803921568627451, "wgt": 117, "relevance": 1}
{"uri": "8150266491", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "17:28:59", "dateTime": "2024-05-28T17:28:59Z", "dateTimePub": "2024-05-28T17:28:10Z", "dataType": "news", "sim": 0.4313725531101227, "url": "https://techcrunch.com/2024/05/28/anthropic-hires-former-openai-safety-lead-to-head-up-new-team/", "title": "Anthropic hires former OpenAI safety lead to head up new team | TechCrunch", "body": "Jan Leike, a leading AI researcher who earlier this month resigned from OpenAI before publicly criticizing the company's approach to AI safety, has joined OpenAI rival Anthropic to lead a new \"superalignment\" team.\n\nIn a post on X, Leike said that his team at Anthropic will focus on various aspects of AI safety and security, specifically \"scalable oversight,\" \"weak-to-strong generalization\" and automated alignment research.\n\nA source familiar with the matter tells TechCrunch that Leike will report directly to Jared Kaplan, Anthropic's chief science officer, and that Anthropic researchers currently working on scalable oversight -- techniques to control large-scale AI's behavior in predictable and desirable ways -- will move to report to Leike as Leike's team spins up.\n\nIn many ways, Leike's team at Anthropic sounds similar in mission to OpenAI's recently-dissolved Superalignment team. The Superalignment team -- which Leike co-led -- had the ambitious goal of solving the core technical challenges of controlling superintelligent AI in the next four years.\n\nAnthropic has often attempted to position itself as more safety-focused than OpenAI.\n\nAnthropic's CEO, Dario Amodei, was the former VP of research at OpenAI, and reportedly split with OpenAI after a disagreement over the company's direction -- namely OpenAI's increasingly commercial focus. Amodei brought with him a number of OpenAI employees including OpenAI's former policy lead Jack Clark.", "source": {"uri": "techcrunch.com", "dataType": "news", "title": "TechCrunch"}, "authors": [{"uri": "kyle_wiggers@techcrunch.com", "name": "Kyle Wiggers", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Anthropic", "type": "wiki", "score": 5, "label": {"eng": "Anthropic"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 4, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/TechCrunch", "type": "wiki", "score": 2, "label": {"eng": "TechCrunch"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_scientific_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief scientific officer"}}, {"uri": "http://en.wikipedia.org/wiki/Superintelligence", "type": "wiki", "score": 1, "label": {"eng": "Superintelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Sports/Paintball/Teams", "label": "dmoz/Sports/Paintball/Teams", "wgt": 13}, {"uri": "dmoz/Computers/Robotics/Competitions", "label": "dmoz/Computers/Robotics/Competitions", "wgt": 13}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 12}, {"uri": "dmoz/Sports/Adventure_Racing/Teams", "label": "dmoz/Sports/Adventure Racing/Teams", "wgt": 11}, {"uri": "dmoz/Business/Education_and_Training/Team_Building", "label": "dmoz/Business/Education and Training/Team Building", "wgt": 11}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 49}], "image": "https://techcrunch.com/wp-content/uploads/2023/11/Claude2_Blog_V1-1.webp?resize=1200,675", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.1529411764705881, "wgt": 110, "relevance": 1}
{"uri": "8150569461", "lang": "eng", "isDuplicate": false, "date": "2024-05-28", "time": "22:14:42", "dateTime": "2024-05-28T22:14:42Z", "dateTimePub": "2024-05-28T22:13:52Z", "dataType": "news", "sim": 0.7215686440467834, "url": "https://wccftech.com/openai-forms-new-safety-and-security-committee/", "title": "OpenAI Forms New 'Safety and Security Committee' That Will Oversee All Decisions Being Made Responsibly Concerning Artificial Intelligence", "body": "The billion-dollar startup OpenAI is no stranger to a rollercoaster turn of events, with some members of the company having departed as they felt that the firm behind ChatGPT is no longer being careful about the proliferation of artificial intelligence and what impact it can cause if there is no accountability. This would be one reason why OpenAI announced that it has formed a 'Safety and Security Committee' that will adopt a more responsible approach in the future.\n\nThe company announcement post states that various OpenAI board members, such as Bret Taylor, Adam D'Angelo, Nicole Seligman, and others, are members of the committee and will be responsible for evaluating the startup's safety processes over the next three months. The team members will then share their findings with the entire OpenAI board of directors for a review. Any adopted suggestions that comply with safety and security will then be published going forward.\n\n\"OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI. While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment.\n\nA first task of the Safety and Security Committee will be to evaluate and further develop OpenAI's processes and safeguards over the next 90 days. At the conclusion of the 90 days, the Safety and Security Committee will share their recommendations with the full Board. Following the full Board's review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security.\"\n\nOpenAI has witnessed various departures in a short time span, particularly from the safety side of the organization. The reason for their resignation is losing confidence that the company would behave responsibly around artificial intelligence becoming more and more capable. One notable individual was Ilya Sutskever, a co-founder of OpenAI, who left in May earlier this year primarily because of Altman's obsession with launching various products powered by AI, but at the expense of any due diligence.\n\nHowever, OpenAI has favored AI regulation and even hired an in-house lobbyist. Additionally, the U.S. Department of Homeland Security announced that Sam Altman would be among the members of its newly formed Artificial Intelligence Safety and Security Board, which may boost the confidence of all those who are torn about the company's vision. All that remains to be seen is how seriously this new 'Safety and Security Committee' is doing its job. It looks like we will find out after the 90-day window.", "source": {"uri": "wccftech.com", "dataType": "news", "title": "Wccftech"}, "authors": [{"uri": "omar_sohail@wccftech.com", "name": "Omar Sohail", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Nicole_Seligman", "type": "person", "score": 3, "label": {"eng": "Nicole Seligman"}}, {"uri": "http://en.wikipedia.org/wiki/Adam_D'Angelo", "type": "person", "score": 3, "label": {"eng": "Adam D'Angelo"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_general_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Artificial general intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Board_of_directors", "type": "wiki", "score": 2, "label": {"eng": "Board of directors"}}, {"uri": "http://en.wikipedia.org/wiki/Ilya_Sutskever", "type": "person", "score": 1, "label": {"eng": "Ilya Sutskever"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 1, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Homeland_Security", "type": "wiki", "score": 1, "label": {"eng": "United States Department of Homeland Security"}}], "categories": [{"uri": "dmoz/Health/Occupational_Health_and_Safety", "label": "dmoz/Health/Occupational Health and Safety", "wgt": 31}, {"uri": "dmoz/Business/Human_Resources/Training_and_Safety", "label": "dmoz/Business/Human Resources/Training and Safety", "wgt": 29}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Colleges_and_Universities", "label": "dmoz/Health/Occupational Health and Safety/Colleges and Universities", "wgt": 27}, {"uri": "dmoz/Health/Occupational_Health_and_Safety/Organizations", "label": "dmoz/Health/Occupational Health and Safety/Organizations", "wgt": 31}, {"uri": "dmoz/Computers/Security/FAQs,_Help,_and_Tutorials", "label": "dmoz/Computers/Security/FAQs, Help, and Tutorials", "wgt": 26}], "image": "https://cdn.wccftech.com/wp-content/uploads/2024/05/OpenAI-wallpaper.jpg", "originalArticle": null, "storyUri": "eng-9604049", "eventUri": "eng-9604049", "location": null, "extractedDates": null, "sentiment": 0.5058823529411764, "wgt": 454630482, "relevance": 2}
