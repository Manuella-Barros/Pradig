{"uri": "eng-9784991", "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 100, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 25, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 23, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 21, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 20, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 19, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 18, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Proprietary_software", "type": "wiki", "score": 17, "label": {"eng": "Proprietary software"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 16, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 16, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 15, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 14, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 14, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 13, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 11, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 11, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 10, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 10, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Mark_Zuckerberg", "type": "person", "score": 10, "label": {"eng": "Mark Zuckerberg"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 10, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 9, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 9, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/Hacker", "type": "wiki", "score": 8, "label": {"eng": "Hacker"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 8, "label": {"eng": "Intellectual property"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 7, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/European_Union", "type": "loc", "score": 7, "label": {"eng": "European Union"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/United_Kingdom", "type": "loc", "score": 6, "label": {"eng": "United Kingdom"}, "location": {"type": "country", "label": {"eng": "United Kingdom"}}}, {"uri": "http://en.wikipedia.org/wiki/Asia-Pacific", "type": "loc", "score": 5, "label": {"eng": "Asia-Pacific"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/India", "type": "loc", "score": 5, "label": {"eng": "India"}, "location": {"type": "country", "label": {"eng": "India"}}}, {"uri": "http://en.wikipedia.org/wiki/China", "type": "loc", "score": 5, "label": {"eng": "China"}, "location": {"type": "country", "label": {"eng": "China"}}}], "eventDate": "2024-08-01", "totalArticleCount": 112, "title": {"eng": "Why monitoring workers with AI won't boost performance"}, "summary": {"eng": "Ask an employee about what they think about artificial intelligence (AI), and more likely than not, they'll tell you they're afraid of losing their job. And while research suggests more employers are turning to AI, they're not using it to replace people. Instead, they're using it to watch them.\n\nWorkplace surveillance technology took off during the pandemic as more people began to work remotely. Now, a number of high-profile employers, including Starbucks (SBUX), Walmart (WMT) and AstraZeneca (AZ"}, "location": null, "categories": [{"uri": "news/Technology", "label": "news/Technology", "wgt": 77}], "articleCounts": {"eng": 112}, "sentiment": 0.2627450980392156, "breakingScore": 0.6722050894752141}
{"uri": "8258605192", "lang": "eng", "isDuplicate": false, "date": "2024-08-04", "time": "12:13:02", "dateTime": "2024-08-04T12:13:02Z", "dateTimePub": "2024-08-04T12:12:20Z", "dataType": "news", "sim": 0.8627451062202454, "url": "https://tech.hindustantimes.com/tech/news/meta-just-launched-the-largest-open-ai-model-in-history-here-s-why-it-matters-71722695907515.html", "title": "Meta just launched the largest 'open' AI model in history. Here's why it matters", "body": "Know how Meta's new AI model could rival other tech giants such as OpenAI, Google, Anthropic, and others.\n\nIn the world of artificial intelligence (AI), a battle is underway. On one side are companies that believe in keeping the datasets and algorithms behind their advanced software private and confidential. On the other are companies that believe in allowing the public to see what's under the hood of their sophisticated AI models.\n\nThink of this as the battle between open- and closed-source AI.\n\nIn recent weeks, Meta, the parent company of Facebook, took up the fight for open-source AI in a big way by releasing a new collection of large AI models. These include a model named Llama 3.1 405B, which Meta's founder and chief executive, Mark Zuckerberg, says is \"the first frontier-level open source AI model\".\n\nFor anyone who cares about a future in which everybody can access the benefits of AI, this is good news.\n\nThe danger of closed-source AI - and the promise of open-source AI Closed-source AI refers to models, datasets and algorithms that are proprietary and kept confidential. Examples include ChatGPT, Google's Gemini and Anthropic's Claude.\n\nAlso read: WhatsApp to make it easier to use Meta AI with this new feature, check details here\n\nThough anyone can use these products, there is no way to find out what dataset and source codes have been used to build the AI model or tool.\n\nWhile this is a great way for companies to protect their intellectual property and their profits, it risks undermining public trust and accountability. Making AI technology closed-source also slows down innovation and makes a company or other users dependent on a single platform for their AI needs. This is because the platform that owns the model controls changes, licensing and updates.\n\nThere are a range of ethical frameworks that seek to improve the fairness, accountability, transparency, privacy and human oversight of AI. However, these principles are often not fully achieved with closed-source AI due to the inherent lack of transparency and external accountability associated with proprietary systems.\n\nIn the case of ChatGPT, its parent company, OpenAI, releases neither the dataset nor code of its latest AI tools to the public. This makes it impossible for regulators to audit it. And while access to the service is free, concerns remain about how users' data are stored and used for retraining models.\n\nBy contrast, the code and dataset behind opeTECHn-source AI models is available for everyone to see.\n\nAlso read: WhatsApp, Instagram users can now access Meta AI in Hindi, chatbot gets support for 7 new languages\n\nThis fosters rapid development through community collaboration and enables the involvement of smaller organisations and even individuals in AI development. It also makes a huge difference for small and medium size enterprises as the cost of training large AI models is colossal.\n\nPerhaps most importantly, open source AI allows for scrutiny and identification of potential biases and vulnerability.\n\nHowever, open-source AI does create new risks and ethical concerns.\n\nFor example, quality control in open source products is usually low. As hackers can also access the code and data, the models are also more prone to cyberattacks and can be tailored and customised for malicious purposes, such as retraining the model with data from the dark web.\n\nAn open-source AI pioneer\n\nAmong all leading AI companies, Meta has emerged as a pioneer of open-source AI. With its new suite of AI models, it is doing what OpenAI promised to do when it launched in December 2015 - namely, advancing digital intelligence \"in the way that is most likely to benefit humanity as a whole\", as OpenAI said back then.\n\nLlama 3.1 405B is the largest open-source AI model in history. It is what's known as a large language model, capable of generating human language text in multiple languages. It can be downloaded online but because of its huge size, users will need powerful hardware to run it.\n\nAlso read: Meta trying to mimic Apple feature? New patent reveals how Vision Pro may 'inspire' next Meta headset\n\nWhile it does not outperform other models across all metrics, Llama 3.1 405B is considered highly competitive and does perform better than existing closed-source and commercial large language models in certain tasks, such as reasoning and coding tasks.\n\nBut the new model is not fully open, because Meta hasn't released the huge data set used to train it. This is a significant \"open\" element that is currently missing.\n\nNonetheless, Meta's Llama levels the playing field for researchers, small organisations and startups because it can be leveraged without the immense resources required to train large language models from scratch.\n\nShaping the future of AI\n\nTo ensure AI is democratised, we need three key pilars:\n\ngovernance: regulatory and ethical frameworks to ensure AI technology is being developed and used responsibly and ethically\n\naccessibility: affordable computing resources and user-friendly tools to ensure a fair landscape for developers and users\n\nopenness: datasets and algorithms to train and build AI tools should be open source to ensure transparency.\n\nAchieving these three pillars is a shared responsibility for government, industry, academia and the public. The public can play a vital role by advocating for ethical policies in AI, staying informed about AI developments, using AI responsibly and supporting open-source AI initiatives.\n\nBut several questions remain about open-source AI. How can we balance protecting intellectual property and fostering innovation through open-source AI? How can we minimise ethical concerns around open-source AI? How can we safeguard open-source AI against potential misuse?\n\nProperly addressing these questions will help us create a future where AI is an inclusive tool for all. Will we rise to the challenge and ensure AI serves the greater good? Or will we let it become another nasty tool for exclusion and control? The future is in our hands.", "source": {"uri": "tech.hindustantimes.com", "dataType": "news", "title": "Hindustan Times Tech"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 5, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Proprietary_software", "type": "wiki", "score": 5, "label": {"eng": "Proprietary software"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 5, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 5, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_AI", "type": "wiki", "score": 4, "label": {"eng": "Meta AI"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 4, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 4, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/WhatsApp", "type": "org", "score": 4, "label": {"eng": "WhatsApp"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 3, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Source_code", "type": "wiki", "score": 3, "label": {"eng": "Source code"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 3, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/Mark_Zuckerberg", "type": "person", "score": 3, "label": {"eng": "Mark Zuckerberg"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 3, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 2, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Hacker", "type": "wiki", "score": 2, "label": {"eng": "Hacker"}}, {"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 2, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 2, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Quality_control", "type": "wiki", "score": 2, "label": {"eng": "Quality control"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 2, "label": {"eng": "Intellectual property"}}, {"uri": "http://en.wikipedia.org/wiki/Media_(communication)", "type": "wiki", "score": 2, "label": {"eng": "Media (communication)"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Instagram", "type": "org", "score": 2, "label": {"eng": "Instagram"}}, {"uri": "http://en.wikipedia.org/wiki/Apple_Inc.", "type": "org", "score": 1, "label": {"eng": "Apple Inc."}}], "categories": [{"uri": "dmoz/Science/Software/Simulation", "label": "dmoz/Science/Software/Simulation", "wgt": 100}, {"uri": "dmoz/Computers/Programming/Methodologies", "label": "dmoz/Computers/Programming/Methodologies", "wgt": 100}, {"uri": "dmoz/Computers/Software/Information_Retrieval", "label": "dmoz/Computers/Software/Information Retrieval", "wgt": 100}, {"uri": "dmoz/Computers/Artificial_Intelligence/Natural_Language", "label": "dmoz/Computers/Artificial Intelligence/Natural Language", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 97}], "image": "https://images.hindustantimes.com/tech/img/2024/08/04/1600x900/pexels-photo-3913025_1722755433896_1722755456478.jpeg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "date": "2015-12-", "textStart": 3582, "textEnd": 3595}], "sentiment": 0.07450980392156858, "wgt": 220, "relevance": 1}
{"uri": "8255514045", "lang": "eng", "isDuplicate": false, "date": "2024-08-02", "time": "08:01:22", "dateTime": "2024-08-02T08:01:22Z", "dateTimePub": "2024-08-02T08:00:27Z", "dataType": "news", "sim": 0.8588235378265381, "url": "https://www.ndtv.com/india-ai/meta-just-launched-the-largest-open-ai-model-in-history-heres-why-it-matters-6246346", "title": "Meta Just Launched The Largest 'Open' AI Model In History. Heres Why It Matters", "body": "Meta, the parent company of Facebook, took up the fight for open-source AI in a big way by releasing a new collection of large AI models.\n\nWith the new Llama 3.1 405B, Meta AI has sparked the debate on open-source AI models (AI Generated Image)\n\nIn the world of artificial intelligence (AI), a battle is underway. On one side are companies that believe in keeping the datasets and algorithms behind their advanced software private and confidential. On the other are companies that believe in allowing the public to see what's under the hood of their sophisticated AI models.\n\nThink of this as the battle between open- and closed-source AI.\n\nIn recent weeks, Meta, the parent company of Facebook, took up the fight for open-source AI in a big way by releasing a new collection of large AI models. These include a model named Llama 3.1 405B, which Meta's founder and chief executive, Mark Zuckerberg, says is \"the first frontier-level open-source AI model\".\n\nFor anyone who cares about a future in which everybody can access the benefits of AI, this is good news.\n\nThe danger of closed-source AI - and the promise of open-source AI\n\nClosed-source AI refers to models, datasets and algorithms that are proprietary and kept confidential. Examples include ChatGPT, Google's Gemini and Anthropic's Claude.\n\nThough anyone can use these products, there is no way to find out what dataset and source codes have been used to build the AI model or tool.\n\nWhile this is a great way for companies to protect their intellectual property and their profits, it risks undermining public trust and accountability. Making AI technology closed source also slows down innovation and makes a company or other users dependent on a single platform for their AI needs. This is because the platform that owns the model controls changes, licensing and updates.\n\nThere are a range of ethical frameworks that seek to improve the fairness, accountability, transparency, privacy and human oversight of AI. However, these principles are often not fully achieved with closed-source AI due to the inherent lack of transparency and external accountability associated with proprietary systems.\n\nIn the case of ChatGPT, its parent company, OpenAI, releases neither the dataset nor code of its latest AI tools to the public. This makes it impossible for regulators to audit it. And while access to the service is free, concerns remain about how users' data are stored and used for retraining models.\n\nBy contrast, the code and dataset behind open-source AI models is available for everyone to see.\n\nThis fosters rapid development through community collaboration and enables the involvement of smaller organisations and even individuals in AI development. It also makes a huge difference for small and medium size enterprises as the cost of training large AI models is colossal.\n\nPerhaps most importantly, open source AI allows for scrutiny and identification of potential biases and vulnerability.\n\nHowever, open-source AI does create new risks and ethical concerns.\n\nFor example, quality control in open source products is usually low. As hackers can also access the code and data, the models are also more prone to cyberattacks and can be tailored and customised for malicious purposes, such as retraining the model with data from the dark web.\n\nAn open-source AI pioneer\n\nAmong all leading AI companies, Meta has emerged as a pioneer of open-source AI. With its new suite of AI models, it is doing what OpenAI promised to do when it launched in December 2015 - namely, advancing digital intelligence \"in the way that is most likely to benefit humanity as a whole\", as OpenAI said back then.\n\nLlama 3.1 405B is the largest open-source AI model in history. It is what's known as a large language model, capable of generating human language text in multiple languages. It can be downloaded online but because of its huge size, users will need powerful hardware to run it.\n\nWhile it does not outperform other models across all metrics, Llama 3.1 405B is considered highly competitive and does perform better than existing closed-source and commercial large language models in certain tasks, such as reasoning and coding tasks.\n\nBut the new model is not fully open, because Meta hasn't released the huge data set used to train it. This is a significant \"open\" element that is currently missing.\n\nNonetheless, Meta's Llama levels the playing field for researchers, small organisations and startups because it can be leveraged without the immense resources required to train large language models from scratch.\n\nShaping the future of AI To ensure AI is democratised, we need three key pillars: Governance: regulatory and ethical frameworks to ensure AI technology is being developed and used responsibly and ethically, Accessibility: affordable computing resources and user-friendly tools to ensure a fair landscape for developers and Users-openness: datasets and algorithms to train and build AI tools should be open source to ensure transparency.\n\nAchieving these three pillars is a shared responsibility for government, industry, academia and the public. The public can play a vital role by advocating for ethical policies in AI, staying informed about AI developments, using AI responsibly and supporting open-source AI initiatives.\n\nPromotedListen to the latest songs, only on JioSaavn.com\n\nBut several questions remain about open-source AI. How can we balance protecting intellectual property and fostering innovation through open-source AI? How can we minimise ethical concerns around open-source AI? How can we safeguard open-source AI against potential misuse? Properly addressing these questions will help us create a future where AI is an inclusive tool for all. Will we rise to the challenge and ensure AI serves the greater good? Or will we let it become another nasty tool for exclusion and control? The future is in our hands.\n\n(This story has not been edited by NDTV staff and is auto-generated from a syndicated feed.)", "source": {"uri": "ndtv.com", "dataType": "news", "title": "NDTV"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 5, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 5, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Proprietary_software", "type": "wiki", "score": 5, "label": {"eng": "Proprietary software"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 5, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 5, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 4, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 3, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 3, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Source_code", "type": "wiki", "score": 3, "label": {"eng": "Source code"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 3, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/Mark_Zuckerberg", "type": "person", "score": 3, "label": {"eng": "Mark Zuckerberg"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 2, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Dark_web", "type": "wiki", "score": 2, "label": {"eng": "Dark web"}}, {"uri": "http://en.wikipedia.org/wiki/Hacker", "type": "wiki", "score": 2, "label": {"eng": "Hacker"}}, {"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 2, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/Quality_control", "type": "wiki", "score": 2, "label": {"eng": "Quality control"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 2, "label": {"eng": "Intellectual property"}}, {"uri": "http://en.wikipedia.org/wiki/Media_(communication)", "type": "wiki", "score": 2, "label": {"eng": "Media (communication)"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Computing", "type": "wiki", "score": 1, "label": {"eng": "Computing"}}], "categories": [{"uri": "dmoz/Science/Software/Simulation", "label": "dmoz/Science/Software/Simulation", "wgt": 100}, {"uri": "dmoz/Computers/Programming/Methodologies", "label": "dmoz/Computers/Programming/Methodologies", "wgt": 100}, {"uri": "dmoz/Computers/Artificial_Intelligence/Belief_Networks", "label": "dmoz/Computers/Artificial Intelligence/Belief Networks", "wgt": 100}, {"uri": "dmoz/Computers/CAD_and_CAM/NX_(Unigraphics)_and_Solid_Edge", "label": "dmoz/Computers/CAD and CAM/NX (Unigraphics) and Solid Edge", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 87}], "image": "https://c.ndtvimg.com/2024-08/i3hcgk9o_open-source-ai-vs-closed-source-ai_625x300_02_August_24.jpg?im=FeatureCrop,algorithm=dnn,width=1200,height=738?ver-20240615.100", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "date": "2015-12-", "textStart": 3510, "textEnd": 3523}], "sentiment": 0.03529411764705892, "wgt": 219, "relevance": 1}
{"uri": "8256886444", "lang": "eng", "isDuplicate": false, "date": "2024-08-03", "time": "04:00:58", "dateTime": "2024-08-03T04:00:58Z", "dateTimePub": "2024-08-03T03:59:47Z", "dataType": "news", "sim": 0.8549019694328308, "url": "https://www.latestly.com/agency-news/world-news-meta-just-launched-the-largest-open-ai-model-in-history-heres-why-it-matters-6160119.html", "title": "World News | Meta Just Launched the Largest 'open' AI Model in History. Here's Why It Matters | LatestLY", "body": "Get latest articles and stories on World at LatestLY. In the world of artificial intelligence (AI), a battle is underway. On one side are companies that believe in keeping the datasets and algorithms behind their advanced software private and confidential. On the other are companies that believe in allowing the public to see what's under the hood of their sophisticated AI models.\n\nMelbourne, Aug 3 (The Conversation) In the world of artificial intelligence (AI), a battle is underway. On one side are companies that believe in keeping the datasets and algorithms behind their advanced software private and confidential. On the other are companies that believe in allowing the public to see what's under the hood of their sophisticated AI models.\n\nThink of this as the battle between open- and closed-source AI.\n\nAlso Read | Earthquake in Philippines: Quake of Magnitude 6.8 on Richter Scale Strikes Surigao Del Sur Province.\n\nIn recent weeks, Meta, the parent company of Facebook, took up the fight for open-source AI in a big way by releasing a new collection of large AI models. These include a model named Llama 3.1 405B, which Meta's founder and chief executive, Mark Zuckerberg, says is \"the first frontier-level open source AI model\".\n\nFor anyone who cares about a future in which everybody can access the benefits of AI, this is good news.\n\nAlso Read | Kamala Harris is Democratic Party Candidate For US Election: Live News Updates Today.\n\nThe danger of closed-source AI - and the promise of open-source AI Closed-source AI refers to models, datasets and algorithms that are proprietary and kept confidential. Examples include ChatGPT, Google's Gemini and Anthropic's Claude.\n\nThough anyone can use these products, there is no way to find out what dataset and source codes have been used to build the AI model or tool.\n\nWhile this is a great way for companies to protect their intellectual property and their profits, it risks undermining public trust and accountability. Making AI technology closed-source also slows down innovation and makes a company or other users dependent on a single platform for their AI needs. This is because the platform that owns the model controls changes, licensing and updates.\n\nThere are a range of ethical frameworks that seek to improve the fairness, accountability, transparency, privacy and human oversight of AI. However, these principles are often not fully achieved with closed-source AI due to the inherent lack of transparency and external accountability associated with proprietary systems.\n\nIn the case of ChatGPT, its parent company, OpenAI, releases neither the dataset nor code of its latest AI tools to the public. This makes it impossible for regulators to audit it. And while access to the service is free, concerns remain about how users' data are stored and used for retraining models.\n\nBy contrast, the code and dataset behind open-source AI models is available for everyone to see.\n\nThis fosters rapid development through community collaboration and enables the involvement of smaller organisations and even individuals in AI development. It also makes a huge difference for small and medium size enterprises as the cost of training large AI models is colossal.\n\nPerhaps most importantly, open source AI allows for scrutiny and identification of potential biases and vulnerability.\n\nHowever, open-source AI does create new risks and ethical concerns.\n\nFor example, quality control in open source products is usually low. As hackers can also access the code and data, the models are also more prone to cyberattacks and can be tailored and customised for malicious purposes, such as retraining the model with data from the dark web.\n\nAn open-source AI pioneer\n\nAmong all leading AI companies, Meta has emerged as a pioneer of open-source AI. With its new suite of AI models, it is doing what OpenAI promised to do when it launched in December 2015 - namely, advancing digital intelligence \"in the way that is most likely to benefit humanity as a whole\", as OpenAI said back then.\n\nLlama 3.1 405B is the largest open-source AI model in history. It is what's known as a large language model, capable of generating human language text in multiple languages. It can be downloaded online but because of its huge size, users will need powerful hardware to run it.\n\nWhile it does not outperform other models across all metrics, Llama 3.1 405B is considered highly competitive and does perform better than existing closed-source and commercial large language models in certain tasks, such as reasoning and coding tasks.\n\nBut the new model is not fully open, because Meta hasn't released the huge data set used to train it. This is a significant \"open\" element that is currently missing.\n\nNonetheless, Meta's Llama levels the playing field for researchers, small organisations and startups because it can be leveraged without the immense resources required to train large language models from scratch.\n\nShaping the future of AI\n\nTo ensure AI is democratised, we need three key pilars:\n\ngovernance: regulatory and ethical frameworks to ensure AI technology is being developed and used responsibly and ethically\n\naccessibility: affordable computing resources and user-friendly tools to ensure a fair landscape for developers and users\n\nopenness: datasets and algorithms to train and build AI tools should be open source to ensure transparency.\n\nAchieving these three pillars is a shared responsibility for government, industry, academia and the public. The public can play a vital role by advocating for ethical policies in AI, staying informed about AI developments, using AI responsibly and supporting open-source AI initiatives.\n\nBut several questions remain about open-source AI. How can we balance protecting intellectual property and fostering innovation through open-source AI? How can we minimise ethical concerns around open-source AI? How can we safeguard open-source AI against potential misuse?\n\nProperly addressing these questions will help us create a future where AI is an inclusive tool for all. Will we rise to the challenge and ensure AI serves the greater good? Or will we let it become another nasty tool for exclusion and control? The future is in our hands. (The Conversation)", "source": {"uri": "latestly.com", "dataType": "news", "title": "LatestLY"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 5, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Proprietary_software", "type": "wiki", "score": 5, "label": {"eng": "Proprietary software"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 5, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 5, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 4, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 3, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 3, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Quake_(video_game)", "type": "wiki", "score": 3, "label": {"eng": "Quake (video game)"}}, {"uri": "http://en.wikipedia.org/wiki/Kamala_Harris", "type": "person", "score": 3, "label": {"eng": "Kamala Harris"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 3, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Earthquake", "type": "wiki", "score": 3, "label": {"eng": "Earthquake"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Mark_Zuckerberg", "type": "person", "score": 3, "label": {"eng": "Mark Zuckerberg"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 3, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Philippines", "type": "loc", "score": 3, "label": {"eng": "Philippines"}, "location": {"type": "country", "label": {"eng": "Philippines"}}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 2, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/The_Conversation_(website)", "type": "org", "score": 2, "label": {"eng": "The Conversation (website)"}}, {"uri": "http://en.wikipedia.org/wiki/Quality_control", "type": "wiki", "score": 2, "label": {"eng": "Quality control"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 2, "label": {"eng": "Intellectual property"}}, {"uri": "http://en.wikipedia.org/wiki/Media_(communication)", "type": "wiki", "score": 2, "label": {"eng": "Media (communication)"}}, {"uri": "http://en.wikipedia.org/wiki/Source_code", "type": "wiki", "score": 2, "label": {"eng": "Source code"}}, {"uri": "http://en.wikipedia.org/wiki/Audit", "type": "wiki", "score": 2, "label": {"eng": "Audit"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 2, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Dark_web", "type": "wiki", "score": 1, "label": {"eng": "Dark web"}}], "categories": [{"uri": "dmoz/Science/Software/Simulation", "label": "dmoz/Science/Software/Simulation", "wgt": 100}, {"uri": "dmoz/Computers/Programming/Methodologies", "label": "dmoz/Computers/Programming/Methodologies", "wgt": 100}, {"uri": "dmoz/Computers/Software/Information_Retrieval", "label": "dmoz/Computers/Software/Information Retrieval", "wgt": 100}, {"uri": "dmoz/Computers/Artificial_Intelligence/Belief_Networks", "label": "dmoz/Computers/Artificial Intelligence/Belief Networks", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 98}], "image": "https://st1.latestly.com/wp-content/uploads/2020/10/Latestly-World-News-784x441.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-08-03", "textStart": 395, "textEnd": 400}, {"amb": false, "date": "2015-12-", "textStart": 3896, "textEnd": 3909}], "sentiment": 0.07450980392156858, "wgt": 218, "relevance": 1}
{"uri": "2024-08-441679276", "lang": "eng", "isDuplicate": false, "date": "2024-08-02", "time": "09:17:50", "dateTime": "2024-08-02T09:17:50Z", "dateTimePub": "2024-08-02T06:57:25Z", "dataType": "news", "sim": 0.8509804010391235, "url": "https://www.telegraphindia.com/world/meta-just-launched-the-largest-open-artificial-intelligence-model-in-history-heres-why-it-matters/cid/2038111", "title": "Meta just launched the largest 'open' AI model in history. Here's why it matters", "body": "As hackers can also access the code and data, the models are also more prone to cyberattacks and can be tailored and customised for malicious purposes, such as retraining the model with data from the dark web\n\nIn the world of artificial intelligence (AI), a battle is underway. On one side are companies that believe in keeping the datasets and algorithms behind their advanced software private and confidential. On the other are companies that believe in allowing the public to see what's under the hood of their sophisticated AI models.\n\nThink of this as the battle between open- and closed-source AI.\n\nIn recent weeks, Meta, the parent company of Facebook, took up the fight for open-source AI in a big way by releasing a new collection of large AI models. These include a model named Llama 3.1 405B, which Meta's founder and chief executive, Mark Zuckerberg, says is \"the first frontier-level open source AI model\".\n\nFor anyone who cares about a future in which everybody can access the benefits of AI, this is good news.\n\nThe danger of closed-source AI - and the promise of open-source AI Closed-source AI refers to models, datasets and algorithms that are proprietary and kept confidential. Examples include ChatGPT, Google's Gemini and Anthropic's Claude.\n\nThough anyone can use these products, there is no way to find out what dataset and source codes have been used to build the AI model or tool.\n\nWhile this is a great way for companies to protect their intellectual property and their profits, it risks undermining public trust and accountability. Making AI technology closed-source also slows down innovation and makes a company or other users dependent on a single platform for their AI needs. This is because the platform that owns the model controls changes, licensing and updates.\n\nThere are a range of ethical frameworks that seek to improve the fairness, accountability, transparency, privacy and human oversight of AI. However, these principles are often not fully achieved with closed-source AI due to the inherent lack of transparency and external accountability associated with proprietary systems.\n\nIn the case of ChatGPT, its parent company, OpenAI, releases neither the dataset nor code of its latest AI tools to the public. This makes it impossible for regulators to audit it. And while access to the service is free, concerns remain about how users' data are stored and used for retraining models.\n\nBy contrast, the code and dataset behind open-source AI models is available for everyone to see.\n\nThis fosters rapid development through community collaboration and enables the involvement of smaller organisations and even individuals in AI development. It also makes a huge difference for small and medium size enterprises as the cost of training large AI models is colossal.\n\nPerhaps most importantly, open source AI allows for scrutiny and identification of potential biases and vulnerability.\n\nHowever, open-source AI does create new risks and ethical concerns.\n\nFor example, quality control in open source products is usually low. As hackers can also access the code and data, the models are also more prone to cyberattacks and can be tailored and customised for malicious purposes, such as retraining the model with data from the dark web.\n\nAn open-source AI pioneer Among all leading AI companies, Meta has emerged as a pioneer of open-source AI. With its new suite of AI models, it is doing what OpenAI promised to do when it launched in December 2015 - namely, advancing digital intelligence \"in the way that is most likely to benefit humanity as a whole\", as OpenAI said back then.\n\nLlama 3.1 405B is the largest open-source AI model in history. It is what's known as a large language model, capable of generating human language text in multiple languages. It can be downloaded online but because of its huge size, users will need powerful hardware to run it.\n\nWhile it does not outperform other models across all metrics, Llama 3.1 405B is considered highly competitive and does perform better than existing closed-source and commercial large language models in certain tasks, such as reasoning and coding tasks.\n\nBut the new model is not fully open, because Meta hasn't released the huge data set used to train it. This is a significant \"open\" element that is currently missing.\n\nNonetheless, Meta's Llama levels the playing field for researchers, small organisations and startups because it can be leveraged without the immense resources required to train large language models from scratch.\n\nShaping the future of AI To ensure AI is democratised, we need three key pilars: -governance: regulatory and ethical frameworks to ensure AI technology is being developed and used responsibly and ethically -accessibility: affordable computing resources and user-friendly tools to ensure a fair landscape for developers and users -openness: datasets and algorithms to train and build AI tools should be open source to ensure transparency.\n\nAchieving these three pillars is a shared responsibility for government, industry, academia and the public. The public can play a vital role by advocating for ethical policies in AI, staying informed about AI developments, using AI responsibly and supporting open-source AI initiatives.\n\nBut several questions remain about open-source AI. How can we balance protecting intellectual property and fostering innovation through open-source AI? How can we minimise ethical concerns around open-source AI? How can we safeguard open-source AI against potential misuse? Properly addressing these questions will help us create a future where AI is an inclusive tool for all. Will we rise to the challenge and ensure AI serves the greater good? Or will we let it become another nasty tool for exclusion and control? The future is in our hands.\n\nThe Conversation", "source": {"uri": "telegraphindia.com", "dataType": "news", "title": "The Telegraph"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 5, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 5, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Proprietary_software", "type": "wiki", "score": 5, "label": {"eng": "Proprietary software"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 5, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Dark_web", "type": "wiki", "score": 4, "label": {"eng": "Dark web"}}, {"uri": "http://en.wikipedia.org/wiki/Hacker", "type": "wiki", "score": 4, "label": {"eng": "Hacker"}}, {"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 4, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 4, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 3, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 3, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Source_code", "type": "wiki", "score": 3, "label": {"eng": "Source code"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 3, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/Mark_Zuckerberg", "type": "person", "score": 3, "label": {"eng": "Mark Zuckerberg"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 3, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 2, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Quality_control", "type": "wiki", "score": 2, "label": {"eng": "Quality control"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 2, "label": {"eng": "Intellectual property"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/The_Conversation_(website)", "type": "org", "score": 1, "label": {"eng": "The Conversation (website)"}}, {"uri": "http://en.wikipedia.org/wiki/Computing", "type": "wiki", "score": 1, "label": {"eng": "Computing"}}, {"uri": "http://en.wikipedia.org/wiki/Data_set", "type": "wiki", "score": 1, "label": {"eng": "Data set"}}], "categories": [{"uri": "dmoz/Computers/Open_Source", "label": "dmoz/Computers/Open Source", "wgt": 26}, {"uri": "dmoz/Computers/Open_Source/Articles", "label": "dmoz/Computers/Open Source/Articles", "wgt": 27}, {"uri": "dmoz/Computers/Hardware/Open_Source", "label": "dmoz/Computers/Hardware/Open Source", "wgt": 28}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 27}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 36}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 91}], "image": "https://assets.telegraphindia.com/telegraph/2023/Dec/1702981283_meta.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "date": "2015-12-", "textStart": 3472, "textEnd": 3485}], "sentiment": 0.1137254901960785, "wgt": 217, "relevance": 1}
{"uri": "2024-08-441596700", "lang": "eng", "isDuplicate": false, "date": "2024-08-02", "time": "07:57:52", "dateTime": "2024-08-02T07:57:52Z", "dateTimePub": "2024-08-02T07:00:20Z", "dataType": "news", "sim": 0.8470588326454163, "url": "https://theprint.in/world/meta-just-launched-the-largest-open-ai-model-in-history-heres-why-it-matters/2204203/", "title": "Meta just launched the largest 'open' AI model in history. Here's why it matters", "body": "In recent weeks, Meta, the parent company of Facebook, took up the fight for open-source AI in a big way by releasing a new collection of large AI models. These include a model named Llama 3.1 405B, which Meta's founder and chief executive, Mark Zuckerberg, says is \"the first frontier-level open source AI model\".\n\nFor anyone who cares about a future in which everybody can access the benefits of AI, this is good news.\n\nThe danger of closed-source AI - and the promise of open-source AI Closed-source AI refers to models, datasets and algorithms that are proprietary and kept confidential. Examples include ChatGPT, Google's Gemini and Anthropic's Claude.\n\nThough anyone can use these products, there is no way to find out what dataset and source codes have been used to build the AI model or tool.\n\nWhile this is a great way for companies to protect their intellectual property and their profits, it risks undermining public trust and accountability. Making AI technology closed-source also slows down innovation and makes a company or other users dependent on a single platform for their AI needs. This is because the platform that owns the model controls changes, licensing and updates.\n\nThere are a range of ethical frameworks that seek to improve the fairness, accountability, transparency, privacy and human oversight of AI. However, these principles are often not fully achieved with closed-source AI due to the inherent lack of transparency and external accountability associated with proprietary systems.\n\nIn the case of ChatGPT, its parent company, OpenAI, releases neither the dataset nor code of its latest AI tools to the public. This makes it impossible for regulators to audit it. And while access to the service is free, concerns remain about how users' data are stored and used for retraining models.\n\nBy contrast, the code and dataset behind open-source AI models is available for everyone to see.\n\nThis fosters rapid development through community collaboration and enables the involvement of smaller organisations and even individuals in AI development. It also makes a huge difference for small and medium size enterprises as the cost of training large AI models is colossal.\n\nPerhaps most importantly, open source AI allows for scrutiny and identification of potential biases and vulnerability.\n\nHowever, open-source AI does create new risks and ethical concerns.\n\nFor example, quality control in open source products is usually low. As hackers can also access the code and data, the models are also more prone to cyberattacks and can be tailored and customised for malicious purposes, such as retraining the model with data from the dark web.\n\nAn open-source AI pioneer Among all leading AI companies, Meta has emerged as a pioneer of open-source AI. With its new suite of AI models, it is doing what OpenAI promised to do when it launched in December 2015 - namely, advancing digital intelligence \"in the way that is most likely to benefit humanity as a whole\", as OpenAI said back then.\n\nLlama 3.1 405B is the largest open-source AI model in history. It is what's known as a large language model, capable of generating human language text in multiple languages. It can be downloaded online but because of its huge size, users will need powerful hardware to run it.\n\nWhile it does not outperform other models across all metrics, Llama 3.1 405B is considered highly competitive and does perform better than existing closed-source and commercial large language models in certain tasks, such as reasoning and coding tasks.\n\nBut the new model is not fully open, because Meta hasn't released the huge data set used to train it. This is a significant \"open\" element that is currently missing.\n\nNonetheless, Meta's Llama levels the playing field for researchers, small organisations and startups because it can be leveraged without the immense resources required to train large language models from scratch.\n\nShaping the future of AI To ensure AI is democratised, we need three key pilars: -governance: regulatory and ethical frameworks to ensure AI technology is being developed and used responsibly and ethically -accessibility: affordable computing resources and user-friendly tools to ensure a fair landscape for developers and users -openness: datasets and algorithms to train and build AI tools should be open source to ensure transparency.\n\nAchieving these three pillars is a shared responsibility for government, industry, academia and the public. The public can play a vital role by advocating for ethical policies in AI, staying informed about AI developments, using AI responsibly and supporting open-source AI initiatives.\n\nBut several questions remain about open-source AI. How can we balance protecting intellectual property and fostering innovation through open-source AI? How can we minimise ethical concerns around open-source AI? How can we safeguard open-source AI against potential misuse? Properly addressing these questions will help us create a future where AI is an inclusive tool for all. Will we rise to the challenge and ensure AI serves the greater good? Or will we let it become another nasty tool for exclusion and control? The future is in our hands. (The Conversation) NSA NSA", "source": {"uri": "theprint.in", "dataType": "news", "title": "ThePrint"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 5, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 5, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Proprietary_software", "type": "wiki", "score": 5, "label": {"eng": "Proprietary software"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 5, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 4, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 4, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 3, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Source_code", "type": "wiki", "score": 3, "label": {"eng": "Source code"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Mark_Zuckerberg", "type": "person", "score": 3, "label": {"eng": "Mark Zuckerberg"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 3, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 2, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Dark_web", "type": "wiki", "score": 2, "label": {"eng": "Dark web"}}, {"uri": "http://en.wikipedia.org/wiki/Hacker", "type": "wiki", "score": 2, "label": {"eng": "Hacker"}}, {"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 2, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/Quality_control", "type": "wiki", "score": 2, "label": {"eng": "Quality control"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 2, "label": {"eng": "Intellectual property"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/The_Conversation_(website)", "type": "org", "score": 1, "label": {"eng": "The Conversation (website)"}}, {"uri": "http://en.wikipedia.org/wiki/Computing", "type": "wiki", "score": 1, "label": {"eng": "Computing"}}, {"uri": "http://en.wikipedia.org/wiki/Data_set", "type": "wiki", "score": 1, "label": {"eng": "Data set"}}, {"uri": "http://en.wikipedia.org/wiki/Usability", "type": "wiki", "score": 1, "label": {"eng": "Usability"}}], "categories": [{"uri": "dmoz/Computers/Open_Source", "label": "dmoz/Computers/Open Source", "wgt": 26}, {"uri": "dmoz/Computers/Open_Source/Articles", "label": "dmoz/Computers/Open Source/Articles", "wgt": 27}, {"uri": "dmoz/Computers/Hardware/Open_Source", "label": "dmoz/Computers/Hardware/Open Source", "wgt": 28}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 26}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 35}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 90}], "image": "https://static.theprint.in/wp-content/uploads/2023/06/theprint_default_image_new.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "date": "2015-12-", "textStart": 2867, "textEnd": 2880}], "sentiment": 0.09019607843137245, "wgt": 216, "relevance": 1}
{"uri": "8257624414", "lang": "eng", "isDuplicate": false, "date": "2024-08-03", "time": "16:11:03", "dateTime": "2024-08-03T16:11:03Z", "dateTimePub": "2024-08-03T16:10:22Z", "dataType": "news", "sim": 0.8470588326454163, "url": "https://techxplore.com/news/2024-08-meta-largest-ai-history.html", "title": "Meta just launched the largest 'open' AI model in history -- here's why it matters", "body": "In the world of artificial intelligence (AI), a battle is underway. On one side are companies that believe in keeping the datasets and algorithms behind their advanced software private and confidential. On the other are companies that believe in allowing the public to see what's under the hood of their sophisticated AI models.\n\nThink of this as the battle between open- and closed-source AI.\n\nIn recent weeks, Meta, the parent company of Facebook, took up the fight for open-source AI in a big way by releasing a new collection of large AI models. These include a model named Llama 3.1 405B, which Meta's founder and chief executive, Mark Zuckerberg, says is \"the first frontier-level open source AI model.\"\n\nFor anyone who cares about a future in which everybody can access the benefits of AI, this is good news.\n\nClosed-source AI refers to models, datasets and algorithms that are proprietary and kept confidential. Examples include ChatGPT, Google's Gemini and Anthropic's Claude.\n\nThough anyone can use these products, there is no way to find out what dataset and source codes have been used to build the AI model or tool.\n\nWhile this is a great way for companies to protect their intellectual property and their profits, it risks undermining public trust and accountability. Making AI technology closed-source also slows down innovation and makes a company or other users dependent on a single platform for their AI needs. This is because the platform that owns the model controls changes, licensing and updates.\n\nThere are a range of ethical frameworks that seek to improve the fairness, accountability, transparency, privacy and human oversight of AI. However, these principles are often not fully achieved with closed-source AI due to the inherent lack of transparency and external accountability associated with proprietary systems.\n\nIn the case of ChatGPT, its parent company, OpenAI, releases neither the dataset nor code of its latest AI tools to the public. This makes it impossible for regulators to audit it. And while access to the service is free, concerns remain about how users' data are stored and used for retraining models.\n\nBy contrast, the code and dataset behind open-source AI models is available for everyone to see.\n\nThis fosters rapid development through community collaboration and enables the involvement of smaller organizations and even individuals in AI development. It also makes a huge difference for small and medium size enterprises as the cost of training large AI models is colossal.\n\nPerhaps most importantly, open source AI allows for scrutiny and identification of potential biases and vulnerability.\n\nHowever, open-source AI does create new risks and ethical concerns.\n\nFor example, quality control in open source products is usually low. As hackers can also access the code and data, the models are also more prone to cyberattacks and can be tailored and customized for malicious purposes, such as retraining the model with data from the dark web.\n\nAmong all leading AI companies, Meta has emerged as a pioneer of open-source AI. With its new suite of AI models, it is doing what OpenAI promised to do when it launched in December 2015 -- namely, advancing digital intelligence \"in the way that is most likely to benefit humanity as a whole,\" as OpenAI said back then.\n\nLlama 3.1 405B is the largest open-source AI model in history. It is what's known as a large language model, capable of generating human language text in multiple languages. It can be downloaded online but because of its huge size, users will need powerful hardware to run it.\n\nWhile it does not outperform other models across all metrics, Llama 3.1 405B is considered highly competitive and does perform better than existing closed-source and commercial large language models in certain tasks, such as reasoning and coding tasks.\n\nBut the new model is not fully open, because Meta hasn't released the huge data set used to train it. This is a significant \"open\" element that is currently missing.\n\nNonetheless, Meta's Llama levels the playing field for researchers, small organizations and startups because it can be leveraged without the immense resources required to train large language models from scratch.\n\nTo ensure AI is democratized, we need three key pillars:\n\nAchieving these three pillars is a shared responsibility for government, industry, academia and the public. The public can play a vital role by advocating for ethical policies in AI, staying informed about AI developments, using AI responsibly and supporting open-source AI initiatives.\n\nBut several questions remain about open-source AI. How can we balance protecting intellectual property and fostering innovation through open-source AI? How can we minimize ethical concerns around open-source AI? How can we safeguard open-source AI against potential misuse?\n\nProperly addressing these questions will help us create a future where AI is an inclusive tool for all. Will we rise to the challenge and ensure AI serves the greater good? Or will we let it become another nasty tool for exclusion and control? The future is in our hands.", "source": {"uri": "techxplore.com", "dataType": "news", "title": "Tech Xplore"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 5, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Proprietary_software", "type": "wiki", "score": 5, "label": {"eng": "Proprietary software"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 5, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 5, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 4, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 3, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 3, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Source_code", "type": "wiki", "score": 3, "label": {"eng": "Source code"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 3, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/Mark_Zuckerberg", "type": "person", "score": 3, "label": {"eng": "Mark Zuckerberg"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 3, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 2, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Hacker", "type": "wiki", "score": 2, "label": {"eng": "Hacker"}}, {"uri": "http://en.wikipedia.org/wiki/Quality_control", "type": "wiki", "score": 2, "label": {"eng": "Quality control"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 2, "label": {"eng": "Intellectual property"}}, {"uri": "http://en.wikipedia.org/wiki/Media_(communication)", "type": "wiki", "score": 2, "label": {"eng": "Media (communication)"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Dark_web", "type": "wiki", "score": 1, "label": {"eng": "Dark web"}}, {"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 1, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/Data_set", "type": "wiki", "score": 1, "label": {"eng": "Data set"}}], "categories": [{"uri": "dmoz/Science/Software/Simulation", "label": "dmoz/Science/Software/Simulation", "wgt": 100}, {"uri": "dmoz/Computers/Programming/Methodologies", "label": "dmoz/Computers/Programming/Methodologies", "wgt": 100}, {"uri": "dmoz/Computers/Artificial_Intelligence/Belief_Networks", "label": "dmoz/Computers/Artificial Intelligence/Belief Networks", "wgt": 100}, {"uri": "dmoz/Computers/CAD_and_CAM/NX_(Unigraphics)_and_Solid_Edge", "label": "dmoz/Computers/CAD and CAM/NX (Unigraphics) and Solid Edge", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 84}], "image": "https://scx2.b-cdn.net/gfx/news/2024/meta.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "date": "2015-12-", "textStart": 3169, "textEnd": 3182}], "sentiment": 0.06666666666666665, "wgt": 216, "relevance": 1}
{"uri": "8259606968", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "07:17:27", "dateTime": "2024-08-05T07:17:27Z", "dateTimePub": "2024-08-05T07:16:52Z", "dataType": "news", "sim": 0.8392156958580017, "url": "https://stuff.co.za/2024/08/05/meta-launched-the-largest-open-ai-model-in/", "title": "Meta Just Launched The Largest 'open' AI Model In History. Here's Why It Matters - Stuff South Africa", "body": "In the world of artificial intelligence (AI), a battle is underway. On one side are companies that believe in keeping the datasets and algorithms behind their advanced software private and confidential. On the other are companies that believe in allowing the public to see what's under the hood of their sophisticated AI models.\n\nThink of this as the battle between open- and closed-source AI.\n\nIn recent weeks, Meta, the parent company of Facebook, took up the fight for open-source AI in a big way by releasing a new collection of large AI models. These include a model named Llama 3.1 405B, which Meta's founder and chief executive, Mark Zuckerberg, says is \"the first frontier-level open source AI model\".\n\nFor anyone who cares about a future in which everybody can access the benefits of AI, this is good news.\n\nClosed-source AI refers to models, datasets and algorithms that are proprietary and kept confidential. Examples include ChatGPT, Google's Gemini and Anthropic's Claude.\n\nThough anyone can use these products, there is no way to find out what dataset and source codes have been used to build the AI model or tool.\n\nWhile this is a great way for companies to protect their intellectual property and their profits, it risks undermining public trust and accountability. Making AI technology closed-source also slows down innovation and makes a company or other users dependent on a single platform for their AI needs. This is because the platform that owns the model controls changes, licensing and updates.\n\nThere are a range of ethical frameworks that seek to improve the fairness, accountability, transparency, privacy and human oversight of AI. However, these principles are often not fully achieved with closed-source AI due to the inherent lack of transparency and external accountability associated with proprietary systems.\n\nIn the case of ChatGPT, its parent company, OpenAI, releases neither the dataset nor code of its latest AI tools to the public. This makes it impossible for regulators to audit it. And while access to the service is free, concerns remain about how users' data are stored and used for retraining models.\n\nBy contrast, the code and dataset behind open-source AI models is available for everyone to see.\n\nThis fosters rapid development through community collaboration and enables the involvement of smaller organisations and even individuals in AI development. It also makes a huge difference for small and medium size enterprises as the cost of training large AI models is colossal.\n\nPerhaps most importantly, open-source AI allows for scrutiny and identification of potential biases and vulnerabilities.\n\nHowever, open-source AI does create new risks and ethical concerns.\n\nFor example, quality control in open-source products is usually low. As hackers can also access the code and data, the models are also more prone to cyberattacks and can be tailored and customised for malicious purposes, such as retraining the model with data from the dark web.\n\nAmong all leading AI companies, Meta has emerged as a pioneer of open-source AI. With its new suite of AI models, it is doing what OpenAI promised to do when it launched in December 2015 - namely, advancing digital intelligence \"in the way that is most likely to benefit humanity as a whole\", as OpenAI said back then.\n\nLlama 3.1 405B is the largest open-source AI model in history. It is what's known as a large language model, capable of generating human language text in multiple languages. It can be downloaded online but because of its huge size, users will need powerful hardware to run it.\n\nWhile it does not outperform other models across all metrics, Llama 3.1 405B is considered highly competitive and does perform better than existing closed-source and commercial large language models in certain tasks, such as reasoning and coding tasks.\n\nBut the new model is not fully open, because Meta hasn't released the huge data set used to train it. This is a significant \"open\" element that is currently missing.\n\nNonetheless, Meta's Llama levels the playing field for researchers, small organisations and startups because it can be leveraged without the immense resources required to train large language models from scratch.\n\nTo ensure AI is democratised, we need three key pillars:\n\nAchieving these three pillars is a shared responsibility for government, industry, academia and the public. The public can play a vital role by advocating for ethical policies in AI, staying informed about AI developments, using AI responsibly and supporting open-source AI initiatives.\n\nHowever several questions remain about open-source AI. How can we balance protecting intellectual property and fostering innovation through open-source AI? How can we minimise ethical concerns around open-source AI? How can we safeguard open-source AI against potential misuse?\n\nProperly addressing these questions will help us create a future where AI is an inclusive tool for all. Will we rise to the challenge and ensure AI serves the greater good? Or will we let it become another nasty tool for exclusion and control? The future is in our hands.", "source": {"uri": "stuff.co.za", "dataType": "news", "title": "Stuff"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 5, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Proprietary_software", "type": "wiki", "score": 5, "label": {"eng": "Proprietary software"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 5, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 5, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 4, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 3, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 3, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Source_code", "type": "wiki", "score": 3, "label": {"eng": "Source code"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 3, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/Mark_Zuckerberg", "type": "person", "score": 3, "label": {"eng": "Mark Zuckerberg"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 3, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 2, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Hacker", "type": "wiki", "score": 2, "label": {"eng": "Hacker"}}, {"uri": "http://en.wikipedia.org/wiki/Quality_control", "type": "wiki", "score": 2, "label": {"eng": "Quality control"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 2, "label": {"eng": "Intellectual property"}}, {"uri": "http://en.wikipedia.org/wiki/Vulnerability_(computing)", "type": "wiki", "score": 2, "label": {"eng": "Vulnerability (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Dark_web", "type": "wiki", "score": 1, "label": {"eng": "Dark web"}}, {"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 1, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/Data_set", "type": "wiki", "score": 1, "label": {"eng": "Data set"}}], "categories": [{"uri": "dmoz/Science/Software/Simulation", "label": "dmoz/Science/Software/Simulation", "wgt": 100}, {"uri": "dmoz/Computers/Programming/Methodologies", "label": "dmoz/Computers/Programming/Methodologies", "wgt": 100}, {"uri": "dmoz/Computers/Artificial_Intelligence/Belief_Networks", "label": "dmoz/Computers/Artificial Intelligence/Belief Networks", "wgt": 100}, {"uri": "dmoz/Computers/CAD_and_CAM/NX_(Unigraphics)_and_Solid_Edge", "label": "dmoz/Computers/CAD and CAM/NX (Unigraphics) and Solid Edge", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 85}], "image": "https://stuff.co.za/wp-content/uploads/2022/09/Meta-Make-A-Video-AI-1.png", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "date": "2015-12-", "textStart": 3171, "textEnd": 3184}], "sentiment": 0.06666666666666665, "wgt": 214, "relevance": 1}
{"uri": "8259510866", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "06:02:50", "dateTime": "2024-08-05T06:02:50Z", "dateTimePub": "2024-08-05T06:02:17Z", "dataType": "news", "sim": 0.8235294222831726, "url": "https://techcentral.co.za/meta-applauded-choosing-open-source-ai/249067/", "title": "Why Meta should be lauded for choosing 'open-source' AI - TechCentral", "body": "In the world of artificial intelligence, a battle is under way. On one side are companies that believe in keeping the datasets and algorithms behind their advanced software private and confidential. On the other are companies that believe in allowing the public to see what's under the bonnet of their sophisticated AI models.\n\nThink of this as the battle between open- and closed-source AI.\n\nIn recent weeks, Meta, the parent company of Facebook, took up the fight for open-source AI in a big way by releasing a new collection of large AI models. These include a model named Llama 3.1 405B, which Meta's founder and chief executive, Mark Zuckerberg, says is \"the first frontier-level open-source AI model\".\n\nFor anyone who cares about a future in which everybody can access the benefits of AI, this is good news.\n\nClosed-source AI refers to models, datasets and algorithms that are proprietary and kept confidential. Examples include ChatGPT, Google's Gemini and Anthropic's Claude.\n\nThough anyone can use these products, there is no way to find out what dataset and source codes have been used to build the AI model or tool.\n\nWhile this is a great way for companies to protect their intellectual property and their profits, it risks undermining public trust and accountability. Making AI technology closed source also slows down innovation and makes a company or other users dependent on a single platform for their AI needs. This is because the platform that owns the model controls changes, licensing and updates.\n\nThere are a range of ethical frameworks that seek to improve the fairness, accountability, transparency, privacy and human oversight of AI. However, these principles are often not fully achieved with closed-source AI due to the inherent lack of transparency and external accountability associated with proprietary systems.\n\nIn the case of ChatGPT, its parent company, OpenAI, releases neither the dataset nor code of its latest AI tools to the public. This makes it impossible for regulators to audit it. And while access to the service is free, concerns remain about how users' data are stored and used for retraining models.\n\nBy contrast, the code and dataset behind open-source AI models is available for everyone to see.\n\nThis fosters rapid development through community collaboration and enables the involvement of smaller organisations and even individuals in AI development. It also makes a huge difference for small and medium-sized enterprises as the cost of training large AI models is colossal.\n\nPerhaps most importantly, open-source AI allows for scrutiny and identification of potential biases and vulnerability.\n\nHowever, open-source AI does create new risks and ethical concerns.\n\nFor example, quality control in open-source products is usually low. As hackers can also access the code and data, the models are also more prone to cyberattacks and can be tailored and customised for malicious purposes, such as retraining the model with data from the dark web.\n\nAmong all leading AI companies, Meta has emerged as a pioneer of open-source AI. With its new suite of AI models, it is doing what OpenAI promised to do when it launched in December 2015 - namely, advancing digital intelligence \"in the way that is most likely to benefit humanity as a whole\", as OpenAI said back then.\n\nLlama 3.1 405B is the largest open-source AI model in history. It is what's known as a large language model, capable of generating human language text in multiple languages. It can be downloaded online but because of its huge size, users will need powerful hardware to run it.\n\nWhile it does not outperform other models across all metrics, Llama 3.1 405B is considered highly competitive and does perform better than existing closed-source and commercial large language models in certain tasks, such as reasoning and coding tasks.\n\nBut the new model is not fully open, because Meta hasn't released the huge data set used to train it. This is a significant \"open\" element that is currently missing.\n\nNonetheless, Meta's Llama levels the playing field for researchers, small organisations and start-ups because it can be leveraged without the immense resources required to train large language models from scratch.\n\nTo ensure AI is democratised, we need three key pilars:\n\nAchieving these three pillars is a shared responsibility for government, industry, academia and the public. The public can play a vital role by advocating for ethical policies in AI, staying informed about AI developments, using AI responsibly and supporting open-source AI initiatives.\n\nBut several questions remain about open-source AI. How can we balance protecting intellectual property and fostering innovation through open-source AI? How can we minimise ethical concerns around open-source AI? How can we safeguard open-source AI against potential misuse?\n\nProperly addressing these questions will help us create a future where AI is an inclusive tool for all. Will we rise to the challenge and ensure AI serves the greater good? Or will we let it become another nasty tool for exclusion and control? The future is in our hands.", "source": {"uri": "techcentral.co.za", "dataType": "news", "title": "TechCentral"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 5, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Proprietary_software", "type": "wiki", "score": 5, "label": {"eng": "Proprietary software"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 5, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 5, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 4, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 3, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 3, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Source_code", "type": "wiki", "score": 3, "label": {"eng": "Source code"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 3, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/Mark_Zuckerberg", "type": "person", "score": 3, "label": {"eng": "Mark Zuckerberg"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 3, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 2, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Hacker", "type": "wiki", "score": 2, "label": {"eng": "Hacker"}}, {"uri": "http://en.wikipedia.org/wiki/Quality_control", "type": "wiki", "score": 2, "label": {"eng": "Quality control"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 2, "label": {"eng": "Intellectual property"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Dark_web", "type": "wiki", "score": 1, "label": {"eng": "Dark web"}}, {"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 1, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/Data_set", "type": "wiki", "score": 1, "label": {"eng": "Data set"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 1, "label": {"eng": "Startup company"}}], "categories": [{"uri": "dmoz/Science/Software/Simulation", "label": "dmoz/Science/Software/Simulation", "wgt": 100}, {"uri": "dmoz/Computers/Programming/Methodologies", "label": "dmoz/Computers/Programming/Methodologies", "wgt": 100}, {"uri": "dmoz/Computers/Software/Information_Retrieval", "label": "dmoz/Computers/Software/Information Retrieval", "wgt": 100}, {"uri": "dmoz/Computers/Artificial_Intelligence/Belief_Networks", "label": "dmoz/Computers/Artificial Intelligence/Belief Networks", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 85}], "image": "https://techcentral.co.za/wp-content/uploads/2024/08/open-doors-1500-800.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "date": "2015-12-", "textStart": 3168, "textEnd": 3181}], "sentiment": 0.06666666666666665, "wgt": 210, "relevance": 1}
{"uri": "8256569757", "lang": "eng", "isDuplicate": false, "date": "2024-08-02", "time": "20:41:59", "dateTime": "2024-08-02T20:41:59Z", "dateTimePub": "2024-08-02T20:41:36Z", "dataType": "news", "sim": 0.8196078538894653, "url": "https://singularityhub.com/2024/08/02/meta-just-launched-the-largest-open-ai-model-in-history-heres-why-it-matters/", "title": "Meta Just launched the Largest 'Open' AI Model in History. Here's Why It Matters.", "body": "In the world of artificial intelligence, a battle is underway. On one side are companies that believe in keeping the datasets and algorithms behind their advanced software private and confidential. On the other are companies that believe in allowing the public to see what's under the hood of their sophisticated AI models.\n\nThink of this as the battle between open- and closed-source AI.\n\nIn recent weeks, Meta, the parent company of Facebook, took up the fight for open-source AI in a big way by releasing a new collection of large AI models. These include a model named Llama 3.1 405B, which Meta's founder and chief executive, Mark Zuckerberg, says is \"the first frontier-level open-source AI model.\"\n\nFor anyone who cares about a future in which everybody can access the benefits of AI, this is good news.\n\nClosed-source AI refers to models, datasets, and algorithms that are proprietary and kept confidential. Examples include ChatGPT, Google's Gemini, and Anthropic's Claude.\n\nThough anyone can use these products, there is no way to find out what dataset and source codes have been used to build the AI model or tool.\n\nWhile this is a great way for companies to protect their intellectual property and profits, it risks undermining public trust and accountability. Making AI technology closed-source also slows down innovation and makes a company or other users dependent on a single platform for their AI needs. This is because the platform that owns the model controls changes, licensing, and updates.\n\nThere are a range of ethical frameworks that seek to improve the fairness, accountability, transparency, privacy, and human oversight of AI. However, these principles are often not fully achieved with closed-source AI due to the inherent lack of transparency and external accountability associated with proprietary systems.\n\nIn the case of ChatGPT, its parent company, OpenAI, releases neither the dataset nor code of its latest AI tools to the public. This makes it impossible for regulators to audit it. And while access to the service is free, concerns remain about how users' data are stored and used for retraining models.\n\nBy contrast, the code and dataset behind open-source AI models is available for everyone to see.\n\nThis fosters rapid development through community collaboration and enables the involvement of smaller organizations and even individuals in AI development. It also makes a huge difference for small- and medium-size enterprises as the cost of training large AI models is colossal.\n\nPerhaps most importantly, open-source AI allows for scrutiny and identification of potential biases and vulnerability.\n\nHowever, open-source AI does create new risks and ethical concerns.\n\nFor example, quality control in open-source products is usually low. As hackers can also access the code and data, the models are also more prone to cyberattacks and can be tailored and customized for malicious purposes, such as retraining the model with data from the dark web.\n\nAmong all leading AI companies, Meta has emerged as a pioneer of open-source AI. With its new suite of AI models, it is doing what OpenAI promised to do when it launched in December 2015 -- namely, advancing digital intelligence \"in the way that is most likely to benefit humanity as a whole,\" as OpenAI said back then.\n\nLlama 3.1 405B is the largest open-source AI model in history. It is what's known as a large language model, capable of generating human language text in multiple languages. It can be downloaded online but because of its huge size, users will need powerful hardware to run it.\n\nWhile it does not outperform other models across all metrics, Llama 3.1 405B is considered highly competitive and does perform better than existing closed-source and commercial large language models in certain tasks, such as reasoning and coding tasks.\n\nBut the new model is not fully open because Meta hasn't released the huge dataset used to train it. This is a significant \"open\" element that is currently missing.\n\nNonetheless, Meta's Llama levels the playing field for researchers, small organizations, and startups because it can be leveraged without the immense resources required to train large language models from scratch.\n\nTo ensure AI is democratized, we need three key pillars:\n\nAchieving these three pillars is a shared responsibility for government, industry, academia and the public. The public can play a vital role by advocating for ethical policies in AI, staying informed about AI developments, using AI responsibly, and supporting open-source AI initiatives.\n\nBut several questions remain about open-source AI. How can we balance protecting intellectual property and fostering innovation through open-source AI? How can we minimize ethical concerns around open-source AI? How can we safeguard open-source AI against potential misuse?\n\nProperly addressing these questions will help us create a future where AI is an inclusive tool for all. Will we rise to the challenge and ensure AI serves the greater good? Or will we let it become another nasty tool for exclusion and control? The future is in our hands.", "source": {"uri": "singularityhub.com", "dataType": "news", "title": "Singularity Hub"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 5, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Proprietary_software", "type": "wiki", "score": 5, "label": {"eng": "Proprietary software"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 5, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 5, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 4, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 3, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 3, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Source_code", "type": "wiki", "score": 3, "label": {"eng": "Source code"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 3, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/Mark_Zuckerberg", "type": "person", "score": 3, "label": {"eng": "Mark Zuckerberg"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 3, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 2, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Hacker", "type": "wiki", "score": 2, "label": {"eng": "Hacker"}}, {"uri": "http://en.wikipedia.org/wiki/Quality_control", "type": "wiki", "score": 2, "label": {"eng": "Quality control"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 2, "label": {"eng": "Intellectual property"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Dark_web", "type": "wiki", "score": 1, "label": {"eng": "Dark web"}}, {"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 1, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 1, "label": {"eng": "Startup company"}}], "categories": [{"uri": "dmoz/Science/Software/Simulation", "label": "dmoz/Science/Software/Simulation", "wgt": 100}, {"uri": "dmoz/Computers/Programming/Methodologies", "label": "dmoz/Computers/Programming/Methodologies", "wgt": 100}, {"uri": "dmoz/Computers/Artificial_Intelligence/Belief_Networks", "label": "dmoz/Computers/Artificial Intelligence/Belief Networks", "wgt": 100}, {"uri": "dmoz/Computers/CAD_and_CAM/NX_(Unigraphics)_and_Solid_Edge", "label": "dmoz/Computers/CAD and CAM/NX (Unigraphics) and Solid Edge", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 82}], "image": "https://singularityhub.com/uploads/2024/08/large-ai-model-neural-network.jpeg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "date": "2015-12-", "textStart": 3163, "textEnd": 3176}], "sentiment": 0.06666666666666665, "wgt": 209, "relevance": 1}
{"uri": "8255716198", "lang": "eng", "isDuplicate": false, "date": "2024-08-02", "time": "10:06:37", "dateTime": "2024-08-02T10:06:37Z", "dateTimePub": "2024-08-02T10:04:39Z", "dataType": "news", "sim": 0.8117647171020508, "url": "https://www.etvbharat.com/en/!technology/meta-just-launched-largest-open-ai-model-in-history-heres-why-it-matters-enn24080202475", "title": "Meta Just Launched Largest 'Open' AI Model In History; Here's Why It Matters", "body": "Sydney: In the world of artificial intelligence (AI), a battle is underway. On one side are companies that believe in keeping the datasets and algorithms behind their advanced software private and confidential. On the other are companies that believe in allowing the public to see what's under the hood of their sophisticated AI models. Think of this as the battle between open- and closed-source AI.\n\nIn recent weeks, Meta, the parent company of Facebook, took up the fight for open-source AI in a big way by releasing a new collection of large AI models. These include a model named Llama 3.1 405B, which Meta's founder and chief executive, Mark Zuckerberg, says is the first frontier-level open-source AI model.\n\nFor anyone who cares about a future in which everybody can access the benefits of AI, this is good news. The danger of closed-source AI and the promise of open-source AI\n\nClosed-source AI refers to models, datasets and algorithms that are proprietary and kept confidential. Examples include ChatGPT, Google's Gemini and Anthropic's Claude.\n\nThough anyone can use these products, there is no way to find out what dataset and source codes have been used to build the AI model or tool. While this is a great way for companies to protect their intellectual property and their profits, it risks undermining public trust and accountability. Making AI technology closed-source also slows down innovation and makes a company or other users dependent on a single platform for their AI needs. This is because the platform that owns the model controls changes, licensing and updates.\n\nThere are a range of ethical frameworks that seek to improve the fairness, accountability, transparency, privacy and human oversight of AI. However, these principles are often not fully achieved with closed-source AI due to the inherent lack of transparency and external accountability associated with proprietary systems. In the case of ChatGPT, its parent company, OpenAI, releases neither the dataset nor code of its latest AI tools to the public. This makes it impossible for regulators to audit it. And while access to the service is free, concerns remain about how users' data are stored and used for retraining models.\n\nBy contrast, the code and dataset behind open-source AI models are available for everyone to see. This fosters rapid development through community collaboration and enables the involvement of smaller organisations and even individuals in AI development. It also makes a huge difference for small and medium size enterprises as the cost of training large AI models is colossal.\n\nPerhaps most importantly, open-source AI allows for scrutiny and identification of potential biases and vulnerabilities. However, open-source AI does create new risks and ethical concerns. For example, quality control in open-source products is usually low. As hackers can also access the code and data, the models are also more prone to cyberattacks and can be tailored and customised for malicious purposes, such as retraining the model with data from the dark web.\n\nAn open-source AI pioneer\n\nAmong all leading AI companies, Meta has emerged as a pioneer of open-source AI. With its new suite of AI models, it is doing what OpenAI promised to do when it launched in December 2015 namely, advancing digital intelligence in the way that is most likely to benefit humanity as a whole, as OpenAI said back then.", "source": {"uri": "etvbharat.com", "dataType": "news", "title": "ETV Bharat News"}, "authors": [{"uri": "etv_bharat@etvbharat.com", "name": "Etv Bharat", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 5, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Proprietary_software", "type": "wiki", "score": 5, "label": {"eng": "Proprietary software"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 4, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 4, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 3, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/Mark_Zuckerberg", "type": "person", "score": 3, "label": {"eng": "Mark Zuckerberg"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 3, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 2, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 2, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 2, "label": {"eng": "Intellectual property"}}, {"uri": "http://en.wikipedia.org/wiki/Source_code", "type": "wiki", "score": 2, "label": {"eng": "Source code"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 2, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 2, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Dark_web", "type": "wiki", "score": 1, "label": {"eng": "Dark web"}}, {"uri": "http://en.wikipedia.org/wiki/Hacker", "type": "wiki", "score": 1, "label": {"eng": "Hacker"}}, {"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 1, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 1, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Vulnerability_(computing)", "type": "wiki", "score": 1, "label": {"eng": "Vulnerability (computing)"}}], "categories": [{"uri": "dmoz/Science/Software/Simulation", "label": "dmoz/Science/Software/Simulation", "wgt": 100}, {"uri": "dmoz/Computers/Programming/Methodologies", "label": "dmoz/Computers/Programming/Methodologies", "wgt": 100}, {"uri": "dmoz/Computers/Software/Data_Administration", "label": "dmoz/Computers/Software/Data Administration", "wgt": 100}, {"uri": "dmoz/Computers/CAD_and_CAM/NX_(Unigraphics)_and_Solid_Edge", "label": "dmoz/Computers/CAD and CAM/NX (Unigraphics) and Solid Edge", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 85}], "image": "https://etvbharatimages.akamaized.net/etvbharat/prod-images/02-08-2024/1200-675-22109498-89-22109498-1722591749286.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "date": "2015-12-", "textStart": 3264, "textEnd": 3277}], "sentiment": 0.04313725490196085, "wgt": 207, "relevance": 1}
{"uri": "8255596614", "lang": "eng", "isDuplicate": false, "date": "2024-08-02", "time": "08:58:29", "dateTime": "2024-08-02T08:58:29Z", "dateTimePub": "2024-08-02T08:57:42Z", "dataType": "news", "sim": 0.7960784435272217, "url": "https://www.deccanherald.com/technology/meta-just-launched-the-largest-open-ai-model-in-history-heres-why-it-matters-3134229", "title": "Explained | Meta just launched the largest 'open' AI model in history. Here's why it matters", "body": "Sydney: In the world of artificial intelligence (AI), a battle is under way. On one side are companies that believe in keeping the datasets and algorithms behind their advanced software private and confidential. On the other are companies that believe in allowing the public to see what's under the hood of their sophisticated AI models.\n\nThink of this as the battle between open- and closed-source AI.\n\nIn recent weeks, Meta, the parent company of Facebook, took up the fight for open-source AI in a big way by releasing a new collection of large AI models. These include a model named Llama 3.1 405B, which Meta's founder and chief executive, Mark Zuckerberg, says is \"the first frontier-level open source AI model\".\n\nFor anyone who cares about a future in which everybody can access the benefits of AI, this is good news.\n\nThe danger of closed-source AI - and the promise of open-source AI Closed-source AI refers to models, datasets and algorithms that are proprietary and kept confidential. Examples include ChatGPT, Google's Gemini and Anthropic's Claude.\n\nThough anyone can use these products, there is no way to find out what dataset and source codes have been used to build the AI model or tool.\n\nWhile this is a great way for companies to protect their intellectual property and their profits, it risks undermining public trust and accountability. Making AI technology closed-source also slows down innovation and makes a company or other users dependent on a single platform for their AI needs. This is because the platform that owns the model controls changes, licensing and updates.\n\nThere are a range of ethical frameworks that seek to improve the fairness, accountability, transparency, privacy and human oversight of AI. However, these principles are often not fully achieved with closed-source AI due to the inherent lack of transparency and external accountability associated with proprietary systems.\n\nIn the case of ChatGPT, its parent company, OpenAI, releases neither the dataset nor code of its latest AI tools to the public. This makes it impossible for regulators to audit it. And while access to the service is free, concerns remain about how users' data are stored and used for retraining models.\n\nBy contrast, the code and dataset behind open-source AI models is available for everyone to see.\n\nThis fosters rapid development through community collaboration and enables the involvement of smaller organisations and even individuals in AI development. It also makes a huge difference for small and medium size enterprises as the cost of training large AI models is colossal.\n\nPerhaps most importantly, open source AI allows for scrutiny and identification of potential biases and vulnerability.\n\nHowever, open-source AI does create new risks and ethical concerns.\n\nFor example, quality control in open source products is usually low. As hackers can also access the code and data, the models are also more prone to cyberattacks and can be tailored and customised for malicious purposes, such as retraining the model with data from the dark web.\n\nAn open-source AI pioneer\n\nAmong all leading AI companies, Meta has emerged as a pioneer of open-source AI. With its new suite of AI models, it is doing what OpenAI promised to do when it launched in December 2015 - namely, advancing digital intelligence \"in the way that is most likely to benefit humanity as a whole\", as OpenAI said back then.\n\nLlama 3.1 405B is the largest open-source AI model in history. It is what's known as a large language model, capable of generating human language text in multiple languages. It can be downloaded online but because of its huge size, users will need powerful hardware to run it.\n\nWhile it does not outperform other models across all metrics, Llama 3.1 405B is considered highly competitive and does perform better than existing closed-source and commercial large language models in certain tasks, such as reasoning and coding tasks.\n\nBut the new model is not fully open, because Meta hasn't released the huge data set used to train it. This is a significant \"open\" element that is currently missing.\n\nNonetheless, Meta's Llama levels the playing field for researchers, small organisations and startups because it can be leveraged without the immense resources required to train large language models from scratch.", "source": {"uri": "deccanherald.com", "dataType": "news", "title": "Deccan Herald"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 5, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Proprietary_software", "type": "wiki", "score": 5, "label": {"eng": "Proprietary software"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 4, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 4, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 3, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 3, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 3, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/Mark_Zuckerberg", "type": "person", "score": 3, "label": {"eng": "Mark Zuckerberg"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 3, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 2, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 2, "label": {"eng": "Intellectual property"}}, {"uri": "http://en.wikipedia.org/wiki/Source_code", "type": "wiki", "score": 2, "label": {"eng": "Source code"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 1, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Dark_web", "type": "wiki", "score": 1, "label": {"eng": "Dark web"}}, {"uri": "http://en.wikipedia.org/wiki/Hacker", "type": "wiki", "score": 1, "label": {"eng": "Hacker"}}, {"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 1, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/Quality_control", "type": "wiki", "score": 1, "label": {"eng": "Quality control"}}, {"uri": "http://en.wikipedia.org/wiki/Data_set", "type": "wiki", "score": 1, "label": {"eng": "Data set"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 1, "label": {"eng": "Startup company"}}], "categories": [{"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 100}, {"uri": "dmoz/Science/Software/Simulation", "label": "dmoz/Science/Software/Simulation", "wgt": 100}, {"uri": "dmoz/Computers/Programming/Methodologies", "label": "dmoz/Computers/Programming/Methodologies", "wgt": 100}, {"uri": "dmoz/Computers/CAD_and_CAM/3D_Modelling", "label": "dmoz/Computers/CAD and CAM/3D Modelling", "wgt": 100}, {"uri": "dmoz/Computers/CAD_and_CAM/NX_(Unigraphics)_and_Solid_Edge", "label": "dmoz/Computers/CAD and CAM/NX (Unigraphics) and Solid Edge", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 85}], "image": "https://images.deccanherald.com/deccanherald%2F2024-03%2F99692c16-7b64-4ed5-a86b-9dc9701b65aa%2Ffb_meta_reuters_1174330_1671781888.png?rect=0%2C0%2C1280%2C672&w=1200&ar=40%3A21&auto=format%2Ccompress&ogImage=true&mode=crop", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "date": "2015-12-", "textStart": 3272, "textEnd": 3285}], "sentiment": 0.04313725490196085, "wgt": 203, "relevance": 1}
{"uri": "8259534458", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "06:21:44", "dateTime": "2024-08-05T06:21:44Z", "dateTimePub": "2024-08-05T06:21:13Z", "dataType": "news", "sim": 0.7333333492279053, "url": "https://www.forbes.com/sites/bernardmarr/2024/08/05/why-your-company-urgently-needs-an-ai-policy-protect-and-propel-your-business/", "title": "Why Your Company Urgently Needs An AI Policy: Protect And Propel Your Business", "body": "The AI revolution is well underway, and I believe just about any business or organization can benefit by automating routine tasks, augmenting decision-making and optimizing operations and processes.\n\nHowever, AI can also harm a business if it isn't used cautiously. So, it's very surprising to me that many companies and organizations don't have any form of official AI policy in place.\n\nAmong the most serious risks are breaching privacy and confidentiality, exposing sensitive data, and inadvertently infringing copyright.\n\nCreating such a policy should be at the top of just about every organization's to-do list, regardless of size or industry. So, in this article, I'll explore the risks that companies are exposing themselves to by allowing unregulated AI use, as well as the benefits of a well-thought-out policy when it comes to navigating the complex and sometimes dangerous waters of business AI.\n\nLong gone are the days when only large companies like Google or Microsoft were using AI. On a daily basis, millions of businesses are leveraging technology such as chatbots for customer support, generative content creation and audience analytics in marketing, screening job applicants in HR, detecting fraudulent transactions, optimizing supply chain operations or extracting business intelligence insights from their data.\n\nUnfortunately, in my experience, many of them are unaware of the risks they're leaving themselves open to.\n\nData privacy and security concerns are perhaps the most obvious, but still overlooked on a surprisingly frequent basis. Employees using tools like ChatGPT to create summaries or respond to emails are often unaware that they're potentially exposing confidential information to the world.\n\nEven if they are, some simply assume it isn't a problem due to the fact they haven't been told not to do it!\n\nSeveral companies have already fallen foul of risks associated with a lack of regulation around AI.\n\nFor example, in 2023, Samsung banned the use of ChatGPT after finding that staff had entered sensitive data.\n\nAnother example is that HR departments routinely use AI tools to screen job applicants. However, unless proper care is taken to mitigate the risk of bias, this could lead to discrimination, potentially leaving the business open to legal action.\n\nThe same goes for businesses that are using AI tools that make decisions that can affect people's lives - for example, processing loan applications or allocating healthcare resources.\n\nWhen it comes to IP and copyright issues, businesses relying on AI-generated content could inadvertently find themselves using content without permission. Several court cases are currently being brought by artists and news agencies, saying their work was used to train algorithms without their permission. The outcome is uncertain right now, but could potentially lead to trouble further down the road for businesses using these tools.\n\nAnd accountability is also an important issue. Are businesses and employees fully aware of their need to take responsibility for decisions that AI makes on their behalf? A lack of transparency and explainability inherent to many AI systems may make it difficult for them to do so. But this is unlikely to work as an excuse if they should find themselves in hot water due to their actions!\n\nGetting any of this wrong could cause huge financial, legal and reputational damage to a company. So what can be done?\n\nIf a business wants to take advantage of the transformative opportunities offered by AI, a clear, detailed and comprehensive AI policy is essential.\n\nEstablishing guidelines around what constitutes acceptable and unacceptable use of AI should be the first step in safeguarding against its potential risks. However, it's crucial to understand that an effective AI policy goes beyond mere risk mitigation - it's also a powerful enabler for innovation and growth.\n\nA well-crafted AI policy doesn't just defend; it empowers. By clearly outlining how AI should be used to enhance productivity and drive innovation, it provides a framework within which employees can confidently explore and leverage AI technologies. This clarity fosters an environment where creative solutions are nurtured within safe and ethical boundaries.\n\nAddressing these issues proactively will also help businesses identify the technological elements necessary for the safe and responsible use of AI.\n\nFor example, understanding the data policies around public cloud-based AI tools such as ChatGPT allows businesses to recognize where more private, secure systems -- such as on-premises infrastructure - could be essential.\n\nWith this policy in place, any organization positions itself on far firmer ground. Rather than stifling them, it will empower organizations with the knowledge that they can experiment and innovate with confidence. An AI policy acts as a launchpad, setting up a framework for responsible and effective AI use that can drive competitive advantage.\n\nThe rapid adoption of AI across industries and the risks that this has created means an AI policy isn't just a good idea -- it's critical to future-proofing any business.\n\nAdditionally, putting an acceptable AI use policy in place helps a company to position itself as a serious player in the AI game, rather than just another business jumping on the bandwagon. In an era where AI capabilities are rapidly becoming a benchmark for industry leadership, having a clear AI policy positions your company as a responsible, forward-thinking player. This can be incredibly attractive to investors, partners, and top talent who prioritize ethical standards and corporate responsibility.\n\nIt also helps to demonstrate to customers, investors and other stakeholders that an organization is committed to building trust and implementing AI in a transparent and ethical way.\n\nThis will be invaluable when it comes to hiring and retaining talent. People with the skills and experience needed to implement organizational AI systems are highly sought-after. Naturally, they're attracted to companies that are able to demonstrate that they are serious and mature in their outlook and practices when it comes to AI.\n\nThis is something that I believe all leaders need to prioritize if they want to benefit from the opportunities offered by AI. A comprehensive AI policy doesn't only defend; it also enables. It clarifies for all employees how AI should be used to enhance productivity and innovation, fostering an environment where creative solutions are nurtured within safe and ethical boundaries.", "source": {"uri": "forbes.com", "dataType": "news", "title": "Forbes"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Confidentiality", "type": "wiki", "score": 4, "label": {"eng": "Confidentiality"}}, {"uri": "http://en.wikipedia.org/wiki/Human_resources", "type": "org", "score": 4, "label": {"eng": "Human resources"}}, {"uri": "http://en.wikipedia.org/wiki/Decision-making", "type": "wiki", "score": 3, "label": {"eng": "Decision-making"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_model", "type": "wiki", "score": 3, "label": {"eng": "Generative model"}}, {"uri": "http://en.wikipedia.org/wiki/Business_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Business intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Supply_chain", "type": "wiki", "score": 3, "label": {"eng": "Supply chain"}}, {"uri": "http://en.wikipedia.org/wiki/Analytics", "type": "wiki", "score": 3, "label": {"eng": "Analytics"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 3, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Information_privacy", "type": "wiki", "score": 3, "label": {"eng": "Information privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 3, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Marketing", "type": "wiki", "score": 3, "label": {"eng": "Marketing"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 2, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 2, "label": {"eng": "Intellectual property"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 2, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Samsung", "type": "org", "score": 2, "label": {"eng": "Samsung"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 2, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Discrimination", "type": "wiki", "score": 2, "label": {"eng": "Discrimination"}}, {"uri": "http://en.wikipedia.org/wiki/Bias", "type": "wiki", "score": 2, "label": {"eng": "Bias"}}, {"uri": "http://en.wikipedia.org/wiki/Health_care", "type": "wiki", "score": 2, "label": {"eng": "Health care"}}, {"uri": "http://en.wikipedia.org/wiki/Benchmarking", "type": "wiki", "score": 1, "label": {"eng": "Benchmarking"}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Society/Issues/Business", "label": "dmoz/Society/Issues/Business", "wgt": 100}, {"uri": "dmoz/Business/Opportunities/Opposing_Views", "label": "dmoz/Business/Opportunities/Opposing Views", "wgt": 100}, {"uri": "dmoz/Society/Work/Telecommuting", "label": "dmoz/Society/Work/Telecommuting", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 46}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 52}], "image": "https://imageio.forbes.com/specials-images/imageserve/66b06eacfe1228278089358c/0x0.jpg?format=jpg&height=600&width=1200&fit=bounds", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.09019607843137245, "wgt": 187, "relevance": 1}
{"uri": "8259968267", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "11:15:45", "dateTime": "2024-08-05T11:15:45Z", "dateTimePub": "2024-08-05T11:14:44Z", "dataType": "news", "sim": 0.7254902124404907, "url": "https://eoc.org.cy/european-artificial-intelligence-act-comes-into-force/", "title": "European Artificial Intelligence Act comes into force - European Office Of Cyprus", "body": "The European Artificial Intelligence Act (AI Act), the world's first comprehensive regulation on artificial intelligence, enters into force. The AI Act is designed to ensure that AI developed and used in the EU is trustworthy, with safeguards to protect people's fundamental rights. The regulation aims to establish a harmonised internal market for AI in the EU, encouraging the uptake of this technology and creating a supportive environment for innovation and investment.\n\nThe AI Act introduces a forward-looking definition of AI, based on a product safety and risk-based approach in the EU:\n\nTo complement this system, the AI Act also introduces rules for so-called general-purpose AI models, which are highly capable AI models that are designed to perform a wide variety of tasks like generating human-like text. General-purpose AI models are increasingly used as components of AI applications. The AI Act will ensure transparency along the value chain and addresses possible systemic risks of the most capable models.\n\nApplication and enforcement of the AI rules\n\nMember States have until 2 August 2025 to designate national competent authorities, who will oversee the application of the rules for AI systems and carry out market surveillance activities. The Commission's AI Office will be the key implementation body for the AI Act at EU-level, as well as the enforcer for the rules for general-purpose AI models.\n\nThree advisory bodies will support the implementation of the rules. The European Artificial Intelligence Board will ensure a uniform application of the AI Act across EU Member States and will act as the main body for cooperation between the Commission and the Member States. A scientific panel of independent experts will offer technical advice and input on enforcement. In particular, this panel can issue alerts to the AI Office about risks associated to general-purpose AI models. The AI Office can also receive guidance from an advisory forum, composed of a diverse set of stakeholders.\n\nCompanies not complying with the rules will be fined. Fines could go up to 7% of the global annual turnover for violations of banned AI applications, up to 3% for violations of other obligations and up to 1.5% for supplying incorrect information.\n\nNext Steps\n\nThe majority of rules of the AI Act will start applying on 2 August 2026. However, prohibitions of AI systems deemed to present an unacceptable risk will already apply after six months, while the rules for so-called General-Purpose AI models will apply after 12 months.\n\nTo bridge the transitional period before full implementation, the Commission has launched the AI Pact. This initiative invites AI developers to voluntarily adopt key obligations of the AI Act ahead of the legal deadlines.\n\nThe Commission is also developing guidelines to define and detail how the AI Act should be implemented and facilitating co-regulatory instruments like standards and codes of practice. The Commission opened a call for expression of interest to participate in drawing-up the first general-purpose AI Code of Practice, as well as a multi-stakeholder consultation giving the opportunity to all stakeholders to have their say on the first Code of Practice under the AI Act.", "source": {"uri": "eoc.org.cy", "dataType": "news", "title": "eoc.org.cy"}, "authors": [{"uri": "ivan_sotiriadis@eoc.org.cy", "name": "Ivan Sotiriadis", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/European_Union", "type": "loc", "score": 5, "label": {"eng": "European Union"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Member_state_of_the_European_Union", "type": "wiki", "score": 4, "label": {"eng": "Member state of the European Union"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_Intelligence_Act", "type": "wiki", "score": 3, "label": {"eng": "Artificial Intelligence Act"}}, {"uri": "http://en.wikipedia.org/wiki/Applications_of_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Applications of artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Fundamental_rights", "type": "wiki", "score": 3, "label": {"eng": "Fundamental rights"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 2, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Surveillance", "type": "wiki", "score": 2, "label": {"eng": "Surveillance"}}, {"uri": "http://en.wikipedia.org/wiki/Value_chain", "type": "wiki", "score": 2, "label": {"eng": "Value chain"}}, {"uri": "http://en.wikipedia.org/wiki/Stakeholder_(corporate)", "type": "wiki", "score": 1, "label": {"eng": "Stakeholder (corporate)"}}, {"uri": "http://en.wikipedia.org/wiki/Revenue", "type": "wiki", "score": 1, "label": {"eng": "Revenue"}}], "categories": [{"uri": "dmoz/Society/Government/Multilateral", "label": "dmoz/Society/Government/Multilateral", "wgt": 100}, {"uri": "dmoz/Computers/Security/Policy", "label": "dmoz/Computers/Security/Policy", "wgt": 100}, {"uri": "dmoz/Society/Issues/Government_Operations", "label": "dmoz/Society/Issues/Government Operations", "wgt": 100}, {"uri": "dmoz/Science/Environment/Impact_Assessment", "label": "dmoz/Science/Environment/Impact Assessment", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 51}], "image": "https://eoc.org.cy/wp-content/uploads/2024/08/European-Artificial-Intelligence-Act-comes-into-force.png", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.5058823529411764, "wgt": 185, "relevance": 1}
{"uri": "8256869580", "lang": "eng", "isDuplicate": false, "date": "2024-08-03", "time": "03:36:36", "dateTime": "2024-08-03T03:36:36Z", "dateTimePub": "2024-08-03T03:34:23Z", "dataType": "news", "sim": 0.7137255072593689, "url": "https://www.devdiscourse.com/article/technology/3040468-open-vs-closed-source-ai-the-battle-for-the-future", "title": "Open vs. Closed-Source AI: The Battle for the Future | Technology", "body": "This article explores the debate between open-source and closed-source artificial intelligence (AI). It highlights Meta's new open-source AI model, Llama 3.1 405B, and discusses the ethical, practical, and security implications of both approaches. The article emphasizes the need for governance, accessibility, and openness to democratize AI.\n\nThe artificial intelligence (AI) community is currently divided into two camps: proponents of open-source AI and advocates of closed-source AI. Meta, the parent company of Facebook, has recently made headlines by releasing a series of open-source AI models, including the groundbreaking Llama 3.1 405B. This move contrasts with companies like OpenAI, Google, and Anthropic, which keep their datasets and algorithms proprietary.\n\nOpen-source AI allows for greater transparency and collaboration, enabling smaller entities to participate in AI advancement. However, it also presents risks such as increased vulnerability to cyberattacks and potential misuse for malicious purposes. In contrast, closed-source AI offers more secure intellectual property protection but lacks transparency and slows down innovation.\n\nThe future of AI relies on achieving a balance between these approaches. Effective governance, ethical frameworks, and accessible resources are essential components for making AI an inclusive tool that benefits everyone. How we address these challenges will shape the future landscape of AI.", "source": {"uri": "devdiscourse.com", "dataType": "news", "title": "Devdiscourse"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 5, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Proprietary_software", "type": "wiki", "score": 5, "label": {"eng": "Proprietary software"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Accessibility", "type": "wiki", "score": 3, "label": {"eng": "Accessibility"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 2, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 2, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 2, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 2, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 2, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 2, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 1, "label": {"eng": "Intellectual property"}}], "categories": [{"uri": "dmoz/Computers/Open_Source", "label": "dmoz/Computers/Open Source", "wgt": 100}, {"uri": "dmoz/Computers/Open_Source/Articles", "label": "dmoz/Computers/Open Source/Articles", "wgt": 100}, {"uri": "dmoz/Computers/Open_Source/Open_Content", "label": "dmoz/Computers/Open Source/Open Content", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 78}], "image": "https://www.devdiscourse.com/remote.axd?https://devdiscourse.blob.core.windows.net/aiimagegallery/03_07_2024_09_41_13_5624806.png?width=920&format=jpeg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3254901960784313, "wgt": 182, "relevance": 1}
{"uri": "8259990243", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "11:29:16", "dateTime": "2024-08-05T11:29:16Z", "dateTimePub": "2024-08-05T11:28:31Z", "dataType": "news", "sim": 0.7019608020782471, "url": "https://business-review.eu/tech/why-ai-shouldnt-make-you-complacent-about-data-security-266669", "title": "Why AI Shouldn't Make You Complacent About Data Security - Business Review", "body": "Artificial intelligence (AI) has completely changed our way of life. You're using it without knowing it.\n\nFrom Alexa to Google Maps - so many technologies are now using AI to build a massive user data profile that feeds into endless systems and helps the Large Language Models (LLMs) grow. And none of it is necessarily safe.\n\nRead on to learn why AI shouldn't make you complacent about data security.\n\nAI can do pretty much anything you ask, apart from reaching the level of human empathy and physical things for you. Anything else? It's mastering it.\n\nIt can make appointments for you, suggest things to buy from the store, or even detect diseases before they get serious. That's a convenience that no one can argue against.\n\nIt observes how we behave, our tastes and preferences, and what we do. It's quickly learning everything about us.\n\nStudies show that the average internet surfer generates 146,880 MB daily, and AI can take it all, depending on where the data source is and whether you've unknowingly agreed to the data collection.\n\nAI systems require massive amounts of data to function effectively. Each search, interaction, and click is captured and scrutinized.\n\nConsider how it works by understanding what goes into creating an AI algorithm.\n\nAI algorithms should learn and adjust themselves by analyzing large datasets. They may include anything from browsing history or purchase patterns to complex details like location information, personal conversations, biometric identifiers, etc - most of which represents information you can remove from the internet with a little proactivity.\n\nThere are also things you don't think about, like smart home devices that collect data on people's daily routines, even their energy consumption at home.\n\nSocial media platforms track who interacts with whom and what preferences they have. Health apps follow exercise habits, sleeping patterns, and diets. The data collection never ends, and AI needs it all to learn and evolve.\n\nArtificial intelligence dependency makes most people feel secure. It gives them the answers they want with minimal effort, often reducing workload and general hassles.\n\nMany people believe that AI systems are safe in themselves and that their personal information is protected. However, this definitely is not always the case.\n\nJust like any other technology, AI systems can be vulnerable to cyberattacks, data breaches, and other security threats. ChatGPT has had a few.\n\nThere are some instances where artificial intelligence has been tricked or manipulated by malicious actors, leading to wrong decisions and recommendations being made using it - just look at the Google AI Overview launch.\n\nIt wasn't necessarily malicious, but the execution of the launch and the search results AI Overview spewed out were ridiculous.\n\nHuman oversight is one of the biggest errors people make when using AI - it's not entirely accurate, and it definitely shouldn't be trusted. Some of the information it uses is biased and inaccurate, and some systems are vulnerable to security weaknesses.\n\nHowever much automation AI may bring and its convenience in life, human oversight still matters a lot. Frequent auditing and monitoring should be carried out on AI systems so that they function properly and securely.\n\nHighlighting possible vulnerabilities at such stages helps address them before they become serious problems. And if you're using AI daily, we'd recommend always second-checking the information it's giving you.\n\nIt is equally important for organizations using AI technology to put more emphasis on data security. This includes having effective security measures in place, carrying out regular security assessments, staying informed about current security practices, etc.\n\nEducating employees or users about the necessity of ensuring data security and the likely risks linked with AI further enhances overall safety.\n\nDespite the known risks, there are proactive steps to take to secure their data while using AI technologies.\n\nFirst and foremost, people must know what kind of information is being captured and how it is being used. As boring as it may be, reading privacy policies and terms of service agreements is a great way to gain insights into data practices.\n\nNever share information with AI systems - if you are signed up to any, that's exactly what you'll be doing with every search.\n\nWe'd also recommend modifying privacy settings on social media sites and disabling unnecessary data collection functions on smart devices, reducing potential data misuse. Remember, AI is using multiple platforms to collect\n\nAI is definitely making us vulnerable online. The technology is only in its infancy and we're already relying on it too much.\n\nPersonal information should be protected amid the convenience and efficiency offered by AI. Understanding how much data is being collected, appreciating the risks of depending too much on AI, taking preventive actions to protect data, and retaining human supervision over processes can help enjoy the benefits of AI with minimum security threats.", "source": {"uri": "business-review.eu", "dataType": "news", "title": "Business Review"}, "authors": [{"uri": "horia_tomescu@business-review.eu", "name": "Horia Tomescu", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 4, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Internet", "type": "wiki", "score": 4, "label": {"eng": "Internet"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 4, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Data_collection", "type": "wiki", "score": 3, "label": {"eng": "Data collection"}}, {"uri": "http://en.wikipedia.org/wiki/Alexa_Internet", "type": "org", "score": 3, "label": {"eng": "Alexa Internet"}}, {"uri": "http://en.wikipedia.org/wiki/Megabyte", "type": "wiki", "score": 3, "label": {"eng": "Megabyte"}}, {"uri": "http://en.wikipedia.org/wiki/Data_security", "type": "wiki", "score": 3, "label": {"eng": "Data security"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 2, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/Web_browsing_history", "type": "wiki", "score": 2, "label": {"eng": "Web browsing history"}}, {"uri": "http://en.wikipedia.org/wiki/Data_breach", "type": "wiki", "score": 2, "label": {"eng": "Data breach"}}, {"uri": "http://en.wikipedia.org/wiki/Home_automation", "type": "wiki", "score": 2, "label": {"eng": "Home automation"}}, {"uri": "http://en.wikipedia.org/wiki/Biometrics", "type": "wiki", "score": 2, "label": {"eng": "Biometrics"}}, {"uri": "http://en.wikipedia.org/wiki/Social_media", "type": "wiki", "score": 2, "label": {"eng": "Social media"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy_settings", "type": "wiki", "score": 1, "label": {"eng": "Privacy settings"}}, {"uri": "http://en.wikipedia.org/wiki/Smart_device", "type": "wiki", "score": 1, "label": {"eng": "Smart device"}}, {"uri": "http://en.wikipedia.org/wiki/Terms_of_service", "type": "wiki", "score": 1, "label": {"eng": "Terms of service"}}, {"uri": "http://en.wikipedia.org/wiki/Vulnerability_(computing)", "type": "wiki", "score": 1, "label": {"eng": "Vulnerability (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy_policy", "type": "wiki", "score": 1, "label": {"eng": "Privacy policy"}}, {"uri": "http://en.wikipedia.org/wiki/Automation", "type": "wiki", "score": 1, "label": {"eng": "Automation"}}, {"uri": "http://en.wikipedia.org/wiki/Audit", "type": "wiki", "score": 1, "label": {"eng": "Audit"}}], "categories": [{"uri": "dmoz/Health/Reproductive_Health/Birth_Control", "label": "dmoz/Health/Reproductive Health/Birth Control", "wgt": 100}, {"uri": "dmoz/Computers/Internet/Abuse", "label": "dmoz/Computers/Internet/Abuse", "wgt": 100}, {"uri": "dmoz/Computers/Security/Honeypots_and_Honeynets", "label": "dmoz/Computers/Security/Honeypots and Honeynets", "wgt": 100}, {"uri": "dmoz/Computers/Hacking/Cryptography", "label": "dmoz/Computers/Hacking/Cryptography", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 81}], "image": "https://business-review.eu/wp-content/uploads/2024/08/Why-AI-Shouldnt-Make-You-Complacent-About-Data-Security.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.1686274509803922, "wgt": 179, "relevance": 1}
{"uri": "8259972596", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "11:17:54", "dateTime": "2024-08-05T11:17:54Z", "dateTimePub": "2024-08-05T11:17:21Z", "dataType": "news", "sim": 0.6941176652908325, "url": "https://repository.uwl.ac.uk/id/eprint/12241/", "title": "Artificial Intelligence: A Twenty First Century International Regulatory Challenge", "body": "Artificial Intelligence (AI) is a twenty first century evolution. Certain aspects of AI have been integrated into daily living. AI applications have also been incorporated into the aviation, banking, cyber security, educational, employment, health, and military sectors respectively. However, the unpredictable nature of AI is a cause for concern because \"In many instances, AI remains under the control of users and designers, but in increasing numbers of applications, the behaviour of a system cannot be predicted by those involved in design and application [...]. Newly developed machines are able to teach themselves and even collect data\u201f1. Consequently, \"The potential benefits and harms of AI have led to calls for governments to adapt quickly to the changes AI is already delivering and the potentially transformative changes to come. These include calls to pause AI development and for countries [...] to deliver a stepchange in regulation\u201f2. \"In March 2023, more than 1,000 artificial intelligence experts, researchers and backers signed an open letter calling for an immediate pause on the creation of \"giant\" AIs for at least six months, so the capabilities and dangers of such systems can be properly studied and mitigated\u201f3. What are the benefits of AI? What are the risks of AI? Which crimes can be committed via AI? What are the regulatory challenges? What has been the international response? In this article, we will explore whether there is a justification for regulating AI from ethical, legal and law enforcement perspectives.", "source": {"uri": "repository.uwl.ac.uk", "dataType": "news", "title": "repository.uwl.ac.uk"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Applications_of_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Applications of artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Evolution", "type": "wiki", "score": 3, "label": {"eng": "Evolution"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 3, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Aviation", "type": "wiki", "score": 3, "label": {"eng": "Aviation"}}, {"uri": "http://en.wikipedia.org/wiki/Law_enforcement", "type": "wiki", "score": 1, "label": {"eng": "Law enforcement"}}, {"uri": "http://en.wikipedia.org/wiki/Open_letter", "type": "wiki", "score": 1, "label": {"eng": "Open letter"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 1, "label": {"eng": "Ethics"}}], "categories": [{"uri": "dmoz/Society", "label": "dmoz/Society", "wgt": 100}, {"uri": "dmoz/Society/Issues", "label": "dmoz/Society/Issues", "wgt": 100}, {"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Health/Reproductive_Health/Birth_Control", "label": "dmoz/Health/Reproductive Health/Birth Control", "wgt": 100}, {"uri": "dmoz/Society/Issues/Science_and_Technology", "label": "dmoz/Society/Issues/Science and Technology", "wgt": 100}], "image": null, "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.1529411764705881, "wgt": 177, "relevance": 1}
{"uri": "8259253777", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "01:03:22", "dateTime": "2024-08-05T01:03:22Z", "dateTimePub": "2024-08-05T01:02:04Z", "dataType": "news", "sim": 0.6901960968971252, "url": "https://www.manilatimes.net/2024/08/04/business/sunday-business-it/tech-summit-highlights-responsible-ai-integration-digital-trust/1961897", "title": "Tech summit highlights responsible AI integration, digital trust", "body": "UN ramps up assistance to survivors of Papua New Guinea massacre\n\nBUSINESSES need to adapt to the rapid growth of technology, particularly with the use of artificial intelligence (AI) and the shift toward digitalization. This is the focal point of KPMG's 2024 tech innovation summit with the theme \"Tech horizons: Unleashing the future of innovation.\"\n\nA future with AI\n\nMicrosoft Philippines Chief Executive Officer (CEO) Peter Maquera describes AI as a genie out of the bottle. AI continues to flock innovation discourse around the world, and there is nothing stopping it now. The only thing businesses can do is to adapt.\n\nPresenting a study, Maquera states that 85 percent of executives across the world are planning to invest more in generative AI (gen AI).\n\nGet the latest news\n\ndelivered to your inbox Sign up for The Manila Times newsletters By signing up with an email address, I acknowledge that I have read and agree to the Terms of Service and Privacy Policy.\n\nThe major factors for the 10 percent of these businesses are having a strong and quantified link between gen AI initiatives and business value, modern technology infrastructure, advanced data strategy, strong leadership support, and responsible AI guidelines and practices in place.\n\nSome of the biggest opportunities for gen AI applications are customer service, risk and compliance, information technology, software coding, and security review and personalization. If used correctly, AI can increase productivity, improve accuracy, make work more efficient and connect with businesses better.\n\nAdvertisement\n\nWorldwide, AI adoption is happening at a rapid scale. According to Maquera, 85 percent of Fortune 500 companies are using Microsoft AI, 60 percent of them use Microsoft 365 Copilot, 90 percent of them use Github and 50 percent of them use Power Platform with AI.\n\nThis trend is also seen locally with 86 percent of Filipino knowledge workers using gen AI at work, 83 percent of Filipino AI users bring their own AI to work, 70 percent of Filipino leaders say they will only hire someone with AI skills and 68 percent of Filipino leaders say they'd rather hire a less experienced candidate with AI skills than a more experienced one without. Meanwhile, 55 percent of Filipino leaders worry that their organizations lack a plan and vision to implement AI.\n\nFor Maquera, AI will be everywhere in the future as observed with the influx of Generative Pretrained Transformer and Copilot technology.\n\nMaquera has also discussed the partnership between Open AI and Microsoft to create Azure Open AI Service. This will enable organizations and businesses to create their own gen AI models such as language, multimodal, fine tuning, image generation, and transcription and translation models.\n\nAdvertisement\n\nTo maintain responsible AI use, Microsoft aligns its efforts with the White House Voluntasry AI Commitments of safety, security and trustworthiness.\n\nPartnering with Microsoft is KPMG, which has also unveiled its new gen AI technology KPMG Ask People, Performance and Culture; KPMG Quality and Risk Assist; and KPMG Tax Chatbot after years of ambitious digital transformation. These tools allow employees to focus their energy on more important tasks, allowing them to balance work and life.\n\nKPMG Philippines Vice Chairman and Chief Operating Officer Noel Bonoan says: \"This expanded alliance aims to enhance engagement and supercharge employee experience in a way that is possible, trustworthy and safe -- a testament to KPMG embracing the future and our belief that AI is [essential] to unlock sustainability. In this way, we hope to be able to bear fruit [through] our people, clients and society. We believe that technology and innovation can catalyze business growth and help developing nations.\"\n\n\"AI offers unprecedented opportunities, efficiency, innovation and growth. The direction of AI is not only for intelligent assistance that does not only perform tasks but also [to] learn and adapt,\" He adds.\n\nAdvertisement\n\n\"At KPMG, since 2020 we have been heavily investing on new technologies, and just last year, we have developed generative AI and natural language processor tools to really help our professionals, especially in the core of our business, it's really more on generating knowledge, providing helpful insights and foresights for our client,\" KPMG partner Gilbert Tirchera says in an interview.\n\nBonoan concludes his talk with some advice for organizations that want to adapt AI: dream big and start small, exploit while exploring, stay curious, make mistakes and move on, and secure top management buy-in.\n\nAccording to David Hardoon, Aboitiz Data Innovation CEO and Unionbank senior advisor for data and AI, AI is not a form of technology but a field of knowledge that should be wielded responsibly. A similar study from the Boston Consulting Group says 10 percent of businesses that are scaling AI are getting better business impact; 50 percent are experimenting while 40 percent have not yet started.\n\nOne of the ways to apply this is through sustainability -- something of which every business should be mindful. In terms of production and demand, AI can be used in emission, energy, material and product service efficiency, and demand reduction.\n\nAdvertisement\n\nAI can also aid in energy transition with three steps: monitoring through satellite-based risk scoring, impact calculations and signal identification; intervention through innovation, reliability, efficiency and optimization; and scaling through practice and updating people, processes and technology.\n\nIn the financial service sector, it can fuel financial growth with data-driven AI solutions and enhance risk, efficiency and revenue management. In the power and industrial sector, it can unlock sustainable, efficient and future-ready solutions. AI can also enhance the community's efficiency and drive engagement with tailor-made AI and data-driven insights in the public sector.\n\nOverall, AI can help amplify the skills of employees and make a positive impact if used responsibly. It can generate solutions that are based on real data if organizations are aware of the risk and responsibility it has. To make AI work responsibly, it is imperative to follow ethical innovation.\n\nAdditionally, MAD Travel, Circle Hostel co-founder and Lighthouse Legacy Foundation Director Rafael Dionisio stresses the role of AI in the intersection of sustainability, particularly in the integration of environmental, social and governance or ESG.\n\nAdvertisement\n\nFostering digital trust\n\nUnionbank Chief Information Officer (CIO) Dennis Omila, Bangko Sentral ng Pilipinas (BSP) Managing Director and CIO Eugene Teves, University of the Philippines - Diliman Professor Erik Capistrano and Rizal Commercial Banking Corp. Chief Information Security Officer Carlos Tengkiat discuss the prospects of building confidence in the digital age.\n\nThe panelists emphasize the importance of forming digital trust, especially in the mobile banking sector. There is still a gap when it comes to honing responsibility between the consumer and the provider. Both must work together to ensure that digital banking remain secure.\n\nThe panelists also address how younger generations tend to create disposable online personas. Once hacked, it is easy for them to create new accounts; however, as they get older, these digital footprints pile up and may result in greater consequences due to lack of digital security.\n\nAdvertisement\n\nAn example is using the same email for most accounts. If a linked social media account were hacked, then it will be easy for the hacker to gain control of the accounts if it is in a shared network.\n\nTo solve this, the panelists emphasize collaboration between the academe and the government to educate people on digital awareness and etiquette. For example, education on the importance of digital hygiene or the right way to use digital services is a start.\n\nCurrently, some universities are offering electives on digital literacy; however, there is also pressure on private and public universities to offer short electives and summer programs for digital literacy, apart from integrating it in the curricula. A proactive curriculum will leave to more active partnerships with private sectors in terms of honing these soft skills, the panelists say.\n\nThe panelists stress the need for funding toward smart laboratories as well to give practical experience to the learners. Industry experts may also be invited to share their knowledge.\n\nPeople also tend to take technology for granted.\n\n\"It's also high time that we realize that [we] -- who are supposed to be teaching the younger generation about technology -- should appreciate that when we talk about digital trust, we need to also consider what stakeholders and the legal aspect of trust has to do with any academic instruction, classroom discussion or research.\" the panelists say.\n\nThe government also has a crucial role in these challenges. According to Teves, BSP highly considers the role of technology. The government agency places a supervisory authority over these technologies. BSP also takes complaints and concerns seriously, regarding digital banking.\n\n\"Right now, we are working with other departments in the government to lessen the impact of cybercrime,\" Teves says.\n\nFor an instance, BSP has consumer protection standards that keep safe client information and ensures their fair treatment. BSP is also actively in charge of investigating cybercrime involving digital banking in accordance with Republic Act 10175 or the Cybercrime Prevention Act of 2012.\n\nStill, the panelists highlight the difference between preventing cybercrime and chasing after it. The best way of eliminating cybercrime is through a robust cyber defense both for the provider and the consumer. The faster one can secure their accounts, the lesser the impact it will have.\n\nOn the provider's side, there must be seamless technology and secure third parties. The provider may also opt for alternatives that are easy to adopt.\n\n\"There are steps and programs that try to adopt how to strengthen our cyberdefense. This is not just limited in the banking center. We're actually looking at extending it in the payment system. The payment operators are also part of the bigger financial ecosystem,\" the panelists say.\n\nLastly, collaboration between the government and private sector is crucial in building digital trust. Being proactive would trigger collaborations and create meaningful outputs, which will generate a good initiative in advancing the cause.\n\nThe Filipino people should also be actively involved as digitalization will be their future.\n\nIn a separate panel discussion, Prosperna CEO Dennis Velasco, Data Science and AI Center of Excellence of Security Bank Corp. head and Senior Vice President Esel Madrid, National Innovation Council Executive Cabinet Member Mark Gersava, Dragonpay CEO Dick Chiang and GCash Chief Financial Officer Tek Olano discuss the effect of digital evolution in businesses.\n\nAccording to the panel members, digital transformation is more than just automation; it is a holistic rethinking of business models. In order to fully unlock this potential and embrace this change, there needs to be a firm leadership system within the company.\n\nBy setting clear and measurable goals, organizations can track the impact of digital initiatives. Studying the market is also crucial. Demonstrating GCash's success, Olano cites the company's problem-solving initiatives in the market, which allowed Filipino users greater access to financial services.\n\nKPMG also showcased startups in the Philippines with Rezbin clinching the grand prize at the Global Tech Innovator (GTI) Philippines 2024 segment of the summit. Rezbin addresses the problem of waste management in the Philippines with a dynamic profit-generating solution.\n\nRezbin CEO Mari Martirez will travel to Lisbon in November to represent the Philippines at the KPMG GTI finals.", "source": {"uri": "manilatimes.net", "dataType": "news", "title": "The Manila times"}, "authors": [{"uri": "khrystyn_andaya@manilatimes.net", "name": "Khrystyn Andaya", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/KPMG", "type": "org", "score": 5, "label": {"eng": "KPMG"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 5, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Philippines", "type": "loc", "score": 5, "label": {"eng": "Philippines"}, "location": {"type": "country", "label": {"eng": "Philippines"}}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 4, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Digital_transformation", "type": "wiki", "score": 4, "label": {"eng": "Digital transformation"}}, {"uri": "http://en.wikipedia.org/wiki/Sustainability", "type": "wiki", "score": 4, "label": {"eng": "Sustainability"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 4, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft_365_Copilot", "type": "wiki", "score": 3, "label": {"eng": "Microsoft 365 Copilot"}}, {"uri": "http://en.wikipedia.org/wiki/Applications_of_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Applications of artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft_Azure", "type": "wiki", "score": 3, "label": {"eng": "Microsoft Azure"}}, {"uri": "http://en.wikipedia.org/wiki/Transcription_(linguistics)", "type": "wiki", "score": 3, "label": {"eng": "Transcription (linguistics)"}}, {"uri": "http://en.wikipedia.org/wiki/Bangko_Sentral_ng_Pilipinas", "type": "org", "score": 3, "label": {"eng": "Bangko Sentral ng Pilipinas"}}, {"uri": "http://en.wikipedia.org/wiki/Knowledge_worker", "type": "wiki", "score": 3, "label": {"eng": "Knowledge worker"}}, {"uri": "http://en.wikipedia.org/wiki/Transformer", "type": "wiki", "score": 3, "label": {"eng": "Transformer"}}, {"uri": "http://en.wikipedia.org/wiki/The_Manila_Times", "type": "wiki", "score": 3, "label": {"eng": "The Manila Times"}}, {"uri": "http://en.wikipedia.org/wiki/Terms_of_service", "type": "wiki", "score": 3, "label": {"eng": "Terms of service"}}, {"uri": "http://en.wikipedia.org/wiki/Risk_management", "type": "wiki", "score": 3, "label": {"eng": "Risk management"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 3, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Fortune_500", "type": "wiki", "score": 3, "label": {"eng": "Fortune 500"}}, {"uri": "http://en.wikipedia.org/wiki/Customer_service", "type": "wiki", "score": 3, "label": {"eng": "Customer service"}}, {"uri": "http://en.wikipedia.org/wiki/Information_technology", "type": "wiki", "score": 3, "label": {"eng": "Information technology"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 3, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/United_Nations", "type": "org", "score": 3, "label": {"eng": "United Nations"}}, {"uri": "http://en.wikipedia.org/wiki/Papua_New_Guinea", "type": "loc", "score": 3, "label": {"eng": "Papua New Guinea"}, "location": {"type": "country", "label": {"eng": "Papua New Guinea"}}}, {"uri": "http://en.wikipedia.org/wiki/Boston_Consulting_Group", "type": "org", "score": 2, "label": {"eng": "Boston Consulting Group"}}, {"uri": "http://en.wikipedia.org/wiki/Developing_country", "type": "loc", "score": 2, "label": {"eng": "Developing country"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Rizal_(province)", "type": "loc", "score": 1, "label": {"eng": "Rizal (province)"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Filipinos", "type": "loc", "score": 1, "label": {"eng": "Filipinos"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/University_of_the_Philippines_Diliman", "type": "org", "score": 1, "label": {"eng": "University of the Philippines Diliman"}}, {"uri": "http://en.wikipedia.org/wiki/Madrid", "type": "loc", "score": 1, "label": {"eng": "Madrid"}, "location": {"type": "place", "label": {"eng": "Madrid"}, "country": {"type": "country", "label": {"eng": "Spain"}}}}, {"uri": "http://en.wikipedia.org/wiki/Lisbon", "type": "loc", "score": 1, "label": {"eng": "Lisbon"}, "location": {"type": "place", "label": {"eng": "Lisbon"}, "country": {"type": "country", "label": {"eng": "Portugal"}}}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Society/Issues/Business", "label": "dmoz/Society/Issues/Business", "wgt": 100}, {"uri": "dmoz/Home/Personal_Finance", "label": "dmoz/Home/Personal Finance", "wgt": 100}, {"uri": "dmoz/Society/Activism/In_Daily_Life", "label": "dmoz/Society/Activism/In Daily Life", "wgt": 100}, {"uri": "dmoz/Society/Work/Telecommuting", "label": "dmoz/Society/Work/Telecommuting", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 49}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 51}], "image": "https://www.manilatimes.net/manilatimes/uploads/images/2024/08/05/384236.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.388235294117647, "wgt": 176, "relevance": 1}
{"uri": "8259640044", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "07:42:09", "dateTime": "2024-08-05T07:42:09Z", "dateTimePub": "2024-08-05T07:41:10Z", "dataType": "news", "sim": 0.686274528503418, "url": "https://www.lexology.com/library/detail.aspx?g=1a55d627-698c-4707-93a7-fde51fe29244", "title": "Zooming in on AI: When will the AI Act apply?", "body": "EU Regulation 2024/1689, also known as the Artificial Intelligence Act (AI Act), enters into force as of 1 August 2024. But when will it become applicable?\n\nSome background\n\nThe AI Act sets out a harmonized legal framework for the development, supply, and use of AI systems in the EU. As a regulation, the AI Act directly enters into force in all EU Member States alike, without the need for transposition into national law. The nature of a regulation also prevents Member States from adopting additional restrictions on the same subject matter, unless explicitly authorized within the AI Act.\n\nThe AI Act introduces a risk-based approach to the regulation of AI, distinguishing between four categories of AI systems: prohibited AI practices, high-risk AI systems, general-purpose AI models, and other AI systems. Each category is subject to different levels of compliance.\n\nNot all the AI Act's provisions will apply immediately. The AI Act sets out different transitional periods and dates of application depending on the type and impact of the AI systems concerned.\n\nWhen will the AI Act apply?\n\nIn this first publication of our \"Zooming in on AI\" series, we will provide an overview of the timeline for the application of the main provisions of the AI Act and highlight some of the key implications for AI providers and deployers.\n\n2 February 2025: prohibited AI Practices\n\nCertain AI practices will be prohibited from 2 February 2025. This concerns AI systems that have been designed or that are used in a manner that is considered to pose an unacceptable risk to humans, such as AI systems that create or expand facial recognition databases through the untargeted scraping of facial images from the internet or CCTV footage. This prohibition applies to a large extent to both the use and supply of such AI systems.\n\n2 May 2025: codes of Practice for General-Purpose AI Models\n\nThe AI Office, which is part of the European Commission, and has been created at the beginning of this year, will issue codes of practice for providers of general-purpose AI models by 2 May 2025. These voluntary codes will enable providers of general-purpose AI models to demonstrate their compliance with the relevant obligations from the AI Act, similarly to the codes of conduct under the GDPR. The AI Office has opened a call for expression of interest to participate in the drawing-up of the first code of practice and has also launched a multi-stakeholder consultation, allowing stakeholders to express their views until 10 September 2024.\n\n2 August 2025: governance and Enforcement Framework and Fines\n\nThe governance and enforcement framework of the AI Act will become effective on 2 August 2025. This means that by then, the EU Member States must designate their national competent authorities, comprising at least one notifying authority and at least one market surveillance authority:\n\nThe EU Member States may designate multiple competent authorities. For example, the data protection authority as well as sector-specific supervisory authorities such as those of the financial, insurance, or telecom sector may be appointed as market surveillance authorities. At a national level, it will be very important to coordinate the approaches of the authorities to achieve effective and consistent enforcement. An undesired outcome would be that authorities adopt diverging or even conflicting interpretations or guidance. It will be up to each Member State to adopt legislation to address this specific issue. If EU Member States do not get this right, it can create inconsistencies and uncertainty for supervised entities.\n\nOn top of the national authorities, the governance and enforcement framework will also include the establishment of a European Artificial Intelligence Board, composed of one representative per Member State, whose role will consist in advising and assisting the Commission and EU Member States on AI matters.\n\nThe AI Office will have the exclusive powers to supervise and enforce the obligations of providers of general-purpose AI models.\n\nGeneral-Purpose AI Models\n\nThe rules regarding general-purpose AI models will begin to apply as of 2 August 2025 (by exception, providers of general-purpose AI models that have been placed on the market before 2 August 2025 must comply with the AI Act by 2 August 2027).\n\nThe rules for providers of general-purpose AI models include, among other things, that they have adequate technical documentation, information, and policies for their models, and that they appoint an authorized representative in the Union if they are established in third countries. Providers of general-purpose AI models with systemic risk, which are models that have high impact capabilities or that have been trained using a certain amount of computation power, have additional obligations, including the obligation for the relevant provider to notify the Commission within two weeks of meeting the criteria.\n\n2 August 2026: general Application Date\n\nThe AI Act applies in its entirety from 2 August 2026, unless otherwise specified.\n\nHigh-Risk AI Systems\n\nThe provisions that apply from 2 August 2026 include those relating to the obligations of high-risk AI system providers, which include creating a risk management system, adhering to data quality and governance standards for training, validating, and testing the system, maintaining technical documentation to facilitate the competent authorities' assessment of the system's compliance, and fulfilling the obligation to log events. Providers must also meet transparency requirements towards deployers, as well as ensure human oversight, robustness, security, and accuracy. Furthermore, providers will need to undergo conformity assessment procedures and adhere to registration requirements.\n\nDeployers must also fulfill various obligations, such as conducting a fundamental rights impact assessment prior to the deployment of certain high-risk systems - for instance, using an AI system to determine a natural person's credit score - and informing the market surveillance authority of the assessment's findings.\n\nLimited Risk AI Systems\n\nThe provisions for AI systems with limited risk will take effect from 2 August 2026 as well. For instance, providers of AI systems designed for direct interaction with individuals must ensure that those individuals are aware that they are interacting with an AI system.\n\nFines for General-Purpose AI Models\n\nThe Commission will be able to impose on providers of general-purpose AI models fines not exceeding 3% of their annual total worldwide turnover in the preceding financial year or EUR15 million whichever is higher.\n\n2 August 2027: AI Systems as Safety Components\n\nAI systems that are safety components of products, or which are themselves products, falling within the scope of certain Union harmonization legislation, will be classified as high-risk as of 2 August 2027 if the product concerned undergoes the conformity assessment procedure with a third-party conformity assessment body pursuant to that relevant Union harmonization legislation. This concerns, for example, products such as machinery, toys, lifts, or medical devices.\n\nGeneral-Purpose AI Models Placed on the Market before 2 August 2025\n\nProviders of general-purpose AI models that have been placed on the market before 2 August 2025 must comply with the AI Act by 2 August 2027.\n\n2 August 2030: AI Systems as Components of Certain Large-Scale IT Systems\n\nAI systems which are components of certain large-scale IT systems, such as the Schengen Information System or the Visa Information System, that have been placed on the market or put into service before 2 August 2027, must be brought into compliance.\n\nExemption for high-risk AI systems that have been placed on the market or put into service before 2 August 2026\n\nOperators of high-risk AI systems that have been placed on the market or put into service before 2 August 2026 are exempt from the AI Act, on the condition that the systems concerned are not subject to significant changes in their decisions. By exception, if such systems are intended to be used by public authorities, their providers and deployers must comply by 2 August 2030 at the latest.\n\nThe AI Act represents a major milestone in the EU's digital agenda, and a significant challenge for providers and deployers of AI systems in the EU. It is therefore crucial for companies to understand the scope and implications of the AI regulation, and to prepare for the upcoming deadlines and obligations. It is not yet clear whether authorities will immediately enforce the AI Act as of the entry into force of an obligation.", "source": {"uri": "lexology.com", "dataType": "news", "title": "Lexology"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Member_state_of_the_European_Union", "type": "wiki", "score": 5, "label": {"eng": "Member state of the European Union"}}, {"uri": "http://en.wikipedia.org/wiki/Surveillance", "type": "wiki", "score": 4, "label": {"eng": "Surveillance"}}, {"uri": "http://en.wikipedia.org/wiki/Transposition_(law)", "type": "wiki", "score": 3, "label": {"eng": "Transposition (law)"}}, {"uri": "http://en.wikipedia.org/wiki/Facial_recognition_system", "type": "wiki", "score": 3, "label": {"eng": "Facial recognition system"}}, {"uri": "http://en.wikipedia.org/wiki/Closed-circuit_television", "type": "wiki", "score": 3, "label": {"eng": "Closed-circuit television"}}, {"uri": "http://en.wikipedia.org/wiki/Regulation_(European_Union)", "type": "wiki", "score": 3, "label": {"eng": "Regulation (European Union)"}}, {"uri": "http://en.wikipedia.org/wiki/States_of_Germany", "type": "loc", "score": 3, "label": {"eng": "States of Germany"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/European_Commission", "type": "org", "score": 3, "label": {"eng": "European Commission"}}, {"uri": "http://en.wikipedia.org/wiki/European_Union", "type": "loc", "score": 3, "label": {"eng": "European Union"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Internet", "type": "wiki", "score": 3, "label": {"eng": "Internet"}}, {"uri": "http://en.wikipedia.org/wiki/Database", "type": "wiki", "score": 3, "label": {"eng": "Database"}}, {"uri": "http://en.wikipedia.org/wiki/Telecommunications", "type": "wiki", "score": 2, "label": {"eng": "Telecommunications"}}, {"uri": "http://en.wikipedia.org/wiki/General_Data_Protection_Regulation", "type": "wiki", "score": 2, "label": {"eng": "General Data Protection Regulation"}}, {"uri": "http://en.wikipedia.org/wiki/Systemic_risk", "type": "wiki", "score": 2, "label": {"eng": "Systemic risk"}}, {"uri": "http://en.wikipedia.org/wiki/Code_of_conduct", "type": "wiki", "score": 2, "label": {"eng": "Code of conduct"}}, {"uri": "http://en.wikipedia.org/wiki/Stakeholder_(corporate)", "type": "wiki", "score": 2, "label": {"eng": "Stakeholder (corporate)"}}, {"uri": "http://en.wikipedia.org/wiki/Information_privacy", "type": "wiki", "score": 2, "label": {"eng": "Information privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Insurance", "type": "wiki", "score": 2, "label": {"eng": "Insurance"}}, {"uri": "http://en.wikipedia.org/wiki/United_States", "type": "loc", "score": 2, "label": {"eng": "United States"}, "location": {"type": "country", "label": {"eng": "United States"}}}, {"uri": "http://en.wikipedia.org/wiki/Visa_Information_System", "type": "wiki", "score": 1, "label": {"eng": "Visa Information System"}}, {"uri": "http://en.wikipedia.org/wiki/Schengen_Information_System", "type": "wiki", "score": 1, "label": {"eng": "Schengen Information System"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 1, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Fundamental_rights", "type": "wiki", "score": 1, "label": {"eng": "Fundamental rights"}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Computers/Security/Policy", "label": "dmoz/Computers/Security/Policy", "wgt": 100}, {"uri": "dmoz/Health/Reproductive_Health/Birth_Control", "label": "dmoz/Health/Reproductive Health/Birth Control", "wgt": 100}, {"uri": "dmoz/Shopping/Health/Emergency_and_Safety", "label": "dmoz/Shopping/Health/Emergency and Safety", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 48}], "image": "https://www.lexology.com/images/share/lexology-social-media.png", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.1058823529411765, "wgt": 175, "relevance": 1}
{"uri": "8259093601", "lang": "eng", "isDuplicate": false, "date": "2024-08-04", "time": "21:02:36", "dateTime": "2024-08-04T21:02:36Z", "dateTimePub": "2024-08-04T21:02:05Z", "dataType": "news", "sim": 0.6823529601097107, "url": "https://techbullion.com/how-ai-is-used-in-cybersecurity-to-detect-and-prevent-threats/", "title": "How AI is Used in Cybersecurity to Detect and Prevent Threats", "body": "Artificial Intelligence (AI) is changing cybersecurity, giving enhanced threat detection, real-time response, and predictive capabilities. By automating routine tasks and providing valuable insights, AI enables organizations to stay ahead of cyber threats. However, it's essential to address the challenges and ethical considerations associated with AI to ensure its responsible and effective use. As AI technology continues to evolve, its role in cybersecurity will only become more critical, helping to create a safer digital landscape for all.\n\nThe Growing Need for AI in Cybersecurity:\n\nCyber threats have become more complex and harder to detect. Hackers use advanced techniques, making it difficult for traditional security systems to identify and mitigate risks. AI addresses these challenges by providing enhanced capabilities for threat detection and prevention. With AI, cybersecurity teams can analyze vast amounts of data quickly and accurately, identifying patterns and anomalies that may indicate a potential threat.\n\nUnderstanding AI in Cybersecurity:\n\nAI involves the simulation of human intelligence by machines. In cybersecurity, AI systems analyze data, identify patterns, and make decisions based on these patterns. Unlike traditional systems, AI can learn and adapt over time. This means that AI systems become more effective as they process more data, improving their ability to detect and prevent threats.\n\nBenefits of AI in Cybersecurity:\n\nThe integration of AI in cybersecurity offers several key benefits:\n\nEnhanced Threat Detection:\n\nAI can process and analyze large volumes of data at high speeds, identifying threats that might go unnoticed by human analysts. This leads to quicker and more accurate threat detection.\n\nReal-Time Response:\n\nAI systems can respond to threats in real-time, reducing the time between threat detection and response. This minimizes potential damage and ensures faster recovery.\n\nReduced False Positives:\n\nTraditional security systems often generate numerous false positives, overwhelming security teams. AI systems are more accurate, reducing the number of false positives and allowing teams to focus on genuine threats.\n\nPredictive Capabilities:\n\nAI can predict future threats by analyzing patterns and trends in historical data. This proactive approach helps organizations prepare for potential attacks and strengthen their defenses.\n\nAutomation:\n\nAI automates routine security tasks, freeing up human analysts to focus on more complex issues. This improves overall efficiency and effectiveness.\n\nKey Applications of AI in Cybersecurity:\n\nAI is used in various ways to enhance cybersecurity. Some of the key applications include:\n\nThreat Intelligence:\n\nAI systems gather and analyze threat data from multiple sources, providing valuable insights into emerging threats and attack vectors. This helps organizations stay ahead of cybercriminals.\n\nBehavioral Analysis:\n\nAI monitors user behavior and identifies deviations from normal patterns. This helps in detecting insider threats and compromised accounts.\n\nMalware Detection:\n\nAI-powered systems can analyze files and code to identify malware, even if it has never been seen before. This is particularly useful in detecting zero-day attacks.\n\nPhishing Detection:\n\nAI can analyze emails and websites to identify phishing attempts. It can also educate users about potential phishing risks, reducing the likelihood of successful attacks.\n\nNetwork Security:\n\nAI monitors network traffic for suspicious activity, identifying potential threats and anomalies in real-time. This helps in preventing data breaches and unauthorized access.\n\nReal-World Examples of AI in Cybersecurity:\n\nSeveral organizations are leveraging AI to enhance their cybersecurity measures. Here are a few examples:\n\nIBM's Watson for Cybersecurity:\n\nWatson uses AI to analyze vast amounts of security data and identify threats. It provides actionable insights to security analysts, helping them respond to threats more effectively.\n\nDarktrace:\n\nThis AI-powered cybersecurity company uses machine learning to detect and respond to threats in real-time. It monitors network traffic and identifies anomalies, helping organizations protect their data.\n\nCylance:\n\nCylance uses AI to prevent malware attacks. Its AI algorithms analyze files and code, identifying potential threats before they can cause harm.\n\nThe Future of AI in Cybersecurity:\n\nThe future of AI in cybersecurity looks promising. As AI technology continues to evolve, its capabilities in threat detection and response will only improve. Here are some potential future developments:\n\nAdvanced Machine Learning Algorithms:\n\nAI systems will become more sophisticated, using advanced machine learning algorithms to identify even the most subtle threats.\n\nIntegration with Other Technologies:\n\nAI will be integrated with other emerging technologies, such as blockchain and the Internet of Things (IoT), to provide even more robust security solutions.\n\nIncreased Automation:\n\nAs AI becomes more advanced, it will automate more complex security tasks, further reducing the burden on human analysts.\n\nImproved User Education:\n\nAI will play a key role in educating users about cybersecurity risks and best practices, helping to create a more security-aware workforce.\n\nEnhanced Collaboration:\n\nAI systems will facilitate better collaboration between different security teams and organizations, sharing threat intelligence and improving overall security posture.\n\nChallenges and Ethical Considerations:\n\nWhile AI offers numerous benefits in cybersecurity, it also presents challenges and ethical considerations. These include:\n\nBias in AI Algorithms:\n\nAI systems can be biased, leading to unfair or inaccurate threat detection. It's crucial to ensure that AI algorithms are transparent and unbiased.\n\nPrivacy Concerns:\n\nAI systems often require access to vast amounts of data, raising privacy concerns. Organizations must ensure that they handle data responsibly and comply with privacy regulations.\n\nAdversarial AI:\n\nCybercriminals can use AI to develop more sophisticated attacks. It's essential to stay ahead of these threats and continuously improve AI security measures.\n\nConclusion:\n\nSince the era of the digital world, cyber threats are evolving rapidly. Traditional cybersecurity measures often struggle to keep up with sophisticated attacks. Artificial intelligence (AI) has emerged as a powerful tool in the fight against cybercrime. By leveraging AI, organizations can detect and prevent threats more effectively. This article explores how AI is used in cybersecurity to detect and prevent threats, highlighting its benefits, applications, and future potential.\n\nRelated Items:2024 Technology, about cybersecurity, AI in Cybersecurity Recommended for you The Role of AI in Modern Cybersecurity: An Overview AI Art and Traditional Art: Blending Techniques for Unique Creations Creating AI Art on a Budget: Affordable Tools and Techniques", "source": {"uri": "techbullion.com", "dataType": "news", "title": "TechBullion"}, "authors": [{"uri": "angela_scott_briggs@techbullion.com", "name": "Angela Scott-Briggs", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Threat_(computer)", "type": "wiki", "score": 5, "label": {"eng": "Threat (computer)"}}, {"uri": "http://en.wikipedia.org/wiki/Real-time_computing", "type": "wiki", "score": 5, "label": {"eng": "Real-time computing"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 5, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Phishing", "type": "wiki", "score": 4, "label": {"eng": "Phishing"}}, {"uri": "http://en.wikipedia.org/wiki/Security", "type": "wiki", "score": 4, "label": {"eng": "Security"}}, {"uri": "http://en.wikipedia.org/wiki/Hacker", "type": "wiki", "score": 3, "label": {"eng": "Hacker"}}, {"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 3, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/Simulation", "type": "wiki", "score": 3, "label": {"eng": "Simulation"}}, {"uri": "http://en.wikipedia.org/wiki/Intelligence", "type": "wiki", "score": 3, "label": {"eng": "Intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Malware", "type": "wiki", "score": 3, "label": {"eng": "Malware"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_monitor", "type": "wiki", "score": 3, "label": {"eng": "Computer monitor"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Zero-day_(computing)", "type": "wiki", "score": 2, "label": {"eng": "Zero-day (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/Cybercrime", "type": "wiki", "score": 2, "label": {"eng": "Cybercrime"}}, {"uri": "http://en.wikipedia.org/wiki/Network_security", "type": "wiki", "score": 2, "label": {"eng": "Network security"}}, {"uri": "http://en.wikipedia.org/wiki/Data_breach", "type": "wiki", "score": 2, "label": {"eng": "Data breach"}}, {"uri": "http://en.wikipedia.org/wiki/IBM", "type": "org", "score": 2, "label": {"eng": "IBM"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 2, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Automation", "type": "wiki", "score": 2, "label": {"eng": "Automation"}}, {"uri": "http://en.wikipedia.org/wiki/Blockchain", "type": "wiki", "score": 1, "label": {"eng": "Blockchain"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 100}, {"uri": "dmoz/Computers/Security/Intrusion_Detection_Systems", "label": "dmoz/Computers/Security/Intrusion Detection Systems", "wgt": 100}, {"uri": "dmoz/Computers/Security/Honeypots_and_Honeynets", "label": "dmoz/Computers/Security/Honeypots and Honeynets", "wgt": 100}, {"uri": "dmoz/Computers/Hacking/Cryptography", "label": "dmoz/Computers/Hacking/Cryptography", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 92}], "image": "https://techbullion.com/wp-content/uploads/2024/08/How-AI-is-Used-in-Cybersecurity-to-Detect-and-Prevent-Threats.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.0980392156862746, "wgt": 174, "relevance": 1}
{"uri": "8259106473", "lang": "eng", "isDuplicate": false, "date": "2024-08-04", "time": "21:17:55", "dateTime": "2024-08-04T21:17:55Z", "dateTimePub": "2024-08-04T21:16:52Z", "dataType": "news", "sim": 0.6745098233222961, "url": "https://www.dreuz.info/2024/08/the-rise-of-artificial-intelligence-and-the-role-of-ai-detectors-301396.html", "title": "The Rise of Artificial Intelligence and the Role of AI Detectors", "body": "Artificial Intelligence (AI) has permeated nearly every aspect of modern life, transforming industries, enhancing everyday tasks, and presenting new ethical dilemmas. From healthcare and finance to entertainment and education, AI's capabilities continue to expand, driving innovation and efficiency. However, as AI systems become more sophisticated, the need for tools to monitor and ensure their ethical use has become paramount. This is where AI detectors come into play.\n\nAI's journey began in the mid-20th century with the development of algorithms capable of basic reasoning and problem-solving. Over the decades, AI has evolved from simple rule-based systems to advanced machine learning and deep learning models. These models can analyze vast amounts of data, recognize patterns, and make predictions with remarkable accuracy.\n\nIn healthcare, AI algorithms assist in diagnosing diseases, personalizing treatment plans, and predicting patient outcomes. In finance, AI-driven systems manage investments, detect fraud, and optimize trading strategies. The entertainment industry leverages AI to recommend content, create realistic animations, and even compose music. Education benefits from AI through personalized learning experiences and automated grading systems.\n\nWhile AI brings numerous benefits, it also poses significant risks. Issues such as biased decision-making, loss of privacy, and the potential for malicious use of AI are pressing concerns. As AI systems become more autonomous, ensuring their accountability and transparency is crucial.\n\nOne of the primary challenges is the potential for AI to perpetuate and even exacerbate existing biases. If an AI system is trained on biased data, it can produce biased outcomes, leading to unfair treatment in areas like hiring, lending, and law enforcement. Additionally, AI's capacity to analyze personal data raises privacy concerns, as individuals' information could be exploited without their consent.\n\nAI detectors have emerged as vital tools in addressing these challenges. An AI detector is a system designed to identify and analyze AI-generated content or behavior. These detectors serve multiple purposes, including ensuring the ethical use of AI, maintaining transparency, and mitigating risks associated with AI applications.\n\nThe development and implementation of AI detectors are still in their early stages, but their importance cannot be overstated. As AI continues to evolve, so too will the need for robust detection systems. Future advancements in AI detectors may include:\n\nTo summarize, artificial intelligence is transforming the world in profound ways, offering unprecedented opportunities and presenting significant challenges. AI detectors play a crucial role in ensuring the responsible and ethical use of AI, addressing issues of bias, privacy, and security. As AI technology continues to advance, the development of sophisticated AI detectors will be essential in navigating the complex landscape of artificial intelligence, safeguarding its benefits, and mitigating its risks.", "source": {"uri": "dreuz.info", "dataType": "news", "title": "Dreuz.info"}, "authors": [{"uri": "dreuz_info@dreuz.info", "name": "Dreuz Info", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 5, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Finance", "type": "wiki", "score": 4, "label": {"eng": "Finance"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 4, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Health_care", "type": "wiki", "score": 4, "label": {"eng": "Health care"}}, {"uri": "http://en.wikipedia.org/wiki/Rule-based_system", "type": "wiki", "score": 3, "label": {"eng": "Rule-based system"}}, {"uri": "http://en.wikipedia.org/wiki/Deep_learning", "type": "wiki", "score": 3, "label": {"eng": "Deep learning"}}, {"uri": "http://en.wikipedia.org/wiki/Problem_solving", "type": "wiki", "score": 3, "label": {"eng": "Problem solving"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 3, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Decision-making", "type": "wiki", "score": 2, "label": {"eng": "Decision-making"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 2, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 2, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Fraud", "type": "wiki", "score": 2, "label": {"eng": "Fraud"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Personal_data", "type": "wiki", "score": 1, "label": {"eng": "Personal data"}}, {"uri": "http://en.wikipedia.org/wiki/Law_enforcement", "type": "wiki", "score": 1, "label": {"eng": "Law enforcement"}}, {"uri": "http://en.wikipedia.org/wiki/Bias", "type": "wiki", "score": 1, "label": {"eng": "Bias"}}], "categories": [{"uri": "dmoz/Health/Reproductive_Health/Birth_Control", "label": "dmoz/Health/Reproductive Health/Birth Control", "wgt": 100}, {"uri": "dmoz/Computers/Artificial_Intelligence", "label": "dmoz/Computers/Artificial Intelligence", "wgt": 100}, {"uri": "dmoz/Computers/Artificial_Life", "label": "dmoz/Computers/Artificial Life", "wgt": 100}, {"uri": "dmoz/Computers/Artificial_Intelligence/Companies", "label": "dmoz/Computers/Artificial Intelligence/Companies", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 53}], "image": null, "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.4588235294117646, "wgt": 172, "relevance": 1}
{"uri": "8260104196", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "12:40:43", "dateTime": "2024-08-05T12:40:43Z", "dateTimePub": "2024-08-05T12:39:56Z", "dataType": "news", "sim": 0.6705882549285889, "url": "https://www.forbes.com/sites/lindsaykohler/2024/08/05/what-pre-existing-beliefs-about-ai-at-work-are-hardest-to-shift/", "title": "What Pre-Existing Beliefs About AI At Work Are Hardest To Shift?", "body": "Given the promised productivity gains of AI, businesses are keen for employees to adopt AI tools. However, the widespread adoption of these tools means overcoming pre-existing beliefs about AI, and some of these beliefs are harder than others to shift. In particular: skepticism. With 41% of employees showing skepticism about using AI at work, Asana's Work Innovation Lab sought to understand whether those skeptics could be transformed into enthusiastic users of AI. The answer to that question is detailed in the July 2024 report \"AI mindsets: How to unlock the power of AI in your organization.\"\n\nIn short, they find that employee beliefs can be changed -- but only under certain circumstances. Asana hypothesized they could turn even the most skeptical people into AI enthusiasts with the right intervention. To that end, they tested several ideas, ranging from promoting AI and all of its benefits, to exploring skepticism around the technology with a human-centered approach. Their findings suggest that focusing on either positive outcomes or addressing concerns directly can be more effective than pushing for a dramatic mindset shift.\n\n\"Fundamentally, we know that humans resist change,\" says Dr. Rebecca Hinds, head of Asana's Work Innovation Lab. \"I think fear of the unknown is hard to shift, and it can't shift overnight. That's why we have to move away from thinking about the technology in terms of features and functionality to thinking about it as a new way of working. We must think about the psychology behind the skepticism for adoption. And that skepticism is going to be activated every time the technology falls short of expectation.\"\n\nHinds then mentions the well-researched idea that negative events and experiences are stronger than positive ones. \"What's most impactful is how they respond to the AI output. If you have one negative interaction, you have to then have five positive interactions to compensate. AI doesn't work all the time -- especially not on the first prompt. And when you have that negative output, even if you have subsequent positive outputs, you still tend to anchor on the negative.\"\n\nThe report defines AI mindsets as \"encompassing the beliefs and attitudes that shape how individuals approach and engage with AI in their lives and work.\" To that end, Asana developed their AI Mindset Scale for organizations to use. It is comprised of 16 statements relating to AI and evenly split between positive and negative statements. Statements include \"Embracing AI means sacrificing human creation and innovation\" and \"Combining AI with human expertise can result in better outcomes than relying on human judgment or AI alone.\"\n\n\"I think the fundamental question to ask is where do you see the role of AI in relation to humans,\" says Hinds. She then shared how an executive at a large company banned the phrase \"artificial intelligence\" and replaced it with \"augmented intelligence,\" and that this reframing is becoming a trend in internal communication. \"I think a critical question is if employees truly believe that AI is going to complement human capabilities or are they scared that it's going to replace, displace or threaten. Understanding where they are on that spectrum tells you a lot about their mental model in approaching the technology.\"\n\nKnowing who your AI enthusiasts are is also valuable because you can then understand who to tap into to lead this change. The AI enthusiasts can evangelize the technology -- but only if companies create the right conditions for it. \"It's about creating a culture of experimentation and making failure okay. Give people the space to experiment with AI -- even if it's going to slow them down in the short term,\" says Hinds. Examples of providing hands-on opportunities to explore AI include innovation labs, AI hackathons, or mentorship opportunities with AI experts.\n\nCompanies must understand there are two aspects of learning how to use AI. There's the technical part, which is prompt engineering and learning how to use the other features. But employees also must embrace change. It doesn't matter if the technology is great if people are fearful of it. That's why understanding these pre-existing beliefs is so important to making AI a success in your organization. \"The human element is going to be much more important than technical training,\" says Hinds. \"If people believe AI is going to complement their own capabilities, you can start training for the technical competency much sooner than the other camp.\"", "source": {"uri": "forbes.com", "dataType": "news", "title": "Forbes"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Asana", "type": "wiki", "score": 5, "label": {"eng": "Asana"}}, {"uri": "http://en.wikipedia.org/wiki/Skepticism", "type": "wiki", "score": 5, "label": {"eng": "Skepticism"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 3, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Mindset", "type": "wiki", "score": 2, "label": {"eng": "Mindset"}}, {"uri": "http://en.wikipedia.org/wiki/Psychology", "type": "wiki", "score": 2, "label": {"eng": "Psychology"}}, {"uri": "http://en.wikipedia.org/wiki/Fear", "type": "wiki", "score": 2, "label": {"eng": "Fear"}}, {"uri": "http://en.wikipedia.org/wiki/Prompt_engineering", "type": "wiki", "score": 1, "label": {"eng": "Prompt engineering"}}, {"uri": "http://en.wikipedia.org/wiki/Electromagnetic_spectrum", "type": "wiki", "score": 1, "label": {"eng": "Electromagnetic spectrum"}}, {"uri": "http://en.wikipedia.org/wiki/Mental_model", "type": "wiki", "score": 1, "label": {"eng": "Mental model"}}, {"uri": "http://en.wikipedia.org/wiki/Evangelism", "type": "wiki", "score": 1, "label": {"eng": "Evangelism"}}], "categories": [{"uri": "dmoz/Health/Mental_Health/Self-Help", "label": "dmoz/Health/Mental Health/Self-Help", "wgt": 100}, {"uri": "dmoz/Society/Transgendered/Coming_Out", "label": "dmoz/Society/Transgendered/Coming Out", "wgt": 100}, {"uri": "dmoz/Society/Advice", "label": "dmoz/Society/Advice", "wgt": 100}, {"uri": "dmoz/Society/Future/Transhumanism", "label": "dmoz/Society/Future/Transhumanism", "wgt": 100}], "image": "https://imageio.forbes.com/specials-images/imageserve/66b0c640cfda43479712ff0c/0x0.jpg?format=jpg&height=600&width=1200&fit=bounds", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3098039215686275, "wgt": 171, "relevance": 1}
{"uri": "8259370919", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "03:42:54", "dateTime": "2024-08-05T03:42:54Z", "dateTimePub": "2024-08-05T03:41:48Z", "dataType": "news", "sim": 0.6666666865348816, "url": "https://dynamicbusiness.com/topics/news/australian-smes-increase-investment-in-ai-finds-bsi.html", "title": "Australian SMEs increase investment in AI, finds BSI", "body": "Australian businesses are recognising the benefits of AI and plan to significantly boost their AI spending in the coming years to improve operations, drive growth, and remain competitive globally, according to BSI's newly published International AI Maturity Model.\n\nThe model reveals that 67% of Australian businesses are investing more this year than last year in AI to improve operations or performance, the second highest market globally.\n\nBSI's model assesses and weights a suite of measures, including organisational confidence and readiness for AI adoption amongst businesses globally, to produce a single maturity score. It identifies Australia in the middle when it comes to AI maturity with a score of 3.1, compared to India, the most AI mature market, scoring 4.6. Based on insights from 932 business leaders across nine countries and seven sectors, the metrics include attitudes and actions including around investment, training, internal and external communications, and safety.\n\nPublished as part of BSI's Trust in AI report, the analysis identifies the UK and Japan to be less mature relative to others, potentially influenced by factors including policy direction or media narratives focused on risk rather than opportunity. China and India lead the way on all measures, with the US in third place, followed by Australia.\n\nThe research by the business improvement and standards company identified gaps between perceptions of what successful AI adoption entails and the concrete steps being taken by businesses. Three-quarters of Australian business leaders (75%) feel that organisations will be at a competitive disadvantage if they do not invest in AI, and only 11% felt that their businesses were not investing enough in AI tools, compared to a global average of 19%. Additionally, six in ten Australian business leaders felt offering training to ensure safe, ethical and effective use was very important (60%), and a similar proportion (86%) felt businesses should train teams to utilise AI tools to protect jobs.\n\nEngagement with AI is high in Australia with 86% reporting their business encourages the use of AI, and 88% feeling confident their business is harnessing the benefits of AI. As AI is already shaping everyday business practice, it is unsurprising that 94% of Australian business leaders say that it is important to inform employees about how AI is being used within organisations and what the plans for the future.\n\nWhile Australia scores above the Asia Pacific average across enterprise, government, and socio-economic dimensions of AI maturity, it still lags AI leaders such as the US, China and India as well as some countries across Europe such as France and the Netherlands. Moreover, Australia had the one of the lowest expectations for businesses having a role to play in building trust in AI across society (82%) compared to China (97%), India (96%) and the US (89%). As a lack of skilled talent persists as one of the top challenges to AI adoption in Australia, the model reveals just under a third (31%) of Australian business leaders reported substantive awareness of their company offering such training compared to India (49%) and China (47%). Just under two-fifths (38%) of Australians said their businesses had a specific learning and development programme compared to China (72%) and India (55%).\n\nCharlene Loo, Managing Director, BSI Australia, said: \"BSI's Global AI Maturity Model paints a positive but nuanced picture of a world excited about AI's potential and its promise as a force for good. While Australian businesses are increasing their investment in AI, we continue to see some challenges relating to a lack of skilled talent. Investment in standards, training and assurance is key as AI becomes integral to the future of life and work.\"\n\nSusan Taylor Martin, CEO, BSI, said: \"While the Model shows diverging paths thus far on AI, its mass adoption and integration into work and life is a marathon, not a sprint. Success is not about being first, but about building trust. BSI is committed to playing a role in shaping the guardrails for the safe and ethical use of AI, which will help businesses in Australia embrace AI to build a positive future for all.\"\n\nNotably, half of Australian businesses have an AI strategy (50%), higher than the global average of 44%. More positively, 88% of Australian business leaders recognise the importance of an ethical approach to AI. BSI recently published the first international AI management system standard (BS ISO/IEC 42001), along with a package of measures designed to enable the safe, secure and responsible use of AI. However, only one in three (30%) were aware of significant moves by their businesses to implement such policies and processes.\n\nBSI also explored where business leaders see scope for AI to be a force for good, with 53% of Australian business leaders saying the key opportunity is around improving productivity and efficiency, including supply chain management (49%). Just over a quarter (27%) see it as a tool to reduce reliance on contractors or consultancies, while nearly two-fifths (38%) expect AI to support the management, measurement and reporting of sustainability goals, and 46% expect to use it to support cybersecurity processes. Reassuringly, only over a third of Australian business leaders (35%) anticipate AI changing or replacing specific job functions.\n\nBSI's research draws together four key takeaways exploring how businesses can act to shape trust in AI across their ecosystems and wider society, so AI can be realised as a force for good. These include:", "source": {"uri": "dynamicbusiness.com", "dataType": "news", "title": "Dynamic Business"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/India", "type": "loc", "score": 5, "label": {"eng": "India"}, "location": {"type": "country", "label": {"eng": "India"}}}, {"uri": "http://en.wikipedia.org/wiki/China", "type": "loc", "score": 5, "label": {"eng": "China"}, "location": {"type": "country", "label": {"eng": "China"}}}, {"uri": "http://en.wikipedia.org/wiki/Australia", "type": "loc", "score": 5, "label": {"eng": "Australia"}, "location": {"type": "country", "label": {"eng": "Australia"}}}, {"uri": "http://en.wikipedia.org/wiki/BSI_Group", "type": "org", "score": 3, "label": {"eng": "BSI Group"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Japan", "type": "loc", "score": 3, "label": {"eng": "Japan"}, "location": {"type": "country", "label": {"eng": "Japan"}}}, {"uri": "http://en.wikipedia.org/wiki/United_Kingdom", "type": "loc", "score": 3, "label": {"eng": "United Kingdom"}, "location": {"type": "country", "label": {"eng": "United Kingdom"}}}, {"uri": "http://en.wikipedia.org/wiki/Socioeconomics", "type": "wiki", "score": 2, "label": {"eng": "Socioeconomics"}}, {"uri": "http://en.wikipedia.org/wiki/Asia-Pacific", "type": "loc", "score": 2, "label": {"eng": "Asia-Pacific"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Europe", "type": "loc", "score": 2, "label": {"eng": "Europe"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Netherlands", "type": "loc", "score": 2, "label": {"eng": "Netherlands"}, "location": {"type": "country", "label": {"eng": "Netherlands"}}}, {"uri": "http://en.wikipedia.org/wiki/France", "type": "loc", "score": 2, "label": {"eng": "France"}, "location": {"type": "country", "label": {"eng": "France"}}}, {"uri": "http://en.wikipedia.org/wiki/International_Organization_for_Standardization", "type": "wiki", "score": 1, "label": {"eng": "International Organization for Standardization"}}, {"uri": "http://en.wikipedia.org/wiki/Supply_chain_management", "type": "wiki", "score": 1, "label": {"eng": "Supply chain management"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 1, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Sustainability", "type": "wiki", "score": 1, "label": {"eng": "Sustainability"}}, {"uri": "http://en.wikipedia.org/wiki/International_Electrotechnical_Commission", "type": "wiki", "score": 1, "label": {"eng": "International Electrotechnical Commission"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 1, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Ecosystem", "type": "wiki", "score": 1, "label": {"eng": "Ecosystem"}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Business/Management", "label": "dmoz/Business/Management", "wgt": 100}, {"uri": "dmoz/Business/Management/Business_Transformation", "label": "dmoz/Business/Management/Business Transformation", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 54}], "image": "https://backend.dynamicbusiness.com/wp-content/uploads/2024/06/igor-omilaev-eGGFZ5X2LnA-unsplash-2.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.5607843137254902, "wgt": 170, "relevance": 1}
{"uri": "2024-08-443861292", "lang": "eng", "isDuplicate": false, "date": "2024-08-04", "time": "20:30:56", "dateTime": "2024-08-04T20:30:56Z", "dateTimePub": "2024-08-04T20:25:00Z", "dataType": "news", "sim": 0.6666666865348816, "url": "https://venturebeat.com/ai/gen-ais-awkward-adolescence-the-rocky-path-to-maturity/", "title": "Gen AI's awkward adolescence: The rocky path to maturity", "body": "Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More\n\nIs it possible that the generative AI revolution will never mature beyond its current state? That seems to be the suggestion from deep learning skeptic Gary Marcus in his recent blog post in which he pronounced the generative AI \"bubble has begun to burst.\" Gen AI refers to systems that can create new content -- such as text, images, code or audio -- based on patterns learned from vast amounts of existing data. Certainly, several recent news stories and analyst reports have questioned the immediate utility and economic value of gen AI, especially bots based on large language models (LLMs).\n\nWe've seen such skepticism before about new technologies. Newsweek famously published an article in 1995 that claimed the Internet would fail, arguing that the web was overhyped and impractical. Today, as we navigate a world transformed by the internet, it's worth considering whether current skepticism about gen AI might be equally shortsighted. Could we be underestimating AI's long-term potential while focusing on its short-term challenges?\n\nFor example, Goldman Sachs recently cast shade in a report titled: \"Gen AI: Too much spend, too little benefit?\" And, a new survey from freelance marketplace company Upwork revealed that \"nearly half (47%) of employees using AI say they have no idea how to achieve the productivity gains their employers expect, and 77% say these tools have actually decreased their productivity and added to their workload.\"\n\nA year ago, industry analyst firm Gartner listed gen AI at the \"peak of inflated expectations.\" However, the firm more recently said the technology was slipping into the \"trough of disillusionment.\" Gartner defines this as the point when interest wanes as experiments and implementations fail to deliver.\n\nWhile Gartner's recent assessment points to a phase of disappointment with early gen AI, this cyclical pattern of technology adoption is not new. The buildup of expectations -- commonly referred to as hype -- is a natural component of human behavior. We are attracted to the shiny new thing and the potential it appears to offer. Unfortunately, the early narratives that emerge around new technologies are often wrong. Translating that potential into real world benefits and value is hard work -- and rarely goes as smoothly as expected.\n\nAnalyst Benedict Evans recently discussed \"what happens when the utopian dreams of AI maximalism meet the messy reality of consumer behavior and enterprise IT budgets: It takes longer than you think, and it's complicated.\" Overestimating the promises of new systems is at the very heart of bubbles.\n\nAll of this is another way of stating an observation made decades ago. Roy Amara, a Stanford University computer scientist, and long-time head of the Institute for the Future, said in 1973 that \"we tend to overestimate the impact of a new technology in the short run, but we underestimate it in the long run.\" This truth of this statement has been widely observed and is now known as \"Amara's Law.\"\n\nThe fact is that it often just takes time for a new technology and its supporting ecosystem to mature. In 1977, Ken Olsen -- the CEO of Digital Equipment Corporation, which was then one of the world's most successful computer companies -- said: \"There is no reason anyone would want a computer in their home.\" Personal computing technology was then immature, as this was several years before the IBM PC was introduced. However, personal computers subsequently became ubiquitous, not just in our homes but in our pockets. It just took time.\n\nThe likely progression of AI technology\n\nGiven the historical context, it's intriguing to consider how AI might evolve. In a 2018 study, PwC described three overlapping cycles of automation driven by AI that will stretch into the 2030s, each with their own degree of impact. These cycles are the algorithm wave which they projected into the early 2020s, the augmentation wave that will prevail into the latter 2020s, and the autonomy wave that is expected to mature in the mid-2030s.\n\nThis projection appears prescient, as so much of the discussion now is on how AI augments human abilities and work. For example, IBM's first Principle for Trust and Transparency states that the purpose of AI is to augment human intelligence. An HBR article \"How generative AI can augment human creativity,\" explores the human plus AI relationship. JPMorgan Chase and Co. CEO Jamie Dimon said that AI technology could \"augment virtually every job.\"\n\nThere are already many such examples. In healthcare, AI-powered diagnostic tools are aiding the accuracy of disease detection, while in finance, AI algorithms are improving fraud detection and risk management. Customer service is also benefiting from AI using sophisticated chatbots that provide 24/7 assistance and streamline customer interactions. These examples illustrate that AI, while not yet revolutionary, is steadily assisting human capabilities and improving efficiency across industries.\n\nAugmentation is not the full automation of human tasks, nor is it likely to eliminate many jobs. In this way, the current state of AI is akin to other computer-enabled tools such as word processing and spreadsheets. Once mastered, these are definite productivity enhancers, but they did not fundamentally change the world. This augmentation wave accurately reflects the current state of AI technology.\n\nShort of expectations\n\nMuch of the hype has been around the expectation that gen AI is revolutionary -- or will be very soon. The gap between that expectation and current reality is leading to disillusionment and fears of an AI bubble bursting. What is missing in this conversation is a realistic timeframe. Evans tells a story about venture capitalist Marc Andreessen, who liked to say that every failed idea from the Dotcom bubble would work now. It just took time.\n\nAI development and implementation will continue to progress. It will be faster and more dramatic in some industries than others and accelerate in certain professions. In other words, there will be ongoing examples of impressive gains in performance and ability and other stories where AI technology is perceived to come up short. The gen AI future, then, will be very uneven. Hence, this is its awkward adolescent phase.\n\nThe AI revolution is coming\n\nGen AI will indeed prove to be revolutionary, although perhaps not as soon as the more optimistic experts have predicted. More than likely, the most significant effects of AI will be felt in ten years, just in time to coincide with what PwC described as the autonomy wave. This is when AI will be able to analyze data from multiple sources, make decisions and take physical actions with little or no human input. In other words, when AI agents are fully mature.\n\nAs we approach the autonomy wave in the mid-2030s, we may witness AI applications becoming mainstream, such as in precision medicine and humanoid robots that seem like science fiction today. It is in this phase, for example, that fully autonomous driverless vehicles may appear at scale.\n\nToday, AI is already augmenting human capabilities in meaningful ways. The AI revolution isn't just coming -- it's unfolding before our eyes, albeit perhaps more gradually than some predicted. Perceived slowing of progress or payoff could lead to more stories about AI falling short of expectation and greater pessimism about its future. Clearly, the journey is not without its challenges. Longer term, in line with Amara's law, AI will mature and live up to the revolutionary predictions.", "source": {"uri": "venturebeat.com", "dataType": "news", "title": "VentureBeat"}, "authors": [{"uri": "gary_grossman@venturebeat.com", "name": "Gary Grossman", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Skepticism", "type": "wiki", "score": 5, "label": {"eng": "Skepticism"}}, {"uri": "http://en.wikipedia.org/wiki/Gartner", "type": "org", "score": 5, "label": {"eng": "Gartner"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 4, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Internet", "type": "wiki", "score": 4, "label": {"eng": "Internet"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 3, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Upwork", "type": "org", "score": 3, "label": {"eng": "Upwork"}}, {"uri": "http://en.wikipedia.org/wiki/Gary_Marcus", "type": "person", "score": 3, "label": {"eng": "Gary Marcus"}}, {"uri": "http://en.wikipedia.org/wiki/Freelancer", "type": "wiki", "score": 3, "label": {"eng": "Freelancer"}}, {"uri": "http://en.wikipedia.org/wiki/Deep_learning", "type": "wiki", "score": 3, "label": {"eng": "Deep learning"}}, {"uri": "http://en.wikipedia.org/wiki/Internet_bot", "type": "wiki", "score": 3, "label": {"eng": "Internet bot"}}, {"uri": "http://en.wikipedia.org/wiki/Newsweek", "type": "wiki", "score": 3, "label": {"eng": "Newsweek"}}, {"uri": "http://en.wikipedia.org/wiki/Value_(economics)", "type": "wiki", "score": 3, "label": {"eng": "Value (economics)"}}, {"uri": "http://en.wikipedia.org/wiki/Personal_computer", "type": "wiki", "score": 3, "label": {"eng": "Personal computer"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Goldman_Sachs", "type": "org", "score": 3, "label": {"eng": "Goldman Sachs"}}, {"uri": "http://en.wikipedia.org/wiki/PwC", "type": "wiki", "score": 2, "label": {"eng": "PwC"}}, {"uri": "http://en.wikipedia.org/wiki/Institute_for_the_Future", "type": "wiki", "score": 2, "label": {"eng": "Institute for the Future"}}, {"uri": "http://en.wikipedia.org/wiki/Ken_Olsen", "type": "person", "score": 2, "label": {"eng": "Ken Olsen"}}, {"uri": "http://en.wikipedia.org/wiki/IBM_Personal_Computer", "type": "wiki", "score": 2, "label": {"eng": "IBM Personal Computer"}}, {"uri": "http://en.wikipedia.org/wiki/Digital_Equipment_Corporation", "type": "org", "score": 2, "label": {"eng": "Digital Equipment Corporation"}}, {"uri": "http://en.wikipedia.org/wiki/Utopia", "type": "wiki", "score": 2, "label": {"eng": "Utopia"}}, {"uri": "http://en.wikipedia.org/wiki/Autonomy", "type": "wiki", "score": 2, "label": {"eng": "Autonomy"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_scientist", "type": "wiki", "score": 2, "label": {"eng": "Computer scientist"}}, {"uri": "http://en.wikipedia.org/wiki/Stanford_University", "type": "org", "score": 2, "label": {"eng": "Stanford University"}}, {"uri": "http://en.wikipedia.org/wiki/Marc_Andreessen", "type": "person", "score": 1, "label": {"eng": "Marc Andreessen"}}, {"uri": "http://en.wikipedia.org/wiki/Jamie_Dimon", "type": "person", "score": 1, "label": {"eng": "Jamie Dimon"}}, {"uri": "http://en.wikipedia.org/wiki/IBM", "type": "org", "score": 1, "label": {"eng": "IBM"}}, {"uri": "http://en.wikipedia.org/wiki/JPMorgan_Chase", "type": "org", "score": 1, "label": {"eng": "JPMorgan Chase"}}], "categories": [{"uri": "dmoz/Computers/Artificial_Intelligence", "label": "dmoz/Computers/Artificial Intelligence", "wgt": 18}, {"uri": "dmoz/Computers/Artificial_Intelligence/Natural_Language", "label": "dmoz/Computers/Artificial Intelligence/Natural Language", "wgt": 20}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 25}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 34}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 25}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 75}], "image": "https://venturebeat.com/wp-content/uploads/2024/08/Cover_image-transformed.jpeg?w=1024?w=1200&strip=all", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": -0.03529411764705881, "wgt": 170, "relevance": 1}
{"uri": "8259074877", "lang": "eng", "isDuplicate": false, "date": "2024-08-04", "time": "20:36:30", "dateTime": "2024-08-04T20:36:30Z", "dateTimePub": "2024-08-04T20:35:28Z", "dataType": "news", "sim": 0.658823549747467, "url": "https://techbullion.com/the-role-of-ai-in-modern-cybersecurity-an-overview/", "title": "The Role of AI in Modern Cybersecurity: An Overview", "body": "Artificial Intelligence (AI) is changing cybersecurity, giving enhanced threat detection, real-time response, and predictive capabilities. By automating routine tasks and providing valuable insights, AI (Artificial Intelligence) enables organizations to stay ahead of cyber threats. However, it's essential to address the challenges and ethical considerations associated with AI to ensure its responsible and effective use. As AI technology continues to evolve, its role in cybersecurity will only become more critical, helping to create a safer digital landscape for all.\n\nThe Evolution of Cybersecurity:\n\nCybersecurity has evolved significantly over the past few decades. Initially, it was all about firewalls and antivirus software. These tools were designed to block known threats and viruses. However, as cyber threats became more advanced, the need for more sophisticated solutions became evident. Hackers began employing complex techniques, making it challenging for traditional security measures to keep up. This is where AI comes into play.\n\nUnderstanding AI in Cybersecurity:\n\nAI refers to the simulation of human intelligence processes by machines, especially computer systems. In cybersecurity, AI helps in identifying and mitigating threats in real-time. It does this by analyzing vast amounts of data and recognizing patterns that could indicate a potential security breach. Unlike traditional systems that rely on predefined rules, AI systems learn and adapt over time, becoming more effective at detecting and preventing threats.\n\nKey Benefits of AI in Cybersecurity:\n\nThe integration of AI in cybersecurity offers numerous benefits. These include:\n\nEnhanced Threat Detection:\n\nAI can analyze vast amounts of data at high speeds, identifying anomalies and potential threats that might go unnoticed by human analysts. This leads to quicker and more accurate threat detection.\n\nReal-Time Response:\n\nAI systems can respond to threats in real-time, reducing the time between threat detection and response. This minimizes potential damage and ensures quicker recovery.\n\nReduced False Positives:\n\nTraditional security systems often generate numerous false positives, overwhelming security teams. AI systems are more accurate, reducing the number of false positives and allowing security teams to focus on genuine threats.\n\nPredictive Capabilities:\n\nAI can predict future threats by analyzing patterns and trends in historical data. This proactive approach helps organizations prepare for potential attacks and strengthen their defenses.\n\nAutomation:\n\nAI automates routine security tasks, freeing up human analysts to focus on more complex issues. This improves overall efficiency and effectiveness.\n\nApplications of AI in Cybersecurity:\n\nAI is being used in various ways to enhance cybersecurity. Some of the key applications include:\n\nThreat Intelligence:\n\nAI systems gather and analyze threat data from multiple sources, providing valuable insights into emerging threats and attack vectors. This helps organizations stay ahead of cybercriminals.\n\nBehavioral Analysis:\n\nAI monitors user behavior and identifies deviations from normal patterns. This helps in detecting insider threats and compromised accounts.\n\nMalware Detection:\n\nAI-powered systems can analyze files and code to identify malware, even if it has never been seen before. This is particularly useful in detecting zero-day attacks.\n\nPhishing Detection:\n\nAI can analyze emails and websites to identify phishing attempts. It can also educate users about potential phishing risks, reducing the likelihood of successful attacks.\n\nNetwork Security:\n\nAI monitors network traffic for suspicious activity, identifying potential threats and anomalies in real-time. This helps in preventing data breaches and unauthorized access.\n\nReal-World Examples of AI in Cybersecurity:\n\nSeveral organizations are leveraging AI to enhance their cybersecurity measures. For instance:\n\nIBM's Watson for Cybersecurity:\n\nWatson uses AI to analyze vast amounts of security data and identify threats. It provides actionable insights to security analysts, helping them respond to threats more effectively.\n\nDarktrace:\n\nThis AI-powered cybersecurity company uses machine learning to detect and respond to threats in real-time. It monitors network traffic and identifies anomalies, helping organizations protect their data.\n\nCylance:\n\nCylance uses AI to prevent malware attacks. Its AI algorithms analyze files and code, identifying potential threats before they can cause harm.\n\nThe Future of AI in Cybersecurity:\n\nThe future of AI in cybersecurity looks promising. As AI technology continues to evolve, its capabilities in threat detection and response will only improve. Here are some potential future developments:\n\nAdvanced Machine Learning Algorithms:\n\nAI systems will become more sophisticated, using advanced machine learning algorithms to identify even the most subtle threats.\n\nIntegration with Other Technologies:\n\nAI will be integrated with other emerging technologies, such as blockchain and the Internet of Things (IoT), to provide even more robust security solutions.\n\nIncreased Automation:\n\nAs AI becomes more advanced, it will automate more complex security tasks, further reducing the burden on human analysts.\n\nImproved User Education:\n\nAI will play a key role in educating users about cybersecurity risks and best practices, helping to create a more security-aware workforce.\n\nEnhanced Collaboration:\n\nAI systems will facilitate better collaboration between different security teams and organizations, sharing threat intelligence and improving overall security posture.\n\nChallenges and Ethical Considerations\n\nWhile AI offers numerous benefits in cybersecurity, it also presents challenges and ethical considerations. These include:\n\nBias in AI Algorithms:\n\nAI systems can be biased, leading to unfair or inaccurate threat detection. It's crucial to ensure that AI algorithms are transparent and unbiased.\n\nPrivacy Concerns:\n\nAI systems often require access to vast amounts of data, raising privacy concerns. Organizations must ensure that they handle data responsibly and comply with privacy regulations.\n\nAdversarial AI:\n\nCybercriminals can use AI to develop more sophisticated attacks. It's essential to stay ahead of these threats and continuously improve AI security measures.\n\nConclusion:\n\nSince the year 2024, cybersecurity has become more critical than ever. With the proliferation of internet-connected devices and the increasing sophistication of cyber threats, traditional security measures are often insufficient. Enter artificial intelligence (AI) - a game-changer in the realm of cybersecurity. This article delves into the role of AI in modern cybersecurity, exploring its benefits, applications, and future potential.\n\nRelated Items:2024 Technology, AI in Cybersecurity, artificial intelliegnce Recommended for you AI Art and Traditional Art: Blending Techniques for Unique Creations Creating AI Art on a Budget: Affordable Tools and Techniques The Role of Machine Learning in AI Art: Tools and Techniques Explained", "source": {"uri": "techbullion.com", "dataType": "news", "title": "TechBullion"}, "authors": [{"uri": "angela_scott_briggs@techbullion.com", "name": "Angela Scott-Briggs", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Threat_(computer)", "type": "wiki", "score": 5, "label": {"eng": "Threat (computer)"}}, {"uri": "http://en.wikipedia.org/wiki/Real-time_computing", "type": "wiki", "score": 5, "label": {"eng": "Real-time computing"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 5, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 4, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/Security", "type": "wiki", "score": 4, "label": {"eng": "Security"}}, {"uri": "http://en.wikipedia.org/wiki/Hacker", "type": "wiki", "score": 3, "label": {"eng": "Hacker"}}, {"uri": "http://en.wikipedia.org/wiki/Simulation", "type": "wiki", "score": 3, "label": {"eng": "Simulation"}}, {"uri": "http://en.wikipedia.org/wiki/Firewall_(computing)", "type": "wiki", "score": 3, "label": {"eng": "Firewall (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/Intelligence", "type": "wiki", "score": 3, "label": {"eng": "Intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Phishing", "type": "wiki", "score": 3, "label": {"eng": "Phishing"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_virus", "type": "wiki", "score": 3, "label": {"eng": "Computer virus"}}, {"uri": "http://en.wikipedia.org/wiki/Malware", "type": "wiki", "score": 3, "label": {"eng": "Malware"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_monitor", "type": "wiki", "score": 3, "label": {"eng": "Computer monitor"}}, {"uri": "http://en.wikipedia.org/wiki/Antivirus_software", "type": "wiki", "score": 3, "label": {"eng": "Antivirus software"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Computer", "type": "wiki", "score": 3, "label": {"eng": "Computer"}}, {"uri": "http://en.wikipedia.org/wiki/Zero-day_(computing)", "type": "wiki", "score": 2, "label": {"eng": "Zero-day (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/Cybercrime", "type": "wiki", "score": 2, "label": {"eng": "Cybercrime"}}, {"uri": "http://en.wikipedia.org/wiki/Network_security", "type": "wiki", "score": 2, "label": {"eng": "Network security"}}, {"uri": "http://en.wikipedia.org/wiki/IBM", "type": "org", "score": 1, "label": {"eng": "IBM"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 100}, {"uri": "dmoz/Computers/Security/Intrusion_Detection_Systems", "label": "dmoz/Computers/Security/Intrusion Detection Systems", "wgt": 100}, {"uri": "dmoz/Computers/Security/Honeypots_and_Honeynets", "label": "dmoz/Computers/Security/Honeypots and Honeynets", "wgt": 100}, {"uri": "dmoz/Computers/Hacking/Cryptography", "label": "dmoz/Computers/Hacking/Cryptography", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 90}], "image": "https://techbullion.com/wp-content/uploads/2024/08/The-Role-of-AI-in-Modern-Cybersecurity-An-Overview.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.2627450980392156, "wgt": 168, "relevance": 1}
{"uri": "8259661184", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "07:57:20", "dateTime": "2024-08-05T07:57:20Z", "dateTimePub": "2024-08-05T07:56:10Z", "dataType": "news", "sim": 0.658823549747467, "url": "https://www.crn.in/?p=66150", "title": "75% of industry leaders strongly believe responsible AI can significantly improve decision-making and governance - Primus Partners Report - CRN - India", "body": "Primus Partners released an influential report titled 'Responsible by Design: Industry's Perspective on India's AI Framework', presenting a detailed study of the responsible and ethical AI ecosystem in India from the industry lens. The report advocates ethical, transparent, and accountable AI practices while outlining possible enforcement mechanisms for AI regulations in India.\n\nThe report offers an in-depth analysis of India's current AI landscape and focuses on critical aspects of responsible AI development and governance. The study comes at a crucial time as India positions itself at the forefront of global AI innovation while addressing the ethical challenges posed by rapid technological advancement.\n\nDevroop Dhar, Co-Founder and Managing Director, Primus Partners, stressed the importance of responsible AI development: \"India's current AI landscape reflects a segment full of opportunities. As we journey towards becoming a trillion-dollar digital economy, we must adopt a balanced approach to AI governance. This involves leveraging AI for its economic benefits while ensuring robust regulatory frameworks that can prevent or curb risks such as deepfakes by promoting ethical standards. As AI's influence is driving significant advancements and efficiencies across diverse industries worldwide, responsible use of AI should be a shared global priority.\"\n\nBased on insights from industry leaders and domain experts across India, the report stresses the potential for AI to contribute up to 10% to India's GDP by 2025 if governed responsibly. It highlights the challenges of data quality and availability (which include data scarcity, biases in datasets, and the complexities of data preparation and cleaning), noting that 76% of the industry views these as their top concerns in AI deployment. It also emphasises that 61% of the industry prioritises privacy and security, including threats posed by deepfakes, as a crucial principle-based element in safe AI deployment.\n\nOther key findings from the report include:\n\n53% of respondents believe that AI systems should be designed to be transparent and explainable to ensure trust and accountability\n\nOver 78% emphasise the need for ongoing skill development and training to keep pace with AI advancements\n\n51% of surveyed industry leaders prefer a hybrid regulatory approach combining traditional frameworks with adaptive guidelines\n\n47.3% believe that over-regulation and over-compliance if put in place, can become a deterrent to AI's growth\n\n67.6% of the industry believes that more PPP engagements are required in critical sectors such as health and education\n\n78% of the industry views that accelerating the Ethical AI Ecosystem in India necessitates operational requisites like continuous skill development and training and Structural Realignment in core AI organisations\n\n89% of the industry believes that specific regulations are essential to ensure ethical practices, accountability, and transparency in AI development and deployment\n\nThe report encompasses strategic actionable recommendations for establishing a robust framework that supports innovation while addressing the ethical challenges posed by AI. It calls for a collaborative approach between the government and the private sector to develop standards and practices that ensure AI benefits all segments of society. Additionally, the report underscores the importance of continuous learning, capacity building, voluntary product iterations and responsible adoption, and educating consumers or end-users in shaping an AI landscape that is both innovative and responsible.", "source": {"uri": "crn.in", "dataType": "news", "title": "CRN - India"}, "authors": [{"uri": "crn_team@crn.in", "name": "Crn Team", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 5, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/India", "type": "loc", "score": 5, "label": {"eng": "India"}, "location": {"type": "country", "label": {"eng": "India"}}}, {"uri": "http://en.wikipedia.org/wiki/Deepfake", "type": "wiki", "score": 3, "label": {"eng": "Deepfake"}}, {"uri": "http://en.wikipedia.org/wiki/Ecosystem", "type": "wiki", "score": 3, "label": {"eng": "Ecosystem"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Digital_economy", "type": "wiki", "score": 2, "label": {"eng": "Digital economy"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 2, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Gross_domestic_product", "type": "wiki", "score": 2, "label": {"eng": "Gross domestic product"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Hybrid_vehicle", "type": "wiki", "score": 1, "label": {"eng": "Hybrid vehicle"}}, {"uri": "http://en.wikipedia.org/wiki/Capacity_building", "type": "wiki", "score": 1, "label": {"eng": "Capacity building"}}, {"uri": "http://en.wikipedia.org/wiki/End_user", "type": "wiki", "score": 1, "label": {"eng": "End user"}}, {"uri": "http://en.wikipedia.org/wiki/Purchasing_power_parity", "type": "wiki", "score": 1, "label": {"eng": "Purchasing power parity"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 1, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Private_sector", "type": "wiki", "score": 1, "label": {"eng": "Private sector"}}], "categories": [{"uri": "dmoz/Society/Issues", "label": "dmoz/Society/Issues", "wgt": 100}, {"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Society/Activism/In_Daily_Life", "label": "dmoz/Society/Activism/In Daily Life", "wgt": 100}, {"uri": "dmoz/Society/Work/Telecommuting", "label": "dmoz/Society/Work/Telecommuting", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 57}], "image": null, "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.4588235294117646, "wgt": 168, "relevance": 1}
{"uri": "8259119488", "lang": "eng", "isDuplicate": false, "date": "2024-08-04", "time": "21:37:03", "dateTime": "2024-08-04T21:37:03Z", "dateTimePub": "2024-08-04T21:35:26Z", "dataType": "news", "sim": 0.6549019813537598, "url": "https://techbullion.com/the-future-of-cybersecurity-how-ai-is-shaping-the-landscape/", "title": "The Future of Cybersecurity: How AI is Shaping the Landscape", "body": "Artificial Intelligence (AI) is transforming the future of cybersecurity, giving enhanced threat detection level, real-time response, and predictive capabilities. By automating schedule tasks and giving valuable insights, Artificial Intelligence (AI) enables organizations to stay ahead of cyber threats. However, it is essential to address the challenges and ethical considerations associated with AI to ensure its responsible and effective use. As AI technology continues to evolve, its role in cybersecurity will only become more critical, helping to create a safer digital landscape for all.\n\nThe Current State of Cybersecurity:\n\nCybersecurity has always been a cat-and-mouse game between security professionals and cybercriminals. As soon as new security measures are developed, cybercriminals find ways to circumvent them. This dynamic has created a need for more advanced, adaptive security solutions. Traditional methods, such as firewalls and antivirus software, are no longer sufficient. They struggle to keep up with the sheer volume and complexity of modern cyber threats.\n\nThe Role of AI in Cybersecurity:\n\nAI is a game-changer in the world of cybersecurity. By leveraging machine learning and other AI technologies, organizations can enhance their ability to detect, analyze, and respond to cyber threats. AI systems can process vast amounts of data quickly and accurately, identifying patterns and anomalies that may indicate a potential threat. Unlike traditional systems, AI can learn and adapt over time, becoming more effective as it processes more data.\n\nKey Benefits of AI in Cybersecurity; The integration of AI into cybersecurity offers numerous benefits: Improved Threat Detection:\n\nAI can analyze large volumes of data at high speeds, identifying threats that might go unnoticed by human analysts. This leads to quicker and more accurate threat detection.\n\nEnhanced Threat Intelligence:\n\nAI systems gather and analyze threat data from multiple sources, providing valuable insights into emerging threats and attack vectors. This helps organizations stay ahead of cybercriminals.\n\nReal-Time Response:\n\nAI systems can respond to threats in real-time, reducing the time between threat detection and response. This minimizes potential damage and ensures faster recovery.\n\nReduced False Positives:\n\nTraditional security systems often generate numerous false positives, overwhelming security teams. AI systems are more accurate, reducing the number of false positives and allowing teams to focus on genuine threats.\n\nPredictive Capabilities:\n\nAI can predict future threats by analyzing patterns and trends in historical data. This proactive approach helps organizations prepare for potential attacks and strengthen their defenses.\n\nAutomation:\n\nAI automates routine security tasks, freeing up human analysts to focus on more complex issues. This improves overall efficiency and effectiveness.\n\nApplications of AI in Cybersecurity:\n\nAI is used in various ways to enhance cybersecurity. Some of the key applications include:\n\nBehavioral Analysis:\n\nAI monitors user behavior and identifies deviations from normal patterns. This helps in detecting insider threats and compromised accounts.\n\nMalware Detection:\n\nAI-powered systems can analyze files and code to identify malware, even if it has never been seen before. This is particularly useful in detecting zero-day attacks.\n\nPhishing Detection:\n\nAI can analyze emails and websites to identify phishing attempts. It can also educate users about potential phishing risks, reducing the likelihood of successful attacks.\n\nNetwork Security:\n\nAI monitors network traffic for suspicious activity, identifying potential threats and anomalies in real-time. This helps in preventing data breaches and unauthorized access.\n\nThreat Hunting:\n\nAI assists in proactive threat hunting by analyzing data and identifying potential indicators of compromise. This helps security teams identify and mitigate threats before they can cause significant damage.\n\nReal-World Examples of AI in Cybersecurity: Several organizations are leveraging AI to enhance their cybersecurity measures. Here are a few examples: IBM's Watson for Cybersecurity:\n\nWatson uses AI to analyze vast amounts of security data and identify threats. It provides actionable insights to security analysts, helping them respond to threats more effectively.\n\nDarktrace:\n\nThis AI-powered cybersecurity company uses machine learning to detect and respond to threats in real-time. It monitors network traffic and identifies anomalies, helping organizations protect their data.\n\nCylance:\n\nCylance uses AI to prevent malware attacks. Its AI algorithms analyze files and code, identifying potential threats before they can cause harm.\n\nThe Future of AI in Cybersecurity:\n\nThe future of AI in cybersecurity looks promising. As AI technology continues to evolve, its capabilities in threat detection and response will only improve. Here are some potential future developments:\n\nAdvanced Machine Learning Algorithms:\n\nAI systems will become more sophisticated, using advanced machine learning algorithms to identify even the most subtle threats.\n\nIntegration with Other Technologies:\n\nAI will be integrated with other emerging technologies, such as blockchain and the Internet of Things (IoT), to provide even more robust security solutions.\n\nIncreased Automation:\n\nAs AI becomes more advanced, it will automate more complex security tasks, further reducing the burden on human analysts.\n\nImproved User Education:\n\nAI will play a key role in educating users about cybersecurity risks and best practices, helping to create a more security-aware workforce.\n\nEnhanced Collaboration:\n\nAI systems will facilitate better collaboration between different security teams and organizations, sharing threat intelligence and improving overall security posture.\n\nChallenges and Ethical Considerations: While AI offers numerous benefits in cybersecurity, it also presents challenges and ethical considerations. These include: Bias in AI Algorithms:\n\nAI systems can be biased, leading to unfair or inaccurate threat detection. It's crucial to ensure that AI algorithms are transparent and unbiased.\n\nPrivacy Concerns:\n\nAI systems often require access to vast amounts of data, raising privacy concerns. Organizations must ensure that they handle data responsibly and comply with privacy regulations.\n\nAdversarial AI:\n\nCybercriminals can use AI to develop more sophisticated attacks. It's essential to stay ahead of these threats and continuously improve AI security measures.\n\nConclusion:\n\nThe digital landscape is evolving at an unprecedented pace, bringing both opportunities and challenges. One of the most significant challenges is the growing threat of cyber attacks. Traditional cybersecurity measures are often inadequate in the face of increasingly sophisticated threats. Enter artificial intelligence (AI), a transformative force that is reshaping the future of cybersecurity. This article explores how AI is shaping the cybersecurity landscape, highlighting its benefits, applications, and potential future developments.\n\nRelated Items:2024 Technology, AI in Cybersecurity, cubersecurity Recommended for you AI-Driven Cybersecurity: Enhancing Threat Intelligence and Response How AI is Used in Cybersecurity to Detect and Prevent Threats The Role of AI in Modern Cybersecurity: An Overview", "source": {"uri": "techbullion.com", "dataType": "news", "title": "TechBullion"}, "authors": [{"uri": "angela_scott_briggs@techbullion.com", "name": "Angela Scott-Briggs", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 5, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/Cybercrime", "type": "wiki", "score": 5, "label": {"eng": "Cybercrime"}}, {"uri": "http://en.wikipedia.org/wiki/Threat_(computer)", "type": "wiki", "score": 5, "label": {"eng": "Threat (computer)"}}, {"uri": "http://en.wikipedia.org/wiki/Real-time_computing", "type": "wiki", "score": 5, "label": {"eng": "Real-time computing"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 5, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Phishing", "type": "wiki", "score": 4, "label": {"eng": "Phishing"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 4, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Firewall_(computing)", "type": "wiki", "score": 3, "label": {"eng": "Firewall (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/Malware", "type": "wiki", "score": 3, "label": {"eng": "Malware"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_monitor", "type": "wiki", "score": 3, "label": {"eng": "Computer monitor"}}, {"uri": "http://en.wikipedia.org/wiki/Antivirus_software", "type": "wiki", "score": 3, "label": {"eng": "Antivirus software"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Indicator_of_compromise", "type": "wiki", "score": 2, "label": {"eng": "Indicator of compromise"}}, {"uri": "http://en.wikipedia.org/wiki/Network_traffic", "type": "wiki", "score": 2, "label": {"eng": "Network traffic"}}, {"uri": "http://en.wikipedia.org/wiki/Zero-day_(computing)", "type": "wiki", "score": 2, "label": {"eng": "Zero-day (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/Network_security", "type": "wiki", "score": 2, "label": {"eng": "Network security"}}, {"uri": "http://en.wikipedia.org/wiki/Data_breach", "type": "wiki", "score": 2, "label": {"eng": "Data breach"}}, {"uri": "http://en.wikipedia.org/wiki/Automation", "type": "wiki", "score": 2, "label": {"eng": "Automation"}}, {"uri": "http://en.wikipedia.org/wiki/Security", "type": "wiki", "score": 2, "label": {"eng": "Security"}}, {"uri": "http://en.wikipedia.org/wiki/IBM", "type": "org", "score": 1, "label": {"eng": "IBM"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 100}, {"uri": "dmoz/Computers/Security/Intrusion_Detection_Systems", "label": "dmoz/Computers/Security/Intrusion Detection Systems", "wgt": 100}, {"uri": "dmoz/Computers/Security/Honeypots_and_Honeynets", "label": "dmoz/Computers/Security/Honeypots and Honeynets", "wgt": 100}, {"uri": "dmoz/Computers/Hacking/Cryptography", "label": "dmoz/Computers/Hacking/Cryptography", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 91}], "image": "https://techbullion.com/wp-content/uploads/2024/08/The-Future-of-Cybersecurity-How-AI-is-Shaping-the-Landscape.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3019607843137255, "wgt": 167, "relevance": 1}
{"uri": "8259080310", "lang": "eng", "isDuplicate": false, "date": "2024-08-04", "time": "20:43:39", "dateTime": "2024-08-04T20:43:39Z", "dateTimePub": "2024-08-04T20:42:46Z", "dataType": "news", "sim": 0.6549019813537598, "url": "https://dnyuz.com/2024/08/04/gen-ais-awkward-adolescence-the-rocky-path-to-maturity/", "title": "Gen AI's awkward adolescence: The rocky path to maturity", "body": "Is it possible that the generative AI revolution will never mature beyond its current state? That seems to be the suggestion from deep learning skeptic Gary Marcus in his recent blog post in which he pronounced the generative AI \"bubble has begun to burst.\" Gen AI refers to systems that can create new content -- such as text, images, code or audio -- based on patterns learned from vast amounts of existing data. Certainly, several recent news stories and analyst reports have questioned the immediate utility and economic value of gen AI, especially bots based on large language models (LLMs).\n\nWe've seen such skepticism before about new technologies. Newsweek famously published an article in 1995 that claimed the Internet would fail, arguing that the web was overhyped and impractical. Today, as we navigate a world transformed by the internet, it's worth considering whether current skepticism about gen AI might be equally shortsighted. Could we be underestimating AI's long-term potential while focusing on its short-term challenges?\n\nFor example, Goldman Sachs recently cast shade in a report titled: \"Gen AI: Too much spend, too little benefit?\" And, a new survey from freelance marketplace company Upwork revealed that \"nearly half (47%) of employees using AI say they have no idea how to achieve the productivity gains their employers expect, and 77% say these tools have actually decreased their productivity and added to their workload.\"\n\nA year ago, industry analyst firm Gartner listed gen AI at the \"peak of inflated expectations.\" However, the firm more recently said the technology was slipping into the \"trough of disillusionment.\" Gartner defines this as the point when interest wanes as experiments and implementations fail to deliver.\n\nWhile Gartner's recent assessment points to a phase of disappointment with early gen AI, this cyclical pattern of technology adoption is not new. The buildup of expectations -- commonly referred to as hype -- is a natural component of human behavior. We are attracted to the shiny new thing and the potential it appears to offer. Unfortunately, the early narratives that emerge around new technologies are often wrong. Translating that potential into real world benefits and value is hard work -- and rarely goes as smoothly as expected.\n\nAnalyst Benedict Evans recently discussed \"what happens when the utopian dreams of AI maximalism meet the messy reality of consumer behavior and enterprise IT budgets: It takes longer than you think, and it's complicated.\" Overestimating the promises of new systems is at the very heart of bubbles.\n\nAll of this is another way of stating an observation made decades ago. Roy Amara, a Stanford University computer scientist, and long-time head of the Institute for the Future, said in 1973 that \"we tend to overestimate the impact of a new technology in the short run, but we underestimate it in the long run.\" This truth of this statement has been widely observed and is now known as \"Amara's Law.\"\n\nThe fact is that it often just takes time for a new technology and its supporting ecosystem to mature. In 1977, Ken Olsen -- the CEO of Digital Equipment Corporation, which was then one of the world's most successful computer companies -- said: \"There is no reason anyone would want a computer in their home.\" Personal computing technology was then immature, as this was several years before the IBM PC was introduced. However, personal computers subsequently became ubiquitous, not just in our homes but in our pockets. It just took time.\n\nGiven the historical context, it's intriguing to consider how AI might evolve. In a 2018 study, PwC described three overlapping cycles of automation driven by AI that will stretch into the 2030s, each with their own degree of impact. These cycles are the algorithm wave which they projected into the early 2020s, the augmentation wave that will prevail into the latter 2020s, and the autonomy wave that is expected to mature in the mid-2030s.\n\nThis projection appears prescient, as so much of the discussion now is on how AI augments human abilities and work. For example, IBM's first Principle for Trust and Transparency states that the purpose of AI is to augment human intelligence. An HBR article \"How generative AI can augment human creativity,\" explores the human plus AI relationship. JPMorgan Chase and Co. CEO Jamie Dimon said that AI technology could \"augment virtually every job.\"\n\nThere are already many such examples. In healthcare, AI-powered diagnostic tools are aiding the accuracy of disease detection, while in finance, AI algorithms are improving fraud detection and risk management. Customer service is also benefiting from AI using sophisticated chatbots that provide 24/7 assistance and streamline customer interactions. These examples illustrate that AI, while not yet revolutionary, is steadily assisting human capabilities and improving efficiency across industries.\n\nAugmentation is not the full automation of human tasks, nor is it likely to eliminate many jobs. In this way, the current state of AI is akin to other computer-enabled tools such as word processing and spreadsheets. Once mastered, these are definite productivity enhancers, but they did not fundamentally change the world. This augmentation wave accurately reflects the current state of AI technology.\n\nMuch of the hype has been around the expectation that gen AI is revolutionary -- or will be very soon. The gap between that expectation and current reality is leading to disillusionment and fears of an AI bubble bursting. What is missing in this conversation is a realistic timeframe. Evans tells a story about venture capitalist Marc Andreessen, who liked to say that every failed idea from the Dotcom bubble would work now. It just took time.\n\nAI development and implementation will continue to progress. It will be faster and more dramatic in some industries than others and accelerate in certain professions. In other words, there will be ongoing examples of impressive gains in performance and ability and other stories where AI technology is perceived to come up short. The gen AI future, then, will be very uneven. Hence, this is its awkward adolescent phase.\n\nGen AI will indeed prove to be revolutionary, although perhaps not as soon as the more optimistic experts have predicted. More than likely, the most significant effects of AI will be felt in ten years, just in time to coincide with what PwC described as the autonomy wave. This is when AI will be able to analyze data from multiple sources, make decisions and take physical actions with little or no human input. In other words, when AI agents are fully mature.\n\nAs we approach the autonomy wave in the mid-2030s, we may witness AI applications becoming mainstream, such as in precision medicine and humanoid robots that seem like science fiction today. It is in this phase, for example, that fully autonomous driverless vehicles may appear at scale.\n\nToday, AI is already augmenting human capabilities in meaningful ways. The AI revolution isn't just coming -- it's unfolding before our eyes, albeit perhaps more gradually than some predicted. Perceived slowing of progress or payoff could lead to more stories about AI falling short of expectation and greater pessimism about its future. Clearly, the journey is not without its challenges. Longer term, in line with Amara's law, AI will mature and live up to the revolutionary predictions.", "source": {"uri": "dnyuz.com", "dataType": "news", "title": "DNyuz"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Skepticism", "type": "wiki", "score": 5, "label": {"eng": "Skepticism"}}, {"uri": "http://en.wikipedia.org/wiki/Gartner", "type": "org", "score": 5, "label": {"eng": "Gartner"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Internet", "type": "wiki", "score": 5, "label": {"eng": "Internet"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 4, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 3, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Gary_Marcus", "type": "person", "score": 3, "label": {"eng": "Gary Marcus"}}, {"uri": "http://en.wikipedia.org/wiki/Freelancer", "type": "wiki", "score": 3, "label": {"eng": "Freelancer"}}, {"uri": "http://en.wikipedia.org/wiki/Deep_learning", "type": "wiki", "score": 3, "label": {"eng": "Deep learning"}}, {"uri": "http://en.wikipedia.org/wiki/Internet_bot", "type": "wiki", "score": 3, "label": {"eng": "Internet bot"}}, {"uri": "http://en.wikipedia.org/wiki/Newsweek", "type": "wiki", "score": 3, "label": {"eng": "Newsweek"}}, {"uri": "http://en.wikipedia.org/wiki/Value_(economics)", "type": "wiki", "score": 3, "label": {"eng": "Value (economics)"}}, {"uri": "http://en.wikipedia.org/wiki/Personal_computer", "type": "wiki", "score": 3, "label": {"eng": "Personal computer"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Goldman_Sachs", "type": "org", "score": 3, "label": {"eng": "Goldman Sachs"}}, {"uri": "http://en.wikipedia.org/wiki/PwC", "type": "wiki", "score": 2, "label": {"eng": "PwC"}}, {"uri": "http://en.wikipedia.org/wiki/Institute_for_the_Future", "type": "wiki", "score": 2, "label": {"eng": "Institute for the Future"}}, {"uri": "http://en.wikipedia.org/wiki/Ken_Olsen", "type": "person", "score": 2, "label": {"eng": "Ken Olsen"}}, {"uri": "http://en.wikipedia.org/wiki/IBM_Personal_Computer", "type": "wiki", "score": 2, "label": {"eng": "IBM Personal Computer"}}, {"uri": "http://en.wikipedia.org/wiki/Digital_Equipment_Corporation", "type": "org", "score": 2, "label": {"eng": "Digital Equipment Corporation"}}, {"uri": "http://en.wikipedia.org/wiki/Utopia", "type": "wiki", "score": 2, "label": {"eng": "Utopia"}}, {"uri": "http://en.wikipedia.org/wiki/Autonomy", "type": "wiki", "score": 2, "label": {"eng": "Autonomy"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_scientist", "type": "wiki", "score": 2, "label": {"eng": "Computer scientist"}}, {"uri": "http://en.wikipedia.org/wiki/Stanford_University", "type": "org", "score": 2, "label": {"eng": "Stanford University"}}, {"uri": "http://en.wikipedia.org/wiki/Marc_Andreessen", "type": "person", "score": 1, "label": {"eng": "Marc Andreessen"}}, {"uri": "http://en.wikipedia.org/wiki/Jamie_Dimon", "type": "person", "score": 1, "label": {"eng": "Jamie Dimon"}}, {"uri": "http://en.wikipedia.org/wiki/IBM", "type": "org", "score": 1, "label": {"eng": "IBM"}}, {"uri": "http://en.wikipedia.org/wiki/JPMorgan_Chase", "type": "org", "score": 1, "label": {"eng": "JPMorgan Chase"}}], "categories": [{"uri": "dmoz/Society/Future", "label": "dmoz/Society/Future", "wgt": 100}, {"uri": "dmoz/Computers/Software/Year_2000", "label": "dmoz/Computers/Software/Year 2000", "wgt": 100}, {"uri": "dmoz/Society/Future/Transhumanism", "label": "dmoz/Society/Future/Transhumanism", "wgt": 100}, {"uri": "dmoz/Society/Work/Rethinking_Work", "label": "dmoz/Society/Work/Rethinking Work", "wgt": 100}, {"uri": "dmoz/Society/Future/Essays", "label": "dmoz/Society/Future/Essays", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 89}], "image": "https://dnyuz.com/wp-content/uploads/2024/08/Gen-AIs-awkward-adolescence-The-rocky-path-to-maturity.jpeg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": -0.03529411764705881, "wgt": 167, "relevance": 1}
{"uri": "8260069783", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "12:18:52", "dateTime": "2024-08-05T12:18:52Z", "dateTimePub": "2024-08-05T12:17:52Z", "dataType": "news", "sim": 0.6509804129600525, "url": "https://english.vov.vn/en/society/global-leading-ai-experts-to-attend-ai4vn-2024-post1112452.vov", "title": "Global leading AI experts to attend AI4VN 2024", "body": "Society Global leading AI experts to attend AI4VN 2024 Monday, 18:55, 05/08/2024 VOV.VN - A number of domestic and international experts are set to gather at the Vietnam Artificial Intelligence Day (AI4VN 2024) slated for August 23 in Hanoi to discuss the topic on Generative AI.\n\nThe event will open with the theme of \"Unlock the power of Generative AI\" and is anticipated to attract the participation of representatives from technology corporations, local and international AI development enterprises, and universities.\n\nAt the event, speakers from Australia, the Republic of Korea, and other countries will deliver speeches on clarifying the trends in the world and how countries are adapting and taking full advantage of the AI technology's strengths.\n\nFurthermore, representatives of domestic technology corporations and enterprises will discuss further on potential opportunities and challenges occurring in the development and application of AI in Vietnam.\n\nThere will be a number of AI workshops held throughout the event related to issues on AI Automation, the application of AI in small and medium-sized enterprises in Vietnam, data centre and AI Cloud, and the application of AI in the health sector.\n\nMoreover, an AI Expo will take place during the event featuring the involvement of booths displaying typical AI products of enterprises, institutes, and schools.\n\nParticipants will have the opportunity to experience the latest in cutting-edge AI products on the Vietnamese market.\n\nWithin the framework of the programme, organizers will also present awards to outstanding AI products and solutions (AI Awards 2024).\n\nVOV\n\nM\u1eddi qu\u00fd \u0111\u1ed9c gi\u1ea3 theo d\u00f5i VOV.VN tr\u00ean", "source": {"uri": "english.vov.vn", "dataType": "news", "title": "VOV - VOV Online Newspaper"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Vietnam", "type": "loc", "score": 4, "label": {"eng": "Vietnam"}, "location": {"type": "country", "label": {"eng": "Vietnam"}}}, {"uri": "http://en.wikipedia.org/wiki/Corporation", "type": "wiki", "score": 3, "label": {"eng": "Corporation"}}, {"uri": "http://en.wikipedia.org/wiki/Hanoi", "type": "loc", "score": 3, "label": {"eng": "Hanoi"}, "location": {"type": "place", "label": {"eng": "Hanoi"}, "country": {"type": "country", "label": {"eng": "Vietnam"}}}}, {"uri": "http://en.wikipedia.org/wiki/South_Korea", "type": "loc", "score": 2, "label": {"eng": "South Korea"}, "location": {"type": "country", "label": {"eng": "South Korea"}}}, {"uri": "http://en.wikipedia.org/wiki/Australia", "type": "loc", "score": 2, "label": {"eng": "Australia"}, "location": {"type": "country", "label": {"eng": "Australia"}}}, {"uri": "http://en.wikipedia.org/wiki/Small_and_medium-sized_enterprises", "type": "wiki", "score": 1, "label": {"eng": "Small and medium-sized enterprises"}}, {"uri": "http://en.wikipedia.org/wiki/Voice_of_Vietnam", "type": "org", "score": 1, "label": {"eng": "Voice of Vietnam"}}, {"uri": "http://en.wikipedia.org/wiki/Automation", "type": "wiki", "score": 1, "label": {"eng": "Automation"}}], "categories": [{"uri": "dmoz/Business/Resources", "label": "dmoz/Business/Resources", "wgt": 100}, {"uri": "dmoz/Society/Activism/In_Daily_Life", "label": "dmoz/Society/Activism/In Daily Life", "wgt": 100}, {"uri": "dmoz/Science/Technology/Conferences_and_Events", "label": "dmoz/Science/Technology/Conferences and Events", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 54}], "image": "https://vov-media.emitech.vn/sites/default/files/styles/og_image_en/public/2024-08/thumbshare.png.jpg?v=1722860090", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-08-23", "textStart": 222, "textEnd": 231}], "sentiment": 0.3019607843137255, "wgt": 166, "relevance": 1}
{"uri": "2024-08-443997291", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "02:28:47", "dateTime": "2024-08-05T02:28:47Z", "dateTimePub": "2024-08-05T02:26:03Z", "dataType": "news", "sim": 0.6470588445663452, "url": "https://www.techtimes.com/articles/307028/20240804/devolved-ais-agc-token-debuts-on-mexc-ushering-in-a-new-era-of-decentralized-intelligence.htm", "title": "Devolved AI's AGC Token Debuts on MEXC: Ushering in a New Era of Decentralized Intelligence", "body": "A ground-breaking combination of blockchain technology and artificial intelligence has surfaced in the fast-moving world of technology, potentially transforming how we use and create AI ultimately. Devolved AI, a pioneer in this incredible new field, has recently reached a key milestone that will impact the future of decentralized intelligence.\n\nThe world of cryptocurrency saw a historic occurrence on August 5, 2024, when AGC, the native token of Devolved AI, had its grand debut on MEXC, one of the top exchanges in the world. This ranking shows that Devolved AI's creative approach to AI development and governance is being increasingly recognized rather than merely being another player in the cryptocurrency industry.\n\nHowever, the update doesn't end there. The listing closely follows a previous significant accomplishment: the smooth introduction of Devolved AI's Layer 1 mainnet on Argochain on July 1, 2024. These two significant accomplishments represent a quantum leap for Devolved AI in the endeavor to democratize artificial intelligence and make it available to everyone.\n\nCombining blockchain technology with artificial intelligence has long been predicted to revolutionize the world. Remarkably, Devolved AI is making this prediction more likely with its offerings. Now that more investors may access AGC, the stage is set for improved market visibility, liquidity, and quick value growth.\n\nReimagining AI Development\n\nImagine a world where tons of developers, researchers, and enthusiasts shape AI instead of a small number of giant corporations controlling it. That is the future that Devolved AI is creating, and anybody can join this AI revolution by purchasing the AGC token, which is currently accessible on MEXC.\n\nOne of the most promising aspects of Devolved AI is its decentralized AI training system, which will use federated learning to attain remarkable speeds. The platform will be able to access an extensive GPU network via this approach, speeding up AI training up to 100 times compared to conventional techniques. This will not only be a small step forward; instead, it will be a revolutionary acceleration that has the potential to accelerate AI progress in all domains significantly.\n\nSpeed, though, isn't everything. Devolved AI is also pioneering a new paradigm of community-driven development, wherein contributions from developers and the worldwide community are rewarded with AGC tokens. With everyone having a stake in the AI's fate, this strategy will create a thriving and active ecosystem.\n\nFurther Developments\n\nNow that AGC has successfully listed on MEXC and its mainnet has gone live, Devolved AI is well-positioned to develop and innovate quickly. However, this is only the start. The company has big intentions to develop its ecosystem even further and push the limits of artificial intelligence.\n\nAn anticipated advancement is Athena 2's upgraded language model by Devolved AI. Using community feedback to produce an AI assistant in tune with users' requirements, Athena 2 is being improved to understand better and serve the Devolved AI project, building on Mixtral 8x7b.\n\nParallel to this, Devolved AI is making significant strides in advancing its federated learning system. This focus on decentralized and secure AI training is crucial for ensuring data privacy and enhancing collaboration within the ecosystem. It's a bold step towards a future where AI can be trained on diverse, high-quality datasets without compromising individual privacy.\n\nThe platform also builds a sophisticated architecture for distributed training to provide scalable and effective AI model training to ensure efficient, scalable, and fair AI development.\n\nA Vision for the Future\n\nAs Nathan Peterson, CEO of Devolved AI, aptly puts it: \"The listing of AGC on MEXC and the successful launch of our mainnet on Argochain are pivotal milestones for Devolved AI. These achievements lay the foundation for our future innovations, particularly with Athena 2, which will leverage federated learning to push the boundaries of decentralized AI.\"\n\nNot only is this idea of a decentralized, community-driven AI intriguing, but it has the ability to alter the world completely. Devolved AI establishes a new benchmark for accountability in AI development by utilizing blockchain technology to preserve an open and unchangeable record of AI models, training data, and governance decisions. This fosters trust within the ecosystem.\n\nFurthermore, the company's emphasis on establishing partnerships with prominent companies in the blockchain and artificial intelligence domains is expected to enhance its technological prowess and broaden its ecosystem.\n\nNotably, the listing of AGC on MEXC offers more than a fresh investment opportunity as we approach this new chapter in the evolution of AI. It's an invitation to join a movement reshaping artificial intelligence's future.\n\nDevolved AI allows everyone to influence the direction of AI in a way that is more just, open, and consistent with human values, regardless of whether they are developers, AI enthusiasts, or just someone who believes in the potential of decentralized technology.", "source": {"uri": "techtimes.com", "dataType": "news", "title": "Tech Times"}, "authors": [{"uri": "carl_williams@techtimes.com", "name": "Carl Williams", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Cryptocurrency", "type": "wiki", "score": 5, "label": {"eng": "Cryptocurrency"}}, {"uri": "http://en.wikipedia.org/wiki/Devolution", "type": "wiki", "score": 5, "label": {"eng": "Devolution"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Blockchain", "type": "wiki", "score": 4, "label": {"eng": "Blockchain"}}, {"uri": "http://en.wikipedia.org/wiki/Decentralization", "type": "wiki", "score": 4, "label": {"eng": "Decentralization"}}, {"uri": "http://en.wikipedia.org/wiki/Federated_learning", "type": "wiki", "score": 3, "label": {"eng": "Federated learning"}}, {"uri": "http://en.wikipedia.org/wiki/Democratization", "type": "wiki", "score": 3, "label": {"eng": "Democratization"}}, {"uri": "http://en.wikipedia.org/wiki/Ecosystem", "type": "wiki", "score": 3, "label": {"eng": "Ecosystem"}}, {"uri": "http://en.wikipedia.org/wiki/Athena", "type": "wiki", "score": 2, "label": {"eng": "Athena"}}, {"uri": "http://en.wikipedia.org/wiki/Paradigm", "type": "wiki", "score": 2, "label": {"eng": "Paradigm"}}, {"uri": "http://en.wikipedia.org/wiki/Market_liquidity", "type": "wiki", "score": 2, "label": {"eng": "Market liquidity"}}, {"uri": "http://en.wikipedia.org/wiki/Revolution", "type": "wiki", "score": 2, "label": {"eng": "Revolution"}}, {"uri": "http://en.wikipedia.org/wiki/Graphics_processing_unit", "type": "wiki", "score": 2, "label": {"eng": "Graphics processing unit"}}, {"uri": "http://en.wikipedia.org/wiki/Corporation", "type": "wiki", "score": 2, "label": {"eng": "Corporation"}}, {"uri": "http://en.wikipedia.org/wiki/Benchmark_(computing)", "type": "wiki", "score": 1, "label": {"eng": "Benchmark (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/Scalability", "type": "wiki", "score": 1, "label": {"eng": "Scalability"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 1, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Evolution", "type": "wiki", "score": 1, "label": {"eng": "Evolution"}}, {"uri": "http://en.wikipedia.org/wiki/Information_privacy", "type": "wiki", "score": 1, "label": {"eng": "Information privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 1, "label": {"eng": "Privacy"}}], "categories": [{"uri": "dmoz/Computers/Artificial_Intelligence", "label": "dmoz/Computers/Artificial Intelligence", "wgt": 18}, {"uri": "dmoz/Computers/Artificial_Intelligence/Associations", "label": "dmoz/Computers/Artificial Intelligence/Associations", "wgt": 18}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 29}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 33}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 25}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 74}], "image": "https://1734811051.rsc.cdn77.org/data/thumbs/full/449952/820/0/0/0/devolved-ai.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.388235294117647, "wgt": 165, "relevance": 1}
{"uri": "8260037844", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "12:00:09", "dateTime": "2024-08-05T12:00:09Z", "dateTimePub": "2024-08-05T11:59:21Z", "dataType": "news", "sim": 0.6470588445663452, "url": "https://techround.co.uk/guides/10-online-courses-ai-skillset-knowledge/", "title": "11 Online Courses To Brush Up Your AI Skillset And Knowledge", "body": "AI is creeping into almost every part of our lives, especially in the business world. The best way to prepare for AI, is to get as educated and informed as possible. With the news last week surrounding the government cutting a huge part of the AI budget, now more than ever, startups need to start educating themselves. On the matter last week, Besnik Vrellaku, the CEO and founder behind Salesflow.io. commented on how the budget fund impacts startups specifically, saying, \"\"If startups are seeking funding for AI projects, there's plenty of venture capital available, and money is flowing in the VC world.\n\n\"On the bright side, fewer bureaucratic barriers could enable startups to develop AI systems faster, fostering innovation and growth. Streamlining processes without complex red tape could positively impact startups.\"\n\nSo, although there was a worry on how startups would operate, its worth remembering that currently, AI startups are the most funded in the UK, and so as Vrellaku puts it, the scene is still fine from an investments perspective. What's left is for startup founders to expand their skillset and knowledge, and for that, there are 11 courses and institutions that help with exactly this:\n\nThe Artificial Intelligence in Marketing from University of Virginia gives an interesting look at how AI can be used with marketing strategies. Instructor Rajkumar Venkatesan guides learners through using AI for customer engagement, and to develop network-based business models. The curriculum here focuses on how data from digital platforms can build sustainable solutions, as well as create personalised experiences for customers. This is great if you have a full time job due to its flexible schedule, and can be taken up by even beginners. Here, you can gain digital marketing skills while using the newest best thing in tech.\n\nThe University of Oxford created this course for managers and business leaders who want to start putting AI in their operational strategies, This is a 6 week course where you look at AI's core aspects, and brings a great foundational understanding of the tech, so that they as leaders can make the most informed decisions that serve the business, the employees, and the law overall.\n\nSelfcode Academy's \"Mastering Artificial Intelligence\" course serves as a guide to the fundamentals and advanced concepts of AI. This course covers different topics, from the history of AI to deep learning and neural network applications. Students engage with on-demand videos, downloadable resources, and interactive projects to understand AI's impact across the industries as well as ethical factors, such as bias and privacy. Suitable for beginners to advanced learners, this course promises to equip its attendees with critical machine learning skills and practical knowledge to face real-world AI cases and applications.\n\nThis Machine Learning Specialisation course at Stanford University, taught by AI expert Andrew Ng, is great for you to grasp the core principles of machine learning. It's especially beneficial if you're just starting out or looking to deepen your understanding in the field. You'll learn how to construct basic regression models and advance to more intricate neural networks and decision-making systems. This programme is perfect for applying these techniques to real-world problems.\n\nThe University of Surrey's MSc in People-Centred Artificial Intelligence focuses on the human aspects of AI. This online course can be done in 24 months, gives technical knowledge together with the social and ethical side of things, AI wise. Students study machine learning, computer vision, and the societal impacts of AI. The programme is a great way to prep students for careers in different fields, like healthcare and sustainability. The course has 11 modules, with topics from deep neural networks to AI's role in society. It is designed to equip students with both practical and theoretical knowledge.\n\nThis Udemy course is for professionals and startup founders in finance, accounting, and auditing. It gives them AI tools that make their jobs easier, without needing to learn how to code. The curriculum introduces practical AI uses like chatbots, smart analytics, and robotic process automation. The course is great with hands-on exercises that use software tools relevant to each AI technique. At the end of the course, you'd have a good understanding of how AI can make operations better, while supporting decision-making processes in their lines of work, so that you're better prepped for financial digital transformation.\n\nThis one can be found on Coursera, and is perfect for those who don't really know AI, but now want to start learning. Perhaps your job just started incorporating AI, and you want to be ahead of your game. This course covers the basic AI concepts like machine learning, neural networks, and natural language processing. The course has 8 hours of flexible, self-paced learning, with quizzes and hands-on labs to apply knowledge. Perfect for professionals and enthusiasts, this course really has a solid foundation in AI, with a shareable certificate upon completion.\n\nGoogle's Professional Certificate in AI for web-based machine learning brings a way for those who are starting out with AI in web platforms by helping with how its applied. Led by Jason Mayes and Laurence Morony, it covers the AI and machine learning basics, their interconnections, and specific applications in web technologies using TensorFlow.js. Over three months, learners will discover how to integrate pre-existing models and craft custom models for tasks like object detection and natural language processing directly in the browser. This is great if you're looking to make web apps more interactive and with the times.\n\nFound on Coursera, this specialisation by the University of Pennsylvania teaches the fundamentals of AI and machine learning with a focus on how it can be applied in businesses. Instructors Peter Cappelli, Matthew Bidwell, and Michael R Roberts guide learners through using AI within business strategies for better operations and customer relationships. The four-course series covers topics like data analytics, ethical AI usage and fraud prevention, to prepare learners for leadership roles that need a deep understanding of AI applications in business contexts. This one is also great for startup founders.\n\nHarvard University's Professional Certificate in Computer Science for Artificial Intelligence is for startup owners who want to find ways to grow how they understand AI. This programme has 2 courses: Introduction to Computer Science and Introduction to Artificial Intelligence with Python. Learners study graph search algorithms, reinforcement learning, and designing intelligent systems. The course also covers AI's practical applications and ethical considerations. With instruction from Harvard faculty, this programme, completed at your own pace over 5 months, provides a thorough grounding in AI principles and practices.\n\nThe ALT AI Academy offers a range of AI training, led by global marketing studio, The Alternative, intended to unleash participants' marketing potential through the academy's bold training, transforming creativity and efficiency through cutting-edge AI tools.\n\nThe academy offers various types of training such as: Rebel CMO Masterclass, bespoke 1-2-1 training designed for senior marketers and CMOs looking to master hands-on AI skills and boost efficiency and creativity; AI Powerhouse Team Training, comprehensive group training covering research, planning, and digital marketing through AI; and their Virtual Innovator Workshops, meant for any marketer, anywhere in the world.\n\nTheir Virtual Innovator Workshops are designed to revolutionise marketing strategies with interactive, hands-on AI training. These online sessions cover all facets of digital marketing, ensuring that participants are kept ahead of the curve in the rapidly evolving AI landscape.\n\nThese sessions are created for marketing professionals who are seeking to innovate and enhance their digital strategy with AI, and are led by industry and AI experts Angel Gaskell and Jaki Jelley, who bring unparalleled insights and practical knowledge.", "source": {"uri": "techround.co.uk", "dataType": "news", "title": "TechRound"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Venture_capital", "type": "wiki", "score": 5, "label": {"eng": "Venture capital"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 5, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 5, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_neural_network", "type": "wiki", "score": 4, "label": {"eng": "Artificial neural network"}}, {"uri": "http://en.wikipedia.org/wiki/Marketing", "type": "wiki", "score": 4, "label": {"eng": "Marketing"}}, {"uri": "http://en.wikipedia.org/wiki/Decision-making", "type": "wiki", "score": 3, "label": {"eng": "Decision-making"}}, {"uri": "http://en.wikipedia.org/wiki/University_of_Virginia", "type": "org", "score": 3, "label": {"eng": "University of Virginia"}}, {"uri": "http://en.wikipedia.org/wiki/Customer_engagement", "type": "wiki", "score": 3, "label": {"eng": "Customer engagement"}}, {"uri": "http://en.wikipedia.org/wiki/University_of_Oxford", "type": "org", "score": 3, "label": {"eng": "University of Oxford"}}, {"uri": "http://en.wikipedia.org/wiki/Deep_learning", "type": "wiki", "score": 3, "label": {"eng": "Deep learning"}}, {"uri": "http://en.wikipedia.org/wiki/Curriculum", "type": "wiki", "score": 3, "label": {"eng": "Curriculum"}}, {"uri": "http://en.wikipedia.org/wiki/Bureaucracy", "type": "wiki", "score": 3, "label": {"eng": "Bureaucracy"}}, {"uri": "http://en.wikipedia.org/wiki/Business_model", "type": "wiki", "score": 3, "label": {"eng": "Business model"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/United_Kingdom", "type": "loc", "score": 3, "label": {"eng": "United Kingdom"}, "location": {"type": "country", "label": {"eng": "United Kingdom"}}}, {"uri": "http://en.wikipedia.org/wiki/Robotic_process_automation", "type": "wiki", "score": 2, "label": {"eng": "Robotic process automation"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 2, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Accounting", "type": "wiki", "score": 2, "label": {"eng": "Accounting"}}, {"uri": "http://en.wikipedia.org/wiki/Coursera", "type": "wiki", "score": 2, "label": {"eng": "Coursera"}}, {"uri": "http://en.wikipedia.org/wiki/Andrew_Ng", "type": "person", "score": 2, "label": {"eng": "Andrew Ng"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_vision", "type": "wiki", "score": 2, "label": {"eng": "Computer vision"}}, {"uri": "http://en.wikipedia.org/wiki/Natural_language_processing", "type": "wiki", "score": 2, "label": {"eng": "Natural language processing"}}, {"uri": "http://en.wikipedia.org/wiki/Stanford_University", "type": "org", "score": 2, "label": {"eng": "Stanford University"}}, {"uri": "http://en.wikipedia.org/wiki/University_of_Pennsylvania", "type": "org", "score": 1, "label": {"eng": "University of Pennsylvania"}}, {"uri": "http://en.wikipedia.org/wiki/Harvard_University", "type": "org", "score": 1, "label": {"eng": "Harvard University"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 1, "label": {"eng": "Google"}}], "categories": [{"uri": "news/Business", "label": "news/Business", "wgt": 61}], "image": "https://techround.co.uk/wp-content/uploads/2024/08/lewis-keegan-gkiZ-F3yPiY-unsplash-scaled.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3490196078431373, "wgt": 165, "relevance": 1}
{"uri": "8259393713", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "04:08:10", "dateTime": "2024-08-05T04:08:10Z", "dateTimePub": "2024-08-05T04:06:41Z", "dataType": "news", "sim": 0.6392157077789307, "url": "https://digiday.com/media-buying/ai-briefing-heres-how-ai-is-showing-up-during-this-earnings-cycle/", "title": "AI Briefing: Here's how AI is showing up during this earnings cycle", "body": "Despite warnings of an AI downturn and mixed signals in financial markets, Big Tech hasn't shied away from talking about AI this earnings season. This month, companies with big bets on AI have all shared quarterly results detailing how they're using AI-powered platforms for advertising, content creation and enterprise applications.\n\nRecent financial filings with the Securities and Exchange Commission reveal at least two dozen companies highlighted generative AI this month in quarterly results. Notable mentions include Google, Meta, Amazon, Microsoft, Pinterest, Coursera, IBM, Coinbase, Udemy and Confluent.\n\nAI was cited as a growth driver by martech companies like Zeta Global and Perion Network, measurement firms DoubleVerify and Integral Ad Science and ad-funded streaming companies like Spotify and SiriusXM. Even agency holding company IPG said AI is enhancing data and analytics services while generative AI will be \"equally fundamental\" for its broader offerings and through partnerships with companies like Blackbird.AI, Getty Images, and Adobe.\n\nDespite the optimism, Wall Street still isn't convinced that Big tech's big AI bets are paying off. Instead, massive AI players like Alphabet, Amazon and Microsoft have all seen share prices fall in the past two weeks. Meanwhile, Meta moved its expected 2024 capital expenditures even higher, increasing it from $35 billion to between $37 billion and $40 billion, largely due to spending further on AI.\n\nAccording to Gartner analyst Nicole Greene, a recent analysis of product announcements in 2023 from 11 leading tech companies -- including Microsoft, Google and Amazon Web Services -- found that 99% mentioned AI or generative AI. She also noted board conversations about generative AI are outpacing talks about cloud computing and happening 2.5 times more than talks about digital transformation.\n\n\"Large tech companies have built businesses on taking risks,\" said Greene. \"They have both the capital and culture to continue to invest in the potential. They are building out the infrastructure, data governance and workflows to support the future transformation that AI can bring to their business partners. Their partnerships and monetization of these future AI features and applications will ultimately determine when these early investments become profitable.\"\n\nHere's a look at some of the individual earnings highlights that focused on AI efforts:\n\nOn Meta's earnings call, CEO Mark Zuckerberg said more than 1 million advertisers in the past month have used at least one of Meta's generative AI ads tools for image expansion, background generation and text generation. He also noted recent AI-powered additions to automated ad platforms like Advantage Plus, which recently debuted a new AI images creation tool and additional conversation types. Other new AI features include AI agents for business and this week's debut of a new AI Studio for creators.\n\nZuckerberg also noted the progress Meta has made with its Llama family of AI large language models and improvements for content recommendation systems across its family of apps. Ray-Ban Meta glasses have also been \"a bigger hit sooner than we expected\" thanks to features like Meta AI.\n\nMeta execs are showing a renewed confidence as the company starts seeing some returns for advertisers. Meta's AI-enabled tools helped generate strong returns for advertisers, according to a research note by William Blair, which cited Advantage Plus driving average of 22% higher return on ad spend for U.S. advertisers. The report also noted Meta AI usage garnering billions of interactions while Meta's recommendation engines drove engagement across its Family of Apps including Reels engagement.\n\n\"In general, their tone is definitely increasingly bullish,\" said Ralph Schackart, an analyst with William Blair. \"I feel like they've sort of got the mojo back with their product momentum. You can hear it sort of in their voice inflection. At least to me, it feels like they're operating off the balls of their feet versus sort of leaning backwards.\"\n\nGoogle added more than 30 new AI-powered ad features and products in the second quarter across its platforms for Google Search, Performance Max and Demand Gen. Alphabet's quarterly results, released last week, also said 1.5 million developers are now using developer tools powered by Google Gemini while AI helped Google Cloud hit $1 billion in profit for the first time.\n\nCEO Sundar Pichai said Google is seeing progress for AI search features like AI Overviews, which he said is getting higher engagement from users ages 18-24. AI features increased average profit uplift for shopping campaigns by 15% and helped beta tests of virtual try-ons attract 60% more views for shopping ads. Google also said it used generative AI features to create nearly 4,500 variations for a campaign promoting the Pixel 8 smartphone across YouTube, Discover and Gmail. But despite the growing confidence, AI isn't changing all platform at the same pace.\n\n\"In terms of getting real generative audio, video experience is working well,\" Pichai told an analyst who asked about AI reaccelerating YouTube growth. \"I think there is still -- it's going to take some time. But over time, obviously, it will be deeply relevant to YouTube. And so, it's an area I'm excited about in the future.\"\n\nSchackart, the William Blair analyst, also noted that Google AI features are also gaining traction with advertisers. Ad buyers are seeing results with ads within AI Overview, Google's generative search feature, but some also expect increased ad prices for keywords within AI-powered search. He also noted organic traffic is also starting to \"wane a bit' as generative AI ads perform better than traditional Google search.\n\n\"Probably the biggest trend quarter to quarter is these companies are giving specifics on how Gen AI is impacting their ad businesses,\" Schackart said. \"I think before it was just conceptual, sort of the hope that these benefits would materialize after the big [capital expenditure] build out.\"\n\nAI-enabled products like Bing and Edge helped Microsoft see a 19% year-over-year increase in search and news ad revenue, excluding traffic acquisition costs, which Microsoft CEO Satya Nadella attributed to improved execution and \"healthy volume growth.\" He also said people have used Copilot to create more than 12 billion images and have 13 billion chats so far in 2024, a 150% increase since the start of the year.\n\nNadella also mentioned advertisers are using AI-enabled features to improve ad optimization and create campaigns with Copilot and Microsoft Performance Max. Microsoft said it now has 60,000 Azure AI customers, a year-over-year 60% increase, while its AI-powered data platform Microsoft Fabric has 14,000 paid customers for a 20% quarter-over-quarter increase.\n\nSnap reported a 16% year-over-year revenue increase to $1.2 billion for Q2 2024, driven by twice as many active advertisers, and growth for generative AI and augmented reality innovations. It also saw daily active users rise by 9% to 432 million while Snapchat+ subscriptions reached 11 million. Snap also noted generative AI augmented reality lenses had high engagement, including one made with with Beyonc\u00e9 for her \"Cowboy Carter\" album that was engaged with 80 million times in three days.\n\nOther ways AI came up in various earnings results and analyst calls:\n\nAI stories from across Digiday:", "source": {"uri": "digiday.com", "dataType": "news", "title": "Digiday"}, "authors": [{"uri": "marty_swant@digiday.com", "name": "Marty Swant", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 5, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_(company)", "type": "org", "score": 5, "label": {"eng": "Amazon (company)"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 5, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 5, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_AI", "type": "wiki", "score": 3, "label": {"eng": "Meta AI"}}, {"uri": "http://en.wikipedia.org/wiki/Big_Tech", "type": "wiki", "score": 3, "label": {"eng": "Big Tech"}}, {"uri": "http://en.wikipedia.org/wiki/Sirius_XM", "type": "wiki", "score": 3, "label": {"eng": "Sirius XM"}}, {"uri": "http://en.wikipedia.org/wiki/Adobe_Inc.", "type": "org", "score": 3, "label": {"eng": "Adobe Inc."}}, {"uri": "http://en.wikipedia.org/wiki/Coinbase", "type": "org", "score": 3, "label": {"eng": "Coinbase"}}, {"uri": "http://en.wikipedia.org/wiki/Alphabet_Inc.", "type": "org", "score": 3, "label": {"eng": "Alphabet Inc."}}, {"uri": "http://en.wikipedia.org/wiki/Recommender_system", "type": "wiki", "score": 3, "label": {"eng": "Recommender system"}}, {"uri": "http://en.wikipedia.org/wiki/Coursera", "type": "wiki", "score": 3, "label": {"eng": "Coursera"}}, {"uri": "http://en.wikipedia.org/wiki/Zeta_Global", "type": "org", "score": 3, "label": {"eng": "Zeta Global"}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_Web_Services", "type": "org", "score": 3, "label": {"eng": "Amazon Web Services"}}, {"uri": "http://en.wikipedia.org/wiki/Enterprise_software", "type": "wiki", "score": 3, "label": {"eng": "Enterprise software"}}, {"uri": "http://en.wikipedia.org/wiki/Digital_transformation", "type": "wiki", "score": 3, "label": {"eng": "Digital transformation"}}, {"uri": "http://en.wikipedia.org/wiki/Gartner", "type": "org", "score": 3, "label": {"eng": "Gartner"}}, {"uri": "http://en.wikipedia.org/wiki/IBM", "type": "org", "score": 3, "label": {"eng": "IBM"}}, {"uri": "http://en.wikipedia.org/wiki/Cloud_computing", "type": "wiki", "score": 3, "label": {"eng": "Cloud computing"}}, {"uri": "http://en.wikipedia.org/wiki/Analytics", "type": "wiki", "score": 3, "label": {"eng": "Analytics"}}, {"uri": "http://en.wikipedia.org/wiki/Wall_Street", "type": "wiki", "score": 3, "label": {"eng": "Wall Street"}}, {"uri": "http://en.wikipedia.org/wiki/Spotify", "type": "wiki", "score": 3, "label": {"eng": "Spotify"}}, {"uri": "http://en.wikipedia.org/wiki/Pinterest", "type": "wiki", "score": 3, "label": {"eng": "Pinterest"}}, {"uri": "http://en.wikipedia.org/wiki/Streaming_media", "type": "wiki", "score": 3, "label": {"eng": "Streaming media"}}, {"uri": "http://en.wikipedia.org/wiki/Getty_Images", "type": "org", "score": 3, "label": {"eng": "Getty Images"}}, {"uri": "http://en.wikipedia.org/wiki/Financial_market", "type": "wiki", "score": 3, "label": {"eng": "Financial market"}}, {"uri": "http://en.wikipedia.org/wiki/Holding_company", "type": "wiki", "score": 3, "label": {"eng": "Holding company"}}, {"uri": "http://en.wikipedia.org/wiki/Mark_Zuckerberg", "type": "person", "score": 3, "label": {"eng": "Mark Zuckerberg"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Advertising", "type": "wiki", "score": 3, "label": {"eng": "Advertising"}}, {"uri": "http://en.wikipedia.org/wiki/U.S._Securities_and_Exchange_Commission", "type": "wiki", "score": 3, "label": {"eng": "U.S. Securities and Exchange Commission"}}, {"uri": "http://en.wikipedia.org/wiki/Sundar_Pichai", "type": "person", "score": 1, "label": {"eng": "Sundar Pichai"}}, {"uri": "http://en.wikipedia.org/wiki/Satya_Nadella", "type": "person", "score": 1, "label": {"eng": "Satya Nadella"}}, {"uri": "http://en.wikipedia.org/wiki/Beyonc\u00e9", "type": "person", "score": 1, "label": {"eng": "Beyonc\u00e9"}}, {"uri": "http://en.wikipedia.org/wiki/Snapchat", "type": "org", "score": 1, "label": {"eng": "Snapchat"}}], "categories": [{"uri": "dmoz/Society/Issues/Business", "label": "dmoz/Society/Issues/Business", "wgt": 100}, {"uri": "dmoz/Society/Activism/Anti-Corporation", "label": "dmoz/Society/Activism/Anti-Corporation", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 70}], "image": "https://digiday.com/wp-content/uploads/sites/3/2023/09/ai-robot-digiday.jpeg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.2784313725490195, "wgt": 163, "relevance": 1}
{"uri": "8259423132", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "04:37:40", "dateTime": "2024-08-05T04:37:40Z", "dateTimePub": "2024-08-05T04:37:00Z", "dataType": "news", "sim": 0.6352941393852234, "url": "https://cyprus-mail.com/2024/08/05/ai-platforms-software-market-poised-for-strong-growth/", "title": "AI platforms software market poised for strong growth", "body": "The market for artificial intelligence (AI) platforms software experienced rapid growth in 2023 and is expected to maintain its remarkable momentum, driven by the increasing adoption of AI across numerous industries, according to market intelligence firm IDC.\n\nIDC's latest forecast projects that worldwide revenue for AI platforms software will reach $153.0 billion by 2028, with a compound annual growth rate (CAGR) of 40.6 per cent over the 2023-2028 forecast period.\n\n\"The AI platforms market shows no signs of slowing down. Rapid innovations in generative AI are changing how companies think about their products, how they develop and deploy AI applications, and how they leverage technology for reinventing their business models and competitive positioning,\" said Ritu Jyoti, group vice president and general manager of IDC's Artificial Intelligence, Automation, Data and Analytics research.\n\n\"IDC expects this upward trajectory will continue to accelerate with the emergence of unified platforms for predictive and generative AI that support interoperating APIs, ecosystem extensibility, and responsible AI adoption at scale,\" Jyoti added.\n\nMoreover, AI adoption soared to new heights in 2023, with worldwide AI platform software revenue growing 44.4 per cent year-over-year to $27.9 billion, according to IDC's 'Worldwide Artificial Intelligence Platforms Software Market Shares, 2023' report.\n\nMicrosoft led the AI platforms software market due to its robust and comprehensive offerings and its vast ecosystem of products and services.\n\nMicrosoft's AI solutions are deeply integrated into its popular software and cloud services, providing a seamless experience for businesses and developers alike.\n\nPalantir, OpenAI, Google, and Amazon Web Services rounded out the top five AI platform software providers in 2023.\n\nFurthermore, according to IDC, half of the organisations currently deploying generative AI in production have already selected an AI platform, while most organisations that have initiated significant investments plan to do so in the next six months.\n\n\"AI has the potential to enhance user experience, optimise advertising, personalise content, and improve data analytics. These advancements can drive increased online activity and commerce, leading to positive economic impacts,\" said Raghunandan Kuppuswamy, research manager, Artificial Intelligence and Automation at IDC.\n\n\"However, AI also presents significant risks. Organisations need to identify patterns and anomalies, recognise potential risks, and remediate problems before they become widespread,\" Kuppuswamy.\n\nThe research manager also stated that \"while not all risks can be removed, risk mitigation can be accelerated using AI itself, providing better security and resilience for customers\".\n\nThe company also stated that AI platforms facilitate the development and deployment of AI models and applications, including intelligent assistants that may mimic human cognitive abilities.\n\nThe technology components of AI platforms include machine learning (ML), deep learning, generative AI (GenAI), natural language processing (NLP), text analytics, rich media analytics, tagging, searching, categorisation, clustering, hypothesis generation, question answering, visualisation, filtering, alerting, and navigation.\n\nThe AI platforms market comprises three functional markets. These include AI life-cycle software, AI software services, and search and knowledge discovery software.\n\nIDC expects cloud-based deployments of AI platforms software to grow at a faster rate than on-premises deployments, with revenue from AI platforms in the public cloud forecast to have a five-year CAGR of 50.9 per cent.\n\n\"This trend is attributed to the advanced security measures, data and regulatory compliance, and the scalability capabilities that cloud vendors offer,\" the company said in a report.\n\n\"With the rapid advancement of technology and the growing demand for AI solutions from businesses across industries, cloud-based deployment of AI platforms software is expected to continue expanding at a rapid rate,\" IDC concluded.", "source": {"uri": "cyprus-mail.com", "dataType": "news", "title": "Cyprus Mail"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/International_Data_Group", "type": "org", "score": 5, "label": {"eng": "International Data Group"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 5, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Compound_annual_growth_rate", "type": "wiki", "score": 4, "label": {"eng": "Compound annual growth rate"}}, {"uri": "http://en.wikipedia.org/wiki/Ecosystem", "type": "wiki", "score": 4, "label": {"eng": "Ecosystem"}}, {"uri": "http://en.wikipedia.org/wiki/Applications_of_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Applications of artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Automation", "type": "wiki", "score": 3, "label": {"eng": "Automation"}}, {"uri": "http://en.wikipedia.org/wiki/Vice_president", "type": "wiki", "score": 3, "label": {"eng": "Vice president"}}, {"uri": "http://en.wikipedia.org/wiki/Business_model", "type": "wiki", "score": 3, "label": {"eng": "Business model"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 3, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/API", "type": "wiki", "score": 2, "label": {"eng": "API"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 2, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_Web_Services", "type": "org", "score": 2, "label": {"eng": "Amazon Web Services"}}, {"uri": "http://en.wikipedia.org/wiki/User_experience", "type": "wiki", "score": 2, "label": {"eng": "User experience"}}, {"uri": "http://en.wikipedia.org/wiki/Cloud_computing", "type": "wiki", "score": 2, "label": {"eng": "Cloud computing"}}, {"uri": "http://en.wikipedia.org/wiki/Analytics", "type": "wiki", "score": 2, "label": {"eng": "Analytics"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 2, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Advertising", "type": "wiki", "score": 2, "label": {"eng": "Advertising"}}, {"uri": "http://en.wikipedia.org/wiki/Question_answering", "type": "wiki", "score": 1, "label": {"eng": "Question answering"}}, {"uri": "http://en.wikipedia.org/wiki/Cluster_analysis", "type": "wiki", "score": 1, "label": {"eng": "Cluster analysis"}}, {"uri": "http://en.wikipedia.org/wiki/Text_mining", "type": "wiki", "score": 1, "label": {"eng": "Text mining"}}, {"uri": "http://en.wikipedia.org/wiki/Knowledge_extraction", "type": "wiki", "score": 1, "label": {"eng": "Knowledge extraction"}}, {"uri": "http://en.wikipedia.org/wiki/Interactive_media", "type": "wiki", "score": 1, "label": {"eng": "Interactive media"}}], "categories": [{"uri": "dmoz/Computers/Software/Human_Resources", "label": "dmoz/Computers/Software/Human Resources", "wgt": 100}, {"uri": "dmoz/Computers/Software/Marketing", "label": "dmoz/Computers/Software/Marketing", "wgt": 100}, {"uri": "dmoz/Computers/Software/Business", "label": "dmoz/Computers/Software/Business", "wgt": 100}, {"uri": "dmoz/Business/Management/Strategy_and_Forecasting", "label": "dmoz/Business/Management/Strategy and Forecasting", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 97}], "image": "https://cms.cyprus-mail.com/wp-content/uploads/2024/07/AI-IDC.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.5137254901960784, "wgt": 162, "relevance": 1}
{"uri": "8259974569", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "11:19:08", "dateTime": "2024-08-05T11:19:08Z", "dateTimePub": "2024-08-05T11:18:39Z", "dataType": "news", "sim": 0.6352941393852234, "url": "https://www.twobirds.com/en/events/uk/2024/ai-bootcamp-for-consumer-facing-businesses", "title": "AI Bootcamp for Consumer-Facing Businesses", "body": "Do you want to find out more about AI, make sure you're getting it right and understand how others are implementing it?\n\nJoin us for an AI bootcamp on 15 October where Uwais Iqbal (Founder at Simplexico - The Legal AI Consultancy) will introduce you to AI from a conceptual standpoint to better appreciate the technology and also dive into AI topics relevant to consumer-facing businesses like yours. Bird & Bird experts will also share the latest updates on AI and employment, contracting for AI and the EU AI Act.\n\nThis bootcamp will help you understand the relevance and potential of AI within your business and give you insights on how AI is being implemented across retail & consumer businesses.\n\nWe're delighted to also offer all attendees the opportunity to register for a complimentary 30-minute consultation with Bird & Bird's AI legal experts following the event. We hope you're able to join us!", "source": {"uri": "twobirds.com", "dataType": "news", "title": "Bird & Bird"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/European_Union", "type": "loc", "score": 1, "label": {"eng": "European Union"}, "location": null}], "categories": [{"uri": "dmoz/Recreation/Birding", "label": "dmoz/Recreation/Birding", "wgt": 100}, {"uri": "dmoz/Recreation/Birding/North_America", "label": "dmoz/Recreation/Birding/North America", "wgt": 100}, {"uri": "dmoz/Recreation/Birding/Europe", "label": "dmoz/Recreation/Birding/Europe", "wgt": 100}, {"uri": "dmoz/Shopping/Pets/Birds", "label": "dmoz/Shopping/Pets/Birds", "wgt": 100}, {"uri": "dmoz/Recreation/Birding/Caribbean", "label": "dmoz/Recreation/Birding/Caribbean", "wgt": 100}], "image": "https://www.twobirds.com/-/media/twobirdssite/logos/bird-and-bird-open-graph-image.png?h=272&iar=0&w=570&hash=181066BBF268E3D4D4FD1462EED6FBC4", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "date": "-10-15", "textStart": 151, "textEnd": 161}], "sentiment": 0.5764705882352941, "wgt": 162, "relevance": 1}
{"uri": "8259770705", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "09:10:27", "dateTime": "2024-08-05T09:10:27Z", "dateTimePub": "2024-08-05T09:09:43Z", "dataType": "news", "sim": 0.6313725709915161, "url": "https://betanews.com/2024/08/05/how-genai-is-changing-business-and-society-qa/", "title": "How GenAI is changing business and society [Q&A]", "body": "Generative AI started out as a bit of a novelty, allowing you to create writing or artwork based on simple prompts. But increasingly it's having an impact on many areas of the world, from writing code to composing music and aiding research.\n\nIn a new book, Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society, futurist and thought leader Bernard Marr takes a closer look at the impact of GenAI. We talked to him to find out more.\n\nBN: Could generative AI be one of the most groundbreaking technologies we've ever developed?\n\nBM: Absolutely, generative AI is poised to be one of the most groundbreaking technologies we've ever developed. Its ability to generate new content -- whether that's text, images, music, or even complex simulations -- opens up unprecedented opportunities for creativity, efficiency, and problem-solving. This technology can perform tasks that were previously thought to be exclusively within the realm of human capabilities, such as creative writing and artistic creation, making it a transformative force across many domains. For instance, in research and development, generative AI can simulate numerous scenarios and outcomes, significantly speeding up the innovation process. Additionally, its potential to automate routine tasks allows professionals to focus on more strategic and creative aspects of their work, thus enhancing productivity and innovation across various fields.\n\nBN: Which sectors are seeing the influence of AI most?\n\nBM: Generative AI is making significant inroads across a variety of sectors. In healthcare, it's being used to create personalized treatment plans and assist in medical research by generating hypotheses and analyzing data at a scale and speed that humans cannot match. This can lead to quicker discoveries of new treatments and more effective patient care. In finance, AI is improving risk assessment, fraud detection, and customer service through intelligent chatbots that can handle customer inquiries and transactions more efficiently. The entertainment industry is also being revolutionized, with AI helping to create music, scripts, and even entire virtual worlds, providing new forms of content and experiences. Additionally, education is seeing AI-driven personalized learning experiences that adapt to individual student needs, and marketing is leveraging AI for hyper-personalized customer interactions and content generation, which can significantly improve engagement and conversion rates.\n\nBN: How can we address concerns around deepfakes, misinformation, etc?\n\nBM: Addressing concerns around deepfakes and misinformation requires a multi-faceted approach. First, we need robust technical solutions that can detect and flag AI-generated content. This involves developing advanced algorithms and tools that can identify inconsistencies and traces of AI manipulation. Second, there should be clear regulatory frameworks and guidelines that govern the ethical use of AI technologies. These regulations should mandate transparency in AI-generated content, requiring clear labeling and accountability. Third, public awareness and education are crucial. People need to be informed about the potential for AI to create false information and how to critically evaluate the content they encounter. Collaboration between tech companies, governments, and educational institutions is essential to create a comprehensive strategy against these risks. Furthermore, investment in continuous research to stay ahead of malicious actors who may exploit AI is necessary to ensure long-term effectiveness.\n\nBN: Isn't there a risk of harm to creative pursuits like writing and musical composition?\n\nBM: There is certainly a concern that generative AI might disrupt traditional creative pursuits. However, I believe AI can also serve as a powerful tool for artists and writers. Instead of replacing human creativity, AI can augment it by offering new perspectives, generating ideas, and automating repetitive tasks. This allows creatives to focus more on the aspects of their work that require a human touch -- emotion, nuance, and storytelling. Additionally, AI can democratize creativity by providing tools and resources to individuals who may not have had access to traditional artistic training. For example, an aspiring musician without formal training can use AI to compose music, opening up new avenues for artistic expression and discovery. The key is to view AI as a collaborator rather than a competitor in the creative process.\n\nBN: How can we ensure that the benefits of generative AI are distributed equitably across different socio-economic groups?\n\nBM: As generative AI becomes more prevalent, it is essential to address the digital divide and ensure its benefits are accessible to all. This involves investing in education to teach AI literacy, building digital infrastructure in underserved areas, and creating inclusive AI solutions that consider the needs of diverse populations. Public-private partnerships can accelerate the deployment of AI benefits, while policies promoting digital inclusion and protecting against bias are crucial. Engaging directly with communities to understand their specific needs and empowering local leaders and organizations can create tailored programs that address unique barriers. By implementing these strategies, we can work towards a more equitable distribution of the benefits of generative AI, ensuring it serves as a tool for inclusion and empowerment.\n\nBN: How do you think we'll see generative AI evolve in the next few years?\n\nBM: In the next few years, generative AI will become more sophisticated and integrated into various aspects of our lives. We will see advancements in its ability to understand context and produce more coherent and relevant outputs. AI will become more accessible, with user-friendly interfaces that allow people with no technical background to harness its power. We can also expect to see generative AI playing a crucial role in solving complex global challenges, such as climate change, by simulating scenarios and generating innovative solutions. Moreover, as AI ethics and governance frameworks evolve, we will develop better ways to manage the risks associated with AI, ensuring it is used responsibly and for the benefit of all. Businesses will increasingly adopt AI to drive efficiency and innovation, and we might even see AI-generated content becoming a standard in media and entertainment. The possibilities are truly vast and exciting.", "source": {"uri": "betanews.com", "dataType": "news", "title": "BetaNews"}, "authors": [{"uri": "ian_barker@betanews.com", "name": "Ian Barker", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Barisan_Nasional", "type": "org", "score": 5, "label": {"eng": "Barisan Nasional"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Creativity", "type": "wiki", "score": 4, "label": {"eng": "Creativity"}}, {"uri": "http://en.wikipedia.org/wiki/Deepfake", "type": "wiki", "score": 3, "label": {"eng": "Deepfake"}}, {"uri": "http://en.wikipedia.org/wiki/Misinformation", "type": "wiki", "score": 3, "label": {"eng": "Misinformation"}}, {"uri": "http://en.wikipedia.org/wiki/Futurist", "type": "wiki", "score": 3, "label": {"eng": "Futurist"}}, {"uri": "http://en.wikipedia.org/wiki/Problem_solving", "type": "wiki", "score": 3, "label": {"eng": "Problem solving"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 3, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Health_care", "type": "wiki", "score": 3, "label": {"eng": "Health care"}}, {"uri": "http://en.wikipedia.org/wiki/Research_and_development", "type": "wiki", "score": 3, "label": {"eng": "Research and development"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 2, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Medical_research", "type": "wiki", "score": 2, "label": {"eng": "Medical research"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 2, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_world", "type": "wiki", "score": 2, "label": {"eng": "Virtual world"}}, {"uri": "http://en.wikipedia.org/wiki/Hypothesis", "type": "wiki", "score": 2, "label": {"eng": "Hypothesis"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 2, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Customer_service", "type": "wiki", "score": 2, "label": {"eng": "Customer service"}}, {"uri": "http://en.wikipedia.org/wiki/Finance", "type": "wiki", "score": 2, "label": {"eng": "Finance"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 2, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Risk_assessment", "type": "wiki", "score": 2, "label": {"eng": "Risk assessment"}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Health/Mental_Health/Self-Help", "label": "dmoz/Health/Mental Health/Self-Help", "wgt": 100}, {"uri": "dmoz/Society/Work/Rethinking_Work", "label": "dmoz/Society/Work/Rethinking Work", "wgt": 100}, {"uri": "dmoz/Society/Activism/In_Daily_Life", "label": "dmoz/Society/Activism/In Daily Life", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 71}], "image": "https://betanews.com/wp-content/uploads/2024/06/Artificial-intelligence-1.jpg?w=640", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3803921568627451, "wgt": 161, "relevance": 1}
{"uri": "8259303849", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "02:15:35", "dateTime": "2024-08-05T02:15:35Z", "dateTimePub": "2024-08-05T02:14:17Z", "dataType": "news", "sim": 0.6313725709915161, "url": "https://ciosea.economictimes.indiatimes.com/news/security/protect-ai-raises-60m-in-series-b-funding/112274610", "title": "Protect AI raises $60M in Series B funding - ET CIO SEA", "body": "Security 3 min read Protect AI raises $60M in Series B funding Protect AI will use the new financing to drive the next phase of innovation and capabilities for its customers, enhancing its AI security posture management platform. Protect AI, a leading artificial intelligence (AI) and machine learning (ML) security company, recently announced it has closed a $60M Series B round of funding led by Evolution Equity Partners with participation from 01 Advisors, StepStone Group, Samsung, and existing investors Acrew Capital, boldstart ventures, Knollwood Capital, Pelion Ventures, and Salesforce Ventures. To date, the company has raised a total of $108.5M to help organisations protect ML systems and AI applications from unique security vulnerabilities and emerging threats.\n\nProtect AI will use the new financing to drive the next phase of innovation and capabilities for its customers, enhancing its AI security posture management platform. This capital infusion will accelerate the company's growth by expanding customer success and sales resources, advancing R&D, and strengthening channel programs. Protect AI is positioned to extend its lead in the AI security market, providing unmatched protection for AI applications and systems worldwide.\n\n\"In less than 12 months Protect AI has built the leading AI security platform in the market by addressing AI risks end-to-end,\" said Richard Seewald, Founder and Managing Partner at Evolution Equity Partners. \"By focusing on comprehensive AI security posture management that spans ML models, LLMs and AI supply chain threats, the company is now a trusted partner for national security organisations and Fortune 500 customers, alike.\"\n\nSince raising $35M in Series A funding one year ago, Protect AI has solidified its leadership in the AI security market. The Protect AI security posture management (AI-SPM) platform is now used by private and public sector customers to secure traditional ML models, LLMs, ML systems, and AI applications. The platform has expanded from one to five products, becoming the most comprehensive end-to-end AI security solution available.\n\nThe company's huntr AI/ML threat research community has grown to more than 15,000 members who identify and fix vulnerabilities in crucial AI/ML supply chain projects. Protect AI's five open-source offerings have been downloaded millions of times, and MLSecOps.com continues to lead AI security education and knowledge sharing. With four acquisitions to date -- Rebuff, Huntr, Laiyer AI, and Syde Labs -- and a 300% year-over-year team growth, Protect AI plans to add 50 more employees by the end of 2024.\n\n\"AI is being deployed across every industry at an accelerating pace, and organisations have realised they need security guardrails for these systems that are not being covered by incumbent security providers,\" said Ian Swanson, Co-Founder and CEO of Protect AI. \"This additional funding provides the resources to extend our technology lead by providing even more unique AI security capabilities for every element of AI-SPM, at every stage of the AI development lifecycle, and serve customers across the globe. Our mission is to lead the AI security category for years to come and help customers build a safer AI-powered world.\"\n\nAI Security Posture Management, or AI-SPM, is the practice of continuously monitoring, managing, and improving the security of AI systems and their components. It involves identifying vulnerabilities, ensuring compliance with security policies, and implementing measures to protect AI models and data throughout their lifecycle. With AI-SPM, companies can ensure their AI systems operate securely and reliably, minimising risks of breaches, misuse, and other security threats.\n\nProtect AI's industry-leading AI-SPM solution offers comprehensive security capabilities such as Guardian, which scans internally built ML models and externally acquired models for threats, and Layer which is a dedicated GenAI security tool designed for LLM security, observability, and governance. Additional services include Radar, providing AI/ML bill of materials with a robust policy engine, and Sightline, which is an AI/ML threat feed derived from the unique supply chain research discovered by the 15K+ Protect AI huntr community.", "source": {"uri": "ciosea.economictimes.indiatimes.com", "dataType": "news", "title": "ETCIO.com"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Applications_of_artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Applications of artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 5, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Equity_(finance)", "type": "wiki", "score": 4, "label": {"eng": "Equity (finance)"}}, {"uri": "http://en.wikipedia.org/wiki/Salesforce", "type": "wiki", "score": 3, "label": {"eng": "Salesforce"}}, {"uri": "http://en.wikipedia.org/wiki/Venture_round", "type": "wiki", "score": 3, "label": {"eng": "Venture round"}}, {"uri": "http://en.wikipedia.org/wiki/Venture_capital_financing", "type": "wiki", "score": 3, "label": {"eng": "Venture capital financing"}}, {"uri": "http://en.wikipedia.org/wiki/Supply_chain", "type": "wiki", "score": 3, "label": {"eng": "Supply chain"}}, {"uri": "http://en.wikipedia.org/wiki/Vulnerability_(computing)", "type": "wiki", "score": 3, "label": {"eng": "Vulnerability (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/Samsung", "type": "org", "score": 3, "label": {"eng": "Samsung"}}, {"uri": "http://en.wikipedia.org/wiki/Research_and_development", "type": "wiki", "score": 3, "label": {"eng": "Research and development"}}, {"uri": "http://en.wikipedia.org/wiki/Partner_(business_rank)", "type": "wiki", "score": 2, "label": {"eng": "Partner (business rank)"}}, {"uri": "http://en.wikipedia.org/wiki/Series_A_round", "type": "wiki", "score": 2, "label": {"eng": "Series A round"}}, {"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 2, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Public_sector", "type": "wiki", "score": 2, "label": {"eng": "Public sector"}}, {"uri": "http://en.wikipedia.org/wiki/Fortune_500", "type": "wiki", "score": 2, "label": {"eng": "Fortune 500"}}, {"uri": "http://en.wikipedia.org/wiki/National_security", "type": "wiki", "score": 2, "label": {"eng": "National security"}}, {"uri": "http://en.wikipedia.org/wiki/Master_of_Laws", "type": "wiki", "score": 1, "label": {"eng": "Master of Laws"}}, {"uri": "http://en.wikipedia.org/wiki/Bill_of_materials", "type": "wiki", "score": 1, "label": {"eng": "Bill of materials"}}, {"uri": "http://en.wikipedia.org/wiki/Radar", "type": "wiki", "score": 1, "label": {"eng": "Radar"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Business/Business_Services/Fire_and_Security", "label": "dmoz/Business/Business Services/Fire and Security", "wgt": 100}, {"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 100}, {"uri": "dmoz/Computers/Security/Policy", "label": "dmoz/Computers/Security/Policy", "wgt": 100}, {"uri": "dmoz/Business/Accounting/Business-to-Business", "label": "dmoz/Business/Accounting/Business-to-Business", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 56}], "image": "https://etimg.etb2bimg.com/thumb/msid-112274610,imgsize-721508,width-1200,height=765,overlay-etciosea/news/security/protect-ai-raises-60m-in-series-b-funding.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.6784313725490196, "wgt": 161, "relevance": 1}
{"uri": "2024-08-444009910", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "03:00:57", "dateTime": "2024-08-05T03:00:57Z", "dateTimePub": "2024-08-05T03:00:00Z", "dataType": "news", "sim": 0.6235294342041016, "url": "https://www.analyticsinsight.net/artificial-intelligence/emerging-careers-in-ai-ethics-compliance", "title": "Emerging Careers in AI Ethics & Compliance", "body": "Education: The AI safety development engineer shall have a background in computer science, engineering, or related fields, with experience in AI and safety engineering. Advanced degrees or certifications in AI safety or risk management will be advantageous. Experience in developing or auditing safety protocols for AI systems will also be desirable.\n\nEthics and Compliance with AI is a developing field and a critical frontier in the technology industry. This might, in particular, be so as current AI systems find increasing applications in almost every walk of life and therefore, due to this, the demand for professionals sailing through the complex landscape of ethics and regulatory requirements would only increase. AI ethics and compliance careers are significant, not just because they go straight to the heart of ensuring that AI technologies are developed and deployed responsibly, but also since they afford human beings the opportunity to shape future technology in a fashion befitting human values and social mores.\n\nThe roles within this field are numerous and varied, changing into an ethical AI officer and compliance analyst, much like the character of AI itself. As the awareness in organizations towards matters of ethics and compliance in the development of AI increases, such professionals will be major drivers for building trust, transparency, and accountability in AI systems. This new career avenue brings great professional growth and impact but underlines the much-needed human touch in guiding technological advancements towards betterment.", "source": {"uri": "analyticsinsight.net", "dataType": "news", "title": "Analytics Insight"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/AI_safety", "type": "wiki", "score": 5, "label": {"eng": "AI safety"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 5, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Safety_engineering", "type": "wiki", "score": 3, "label": {"eng": "Safety engineering"}}, {"uri": "http://en.wikipedia.org/wiki/Risk_management", "type": "wiki", "score": 3, "label": {"eng": "Risk management"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_science", "type": "wiki", "score": 3, "label": {"eng": "Computer science"}}, {"uri": "http://en.wikipedia.org/wiki/Engineering", "type": "wiki", "score": 3, "label": {"eng": "Engineering"}}, {"uri": "http://en.wikipedia.org/wiki/Audit", "type": "wiki", "score": 3, "label": {"eng": "Audit"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Ethics of artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 1, "label": {"eng": "Accountability"}}], "categories": [{"uri": "dmoz/Society/Philosophy/Ethics", "label": "dmoz/Society/Philosophy/Ethics", "wgt": 29}, {"uri": "dmoz/Computers/Ethics", "label": "dmoz/Computers/Ethics", "wgt": 28}, {"uri": "dmoz/Science/Science_in_Society/Research_Ethics", "label": "dmoz/Science/Science in Society/Research Ethics", "wgt": 26}, {"uri": "dmoz/Business/Management/Ethics", "label": "dmoz/Business/Management/Ethics", "wgt": 28}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 31}], "image": "https://media.assettype.com/analyticsinsight%2F2024-08%2F811940d1-1ccf-437c-85cf-a35fd7306a47%2FEmerging-Careers-in-AI-Ethics-and-Compliance.jpg?w=1200&ar=40%3A21&auto=format%2Ccompress&ogImage=true&mode=crop&enlarge=true&overlay=false&overlay_position=bottom&overlay_width=100", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3647058823529412, "wgt": 159, "relevance": 1}
{"uri": "8260054340", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "12:09:06", "dateTime": "2024-08-05T12:09:06Z", "dateTimePub": "2024-08-05T12:08:35Z", "dataType": "news", "sim": 0.6235294342041016, "url": "https://www.informationweek.com/machine-learning-ai/faceoff-auditable-ai-versus-the-ai-blackbox-problem", "title": "Faceoff: Auditable AI Versus the AI Blackbox Problem", "body": "Fears surrounding artificial intelligence are all based on one of two types of ignorance. The first is borne from imagination and sci-fi lore in the heads of those who do not understand what AI is and isn't. The second is borne from a true lack of information, specifically the inability of anyone skilled in AI to see what models are doing to arrive at individual decisions -- the infamous and impenetrable AI black box. Companies that can't see how AI is making each decision are at risk financially, reputationally, and legally. The prevailing atmosphere of ignorance -- one formed from illogical fear and the other from a lack of information -- is untenable. But breaking the AI black box seems undoable. And yet remarkable progress has been made in making AI auditable -- an important step in coaxing AI to reveal its secrets.\n\n\"The notion of auditable AI extends beyond the principles of responsible AI, which focuses on making AI systems robust, explainable, ethical, and efficient. While these principles are essential, auditable AI goes a step further by providing the necessary documentation and records to facilitate regulatory reviews and build confidence among stakeholders, including customers, partners, and the general public,\" says Adnan Masood, PhD, chief AI architect at UST, a global provider of digital solutions, platforms, product engineering, and innovation services. Masood is also a visiting scholar at the Stanford AI Lab where he works closely with academia and industry.\n\nRelated:NFL IT Leader on How the League Uses AI, Data Analytics\n\nBut how can auditable AI exist in the absence of explainable AI? How can you audit something you can't track?\n\n\"The answer to these questions depends on whether you're talking simply about auditing AI inputs and outputs, because that is easy. Or are we talking about auditing for transparency and explainability of the AI itself, which is very difficult?\" says Kristof Horompoly, VP, AI Risk Management at ValidMind, an AI model risk management company.\n\nTime to take a hard look at AI auditing options and consider FICO as a case study for succeeding by creating their own unique path to auditing AI to safeguard everyone's credit scores.\n\nFirst, consider that not all AI systems are created equally, and neither are their builders or users. This means that auditing types, methods, and levels of difficulty can and do vary.\n\n\"There are a few different types of AI audits. One type is a fairly standard organizational governance audit where auditors will be looking for adherence to an organization's own AI policies,\" explains Andrew Gamino-Cheong, CTO & co-founder at Trustible, a provider of responsible AI governance software.\n\nRelated:How to Identify Innovation Opportunities In-House and Externally\n\nAs an example, Gamino-Cheong points to the recently published ISO 42001 standard, which he says is \"heavily focused on this kind of organizational level audit.\" This type of AI audit, he explains, consists of showing paper trails of approvals, good quality documentation, and evidence of appropriate controls.\n\n\"In contrast, there is also a highly technical, model-level audit. For example, the NYC Local Law 144 for AI bias in hiring system requires a model-level audit where the developer must prove that their model passes certain statistical tests,\" Gamino-Cheong adds.\n\nMethods vary as well, but generally come from two main approaches: input and output logs, or training data governance.\n\n\"There are two sides of auditing: the training data side, and the output side. The training data side includes where the data came from, the rights to use it, the outcomes, and whether the results can be traced back to show reasoning and correctness,\" says Kevin Marcus, CTO at Versium, a data tools and marketing platform provider.\n\n\"The output side is trickier. Some algorithms, such as neural networks, are not explainable, and it is difficult to determine why a result is being produced. Other algorithms such as tree structures enable very clear traceability to show how a result is being produced,\" Marcus adds.\n\nRelated:Salary Report: IT in Choppy Economic Seas and Roaring Winds of Change\n\nToday, many companies -- specifically those in less regulated industries -- rely on I/O logs as their audit trail.\n\n\"To me, an audit trail just means there's a log of what happened when, but it [the log] won't go into what happened between the input and the output,\" says ValidMind's Horompoly.\n\nIn other words, the black box, which contains everything that happened between the input and the output, remains intact. In this method, it is the results in relation to the query that are audited, not the calculations that rendered the output. Auditing what happens there remains the supreme challenge. It's even more of a challenge in generative AI models.\n\n\"Traditional machine learning models, like linear regression and decision trees, are easier to audit and explain due to their transparency. In contrast, large language models (LLMs) using neural networks are more opaque, making it challenging to trace and understand their decision-making processes,\" says Stephen Drew, chief AI officer at RNL, a provider of higher education enrollment management, student success, and fundraising products and services.\n\n\"For this reason, we try to avoid cracking walnuts with sledgehammers, meaning that we use LLMs when needed but always strive to solve problems with AI models using the simplest and most explainable architecture for the task,\" Drew adds.\n\nDespite the challenges, some companies are making serious headway in a number of novel approaches.\n\nTake for example, FICO, the company the world relies on for credit risk scoring services. The company started working with analytics and massive amounts of data as far back as the 1950s. The now famous FICO scores hit the scene around 1989, some seven years after the company started releasing neural network technologies to detect financial fraud. To say that FICO has a long history in operationalizing AI, machine learning, and analytics is an understatement.\n\nToday, Scott Zoldi is the chief analytics officer at FICO after working up the ranks over the past 25 years and counting. By all accounts, he's an extremely active AI researcher. During his quarter century of service at FICO, he has focused on the development of unique algorithms to meet specific AI and machine learning requirements for its customers, which are largely financial institutions. He also authored about 138 patents for FICO in that same amount of time.\n\n\"Back when I was a student, it was all about trying to find order in chaos. And that kind of describes my daily life here at FICO sometimes with data. I have this fundamental belief that behind all data is structure. And it's up to us to find that structure that explains behavior. And if we can do that, then you have models that are predictive, and you can use these tools to make decisions,\" Zoldi says.\n\nBut that, of course, is easier said than done. After years of working with various types of AI, FICO has honed a unique method of developing AI models that meet strict criteria in accountability and fairness before they are deployed.\n\n\"We have a very narrow path of how we develop models, because I can't have 400 data scientists building models in 400 different ways, right? They have to be built to a standard. And that standard then is codified on the blockchain,\" he explains.\n\nThe process FICO uses goes like this:\n\n\"I assign who's going to do the work, who's going to test that each task was done properly, and who's going to verify that both the AI scientist and the tester did their work properly? All of that information is on the blockchain,\" Zoldi says.\n\n\"Now, if it's done incorrectly, it's on the blockchain. If it's done correctly, it's on the blockchain. But it is an immutable record of exactly how the model development standard was followed and where the success criteria is met or not. And we can turn that over to a governance team, to a regulator, or to a legal team to inspect so that there's no debate about what's in the model,\" Zoldi adds.\n\nIf a model fails at any step it is returned for further evaluation or revisions, or it's discarded. An AI model is not deployed unless it passes on every step.\n\n\"The benefits of auditable AI are significant. We're looking at increased transparency and trust, better risk management, improved regulatory compliance, enhanced ability to identify and correct biases, and greater accountability in AI decision-making,\" says Vall Herard, CEO at Saifr, an AI fintech company.\n\n\"However, we must also acknowledge the challenges. The complexity of AI systems, especially LLMs, the resource-intensive nature of audit tools, the rapidly evolving field requiring constant updates, lack of standardized procedures and the need for specialized expertise are all hurdles we face,\" Herard adds.\n\nDeveloping explainable AI remains the holy grail and many an AI team is on a quest to find it. Until then, several efforts are underway to develop various ways to audit AI in order to have a stronger grip over its behavior and performance. Unfortunately, there aren't enough people working on this issue.\n\n\"Auditable AI is the starting point of all forms of existing and future AI regulation. Unfortunately, its existence is also far too rare outside of advanced data science teams in heavily regulated industries like financial services, insurance, and biopharma,\" says Kjell Carlsson, PhD, head of AI strategy at Domino Data Lab.\n\nThere's been a lot of lip service about Responsible AI which far too often turns out to be little more than a lot of marketing hot air. Keep an eye out for proof that the AI being used is performing as billed.", "source": {"uri": "informationweek.com", "dataType": "news", "title": "InformationWeek"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Black_box", "type": "wiki", "score": 5, "label": {"eng": "Black box"}}, {"uri": "http://en.wikipedia.org/wiki/FICO", "type": "org", "score": 5, "label": {"eng": "FICO"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Audit", "type": "wiki", "score": 5, "label": {"eng": "Audit"}}, {"uri": "http://en.wikipedia.org/wiki/Explainable_artificial_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Explainable artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 4, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Information_technology", "type": "wiki", "score": 4, "label": {"eng": "Information technology"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_technology_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief technology officer"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 3, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Doctor_of_Philosophy", "type": "wiki", "score": 3, "label": {"eng": "Doctor of Philosophy"}}, {"uri": "http://en.wikipedia.org/wiki/Stakeholder_(corporate)", "type": "wiki", "score": 3, "label": {"eng": "Stakeholder (corporate)"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 3, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_neural_network", "type": "wiki", "score": 3, "label": {"eng": "Artificial neural network"}}, {"uri": "http://en.wikipedia.org/wiki/Credit_score", "type": "wiki", "score": 3, "label": {"eng": "Credit score"}}, {"uri": "http://en.wikipedia.org/wiki/Analytics", "type": "wiki", "score": 3, "label": {"eng": "Analytics"}}, {"uri": "http://en.wikipedia.org/wiki/Vice_president", "type": "wiki", "score": 3, "label": {"eng": "Vice president"}}, {"uri": "http://en.wikipedia.org/wiki/Engineering", "type": "wiki", "score": 3, "label": {"eng": "Engineering"}}, {"uri": "http://en.wikipedia.org/wiki/Stanford_University", "type": "org", "score": 3, "label": {"eng": "Stanford University"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Atmosphere", "type": "wiki", "score": 3, "label": {"eng": "Atmosphere"}}, {"uri": "http://en.wikipedia.org/wiki/Architecture", "type": "wiki", "score": 3, "label": {"eng": "Architecture"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 2, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/New_York_City", "type": "loc", "score": 2, "label": {"eng": "New York City"}, "location": {"type": "place", "label": {"eng": "New York City"}, "country": {"type": "country", "label": {"eng": "United States"}}}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Health/Reproductive_Health/Birth_Control", "label": "dmoz/Health/Reproductive Health/Birth Control", "wgt": 100}, {"uri": "dmoz/Society/Relationships/Anger_Management", "label": "dmoz/Society/Relationships/Anger Management", "wgt": 100}, {"uri": "dmoz/Computers/Software/Year_2000", "label": "dmoz/Computers/Software/Year 2000", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 48}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 51}], "image": "https://eu-images.contentstack.com/v3/assets/blt69509c9116440be8/blt3793559817229aa9/66aa5b19b4308e883f60a01f/faceoff-Brain_light_-alamy.jpg?disable=upscale&width=1200&height=630&fit=crop", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.09019607843137245, "wgt": 159, "relevance": 1}
{"uri": "8259438270", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "04:55:15", "dateTime": "2024-08-05T04:55:15Z", "dateTimePub": "2024-08-05T04:53:54Z", "dataType": "news", "sim": 0.6235294342041016, "url": "https://www.consultancy.com.au/news/9743/ensuring-safe-and-responsible-ai-in-government-portfolios", "title": "Ensuring safe and responsible AI in government portfolios", "body": "Artificial Intelligence (AI) is evolving at breakneck speed. Yet with all the benefits come also numerous risks. Declan Norrie and Kyle Wood from Proximity outline how governments can ensure AI risks are appropriately managed and its opportunities maximised in a safe and responsible manner.\n\nWhile AI businesses pledge their commitment to the ethical design, development and deployment of artificial intelligence through internal controls and industry-developed non-binding standards, nations across the world are grappling with how best to ensure AI is used in a safe and responsible manner.\n\nWhen it comes to effectively regulating AI, there is however so much to unpack and so much to consider.\n\nFrom how AI is defined to what is meant by \"safe and responsible\", from who in the AI value chain should be influenced through regulation and methods to identify tangible (and ideally quantifiable) risks and challenges that this emerging technology presents. It's a balancing act - between trying to support businesses and individuals with leveraging the incredible potential of AI, and containing the risks to an \"acceptable\" level.\n\nAs ASIC Chair Joe Longo highlighted in a speech on AI regulation earlier this year, the development and deployment of AI in Australia is hardly a lawless \"Wild West\". To varying extents, AI developers and deployers are subject to Australia's existing suite of (generally) technology neutral laws and associated regulatory frameworks.\n\nDespite this, evidence indicates that a majority of Australians have low trust in AI, and are either unsure or disagree that existing protections are sufficient to ensure safety against AI-related harms.\n\nThey are not isolated in their concerns: the Bletchley Declaration, signed by Australia amongst a group of 28 countries and the EU on 1 November 2023, welcomed \"recognition that the protection of human rights, transparency and explainability, fairness, accountability, regulation, safety, appropriate human oversight, ethics, bias mitigation, privacy and data protection needs to be addressed\".\n\nWith trust already low, AI-related safety incidents risk hampering the sector's development and impacting our ability to reap the significant public and private benefit of this emerging technology. Effective regulation is critical to mitigate the risk of individual and social harms, to ultimately provide the public and businesses with certainty and confidence. Longo's closing point on existing regulation remains salient: \"is this enough?\"\n\nThe Australian Government has committed to investigating options for a risk-based approach to regulating to ensure safe and responsible AI. As confirmed at the 2024 Budget, this will include consultation on potential mandatory, risk-based guardrails applying generally to AI systems, and consideration of options to strengthen and clarify existing laws which already regulate (or should regulate) AI in particular domains.\n\nAt time of writing, there are diverse approaches to AI regulation amongst similar developed nations despite agreement that alignment will be crucial. A simplified snapshot of how these approaches compare, both in terms of how mandatory key regulatory instruments are, and the breadth of their application:\n\nFOTO: Figure bijlage\n\nThe characteristics of AI technologies pose specific challenges to designing and implementing effective regulation, so they need to be closely considered in any regulatory approach.\n\nDefining AI\n\nAny bespoke regulatory approach faces the challenge of how to define AI to ensure sufficient legal certainty of what it applies to, while remaining sufficiently flexible to account for paradigmatic changes in AI's nature and capabilities.\n\nSetting the requirements for safe and responsible AI\n\nAgencies must determine what safe and responsible means in their particular context, and what obligations and associated regulatory tools are required to achieve that.\n\nIdentifying and quantifying critical risks\n\nQuantifying tangible risks and challenges is critical to operating a risk-based regulatory system, which can use limited resources to monitor, investigate, and enforce regulatory non-compliance most effectively.\n\nAddressing the complex AI value chain\n\nRegulation must be targeted to achieve regulatory outcomes that are efficient and effective. It needs to influence the right actors at the right time to minimise burden and maximise outcomes. The complex nature of the AI value chain, which may include a range of organisations across multiple jurisdictions, makes this challenging.\n\nAll areas of government will need a baseline understanding of AI issues to ensure effective coordination of an approach to safe and responsible AI. As a starting point, public sector personnel at all levels can engage meaningfully with safe and responsible AI in their domain, by taking the following actions:\n\n1) Read up\n\nDevelop a baseline understanding of AI's applications, technical and ethical challenges. Acknowledging the complexity of the field and rapidity of change, utilise accessible resources including those published by DISR, the National AI Centre and academic institutions. Engage with experts and stay informed about emerging trends - both in your domain and more broadly.\n\n2) Build capability\n\nInvest in AI literacy. Recruit and train policymakers, regulators, and legal professionals at all levels to understand AI and navigate AI-related issues effectively. Review your policy, regulatory, and legislative tools to identify any gaps, challenges or risks to mitigating AI-related harms.\n\n3) Collaborate with critical stakeholders\n\nThe government should work together with critical stakeholders including other government agencies, industry, academia, and civil society. Share insights, concerns and positions to ensure that critical risks are shared and don't fall through cracks. Seek to engage with both central agencies and line agencies to address key pain points, especially areas of intersection and duplication.\n\n4) Horizon scan: Anticipate future AI developments\n\nConsider the impact of quantum computing, autonomous systems, and AI-driven decision-making on key activities and stakeholders in your domain. While you might not be able to predict all in a fast moving and complex field of technology, practicing preparation will give you the tools to adapt more quickly to change.\n\nProximity's multi-disciplinary experts are knowledgeable in the challenges of designing, developing and reviewing complex and innovative regulatory frameworks. From assurance reviews to seconded lawyers, Proximity's offerings can help ensure governments are well equipped to best seize the opportunities and manage the risks of artificial intelligence.", "source": {"uri": "consultancy.com.au", "dataType": "news", "title": "consultancy.com.au"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Australia", "type": "loc", "score": 5, "label": {"eng": "Australia"}, "location": {"type": "country", "label": {"eng": "Australia"}}}, {"uri": "http://en.wikipedia.org/wiki/Emerging_technologies", "type": "wiki", "score": 4, "label": {"eng": "Emerging technologies"}}, {"uri": "http://en.wikipedia.org/wiki/Value_chain", "type": "wiki", "score": 4, "label": {"eng": "Value chain"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 4, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Kyle_Wood_(ice_hockey)", "type": "person", "score": 3, "label": {"eng": "Kyle Wood (ice hockey)"}}, {"uri": "http://en.wikipedia.org/wiki/Outline_(list)", "type": "wiki", "score": 3, "label": {"eng": "Outline (list)"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_dollar", "type": "wiki", "score": 3, "label": {"eng": "United States dollar"}}, {"uri": "http://en.wikipedia.org/wiki/Explainable_artificial_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Explainable artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 2, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Paradigm", "type": "wiki", "score": 2, "label": {"eng": "Paradigm"}}, {"uri": "http://en.wikipedia.org/wiki/The_Australian", "type": "wiki", "score": 2, "label": {"eng": "The Australian"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 2, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Bias", "type": "wiki", "score": 2, "label": {"eng": "Bias"}}, {"uri": "http://en.wikipedia.org/wiki/Information_privacy", "type": "wiki", "score": 2, "label": {"eng": "Information privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Developed_country", "type": "wiki", "score": 2, "label": {"eng": "Developed country"}}, {"uri": "http://en.wikipedia.org/wiki/European_Union", "type": "loc", "score": 2, "label": {"eng": "European Union"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Human_rights", "type": "wiki", "score": 2, "label": {"eng": "Human rights"}}, {"uri": "http://en.wikipedia.org/wiki/Decision-making", "type": "wiki", "score": 1, "label": {"eng": "Decision-making"}}, {"uri": "http://en.wikipedia.org/wiki/Quantum_computing", "type": "wiki", "score": 1, "label": {"eng": "Quantum computing"}}, {"uri": "http://en.wikipedia.org/wiki/Applications_of_artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Applications of artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Autonomous_robot", "type": "wiki", "score": 1, "label": {"eng": "Autonomous robot"}}], "categories": [{"uri": "dmoz/Society/Issues", "label": "dmoz/Society/Issues", "wgt": 100}, {"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Society/Work/Whistleblowing", "label": "dmoz/Society/Work/Whistleblowing", "wgt": 100}, {"uri": "dmoz/Society/Activism/In_Daily_Life", "label": "dmoz/Society/Activism/In Daily Life", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 71}], "image": "https://www.consultancy.com.au/illustrations/news/spotlight/2024-08-02-012404728-Ensuring_safe_and_responsible_AI_in_government_portfolios_spot.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3725490196078431, "wgt": 159, "relevance": 1}
{"uri": "8259989601", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "11:28:41", "dateTime": "2024-08-05T11:28:41Z", "dateTimePub": "2024-08-05T11:28:01Z", "dataType": "news", "sim": 0.6196078658103943, "url": "https://www.expresscomputer.in/guest-blogs/the-crucial-role-of-cloud-infrastructure-in-accelerating-the-ai-revolution/114669/", "title": "The crucial role of cloud infrastructure in accelerating the AI revolution - Express Computer", "body": "By Saju Sankarankutty, Senior Vice President and Unit Technology Officer, Cloud, Infosys\n\nThe growing adoption of generative AI is driving increased demand for infrastructure that supports these advanced systems. This includes AI-ready hardware and software in data centers, specialized processors, high-powered systems with GPUs, efficient storage and\n\nmemory for fast data transfers, and infrastructure to handle massive edge data.\n\nCloud Infrastructure for AI: Backbone for computational power and scalability\n\nCloud platforms are emerging as the ideal solution for businesses of all sizes to leverage AI without significant upfront hardware investments. They serve as the backbone for scalable and efficient AI operations by handling data storage, processing, and dissemination. Additionally, these platforms are being enhanced with AI capabilities, further increasing their value.\n\nAI can be described as a catalog sitting atop any cloud platform, offering models and solutions that are customisable for various needs. This highlights the need to modernise cloud infrastructures to better manage resources, billing, and networking for the AI era. AI clouds also employ a combination of InfiniBand and IP-based networking. As the cloud evolves to support AI, it emphasizes the combined use of GPUs and CPUs.\n\nUnparalleled computing power\n\nCloud infrastructure delivers the computational power required for sophisticated AI models, which were once exclusive to elite institutions. This is made possible by the advent of GPUs (Graphics Processing Units) and advanced CPUs (Central Processing Units). GPUs, particularly those from NVIDIA and AMD, offer the raw computational power necessary for AI tasks, while innovations like Intel&#39;s Gaudi simulate GPU capabilities on CPUs, creating a flexible and powerful resource layer. This combination ensures that businesses have the computational muscle needed to train and deploy AI models effectively.\n\nDemocratising access to advanced technologies\n\nCloud infrastructure democratizes access to AI by providing scalable, on-demand resources. This allows startups and small businesses to leverage AI technologies previously available only to large corporations, fostering innovation across industries.\n\nFacilitating collaboration and data sharing\n\nCloud infrastructure supports collaboration by facilitating the sharing of AI models and datasets across diverse domains. This capability is crucial in today's interconnected world, where cross- functional teams often need to work together seamlessly. By leveraging the cloud, businesses can easily share insights, collaborate on projects, and accelerate the development of AI solutions.\n\nAI for Cloud: Boosting resilience, security, and efficiency\n\nEnhancing Security\n\nAI plays a pivotal role in enhancing the resilience of cloud infrastructure. By leveraging machine learning algorithms, cloud platforms can predict and mitigate potential failures, reducing Mean Time to Detect (MTTD) and Mean Time to Repair (MTTR). This proactive approach ensures that businesses remain operational even in the face of cybersecurity threats, thereby safeguarding sensitive data and maintaining customer trust.\n\nDriving cost savings and efficiency with data analysis\n\nThe convergence of AI and cloud infrastructure automates crucial processes like data analysis, management, security, and decision-making, leading to substantial cost savings. Businesses can streamline their operations, reduce manual intervention, and achieve higher levels of efficiency. For example, AI-powered predictive maintenance can significantly reduce downtime and maintenance costs by proactively identifying potential issues before they become critical.\n\nCloud plus AI: Accelerating digital transformation\n\nThe synergy between AI and cloud computing is a powerful catalyst for digital transformation. By leveraging AI-powered cloud services, businesses can automate routine tasks, gain deeper insights from their data, and make more informed decisions. This transformation enhances operational efficiency and drives innovation, enabling businesses to stay competitive in a\n\nrapidly evolving market.\n\nAI and Cloud: Beating the challenges for success\n\nDespite the clear benefits of AI and cloud integration, businesses face challenges such as setup costs, data security, privacy, and AI model complexities. With a strategic approach and expert guidance, these challenges can be overcome, enabling full realization of AI-driven cloud solutions.\n\nSeveral companies have already integrated AI and cloud infrastructure to transform their businesses in a big way. For example, telecommunications firms are using AI clouds to offer advanced services. Large enterprises are adopting GPU-as-a-service models to validate AI concepts and foster innovation. These real-world applications highlight the benefits of combining AI with cloud technologies.\n\nThe relationship between AI and cloud infrastructure will strengthen as AI evolves, increasing the need for scalable, efficient, and secure cloud solutions. Businesses investing in this synergy today will lead their industries, drive innovation, and achieve sustained growth.", "source": {"uri": "expresscomputer.in", "dataType": "news", "title": "Express Computer"}, "authors": [{"uri": "express_computer@expresscomputer.in", "name": "Express Computer", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Scalability", "type": "wiki", "score": 5, "label": {"eng": "Scalability"}}, {"uri": "http://en.wikipedia.org/wiki/Central_processing_unit", "type": "wiki", "score": 5, "label": {"eng": "Central processing unit"}}, {"uri": "http://en.wikipedia.org/wiki/Cloud_computing", "type": "wiki", "score": 5, "label": {"eng": "Cloud computing"}}, {"uri": "http://en.wikipedia.org/wiki/Graphics_processing_unit", "type": "wiki", "score": 5, "label": {"eng": "Graphics processing unit"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/InfiniBand", "type": "wiki", "score": 3, "label": {"eng": "InfiniBand"}}, {"uri": "http://en.wikipedia.org/wiki/Infosys", "type": "org", "score": 3, "label": {"eng": "Infosys"}}, {"uri": "http://en.wikipedia.org/wiki/Internet_Protocol", "type": "wiki", "score": 3, "label": {"eng": "Internet Protocol"}}, {"uri": "http://en.wikipedia.org/wiki/Data_center", "type": "wiki", "score": 3, "label": {"eng": "Data center"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_data_storage", "type": "wiki", "score": 3, "label": {"eng": "Computer data storage"}}, {"uri": "http://en.wikipedia.org/wiki/Vice_president", "type": "wiki", "score": 3, "label": {"eng": "Vice president"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 3, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/AMD", "type": "wiki", "score": 2, "label": {"eng": "AMD"}}, {"uri": "http://en.wikipedia.org/wiki/Data_sharing", "type": "wiki", "score": 2, "label": {"eng": "Data sharing"}}, {"uri": "http://en.wikipedia.org/wiki/Data_analysis", "type": "wiki", "score": 2, "label": {"eng": "Data analysis"}}, {"uri": "http://en.wikipedia.org/wiki/Nvidia", "type": "org", "score": 2, "label": {"eng": "Nvidia"}}, {"uri": "http://en.wikipedia.org/wiki/Computing", "type": "wiki", "score": 2, "label": {"eng": "Computing"}}, {"uri": "http://en.wikipedia.org/wiki/Video_on_demand", "type": "wiki", "score": 2, "label": {"eng": "Video on demand"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 2, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Intel", "type": "org", "score": 2, "label": {"eng": "Intel"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 2, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Small_business", "type": "wiki", "score": 2, "label": {"eng": "Small business"}}, {"uri": "http://en.wikipedia.org/wiki/Corporation", "type": "wiki", "score": 2, "label": {"eng": "Corporation"}}], "categories": [{"uri": "dmoz/Computers/Software/Master_Data_Management", "label": "dmoz/Computers/Software/Master Data Management", "wgt": 100}, {"uri": "dmoz/Computers/Hardware/Systems", "label": "dmoz/Computers/Hardware/Systems", "wgt": 100}, {"uri": "dmoz/Business/Information_Technology/Outsourcing", "label": "dmoz/Business/Information Technology/Outsourcing", "wgt": 100}, {"uri": "dmoz/Computers/Artificial_Intelligence/Companies", "label": "dmoz/Computers/Artificial Intelligence/Companies", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 92}], "image": "https://cdn1.expresscomputer.in/wp-content/uploads/2024/03/08132620/ec-cloud-technology-cloud-computing-750.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.411764705882353, "wgt": 158, "relevance": 1}
{"uri": "8259667410", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "08:01:19", "dateTime": "2024-08-05T08:01:19Z", "dateTimePub": "2024-08-05T08:00:48Z", "dataType": "news", "sim": 0.6117647290229797, "url": "https://www.zdnet.com/article/todays-challenge-working-around-ais-fuzzy-returns-and-questionable-accuracy/", "title": "Today's challenge: Working around AI's fuzzy returns and questionable accuracy", "body": "Unfortunately, there are no clear-cut 'before-and-after' pictures that graphically illustrate the impact or accuracy of AI.\n\nIt has become difficult to set realistic expectations about artificial intelligence -- and this could ultimately confuse efforts to understand the actual value of AI efforts. As the use of technology increases, it means changes in the career landscape for technology professionals, favoring more creative thinkers.\n\nThat's the word from Ajay Malik, former head of architecture and engineering of Google's Worldwide Corporate Network, and currently CEO of Secomind.ai, who sees a rocky road ahead in the AI space. Perhaps one of the most challenging aspects of AI at this point is setting realistic expectations, he said in a recent podcast hosted by Thomas Erl, president of Arcitura Education.\n\nAlso: Photoshop vs. Midjourney vs. DALL-E 3: Only one AI image generator passed my 5 tests\n\nFor starters, there isn't enough measurement or awareness of the potential gains AI is delivering, Malik said. Decision-makers \"want to be sure that all the information that they will use internally, or for interacting with customers, is accurate,\" he said. \"How will companies measure the accuracy of what AI is doing? So AI did something, how do you always know it's accurate? How can you trust it 100%?\"\n\nThis weighs on how well business goals can be achieved through AI, Erl said. \"If organizations are not successful or if they stumble, or if they invest in AI systems that end up resulting in loss instead of growth, that may postpone or change the outcome of how AI might impact their workforce. They might think, 'this didn't work out, let's go back to human workers.'\" But the opportunity is real and we should prepare ourselves for whatever the impact will be.\"\n\nUnfortunately, there are no clear-cut \"before-and-after\" pictures that graphically illustrate the impact or accuracy of AI, Malik said. To address this, \"they need to design built-in verification, built-in explainability, and built-in checks and balances to see if the AI's answer is correct.\" This includes \"an alternative path, mechanism, model that provides a technique so that they can verify the answer.\"\n\nThe key is understanding what exactly the AI system is producing, Malik advised. \"Don't use AI as a black box that you depend upon without even thinking. We are not there today.\" In addition, businesses cannot rely on services such as ChatGPT, as responses need to be accurate and free of hallucinations.\n\nAlso: AI-powered 'narrative attacks' a growing threat: 3 defense strategies for business leaders\n\nInstead, he advises, AI systems should have \"checks and balances built in, verifying the answers, verifying the data, and offering explainability. There is a term for it called XAI, or explainable AI.\"\n\nThere are also profound implications for technology-oriented career growth, Malik continued. \"There is a big resource shift coming,\" he said. Those employees who use AI will become lot more valuable than the employees who do not use AI.\"\n\nAI's impact will be felt in the types of jobs and roles that will flourish in the months and years to come. \"Even in software, even in programming, even in testing, a lot of those jobs will get eliminated -- not today, but over time,\" Malik predicted. \"This is work which the AI can do -- very junior level work or very repetitive redundant level of work.\"\n\nThis will especially apply to coder-level jobs, versus higher-level software engineering jobs, he continued. \"Coders are just coding based on some known facts, and programming uses more thinking. In my own company, we see 20 to 25 times higher productivity because of using AI for supporting coding, for supporting meetings, meeting minutes, action items they can do a lot more with less people now.\"\n\nAlso: Intel sees AI in enterprise on a 'three to five-year path'\n\nAt the same time, there will be a shift toward \"the thinkers, the problem solvers, the people who are creative,\" Malik added. \"AI will take care of the labor, repetitive, or well-defined. But the creative humans will use AI to produce in high velocity and high quality and something really creative. That shift is coming.\"", "source": {"uri": "zdnet.com", "dataType": "news", "title": "ZDNet"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Thomas_Erl", "type": "person", "score": 4, "label": {"eng": "Thomas Erl"}}, {"uri": "http://en.wikipedia.org/wiki/Midjourney", "type": "wiki", "score": 3, "label": {"eng": "Midjourney"}}, {"uri": "http://en.wikipedia.org/wiki/DALL-E", "type": "wiki", "score": 3, "label": {"eng": "DALL-E"}}, {"uri": "http://en.wikipedia.org/wiki/Explainable_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Explainable artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Adobe_Photoshop", "type": "wiki", "score": 3, "label": {"eng": "Adobe Photoshop"}}, {"uri": "http://en.wikipedia.org/wiki/Podcast", "type": "wiki", "score": 3, "label": {"eng": "Podcast"}}, {"uri": "http://en.wikipedia.org/wiki/Engineering", "type": "wiki", "score": 3, "label": {"eng": "Engineering"}}, {"uri": "http://en.wikipedia.org/wiki/Electric_generator", "type": "wiki", "score": 3, "label": {"eng": "Electric generator"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Black_box", "type": "wiki", "score": 2, "label": {"eng": "Black box"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 1, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Software_engineering", "type": "wiki", "score": 1, "label": {"eng": "Software engineering"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 1, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Intel", "type": "org", "score": 1, "label": {"eng": "Intel"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 1, "label": {"eng": "Software"}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Recreation/Humor/Useless_Pages", "label": "dmoz/Recreation/Humor/Useless Pages", "wgt": 100}, {"uri": "dmoz/Society/Advice", "label": "dmoz/Society/Advice", "wgt": 100}, {"uri": "dmoz/Society/Work/Workweek_Reduction", "label": "dmoz/Society/Work/Workweek Reduction", "wgt": 100}, {"uri": "dmoz/Computers/Software/Year_2000", "label": "dmoz/Computers/Software/Year 2000", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 50}], "image": "https://www.zdnet.com/a/img/resize/c514cea7d2b7b86858373b6cef1a397fac6b2a29/2024/08/05/9fcf3cdd-3c8e-4fa3-bb27-fba3174eb498/gettyimages-1331744969.jpg?auto=webp&fit=crop&height=675&width=1200", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.192156862745098, "wgt": 156, "relevance": 1}
{"uri": "8260098527", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "12:37:08", "dateTime": "2024-08-05T12:37:08Z", "dateTimePub": "2024-08-05T12:36:13Z", "dataType": "news", "sim": 0.6117647290229797, "url": "https://profit.pakistantoday.com.pk/2024/08/05/google-launches-ai-academy-to-boost-startups-in-pakistan-and-apac-region/", "title": "Google launches AI Academy to boost startups in Pakistan and APAC region  - Profit by Pakistan Today", "body": "Program to support over 20 AI startups with mentorship and resources\n\nGoogle for Startups has launched AI Academy, a new program aimed at supporting and accelerating the growth of AI startups in Pakistan and the Asia-Pacific (APAC) region.\n\nThe initiative, announced on Monday, will involve more than 20 startups developing AI technologies, fostering a vibrant AI community within APAC and promoting cross-border innovation and partnerships.\n\nThe collaborative environment of the program will encourage the exchange of ideas, expertise, and resources, accelerating the development of advanced AI solutions and establishing APAC as a global hub for AI advancements. Selected startups will receive tailored mentorship and access to Google's AI experts for personalized guidance.\n\nThe program offers up to $350,000 in Google Cloud credits to support AI development and experimentation. Additionally, it provides opportunities for community building and collaboration with other AI startups across the APAC region.\n\nAI Academy aims to fast-track startups to market by enabling them to build a \"proof of concept\" and develop a product roadmap, rapidly validating and enhancing their AI solutions. By applying Google Cloud tools to their data, startups can integrate their AI innovations into existing products more efficiently, speeding up their path to success.\n\nFarhan S. Qureshi, Google Pakistan's country director, highlighted the importance of this initiative, stating, \"Our AI Academy program demonstrates Google's commitment to fostering AI growth across the Asia-Pacific. With Pakistan being a key market, we hope local startups will leverage this opportunity to enhance their AI solutions and strengthen the AI ecosystem in APAC.\"", "source": {"uri": "profit.pakistantoday.com.pk", "dataType": "news", "title": "Profit by Pakistan Today"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 5, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Asia-Pacific", "type": "loc", "score": 5, "label": {"eng": "Asia-Pacific"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Mentorship", "type": "wiki", "score": 4, "label": {"eng": "Mentorship"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Pakistan", "type": "loc", "score": 3, "label": {"eng": "Pakistan"}, "location": {"type": "country", "label": {"eng": "Pakistan"}}}, {"uri": "http://en.wikipedia.org/wiki/Google_AI", "type": "wiki", "score": 2, "label": {"eng": "Google AI"}}, {"uri": "http://en.wikipedia.org/wiki/Google_Cloud_Platform", "type": "wiki", "score": 2, "label": {"eng": "Google Cloud Platform"}}, {"uri": "http://en.wikipedia.org/wiki/Global_city", "type": "wiki", "score": 2, "label": {"eng": "Global city"}}, {"uri": "http://en.wikipedia.org/wiki/Proof_of_concept", "type": "wiki", "score": 1, "label": {"eng": "Proof of concept"}}, {"uri": "http://en.wikipedia.org/wiki/Ecosystem", "type": "wiki", "score": 1, "label": {"eng": "Ecosystem"}}], "categories": [{"uri": "dmoz/Society/Philanthropy/Grants", "label": "dmoz/Society/Philanthropy/Grants", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 66}], "image": "https://profit.pakistantoday.com.pk/wp-content/uploads/2024/08/Google-For-Startups-1.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.5529411764705883, "wgt": 156, "relevance": 1}
{"uri": "8259582886", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "07:01:32", "dateTime": "2024-08-05T07:01:32Z", "dateTimePub": "2024-08-05T07:00:57Z", "dataType": "news", "sim": 0.6117647290229797, "url": "https://www.forbes.com/sites/sallypercy/2024/08/05/do-the-right-thing-4-ways-to-navigate-the-ethics-of-ai/", "title": "Do The Right Thing: 4 Ways To Navigate The Ethics Of AI", "body": "Artificial intelligence (AI) technologies are now being widely used by organizations. In fact, 72% of organizations surveyed by consultancy McKinsey earlier this year had adopted AI in at least one business function. What's more, 65% of respondents reported that their organizations were regularly using generative AI (genAI) technologies, while three-quarters predicted that genAI would lead to significant or disruptive change in their industries over the coming years.\n\nAI can be applied to a host of business use cases that boost efficiency, productivity and competitiveness, from the automation of routine tasks through to the sophisticated analysis of large datasets. At the same time, however, the technology presents some significant ethical risks, particularly in relation to bias, intellectual property and privacy. So, how can leaders help their organizations to navigate the ethical risks associated with AI?\n\n\"Developing and deploying new technologies in an ethical, responsible way will depend on human judgment,\" says Rob Hayward, chief strategy officer at organizational ethics advisory firm Principia. \"AI is not simply good or evil, but every new AI solution will involve thousands of micro decisions on the ground throughout the innovation lifecycle. Those decisions will not only depend on legal and regulatory parameters, but on individual and collective judgement on the right thing to do.\"\n\nHayward says that exercising sound judgment will require people at every level of the organization, from designers and engineers through to marketers and product managers, \"to identify and reflect on the ethical challenges presented by new technologies, and to understand their decisions through the lens of the impact that they will have on the world.\"\n\nThe most important thing that leaders can do is to engage their people in open and honest dialogue on how AI can help or hinder the organization's ethical aspirations and commitments, notes Hayward. To drive ethical AI, he also argues that leaders must strengthen organizational systems, policies and governance mechanisms.\n\nCulture is key to success in almost every organizational endeavor. So, with AI, it's essential to promote a culture of responsible innovation, explains Nell Watson, an AI expert, ethicist and author of Taming the Machine: Ethically harness the power of AI. \"Conduct regular audits for biases and unintended consequences,\" she says, \"especially in high-stakes domains like hiring and performance evaluation. Prioritize data privacy and security with robust access safeguards and explicit consent protocols.\"\n\nWatson recommends that leaders implement clear monitoring for AI decision-making, ensuring accountability and preserving the right to challenge algorithmic outcomes. They should also consider the long-term implications of deploying AI, including potential job displacement, and proactively invest in reskilling initiatives to future-proof the workforce.\n\n\"Remember that ethical AI is a journey, not a destination,\" Watson says. \"Foster open dialogue with stakeholders, including employees and the public, to address reasonable concerns and build trust. By balancing the efficiency from innovation with ethical considerations, leaders can harness AI's incredible potential without causing scandal or putting unfair burdens onto others.\"\n\nAI is just one technology among many that make up the Fourth Industrial Revolution or Industry 4.0. Other technologies in the mix include advanced analytics, blockchain and the cloud. \"These emerging digital technologies all come with complex trade-offs around ethics, sustainability and 'tech for good,'\" says Richard Markoff, supply chain management professor at ESCP Business School in Paris and co-author of The Digital Supply Chain Challenge.\n\nMarkoff states that just like with other technologies, any deployment of AI should derive from true business drivers, have a robust business case, and be subject to \"a careful implementation with deep engagement and commitment from company leadership.\" Citing the example of driverless vehicles, he says that while much debate has focused on passenger cars and taxis, the most likely near-term application could be \"driverless trucks that carry freight within the supply chains of most businesses.\"\n\nSuch is the controversy around AI, it's easy to forget that the technology is here to help, not to take over. \"AI can handle the mundane tasks so you can focus on what truly matters,\" emphasizes Chris Griffiths, co-author of The Focus Fix: Finding clarity, creativity and resilience in an overwhelming world. \"By offloading repetitive chores to AI, you free up your team's brainpower for strategic and creative thinking.\"\n\nGriffiths believes that we need to embrace AI as our ally, using it to lighten our cognitive load while ensuring that we're ethically sound in our approach. \"This way, we not only enhance our productivity, but also find greater clarity, creativity and joy in our everyday work,\" he says.\n\nTraining in the ethical use of AI is critical. \"This isn't just a matter of teaching people to push the right buttons, or use the right AI model,\" Griffiths explains. \"It's about understanding how to ethically harness AI's full potential. Leaders need to cultivate an environment where teams see AI as a tool for good - a way to boost productivity without sacrificing mental wellbeing.\"", "source": {"uri": "forbes.com", "dataType": "news", "title": "Forbes"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 5, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Organizational_ethics", "type": "wiki", "score": 3, "label": {"eng": "Organizational ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Use_case", "type": "wiki", "score": 3, "label": {"eng": "Use case"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 3, "label": {"eng": "Intellectual property"}}, {"uri": "http://en.wikipedia.org/wiki/Automation", "type": "wiki", "score": 3, "label": {"eng": "Automation"}}, {"uri": "http://en.wikipedia.org/wiki/Bias", "type": "wiki", "score": 3, "label": {"eng": "Bias"}}, {"uri": "http://en.wikipedia.org/wiki/McKinsey_&_Company", "type": "org", "score": 3, "label": {"eng": "McKinsey & Company"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 3, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Decision-making", "type": "wiki", "score": 2, "label": {"eng": "Decision-making"}}, {"uri": "http://en.wikipedia.org/wiki/Unintended_consequences", "type": "wiki", "score": 2, "label": {"eng": "Unintended consequences"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 2, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 2, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 2, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Audit", "type": "wiki", "score": 2, "label": {"eng": "Audit"}}, {"uri": "http://en.wikipedia.org/wiki/Information_privacy", "type": "wiki", "score": 2, "label": {"eng": "Information privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Marketing", "type": "wiki", "score": 2, "label": {"eng": "Marketing"}}, {"uri": "http://en.wikipedia.org/wiki/Fourth_Industrial_Revolution", "type": "wiki", "score": 2, "label": {"eng": "Fourth Industrial Revolution"}}, {"uri": "http://en.wikipedia.org/wiki/Chris_Griffiths_(field_hockey)", "type": "wiki", "score": 1, "label": {"eng": "Chris Griffiths (field hockey)"}}, {"uri": "http://en.wikipedia.org/wiki/ESCP_Business_School", "type": "org", "score": 1, "label": {"eng": "ESCP Business School"}}, {"uri": "http://en.wikipedia.org/wiki/Self-driving_car", "type": "wiki", "score": 1, "label": {"eng": "Self-driving car"}}, {"uri": "http://en.wikipedia.org/wiki/Blockchain", "type": "wiki", "score": 1, "label": {"eng": "Blockchain"}}, {"uri": "http://en.wikipedia.org/wiki/Paris", "type": "loc", "score": 1, "label": {"eng": "Paris"}, "location": {"type": "place", "label": {"eng": "Paris"}, "country": {"type": "country", "label": {"eng": "France"}}}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Health/Mental_Health/Self-Help", "label": "dmoz/Health/Mental Health/Self-Help", "wgt": 100}, {"uri": "dmoz/Society/Future/Transhumanism", "label": "dmoz/Society/Future/Transhumanism", "wgt": 100}, {"uri": "dmoz/Society/Work/Rethinking_Work", "label": "dmoz/Society/Work/Rethinking Work", "wgt": 100}, {"uri": "dmoz/Society/Activism/In_Daily_Life", "label": "dmoz/Society/Activism/In Daily Life", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 59}], "image": "https://imageio.forbes.com/specials-images/imageserve/66a68b07e6127745da0b494f/0x0.jpg?format=jpg&height=600&width=1200&fit=bounds", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3254901960784313, "wgt": 156, "relevance": 1}
{"uri": "2024-08-444273996", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "08:43:41", "dateTime": "2024-08-05T08:43:41Z", "dateTimePub": "2024-08-05T08:11:28Z", "dataType": "news", "sim": 0.6117647290229797, "url": "https://programming.am/the-daily-tech-digest-august-5-2024-104ea8108ff0", "title": "The Daily Tech Digest: August 5, 2024", "body": "Welcome to your daily roundup of the latest and most significant news in technology. Today's edition spans advancements in artificial intelligence, cybersecurity, business developments, consumer tech, and space exploration. Dive in to stay informed and inspired by the rapidly evolving tech landscape.\n\nGitHub Models have been introduced, enabling over 100 million developers to access and experiment with top AI models directly within their workflow. This integration promises to streamline development and enhance productivity, making AI tools more accessible than ever. Read more\n\nGemini 1.5 Pro Early Testing\n\nGoogle AI has released an experimental version of Gemini 1.5 Pro for early testing. Available through Google AI Studio and the Gemini API, this model seeks feedback to refine its capabilities. Read more\n\nEurope Enacts AI Act\n\nThe European Commission has implemented the world's first comprehensive AI regulations under the AI Act. This legislation is designed to ensure safe and ethical AI usage across the EU, setting a global standard for AI governance. Read more\n\nTackling AI Hallucinations\n\nMicrosoft has developed new tools to detect and reduce AI hallucinations, where models generate incorrect or misleading information. These advancements aim to improve the reliability of AI systems. Read more\n\nMeta's Segment Anything Model 2\n\nMeta has unveiled SAM 2, a unified model for real-time, promptable object segmentation in images and videos. This model, available under Apache 2.0, is expected to drive advancements in computer vision. Read more", "source": {"uri": "programming.am", "dataType": "news", "title": "Medium"}, "authors": [{"uri": "souren_stepanyan@programming.am", "name": "Souren Stepanyan", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/GitHub", "type": "org", "score": 3, "label": {"eng": "GitHub"}}, {"uri": "http://en.wikipedia.org/wiki/Space_exploration", "type": "wiki", "score": 3, "label": {"eng": "Space exploration"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 3, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/API", "type": "wiki", "score": 2, "label": {"eng": "API"}}, {"uri": "http://en.wikipedia.org/wiki/Experiment", "type": "wiki", "score": 2, "label": {"eng": "Experiment"}}, {"uri": "http://en.wikipedia.org/wiki/Workflow", "type": "wiki", "score": 2, "label": {"eng": "Workflow"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 2, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/European_Commission", "type": "org", "score": 2, "label": {"eng": "European Commission"}}, {"uri": "http://en.wikipedia.org/wiki/Europe", "type": "loc", "score": 2, "label": {"eng": "Europe"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Simulation_for_Automatic_Machinery", "type": "wiki", "score": 1, "label": {"eng": "Simulation for Automatic Machinery"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 1, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/Image_segmentation", "type": "wiki", "score": 1, "label": {"eng": "Image segmentation"}}, {"uri": "http://en.wikipedia.org/wiki/Apache_License", "type": "wiki", "score": 1, "label": {"eng": "Apache License"}}, {"uri": "http://en.wikipedia.org/wiki/Real-time_computing", "type": "wiki", "score": 1, "label": {"eng": "Real-time computing"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_vision", "type": "wiki", "score": 1, "label": {"eng": "Computer vision"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 1, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Hallucination", "type": "wiki", "score": 1, "label": {"eng": "Hallucination"}}, {"uri": "http://en.wikipedia.org/wiki/European_Union", "type": "loc", "score": 1, "label": {"eng": "European Union"}, "location": null}], "categories": [{"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 20}, {"uri": "dmoz/Recreation/Models/Scale", "label": "dmoz/Recreation/Models/Scale", "wgt": 21}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 24}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 30}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 23}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 91}], "image": "https://miro.medium.com/v2/resize:fit:1200/1*4j39SaOfeEMfTVWzNqA2CA.png", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3411764705882352, "wgt": 156, "relevance": 1}
{"uri": "2024-08-444447064", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "11:14:11", "dateTime": "2024-08-05T11:14:11Z", "dateTimePub": "2024-08-05T11:04:17Z", "dataType": "news", "sim": 0.6117647290229797, "url": "https://www.aol.co.uk/news/ai-changed-world-continue-university-110417728.html", "title": "'AI has changed the world, and will continue to do so': the university fast-tracking students to careers of the future", "body": "'AI has changed the world, and will continue to do so': the university fast-tracking students to careers of the future\n\nHolly Brockwell\n\n5 August 2024 at 1:04 pm\n\nArtificial intelligence (AI) has transformed from the preserve of sci-fi movies into something most of us use every day, whether we realise it or not. It's a fast-growing industry that underpins countless crucial sectors from healthcare to law enforcement.\n\nIn spite of it being a hot topic, there is a lack of understanding of AI, and even less technical experience. As this nascent sector expands, true specialists have become sought-after and, in the coming years, those with the foresight to gain qualifications early will not only have access to the pick of the jobs - their work could be instrumental in designing the future.\n\nThe University of Derby's five new applied AI degrees offer undergraduates the opportunity to study how artificial intelligence intersects with industries as diverse as criminology, psychology, healthcare, digital marketing and human resources, and gives them insight into how to keep their skills at the forefront of tech progress after graduation.\n\nWe spoke to Prof Stephan Reiff-Marganiec, head of the school of computing, and Prof Ian Turner, professor of learning and teaching, about what it's like to study AI at the University of Derby, and how the new degree programmes will prepare graduates for a career in the fast-moving world of AI.\n\nProf Stephan Reiff-Marganiec\n\nHead of the school of computing\n\nLeads research in data-driven systems that provide a basis for AI insights into everything from rerouting cars to optimising factory processes.\n\nProf Ian Turner\n\nProfessor of learning and teaching\n\nLeads the generative artificial intelligence (Gen AI) working group across the university, and helps to implement the university's AI code of practice in its teaching and learning.\n\nForget what you think you know\n\n\"When we look at the industry around AI, everyone thinks of companies like OpenAI [makers of ChatGPT], Google or Amazon,\" says Reiff-Marganiec. \"That is the wrong way to look at it. AI is part of our every day - it impacts everyone and is everywhere. That phone sitting on your desk has AI built into it, and has had for many years. The way we shop, book appointments or do our banking is all underpinned by AI - there are very few industries that are not impacted by it in one way or another. AI has changed the world, and it will continue to do so; we want to make sure that our students are in the best possible position to capitalise on the opportunities that this will bring.\"\n\nThe university's suite of applied AI BSc qualifications are designed to dovetail with the needs of modern businesses, now and in the future, with modules informed by industry and research to keep up with the ever-changing tech landscape. Partnerships with local and global companies play a key role in helping the university keep abreast of industry trends. \"Companies that we work with - such as Rolls-Royce and Toyota - get insights from their manufacturing plants, the devices they produce, the cars they are putting on the roads: all generating data that they analyse,\" says Reiff-Marganiec. \"This means that we are at the forefront of technological advancements, which ensures that our curriculum is aligned to industry needs, relevant to current trends, and has an eye on the future.\"\n\nTurner adds: \"AI has been around for a long time. Everyone from the NHS, to local constabularies to the small companies in our region are using AI in their work. And with the gen [generative] AI boom, a whole new range of businesses have had their eyes opened to the possibilities AI can create for them.\n\nIt's not about chatbots\n\nThe purpose of artificial intelligence is to take some of the strain off human shoulders - to do the legwork so you can focus on the interesting parts. That goes for studying for your degree, too - but no, you can't get a chatbot to write your essay.\n\n\"These degree programmes we are running are not about telling people how to use ChatGPT to write documents. We are talking about tackling big issues like social inequality and miscarriages of justice,\" says Turner. \"Challenges where AI can play its part in redressing some of the problems affecting society - and our students can have a role in this.\"\n\nReiff-Marganiec adds: \"Contrary to the popular narrative that AI will replace humans, it will actually allow us to be more human by taking away some of those mundane tasks which require cognitive load, enabling us to do the things that require true human creativity.\n\n\"Imagine a future where a doctor does not have to analyse thousands of X-ray images because AI can do that for them, freeing up their precious time to see more patients and ultimately save more lives. It can have a transformative effect on industry and society if used effectively and ethically.\"\n\nThese, and similar challenges across a range of industries, are some of the problems the University of Derby's students will tackle when the new programmes commence this autumn.\n\nA modern legacy\n\nWith AI being such a hot industry, it's no surprise that online institutions offering related courses have already begun to proliferate - where there's interest, there's profit. But in a crowded market, a qualification from a respected institution such as the University of Derby carries weight - and there are also considerable benefits to learning in person, say the professors.\n\n\"One of the key things you do not get online is happenstance,\" Reiff-Marganiec says. \"The arrow goes straight. But on campus, [you get] lots of unexpected diversions from speaking to people - and those opportunities make your experience far richer, which you can then take into the workplace.\"\n\nState of the art university labs also give students access to pro-level tools and hardware, which can be prohibitively expensive for an individual to acquire. So students can plug in and play on day one, regardless of their background or resources.\n\nAnd as the applied AI courses at Derby are designed to be cross-disciplinary, students have access to experiential learning spaces from other specialisms - such as the criminology department's replica magistrates court, custody suite, and forensic training facility, complete with seven facsimile crime scenes and a blood spatter room. Something else you're unlikely to see or experience from an online course, note the professors.\n\nAI degree courses at the University of Derby\n\nNew AI practitioner-focused degrees starting at the university in September will ensure that students graduate with the skills, knowledge and expertise to understand, pre-empt and maximise the opportunities that this new technology provides.\n\nSubject areas include criminology, digital marketing, healthcare, human resources, data science and psychology.\n\n* Artificial Intelligence in Healthcare\n\n* Artificial Intelligence in Digital Marketing\n\n* Artificial Intelligence in Psychology\n\n* Artificial Intelligence in Human Resources\n\n* Artificial Intelligence in Criminology\n\n* Artificial Intelligence and Data Science\n\n* Artificial Intelligence and Data Science with Foundation Year\n\nFind out more about being part of the AI revolution:\n\nHow can young people prepare for an AI future?\n\nUndergraduate AI courses\n\nThe friendly face of industry\n\nBy working closely with companies that use AI tools in their day-to-day work, Derby students are ideally placed to find jobs after graduation. On top of its decades of leading research and teaching in data science, the university's partnerships with organisations including Rolls-Royce, Toyota and the NHS can open doors for students and guide curriculum development.\n\n\"Our industry partners are informing us of the next advancements they anticipate they will need in their workforce and the questions that will need answering,\" says Reiff-Marganiec. \"As a future-focused university, we are challenging them to look even further ahead, five, ten years down the line, as by the time a student enters the workforce the world could be quite different. It is our job to prepare students of today for the work of the future, ensuring our curriculum evolves in line with industry needs, and that our students are equipped with the skills required to be successful, whatever path they may choose.\"\n\nA degree of employability\n\nWhen students make the decision to invest in their education, they're thinking far beyond a framed certificate - they want to know how that qualification will ease their path to career success. At the University of Derby, employability is a key component of both existing and new courses.\n\nRelated: Students and jobs: how industry and academia are teaming up to future-proof graduates' skills\n\n\"As an applied university it is key that we are aligned to industry so that our students can experience the world of work and gain those transferable skills. To support this we bring employers in to deliver live briefs to our students,\" says Reiff-Marganiec. \"They may set themes for a hackathon or practical activities, and we have this constant dialogue with the people who will hire our graduates so we can ensure that what we deliver is future focused and responds to their skills needs.\n\n\"Many students go on placements after their second year to further their involvement with employers, and that enables them to take ideas from there into their final year project. If they play that right, they will likely have a job offer before they even graduate.\"\n\nTurner adds: \"The companies around us are embracing AI. They want to recruit from the best talent pool, so they home in on graduates with these specific skill sets. They cannot wait for them to come out the other end of the course, which puts our students in a strong position if they work hard and take advantage of all the opportunities the University of Derby offers.\n\n\"A common question we get is: 'Which career is this going to be relevant to?' But I think the question should actually be: 'Which careers do you think will not need AI?'\"\n\nThe seminar's key takeaways\n\n* The university's new applied AI courses are designed to dovetail with what industry looks for in its new hires, not just now but at and beyond graduation time.\n\n* Students graduate with practical experience and strong contacts at local and global companies, including huge names such as Rolls-Royce, and often with a job offer already in hand.\n\n* Courses are research-informed and constantly adjusted to remain current, and include applications across industries that go far beyond the generative AI focus of many online courses.\n\nTo find out more and start your journey to becoming a sought-after graduate with a degree in applied AI, or to explore the other degrees on offer, visit derby.ac.uk", "source": {"uri": "aol.co.uk", "dataType": "news", "title": "Yahoo News"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/University_of_Derby", "type": "org", "score": 5, "label": {"eng": "University of Derby"}}, {"uri": "http://en.wikipedia.org/wiki/University", "type": "wiki", "score": 5, "label": {"eng": "University"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Health_care", "type": "wiki", "score": 5, "label": {"eng": "Health care"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Ian_Turner_(Australian_political_activist)", "type": "person", "score": 4, "label": {"eng": "Ian Turner (Australian political activist)"}}, {"uri": "http://en.wikipedia.org/wiki/Criminology", "type": "wiki", "score": 4, "label": {"eng": "Criminology"}}, {"uri": "http://en.wikipedia.org/wiki/Computing", "type": "wiki", "score": 4, "label": {"eng": "Computing"}}, {"uri": "http://en.wikipedia.org/wiki/Digital_marketing", "type": "wiki", "score": 4, "label": {"eng": "Digital marketing"}}, {"uri": "http://en.wikipedia.org/wiki/Psychology", "type": "wiki", "score": 4, "label": {"eng": "Psychology"}}, {"uri": "http://en.wikipedia.org/wiki/Human_resources", "type": "org", "score": 4, "label": {"eng": "Human resources"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 3, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_(company)", "type": "org", "score": 3, "label": {"eng": "Amazon (company)"}}, {"uri": "http://en.wikipedia.org/wiki/Curriculum", "type": "wiki", "score": 3, "label": {"eng": "Curriculum"}}, {"uri": "http://en.wikipedia.org/wiki/Law_enforcement", "type": "wiki", "score": 3, "label": {"eng": "Law enforcement"}}, {"uri": "http://en.wikipedia.org/wiki/Data_science", "type": "wiki", "score": 3, "label": {"eng": "Data science"}}, {"uri": "http://en.wikipedia.org/wiki/Undergraduate_education", "type": "wiki", "score": 3, "label": {"eng": "Undergraduate education"}}, {"uri": "http://en.wikipedia.org/wiki/Toyota", "type": "org", "score": 3, "label": {"eng": "Toyota"}}, {"uri": "http://en.wikipedia.org/wiki/Bank", "type": "wiki", "score": 3, "label": {"eng": "Bank"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Science_fiction", "type": "wiki", "score": 3, "label": {"eng": "Science fiction"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_model", "type": "wiki", "score": 2, "label": {"eng": "Generative model"}}, {"uri": "http://en.wikipedia.org/wiki/Cognitive_load", "type": "wiki", "score": 2, "label": {"eng": "Cognitive load"}}, {"uri": "http://en.wikipedia.org/wiki/Miscarriage_of_justice", "type": "wiki", "score": 2, "label": {"eng": "Miscarriage of justice"}}, {"uri": "http://en.wikipedia.org/wiki/Rolls-Royce_Limited", "type": "org", "score": 2, "label": {"eng": "Rolls-Royce Limited"}}, {"uri": "http://en.wikipedia.org/wiki/Derby", "type": "loc", "score": 2, "label": {"eng": "Derby"}, "location": {"type": "place", "label": {"eng": "Derby"}, "country": {"type": "country", "label": {"eng": "United Kingdom"}}}}], "categories": [{"uri": "dmoz/Computers/Artificial_Intelligence", "label": "dmoz/Computers/Artificial Intelligence", "wgt": 27}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 35}, {"uri": "dmoz/Computers/Artificial_Intelligence/Academic_Departments", "label": "dmoz/Computers/Artificial Intelligence/Academic Departments", "wgt": 29}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 36}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 35}, {"uri": "news/Business", "label": "news/Business", "wgt": 79}], "image": "https://media.zenfs.com/en/aol_the_guardian_uk_429/755a619d352d94253ceb9a83ab2a1ba3", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.2078431372549019, "wgt": 156, "relevance": 1}
{"uri": "2024-08-444018472", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "03:17:41", "dateTime": "2024-08-05T03:17:41Z", "dateTimePub": "2024-08-05T02:58:27Z", "dataType": "news", "sim": 0.6117647290229797, "url": "https://eu.detroitnews.com/story/news/local/oakland-county/2024/08/04/artificial-intelligence-bootcamp-novi-high-school/74543065007/", "title": "As artificial intelligence enters the classroom, Novi High boot camp explores ethics, improving the world", "body": "Novi -- Instructor Raghu Arghal presented the trolley dilemma -- a thought experiment in which a bystander must choose between saving five people or one person -- to a room of teens in an artificial intelligence summer course.\n\nA computer science and AI researcher, Arghal asked the Michigan high school students to consider the variations of solving the fictional ethical question and applying the same thought process to real-world scenarios, including autonomous vehicles, where computer instructions are making decisions that affect lives.\n\n\"Now we are in positions where we have algorithms that are making decisions with consequences on a similar scale. So if it's ambiguous morally for humans and they can't come to an agreement, there are huge implications when we let computers make these decisions for themselves,\" Arghal said.\n\nAt Novi High School this summer, Arghal and fellow teacher Adithya Sairamachandran are leading AI Scholars, an in-person boot camp that exposes high school students to fundamental AI concepts and guides them to build a project with social impact.\n\nThe two-week, pre-college enrichment program costs $1,500 and was created by Inspirit AI, a company started to inspire students at an early age to understand and apply Artificial Intelligence to improve the world, said Maddie Bradshaw, director of product at the Palo Alto, California company.\n\n\"It's this idea that high schoolers can learn how to see themselves in AI and apply it to their interests,\" Bradshaw said. \"AI is a hot topic. We want to provide students with a toolkit so they can see its impact on medicine, criminal justice and economics. So students can see themselves in the fields they may be entering.\"\n\nThe intensive summer school comes at a time when many Michigan school districts lack policies on AI's use in the classroom or for schoolwork, even though it is moving quickly into the lives of young people and as a national debate has emerged over how to best manage the tool in personal lives and workplaces.\n\nAt the Novi summer school, organizers said they are bringing the most recent developments in AI from courses and labs in Silicon Valley to empower high school students globally. The focus on ethics is just as important, Bradshaw said.\n\n\"Just like other types of technology, AI is a tool that exists,\" she said. \"We want students to learn social, cultural, economic implications of this technology with the intentions of them using this tool for good.\"\n\nHow AI course works\n\nAbout 17 students are spending two weeks learning about AI's core technologies, including applications, foundational concepts and programming tools. In the second half of the course, students complete a mentor-led AI for Social Good project where they apply the programming skills they've learned.\n\nAmong the projects the students are working on:\n\nTeens and their families are already using AI in everyday life, from Alexa, Amazon's virtual assistant technology, to iPhone's face recognition technology. Averi Moncrief, 16, enrolled in the intensive program to further her interest in engineering as a career. She came to the class with some coding experience but not in Python, which she learned in the first week of summer class.\n\n\"AI can be used for a wonderful thing like medical advancement or to make life a whole lot easier. It can be a great thing if used correctly. If not used correctly, it can become a problem,\" Moncrief said.\n\nPart of classroom discussions have included how AI and human \"thinking\" differ, Moncrief said, explaining that AI sees letters of words while humans see the full sentence.\n\n\"AI kind of thinks like humans but not quite like humans,\" she said.\n\nVrishab Makam, 15, said he signed up to learn more about foundational AI concepts and Python notebooks. The 10th grader is part of the robotics team at Novi High School and wants to focus on computer science.\n\n\"It's very beginner-friendly, and I liked that,\" Makam said. \"We are learning about different applications of AI like computer vision, natural language processing. Like AI being able to read and understand text and understand what they actually mean. Not just looking at the characters, but retain the meaning.\"\n\nSchools face AI challenges\n\nMichigan educators said school districts still face the challenge of training teachers to use all the new tools available for lesson planning, direct instruction and one-on-one tutoring for students. Teachers are changing their assignments to be more AI proof, and schools are looking to integrate AI into courses to teach students appropriate use.\n\nIn April, Michigan Virtual released a K-12 AI Guidance document that offers an educator approach to AI use, including recommended practices and data stewardship. It focuses on the impacts of data compliance, ethical use requirements and the challenges around disclosure for educators.\n\nMichigan Virtual, a nonprofit that provides online courses for students and professional development for educators, created an AI Lab to support schools as they learn about the technology.\n\nJustin Bruno, an AI learning strategist at Michigan Virtual, said most Michigan school districts are in the early stages of navigating AI, holding awareness sessions to make sure teachers, administrators, parents and students understand what AI is and its potential impact on education before they dive into developing and creating policies.\n\n\"Schools want to build AI literacy among their staff first. They are hesitant to take any steps before they know their teachers are ready,\" Bruno said. \"It's been a grassroots approach and mostly dependent on the teacher and their own capacity.\"\n\nThe next steps for school districts include forming an advisory team and exploring AI tools, Bruno said, as well as exploring equity issues around AI, such as that the technology might create disadvantages for minority or low-income students.\n\n\"School leaders are trying to figure this out among all the competing priorities,\" Bruno said.\n\nAlthough some schools are trying to restrict student use of things like ChatGPT, Sairamachandran said he encourages educators and the public not to view AI as the enemy but as an aid to learning.\n\n\"At the end of the day, as educators, our goal is to ensure that students know how to work with the technology around them,\" he said. \"They are going to be entering a workforce in a couple of years from now where this is going to be commonplace. We are using AI in the real world.\"", "source": {"uri": "detroitnews.com", "dataType": "news", "title": "The Detroit News"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Secondary_school", "type": "wiki", "score": 5, "label": {"eng": "Secondary school"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 5, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Michigan", "type": "loc", "score": 5, "label": {"eng": "Michigan"}, "location": {"type": "place", "label": {"eng": "Michigan"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Novi_High_School", "type": "org", "score": 3, "label": {"eng": "Novi High School"}}, {"uri": "http://en.wikipedia.org/wiki/Thought_experiment", "type": "wiki", "score": 3, "label": {"eng": "Thought experiment"}}, {"uri": "http://en.wikipedia.org/wiki/Vehicular_automation", "type": "wiki", "score": 3, "label": {"eng": "Vehicular automation"}}, {"uri": "http://en.wikipedia.org/wiki/School_district", "type": "wiki", "score": 3, "label": {"eng": "School district"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_science", "type": "wiki", "score": 3, "label": {"eng": "Computer science"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 3, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Computer", "type": "wiki", "score": 3, "label": {"eng": "Computer"}}, {"uri": "http://en.wikipedia.org/wiki/Palo_Alto,_California", "type": "loc", "score": 3, "label": {"eng": "Palo Alto, California"}, "location": {"type": "place", "label": {"eng": "Palo Alto, California"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_Alexa", "type": "wiki", "score": 2, "label": {"eng": "Amazon Alexa"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 2, "label": {"eng": "Virtual assistant"}}, {"uri": "http://en.wikipedia.org/wiki/Facial_recognition_system", "type": "wiki", "score": 2, "label": {"eng": "Facial recognition system"}}, {"uri": "http://en.wikipedia.org/wiki/Python_(programming_language)", "type": "wiki", "score": 2, "label": {"eng": "Python (programming language)"}}, {"uri": "http://en.wikipedia.org/wiki/Engineering", "type": "wiki", "score": 2, "label": {"eng": "Engineering"}}, {"uri": "http://en.wikipedia.org/wiki/Criminal_justice", "type": "wiki", "score": 2, "label": {"eng": "Criminal justice"}}, {"uri": "http://en.wikipedia.org/wiki/IPhone", "type": "wiki", "score": 2, "label": {"eng": "IPhone"}}, {"uri": "http://en.wikipedia.org/wiki/Economics", "type": "wiki", "score": 2, "label": {"eng": "Economics"}}, {"uri": "http://en.wikipedia.org/wiki/Silicon_Valley", "type": "loc", "score": 2, "label": {"eng": "Silicon Valley"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Medicine", "type": "wiki", "score": 2, "label": {"eng": "Medicine"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 1, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/K\u201312", "type": "wiki", "score": 1, "label": {"eng": "K\u201312"}}], "categories": [{"uri": "dmoz/Society/Issues/Education", "label": "dmoz/Society/Issues/Education", "wgt": 24}, {"uri": "dmoz/Computers/Artificial_Intelligence", "label": "dmoz/Computers/Artificial Intelligence", "wgt": 25}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 29}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 38}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 31}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 87}], "image": "https://www.gannett-cdn.com/authoring/authoring-images/2024/07/30/PDTN/74605955007-20240730-nh-a-isummerschool-022.jpg?auto=webp&crop=5263,2961,x0,y276&format=pjpg&width=1200", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3803921568627451, "wgt": 156, "relevance": 1}
{"uri": "8259857878", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "10:07:06", "dateTime": "2024-08-05T10:07:06Z", "dateTimePub": "2024-08-05T10:06:25Z", "dataType": "news", "sim": 0.6117647290229797, "url": "https://timesofindia.indiatimes.com/blogs/voices/viksit-bharat-needs-awakened-india-and-ai/", "title": "Viksit Bharat needs awakened India and AI", "body": "A truly Viksit Bharat can be aided in its journey, by harnessing the positivity of AI (Artificial Intelligence), leading to an Awakened India. As the nation stands on the transformative cusp of its next development phase, integrating AI can drive unprecedented progress, inclusive at that.\n\nThe urgency to scale and enhance AI policies cannot be overstated. As the world races towards technological supremacy, India must not only keep pace but lead in shaping the future. As AI emerges as a defining geopolitical force, surpassing traditional markers of power such as military might and economic strength, India must accelerate its efforts. To ensure that it remains a key player in this transformative era, India must decisively embrace and scale its AI policies, integrating these technologies into its national framework and capitalising on its demographic and historical strengths.\n\nAssuming that other nations will genuinely collaborate in the AI race would be both politically naive and policy disastrous. The competitive nature of AI development means that countries are primarily driven by self-interest and strategic advantage, rather than cooperative goals. India, with one-sixth of humanity, must assert itself as a pivotal voice in shaping global AI regulations. To do so effectively, it cannot rely solely on its consumption-based economy. Instead, India needs to develop and hold technological intellectual property and exert commercial influence.\n\nWhile concerns around AI's ethical implications and potential misuse are valid, it is imperative to harness its power for the global good. Indian Dharmic principles, which emphasise the welfare of society and the pursuit of righteousness, provide a strong foundation for values-based governance. These timeless teachings can serve as a powerful motivator to ensure that AI development aligns with the greater good, promoting equity, fairness, and inclusivity. By actively participating in the global evolution of AI regulations, India can advocate for frameworks that prevent any single nation's dominance and protect against ideological biases that could harm global harmony.\n\nTo realise this vision, India needs to urgently address several critical areas. First, reskilling our workforce with AI mentorship is essential. The transition to an AI-driven economy will require a significant upskilling of our current labour and work force to ensure they are equipped with the knowledge and skills necessary for new roles. AI mentors will play a pivotal role in this transformation, guiding individuals through the complexities of AI technologies and applications.\n\nHumans are now more digital and mobile-first than ever before. In India, thanks to its emphasis on data and digital technology, there are now more keypad-literate individuals than formally literate ones. This digital fluency must be effectively harnessed in the age of AI to enhance quality of living and create better livelihood opportunities. By leveraging this vast pool of digital-savvy individuals, India can drive significant advancements in productivity and development. Embracing this digital literacy as a core asset will enable us to fully capitalise on AI technologies, fostering improvements in living standards and economic growth.\n\nMoreover, our approach to the 'future of work' must integrate the latest advancements, such as AI-ready smartphones. Far from being mere accessories, these devices are crucial for enhancing productivity and embedding AI into daily operations. They would soon serve as gateways to harness AI's capabilities, enabling seamless interaction with intelligent applications and data analytics on the go. By incorporating these emerging technologies into our skilling strategies, we must ensure that our workforce is well-prepared for a future where AI is omnipresent. These will facilitate real-time decision-making, remote collaboration, and automation of routine tasks, thus driving efficiency and innovation.\n\nEmbedding AI in the Indian mindset means integrating our rich cultural heritage with cutting-edge technology to create a future where innovation and tradition coexist, driving progress and harmony for all. There is a profound opportunity to weave India's rich cultural heritage and traditional knowledge into the AI landscape. India's vast and diverse repository of ancient wisdom, including insights from its Upanishads, Vedas, and other classical texts, holds valuable perspectives on humanity and human sciences. By integrating this native intelligence and profound understanding into AI systems, India can offer unique contributions that enrich global AI developments.\n\nThis fusion of traditional knowledge with cutting-edge technology could lead to the creation of AI models that not only reflect advanced scientific and technical prowess but also embody the deep, holistic understanding of human nature that has been a hallmark of Indian thought for millennia. Such an approach promises to enhance the relevance and depth of AI applications, making them more culturally resonant and human-centric.\n\nReflecting on our history, India was once the most prosperous nation on the planet, a beacon of knowledge and innovation. Reviving and applying the pathways that led to this historical success can guide us in our quest to regain global prominence. This means reviving our traditional strengths in innovation and scholarship while strategically leveraging contemporary tools and practices.\n\nAI's intersection with sustainability offers India a transformative opportunity to lead by example and achieve significant positive impacts. By integrating AI with our sustainability initiatives, India has the potential to surpass its 2070 net-zero commitment and become the first nation to achieve this goal ahead of schedule. AI can play a pivotal role in optimising resource use, reducing waste, and enhancing energy efficiency across various sectors. It can drive innovations in renewable energy, improve waste management, and facilitate smart agriculture practices that align with our environmental objectives. This approach demonstrates that economic growth and sustainability are not mutually exclusive but can be harmoniously integrated to create a model of progress that balances environmental stewardship with development.\n\nThe transformative power of AI has to be utilised to elevate individual and industrial productivity, providing each citizen with a co-pilot that can enhance their capabilities tenfold. This advancement will not only propel India to the forefront of global innovation but also foster a socio-economic environment that is inclusive and equitable. By ensuring that the benefits of AI are widely distributed, we can build a more advanced, prosperous, and happy nation.", "source": {"uri": "timesofindia.indiatimes.com", "dataType": "news", "title": "The Times of India"}, "authors": [{"uri": "shailesh_haribhakti@timesofindia.indiatimes.com", "name": "Shailesh Haribhakti", "type": "author", "isAgency": false}, {"uri": "srinath_sridharan@timesofindia.indiatimes.com", "name": "Srinath Sridharan", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/India", "type": "loc", "score": 5, "label": {"eng": "India"}, "location": {"type": "country", "label": {"eng": "India"}}}, {"uri": "http://en.wikipedia.org/wiki/Dharma", "type": "wiki", "score": 3, "label": {"eng": "Dharma"}}, {"uri": "http://en.wikipedia.org/wiki/Geopolitics", "type": "wiki", "score": 3, "label": {"eng": "Geopolitics"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 3, "label": {"eng": "Intellectual property"}}, {"uri": "http://en.wikipedia.org/wiki/Demography", "type": "wiki", "score": 3, "label": {"eng": "Demography"}}, {"uri": "http://en.wikipedia.org/wiki/Cooperative", "type": "wiki", "score": 3, "label": {"eng": "Cooperative"}}, {"uri": "http://en.wikipedia.org/wiki/Welfare", "type": "wiki", "score": 3, "label": {"eng": "Welfare"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Digital_literacy", "type": "wiki", "score": 2, "label": {"eng": "Digital literacy"}}, {"uri": "http://en.wikipedia.org/wiki/Traditional_knowledge", "type": "wiki", "score": 2, "label": {"eng": "Traditional knowledge"}}, {"uri": "http://en.wikipedia.org/wiki/Standard_of_living", "type": "wiki", "score": 2, "label": {"eng": "Standard of living"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 2, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Cultural_heritage", "type": "wiki", "score": 2, "label": {"eng": "Cultural heritage"}}, {"uri": "http://en.wikipedia.org/wiki/Analytics", "type": "wiki", "score": 2, "label": {"eng": "Analytics"}}, {"uri": "http://en.wikipedia.org/wiki/Quality_of_life", "type": "wiki", "score": 2, "label": {"eng": "Quality of life"}}, {"uri": "http://en.wikipedia.org/wiki/Equity_(finance)", "type": "wiki", "score": 2, "label": {"eng": "Equity (finance)"}}, {"uri": "http://en.wikipedia.org/wiki/Evolution", "type": "wiki", "score": 2, "label": {"eng": "Evolution"}}, {"uri": "http://en.wikipedia.org/wiki/Information_technology", "type": "wiki", "score": 2, "label": {"eng": "Information technology"}}, {"uri": "http://en.wikipedia.org/wiki/Economic_growth", "type": "wiki", "score": 2, "label": {"eng": "Economic growth"}}, {"uri": "http://en.wikipedia.org/wiki/Smartphone", "type": "wiki", "score": 2, "label": {"eng": "Smartphone"}}], "categories": [{"uri": "dmoz/Society/Future", "label": "dmoz/Society/Future", "wgt": 100}, {"uri": "dmoz/Society/Religion_and_Spirituality/Sikhism", "label": "dmoz/Society/Religion and Spirituality/Sikhism", "wgt": 100}, {"uri": "dmoz/Society/Religion_and_Spirituality/Meditation", "label": "dmoz/Society/Religion and Spirituality/Meditation", "wgt": 100}, {"uri": "dmoz/Society/Future/Transhumanism", "label": "dmoz/Society/Future/Transhumanism", "wgt": 100}, {"uri": "dmoz/Society/Future/Essays", "label": "dmoz/Society/Future/Essays", "wgt": 100}], "image": "https://static.toiimg.com/imagenext/toiblogs/photo/blogs/wp-content/uploads/2024/08/viksit-bharat.jpeg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.2705882352941176, "wgt": 156, "relevance": 1}
{"uri": "8259863309", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "10:10:45", "dateTime": "2024-08-05T10:10:45Z", "dateTimePub": "2024-08-05T10:09:45Z", "dataType": "news", "sim": 0.6078431606292725, "url": "https://www.thehansindia.com/tech/78-pc-industry-leaders-urge-for-accelerating-responsible-ai-ecosystem-in-india-896981", "title": "78 pc industry leaders urge for accelerating responsible AI ecosystem in India", "body": "Mumbai : About 78 per cent of industry leaders urge for accelerating a responsible Artificial Intelligence (AI) ecosystem in India to help improve decision-making and governance, according to a report on Monday.\n\nThe report by management consultancy Primus Partners presents a detailed study of the responsible and ethical AI ecosystem in India from the industry perspective and advocates ethical, transparent, and accountable AI practices while also outlining possible enforcement mechanisms for AI regulations in India.\n\nIf governed responsibly, AI has the potential to contribute up to 10 per cent to India's GDP by 2025, revealed the report.\n\nFor about 76 per cent of industry leaders, the top concerns in AI deployment include challenges of data quality and availability (which include data scarcity, biases in datasets, and the complexities of data preparation and cleaning).\n\nThe report also emphasises that 61 per cent of the industry prioritises privacy and security, including threats posed by deep fakes, as a crucial principle-based element in safe AI deployment.\n\nIt comes at a crucial time as India positions itself at the forefront of global AI innovation while addressing the ethical challenges posed by rapid technological advancement.\n\n\"India's current AI landscape reflects a segment full of opportunities. As we journey towards becoming a trillion-dollar digital economy, we must adopt a balanced approach to AI governance. This involves leveraging AI for its economic benefits while ensuring robust regulatory frameworks that can prevent or curb risks such as deepfakes by promoting ethical standards,\" said Devroop Dhar, Co-Founder and Managing Director, Primus Partners.\n\n\"As AI's influence is driving significant advancements and efficiencies across diverse industries worldwide, responsible use of AI should be a shared global priority,\" he added.\n\nFurther, the report showed that 53 per cent of respondents believe that AI systems should be designed to be transparent and explainable to ensure trust and accountability, while 78 per cent emphasise the need for ongoing skill development and training to keep pace with AI advancements.\n\nMany industry leaders (51 per cent) also prefer a hybrid regulatory approach combining traditional frameworks with adaptive guidelines, while some (47.3 per cent) believe that over-regulation and over-compliance if put in place, can become a deterrent to AI's growth.\n\nOthers (89 per cent) believe that specific regulations are essential to ensure ethical practices, accountability, and transparency in AI development and deployment.\n\nThe report also calls for a collaborative approach between the government and the private sector to develop standards and practices that ensure AI benefits all segments of society.", "source": {"uri": "thehansindia.com", "dataType": "news", "title": "The Hans India"}, "authors": [{"uri": "hans_india@thehansindia.com", "name": "Hans India", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 5, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Ecosystem", "type": "wiki", "score": 5, "label": {"eng": "Ecosystem"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/India", "type": "loc", "score": 5, "label": {"eng": "India"}, "location": {"type": "country", "label": {"eng": "India"}}}, {"uri": "http://en.wikipedia.org/wiki/Deepfake", "type": "wiki", "score": 3, "label": {"eng": "Deepfake"}}, {"uri": "http://en.wikipedia.org/wiki/Decision-making", "type": "wiki", "score": 3, "label": {"eng": "Decision-making"}}, {"uri": "http://en.wikipedia.org/wiki/Economy_of_India", "type": "wiki", "score": 3, "label": {"eng": "Economy of India"}}, {"uri": "http://en.wikipedia.org/wiki/Mumbai", "type": "loc", "score": 3, "label": {"eng": "Mumbai"}, "location": {"type": "place", "label": {"eng": "Mumbai"}, "country": {"type": "country", "label": {"eng": "India"}}}}, {"uri": "http://en.wikipedia.org/wiki/Digital_economy", "type": "wiki", "score": 2, "label": {"eng": "Digital economy"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 1, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Private_sector", "type": "wiki", "score": 1, "label": {"eng": "Private sector"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 1, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Society/Issues", "label": "dmoz/Society/Issues", "wgt": 100}, {"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Society/Issues/Economic", "label": "dmoz/Society/Issues/Economic", "wgt": 100}, {"uri": "dmoz/Society/Activism/In_Daily_Life", "label": "dmoz/Society/Activism/In Daily Life", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 59}], "image": "https://assets.thehansindia.com/h-upload/2024/08/05/1468302-ai.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": {"type": "place", "label": {"eng": "Mumbai"}, "country": {"type": "country", "label": {"eng": "India"}}}, "extractedDates": null, "sentiment": 0.3960784313725489, "wgt": 155, "relevance": 1}
{"uri": "8258502246", "lang": "eng", "isDuplicate": false, "date": "2024-08-04", "time": "10:36:18", "dateTime": "2024-08-04T10:36:18Z", "dateTimePub": "2024-08-04T10:35:15Z", "dataType": "news", "sim": 0.6078431606292725, "url": "https://www.analyticsinsight.net/artificial-intelligence/open-source-ai-benefits-and-challenges-for-developers", "title": "Open Source AI: Benefits and Challenges for Developers", "body": "In recent years, the field of artificial intelligence (AI) has experienced tremendous growth and innovation. Central to this development is the open-source movement, which has revolutionized how AI technologies are created, shared, and utilized. Open source AI refers to AI tools, frameworks, and algorithms that are made publicly available for anyone to use, modify, and distribute.\n\nThis collaborative approach has brought numerous benefits to developers, but it also comes with its own set of challenges. This article explores the benefits and challenges of open-source AI for developers, providing a comprehensive overview of this dynamic and influential aspect of modern AI development.", "source": {"uri": "analyticsinsight.net", "dataType": "news", "title": "Analytics Insight"}, "authors": [{"uri": "harshini_chakka@analyticsinsight.net", "name": "Harshini Chakka", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Open-source-software_movement", "type": "wiki", "score": 3, "label": {"eng": "Open-source-software movement"}}, {"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 2, "label": {"eng": "Open-source software"}}], "categories": [{"uri": "dmoz/Computers/Open_Source", "label": "dmoz/Computers/Open Source", "wgt": 100}, {"uri": "dmoz/Computers/Open_Source/Articles", "label": "dmoz/Computers/Open Source/Articles", "wgt": 100}, {"uri": "dmoz/Computers/Open_Source/Advocacy", "label": "dmoz/Computers/Open Source/Advocacy", "wgt": 100}, {"uri": "dmoz/Computers/Open_Source/Open_Content", "label": "dmoz/Computers/Open Source/Open Content", "wgt": 100}], "image": "https://media.assettype.com/analyticsinsight%2F2024-08%2Fe8c0b1e1-67f4-4506-aa30-bb9319665705%2FOpen-Source-A--Benefits-and-Challenges-for-Developers.jpg?w=1200&ar=40%3A21&auto=format%2Ccompress&ogImage=true&mode=crop&enlarge=true&overlay=false&overlay_position=bottom&overlay_width=100", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.5058823529411764, "wgt": 155, "relevance": 1}
{"uri": "8259872757", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "10:16:36", "dateTime": "2024-08-05T10:16:36Z", "dateTimePub": "2024-08-05T10:15:32Z", "dataType": "news", "sim": 0.6000000238418579, "url": "https://fintech.global/2024/08/05/the-transformative-power-of-ai-in-compliance/", "title": "The transformative power of AI in compliance", "body": "The integration of AI within compliance frameworks is revolutionising how companies process vast amounts of data, bringing unprecedented efficiency and effectiveness.\n\nAccording to MCO, by harnessing AI, firms can rapidly analyse data, significantly diminishing the time required for routine compliance checks. This capability not only helps in spotting complex patterns and anomalies that may suggest compliance issues but also in reducing the number of false positives. Moreover, AI's ability to pinpoint security threats and malicious activities further exemplifies its utility in safeguarding firm data against cyber threats.\n\nDespite its advantages, the deployment of AI in compliance does not come without risks. As a nascent technology with rapidly expanding capabilities, AI introduces new forms of risk. Its decision-making processes can sometimes be non-transparent and lack the nuanced understanding inherent in human judgement, which is crucial for interpreting regulations and behaviours. Furthermore, biases in data or outdated models can lead to inaccurate outputs, while over-reliance on AI could foster a misleading sense of security. Rushed AI solutions may suffer from performance issues, and AI systems themselves can become targets for cyberattacks.\n\nThe effectiveness of AI systems hinges on the quality of data they process. As highlighted by researchers from the MIT Center for Information Systems Research, AI tools must be fed with accurate and comprehensive data to avoid problematic outcomes. \"AI is a tool to get things done. To use it properly and generate value, organizations need the right capabilities -- including a good understanding of data.\" Ensuring data integrity is therefore paramount in leveraging AI for effective compliance.\n\nRegulatory bodies are increasingly vigilant about organisations relying heavily on AI for compliance, particularly concerning issues of transparency and accountability. As noted by Keith Pyke, MCO's Director of Solution Sales, during the webinar Maximizing Control Effectiveness, regulators demand clarity on the rationale behind AI-driven decisions, expecting firms to demonstrate and explain the data underpinning their actions.\n\nAs AI continues to proliferate across various sectors, governments and regulatory authorities are stepping up to frame policies that address its implications. The European Union's Artificial Intelligence Act, effective from August 1, 2024, is a pioneering initiative categorising AI applications by risk level. Concurrently, other regions like the US, Singapore, Hong Kong, the UK, and Australia are actively developing guidelines and frameworks to manage AI's integration into business and governance, underscoring the global momentum towards regulated AI utilisation.", "source": {"uri": "fintech.global", "dataType": "news", "title": "FinTech Global"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 3, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/Decision-making", "type": "wiki", "score": 2, "label": {"eng": "Decision-making"}}, {"uri": "http://en.wikipedia.org/wiki/MIT_Center_for_Information_Systems_Research", "type": "wiki", "score": 2, "label": {"eng": "MIT Center for Information Systems Research"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_Intelligence_Act", "type": "wiki", "score": 1, "label": {"eng": "Artificial Intelligence Act"}}, {"uri": "http://en.wikipedia.org/wiki/Data_integrity", "type": "wiki", "score": 1, "label": {"eng": "Data integrity"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 1, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 1, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/European_Union", "type": "loc", "score": 1, "label": {"eng": "European Union"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Hong_Kong", "type": "loc", "score": 1, "label": {"eng": "Hong Kong"}, "location": {"type": "country", "label": {"eng": "Hong Kong"}}}, {"uri": "http://en.wikipedia.org/wiki/Singapore", "type": "loc", "score": 1, "label": {"eng": "Singapore"}, "location": {"type": "country", "label": {"eng": "Singapore"}}}, {"uri": "http://en.wikipedia.org/wiki/United_Kingdom", "type": "loc", "score": 1, "label": {"eng": "United Kingdom"}, "location": {"type": "country", "label": {"eng": "United Kingdom"}}}, {"uri": "http://en.wikipedia.org/wiki/Australia", "type": "loc", "score": 1, "label": {"eng": "Australia"}, "location": {"type": "country", "label": {"eng": "Australia"}}}], "categories": [{"uri": "dmoz/Computers/Software/Master_Data_Management", "label": "dmoz/Computers/Software/Master Data Management", "wgt": 100}, {"uri": "dmoz/Computers/Security/Biometrics", "label": "dmoz/Computers/Security/Biometrics", "wgt": 100}, {"uri": "dmoz/Computers/Software/Enterprise_Information_Integration", "label": "dmoz/Computers/Software/Enterprise Information Integration", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 60}], "image": "https://fintech.global/wp-content/uploads/2024/08/igor-omilaev-hibWw5mk1UY-unsplash-scaled.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.01960784313725483, "wgt": 153, "relevance": 1}
{"uri": "2024-08-443906051", "lang": "eng", "isDuplicate": false, "date": "2024-08-04", "time": "22:16:02", "dateTime": "2024-08-04T22:16:02Z", "dateTimePub": "2024-08-04T21:42:49Z", "dataType": "news", "sim": 0.5960784554481506, "url": "https://sousabrothers.medium.com/openais-sam-altman-is-becoming-one-of-the-most-powerful-people-in-the-world-but-at-what-cost-674661c29475", "title": "OpenAI's Sam Altman is becoming one of the most powerful people in the world. But at what cost?", "body": "OpenAI CEO Sam Altman has expressed concerns about the potential risks associated with the rapid development of artificial intelligence (AI). In a recent interview, Altman emphasized the need for more regulation and oversight in the AI industry, particularly in Silicon Valley. He highlighted the importance of ensuring that AI systems are designed and deployed responsibly, citing the potential for AI to exacerbate existing social issues if not managed properly.\n\nAltman's comments were echoed by Gary Marcus, a prominent AI researcher and critic. Marcus has long advocated for more transparency and accountability in AI development, warning that the unchecked growth of AI could lead to unintended and potentially harmful consequences.\n\nThe concerns raised by Altman and Marcus come as AI technology continues to advance at a rapid pace. The increasing use of AI-generated content, such as the recent proliferation of AI-generated news websites, has raised questions about the reliability and trustworthiness of information online. Furthermore, the potential for AI to be used to spread misinformation and manipulate public opinion has become a significant concern.\n\nIn response to these concerns, there are growing calls for greater regulation and oversight of the AI industry. Many experts believe that stricter guidelines and standards are needed to ensure that AI systems are developed and deployed in a responsible and ethical manner. As the use of AI continues to expand, the need for effective regulation and oversight will only continue to grow in importance.\n\nsource:https://www.theguardian.com/technology/article/2024/aug/03/open-ai-sam-altman-chatgpt-gary-marcus-taming-silicon-valley", "source": {"uri": "sousabrothers.medium.com", "dataType": "news", "title": "Medium"}, "authors": [{"uri": "sousa_brothers@sousabrothers.medium.com", "name": "Sousa Brothers", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Sam_Altman", "type": "person", "score": 5, "label": {"eng": "Sam Altman"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Silicon_Valley", "type": "loc", "score": 3, "label": {"eng": "Silicon Valley"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Gary_Marcus", "type": "person", "score": 2, "label": {"eng": "Gary Marcus"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 2, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Misinformation", "type": "wiki", "score": 1, "label": {"eng": "Misinformation"}}, {"uri": "http://en.wikipedia.org/wiki/Nuclear_proliferation", "type": "wiki", "score": 1, "label": {"eng": "Nuclear proliferation"}}, {"uri": "http://en.wikipedia.org/wiki/Public_opinion", "type": "wiki", "score": 1, "label": {"eng": "Public opinion"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 1, "label": {"eng": "Ethics"}}], "categories": [{"uri": "dmoz/Computers/Artificial_Intelligence", "label": "dmoz/Computers/Artificial Intelligence", "wgt": 13}, {"uri": "dmoz/Computers/Artificial_Intelligence/Natural_Language", "label": "dmoz/Computers/Artificial Intelligence/Natural Language", "wgt": 14}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 24}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 28}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 20}], "image": "https://miro.medium.com/v2/1*kFrc4tBFM_tCis-2Ic87WA.png", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.1529411764705881, "wgt": 152, "relevance": 1}
{"uri": "8259696191", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "08:20:35", "dateTime": "2024-08-05T08:20:35Z", "dateTimePub": "2024-08-05T08:19:21Z", "dataType": "news", "sim": 0.5960784554481506, "url": "https://www.news9live.com/science/educate-online-encourages-students-to-use-ai-for-real-world-applications-2644072", "title": "Educate Online encourages students to use AI for real world applications", "body": "New Delhi: Educate Online is an online platform offering education for students aged between four and 19, providing access to international curriculums in the US, UK and Canada. The service is meant to accentuate school work, opening opportunities for students who can use their international credentials for global university applications. The flexible programmes allow students to opt for part-time or full-time courses, allowing students to obtain diplomas from an international institution in addition to the local school.\n\nWe spoke to Alexander Zheltov, cofounder and CEO of Educate Online, on the use of AI in education. Internationally, the effort from major AI companies is towards making AI more human. However, humans, especially young children, may not be getting an accurate picture about the powers and capabilities of the AI tools that they are using.\n\nZheltov says, \"Both humanizing AI and educating users are crucial, but educating users takes precedence and is necessary. The successful integration of AI relies on teaching responsible use while making AI more human-like. Our main focus should be on helping individuals understand AI's capabilities, risks, and limitations. This knowledge enables informed decisions about AI usage, preventing misuse and building trust. While humanizing AI is valuable, proper education ensures AI isn't misunderstood or misused. Education empowers people to be active, responsible participants in the AI revolution rather than passive consumers.\"\n\nThe old paradigm of going to school for 15 odd years and then working for the rest of your life till the retirement age does not work any more. The tools used by all professions are changing rapidly, and getting outdated within decades. Professionals have to stay updated all their lives, and young people entering job environments for the first time stand to benefit if they are familiar with the tools and techniques used. Educate Online attempts to address this requirement.\n\nZheltov says, \"At Educate Online, we embrace tech-oriented teaching for the evolving job market. We are integrating AI, machine learning, data science, and cybersecurity content into our programs while emphasizing critical thinking and adaptability. Our global university partnerships offer affordable, high-quality online education from prestigious institutions and the curriculum integrates projects as well as industry-based experiences, preparing students for current and future tech jobs. By providing technical knowledge, soft skills, and real-world experience, we aim to help learners succeed in the evolving tech sector while ensuring quality education for all.\"\n\nEveryone and their grandmothers are using AI and the companies are no different. AI is getting increasingly integrated into workplaces, and Educate Online prepares students for this new world. Zheltov says, \"We ensure the quality and relevance of AI education through some key strategies such as partnerships with prominent universities for updated curriculum and hands-on learning through real-world projects. In addition, our platform, \"The Hub,\" provides a comprehensive learning environment for AI studies, complemented by unique internship and mentorship programs. We also focus on developing technical skills, critical thinking, problem-solving, and ethical considerations in AI. By combining high-quality online education with practical experience and holistic development, we prepare students for successful AI careers while keeping our programs affordable and globally accessible.\"\n\nOne of the biggest concerns about any disruptive new technology are the ethical considerations that are evolving rapidly, and getting increasingly formalised. When asked about how Educate Online helps students use AI responsibly, Zheltov says, \"Ethics are a crucial part of our AI curriculum, emphasizing responsible use of AI. We provide courses that cover potential misuse consequences like deep fakes and security breaches. Our ethics curriculum includes data privacy, algorithmic bias, and AI's social impact. We encourage critical evaluation of ethical implications and teach existing AI ethics guidelines and regulations. Through case studies and discussions, we equip learners with a strong ethical foundation for using AI responsibly. Our goal is to produce skilled, ethical AI professionals who understand their societal responsibility.\"\n\nWhen asked to provide an example of such use, Zheltov told News9, \"At Educate Online, our students, regardless of age or background, have successfully implemented AI solutions in real-world scenarios. Our platform, \"The Hub,\" and university partnerships provide knowledge and tools for impactful AI projects. A 14-year-old from India learned coding through our program, aiming to do something constructive. This exemplifies how we nurture young talent for an AI-driven future. By combining quality online education with practical skills like coding, we empower students globally to contribute meaningfully to AI.\"", "source": {"uri": "news9live.com", "dataType": "news", "title": "News9live"}, "authors": [{"uri": "aditya_madanapalle@news9live.com", "name": "Aditya Madanapalle", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/University", "type": "wiki", "score": 4, "label": {"eng": "University"}}, {"uri": "http://en.wikipedia.org/wiki/Curriculum", "type": "wiki", "score": 3, "label": {"eng": "Curriculum"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/New_Delhi", "type": "loc", "score": 3, "label": {"eng": "New Delhi"}, "location": {"type": "place", "label": {"eng": "New Delhi"}, "country": {"type": "country", "label": {"eng": "India"}}}}, {"uri": "http://en.wikipedia.org/wiki/United_Kingdom", "type": "loc", "score": 3, "label": {"eng": "United Kingdom"}, "location": {"type": "country", "label": {"eng": "United Kingdom"}}}, {"uri": "http://en.wikipedia.org/wiki/Canada", "type": "loc", "score": 3, "label": {"eng": "Canada"}, "location": {"type": "country", "label": {"eng": "Canada"}}}, {"uri": "http://en.wikipedia.org/wiki/Distance_education", "type": "wiki", "score": 2, "label": {"eng": "Distance education"}}, {"uri": "http://en.wikipedia.org/wiki/Critical_thinking", "type": "wiki", "score": 2, "label": {"eng": "Critical thinking"}}, {"uri": "http://en.wikipedia.org/wiki/Paradigm", "type": "wiki", "score": 2, "label": {"eng": "Paradigm"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 2, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Data_science", "type": "wiki", "score": 2, "label": {"eng": "Data science"}}, {"uri": "http://en.wikipedia.org/wiki/Labour_economics", "type": "wiki", "score": 2, "label": {"eng": "Labour economics"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 2, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithmic_bias", "type": "wiki", "score": 1, "label": {"eng": "Algorithmic bias"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Ethics of artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Case_study", "type": "wiki", "score": 1, "label": {"eng": "Case study"}}, {"uri": "http://en.wikipedia.org/wiki/Holism", "type": "wiki", "score": 1, "label": {"eng": "Holism"}}, {"uri": "http://en.wikipedia.org/wiki/Mentorship", "type": "wiki", "score": 1, "label": {"eng": "Mentorship"}}, {"uri": "http://en.wikipedia.org/wiki/Problem_solving", "type": "wiki", "score": 1, "label": {"eng": "Problem solving"}}, {"uri": "http://en.wikipedia.org/wiki/Internship", "type": "wiki", "score": 1, "label": {"eng": "Internship"}}, {"uri": "http://en.wikipedia.org/wiki/Information_privacy", "type": "wiki", "score": 1, "label": {"eng": "Information privacy"}}, {"uri": "http://en.wikipedia.org/wiki/India", "type": "loc", "score": 1, "label": {"eng": "India"}, "location": {"type": "country", "label": {"eng": "India"}}}], "categories": [{"uri": "dmoz/Society/Issues/Education", "label": "dmoz/Society/Issues/Education", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 61}], "image": "https://images.news9live.com/wp-content/uploads/2024/08/Alexander-Zheltov.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": {"type": "place", "label": {"eng": "New Delhi"}, "country": {"type": "country", "label": {"eng": "India"}}}, "extractedDates": null, "sentiment": 0.2078431372549019, "wgt": 152, "relevance": 1}
{"uri": "8255428864", "lang": "eng", "isDuplicate": false, "date": "2024-08-02", "time": "07:00:13", "dateTime": "2024-08-02T07:00:13Z", "dateTimePub": "2024-08-02T06:58:43Z", "dataType": "news", "sim": 0.5921568870544434, "url": "https://www.devdiscourse.com/article/technology/3039402-the-open-source-battle-metas-llama-31-leads-the-charge", "title": "The Open-Source Battle: Meta's Llama 3.1 Leads the Charge | Technology", "body": "A significant debate is occurring within the AI industry between proponents of open-source and closed-source models. Meta has recently contributed to the open-source side by releasing AI models like Llama 3.1 405B. This development underscores the promise of open-source AI in fostering innovation and accountability, despite inherent risks.\n\nIn the realm of artificial intelligence, a major debate is brewing. Companies are split between keeping their AI datasets and algorithms private or opening them to the public.\n\nRecently, Meta, Facebook's parent company, made a significant move by releasing new open-source AI models, including the landmark Llama 3.1 405B. This model is touted by Meta's CEO, Mark Zuckerberg, as a groundbreaking advancement in open-source AI.\n\nWhile the open-source approach promises transparency and fosters rapid innovation, it also presents challenges, such as quality control and vulnerability to cyberattacks. Meta's move could democratize AI, but questions about balancing innovation and intellectual property protection remain crucial for the future of AI.", "source": {"uri": "devdiscourse.com", "dataType": "news", "title": "Devdiscourse"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 5, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 4, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/Proprietary_software", "type": "wiki", "score": 3, "label": {"eng": "Proprietary software"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 2, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 2, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 2, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Quality_control", "type": "wiki", "score": 1, "label": {"eng": "Quality control"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 1, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Intellectual_property", "type": "wiki", "score": 1, "label": {"eng": "Intellectual property"}}, {"uri": "http://en.wikipedia.org/wiki/Mark_Zuckerberg", "type": "person", "score": 1, "label": {"eng": "Mark Zuckerberg"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Computers/Open_Source/Articles", "label": "dmoz/Computers/Open Source/Articles", "wgt": 100}, {"uri": "dmoz/Business/Management/Strategy_and_Forecasting", "label": "dmoz/Business/Management/Strategy and Forecasting", "wgt": 100}, {"uri": "dmoz/Computers/CAD_and_CAM/3D_Modelling", "label": "dmoz/Computers/CAD and CAM/3D Modelling", "wgt": 100}, {"uri": "dmoz/Computers/Hardware/Open_Source", "label": "dmoz/Computers/Hardware/Open Source", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 53}], "image": "https://www.devdiscourse.com/remote.axd?https://devdiscourse.blob.core.windows.net/aiimagegallery/21_07_2024_12_58_12_7639996.png?width=920&format=jpeg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3725490196078431, "wgt": 151, "relevance": 1}
{"uri": "8259923113", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "10:47:24", "dateTime": "2024-08-05T10:47:24Z", "dateTimePub": "2024-08-05T10:46:39Z", "dataType": "news", "sim": 0.5882353186607361, "url": "https://www.analyticsinsight.net/press-release/75-of-industry-leaders-strongly-believe-responsible-ai-can-significantly-improve-decision-making-and-governance-primus-partners-report", "title": "75% of Industry Leaders Strongly Believe Responsible AI Can Significantly Improve Decision-Making and Governance - Primus Partners Report", "body": "78% emphasize the need for ongoing skill development and training to keep pace with AI advancements\n\nNew Delhi, 05 August 2024: Primus Partners today released an influential report titled 'Responsible by Design: Industry's Perspective on India's AI Framework', presenting a detailed study of the responsible and ethical AI ecosystem in India from the industry lens. The report advocates ethical, transparent, and accountable AI practices while outlining possible enforcement mechanisms for AI regulations in India.\n\nThe report offers an in-depth analysis of India's current AI landscape and focuses on critical aspects of responsible AI development and governance. The study comes at a crucial time as India positions itself at the forefront of global AI innovation while addressing the ethical challenges posed by rapid technological advancement.", "source": {"uri": "analyticsinsight.net", "dataType": "news", "title": "Analytics Insight"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/India", "type": "loc", "score": 4, "label": {"eng": "India"}, "location": {"type": "country", "label": {"eng": "India"}}}, {"uri": "http://en.wikipedia.org/wiki/New_Delhi", "type": "loc", "score": 3, "label": {"eng": "New Delhi"}, "location": {"type": "place", "label": {"eng": "New Delhi"}, "country": {"type": "country", "label": {"eng": "India"}}}}, {"uri": "http://en.wikipedia.org/wiki/Ecosystem", "type": "wiki", "score": 2, "label": {"eng": "Ecosystem"}}], "categories": [{"uri": "dmoz/Society/Religion_and_Spirituality/Sikhism", "label": "dmoz/Society/Religion and Spirituality/Sikhism", "wgt": 100}, {"uri": "dmoz/Society/Religion_and_Spirituality/Jainism", "label": "dmoz/Society/Religion and Spirituality/Jainism", "wgt": 100}, {"uri": "dmoz/Society/Religion_and_Spirituality/Meditation", "label": "dmoz/Society/Religion and Spirituality/Meditation", "wgt": 100}], "image": "https://media.assettype.com/analyticsinsight%2F2024-08%2F4990ab70-eec7-4c05-aa98-d5c8ba8905b1%2F75%25-of-industry-leaders-strongly-believe-responsible-AI-can-significantly-improve-decision-making-and-governance-%E2%80%93-Primus-Partners-Report.jpg?w=1200&ar=40%3A21&auto=format%2Ccompress&ogImage=true&mode=crop&enlarge=true&overlay=false&overlay_position=bottom&overlay_width=100", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.5294117647058822, "wgt": 150, "relevance": 1}
{"uri": "8259967006", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "11:15:48", "dateTime": "2024-08-05T11:15:48Z", "dateTimePub": "2024-08-05T11:13:56Z", "dataType": "news", "sim": 0.5803921818733215, "url": "https://ca.news.yahoo.com/ai-changed-world-continue-university-110417675.html", "title": "'AI has changed the world, and will continue to do so': the university fast-tracking students to careers of the future", "body": "Artificial intelligence (AI) has transformed from the preserve of sci-fi movies into something most of us use every day, whether we realise it or not. It's a fast-growing industry that underpins countless crucial sectors from healthcare to law enforcement.\n\nIn spite of it being a hot topic, there is a lack of understanding of AI, and even less technical experience. As this nascent sector expands, true specialists have become sought-after and, in the coming years, those with the foresight to gain qualifications early will not only have access to the pick of the jobs - their work could be instrumental in designing the future.\n\nThe University of Derby's five new applied AI degrees offer undergraduates the opportunity to study how artificial intelligence intersects with industries as diverse as criminology, psychology, healthcare, digital marketing and human resources, and gives them insight into how to keep their skills at the forefront of tech progress after graduation.\n\nWe spoke to Prof Stephan Reiff-Marganiec, head of the school of computing, and Prof Ian Turner, professor of learning and teaching, about what it's like to study AI at the University of Derby, and how the new degree programmes will prepare graduates for a career in the fast-moving world of AI.\n\nProf Stephan Reiff-Marganiec\n\nHead of the school of computing\n\nLeads research in data-driven systems that provide a basis for AI insights into everything from rerouting cars to optimising factory processes.\n\nProf Ian Turner\n\nProfessor of learning and teaching\n\nLeads the generative artificial intelligence (Gen AI) working group across the university, and helps to implement the university's AI code of practice in its teaching and learning.\n\n\"When we look at the industry around AI, everyone thinks of companies like OpenAI [makers of ChatGPT], Google or Amazon,\" says Reiff-Marganiec. \"That is the wrong way to look at it. AI is part of our every day - it impacts everyone and is everywhere. That phone sitting on your desk has AI built into it, and has had for many years. The way we shop, book appointments or do our banking is all underpinned by AI - there are very few industries that are not impacted by it in one way or another. AI has changed the world, and it will continue to do so; we want to make sure that our students are in the best possible position to capitalise on the opportunities that this will bring.\"\n\nThe university's suite of applied AI BSc qualifications are designed to dovetail with the needs of modern businesses, now and in the future, with modules informed by industry and research to keep up with the ever-changing tech landscape. Partnerships with local and global companies play a key role in helping the university keep abreast of industry trends. \"Companies that we work with - such as Rolls-Royce and Toyota - get insights from their manufacturing plants, the devices they produce, the cars they are putting on the roads: all generating data that they analyse,\" says Reiff-Marganiec. \"This means that we are at the forefront of technological advancements, which ensures that our curriculum is aligned to industry needs, relevant to current trends, and has an eye on the future.\"\n\nTurner adds: \"AI has been around for a long time. Everyone from the NHS, to local constabularies to the small companies in our region are using AI in their work. And with the gen [generative] AI boom, a whole new range of businesses have had their eyes opened to the possibilities AI can create for them.\n\nThe purpose of artificial intelligence is to take some of the strain off human shoulders - to do the legwork so you can focus on the interesting parts. That goes for studying for your degree, too - but no, you can't get a chatbot to write your essay.\n\n\"These degree programmes we are running are not about telling people how to use ChatGPT to write documents. We are talking about tackling big issues like social inequality and miscarriages of justice,\" says Turner. \"Challenges where AI can play its part in redressing some of the problems affecting society - and our students can have a role in this.\"\n\nReiff-Marganiec adds: \"Contrary to the popular narrative that AI will replace humans, it will actually allow us to be more human by taking away some of those mundane tasks which require cognitive load, enabling us to do the things that require true human creativity.\n\n\"Imagine a future where a doctor does not have to analyse thousands of X-ray images because AI can do that for them, freeing up their precious time to see more patients and ultimately save more lives. It can have a transformative effect on industry and society if used effectively and ethically.\"\n\nThese, and similar challenges across a range of industries, are some of the problems the University of Derby's students will tackle when the new programmes commence this autumn.\n\nWith AI being such a hot industry, it's no surprise that online institutions offering related courses have already begun to proliferate - where there's interest, there's profit. But in a crowded market, a qualification from a respected institution such as the University of Derby carries weight - and there are also considerable benefits to learning in person, say the professors.\n\n\"One of the key things you do not get online is happenstance,\" Reiff-Marganiec says. \"The arrow goes straight. But on campus, [you get] lots of unexpected diversions from speaking to people - and those opportunities make your experience far richer, which you can then take into the workplace.\"\n\nState of the art university labs also give students access to pro-level tools and hardware, which can be prohibitively expensive for an individual to acquire. So students can plug in and play on day one, regardless of their background or resources.\n\nAnd as the applied AI courses at Derby are designed to be cross-disciplinary, students have access to experiential learning spaces from other specialisms - such as the criminology department's replica magistrates court, custody suite, and forensic training facility, complete with seven facsimile crime scenes and a blood spatter room. Something else you're unlikely to see or experience from an online course, note the professors.\n\nBy working closely with companies that use AI tools in their day-to-day work, Derby students are ideally placed to find jobs after graduation. On top of its decades of leading research and teaching in data science, the university's partnerships with organisations including Rolls-Royce, Toyota and the NHS can open doors for students and guide curriculum development.\n\n\"Our industry partners are informing us of the next advancements they anticipate they will need in their workforce and the questions that will need answering,\" says Reiff-Marganiec. \"As a future-focused university, we are challenging them to look even further ahead, five, ten years down the line, as by the time a student enters the workforce the world could be quite different. It is our job to prepare students of today for the work of the future, ensuring our curriculum evolves in line with industry needs, and that our students are equipped with the skills required to be successful, whatever path they may choose.\"\n\nWhen students make the decision to invest in their education, they're thinking far beyond a framed certificate - they want to know how that qualification will ease their path to career success. At the University of Derby, employability is a key component of both existing and new courses.\n\nRelated: Students and jobs: how industry and academia are teaming up to future-proof graduates' skills\n\n\"As an applied university it is key that we are aligned to industry so that our students can experience the world of work and gain those transferable skills. To support this we bring employers in to deliver live briefs to our students,\" says Reiff-Marganiec. \"They may set themes for a hackathon or practical activities, and we have this constant dialogue with the people who will hire our graduates so we can ensure that what we deliver is future focused and responds to their skills needs.\n\n\"Many students go on placements after their second year to further their involvement with employers, and that enables them to take ideas from there into their final year project. If they play that right, they will likely have a job offer before they even graduate.\"\n\nTurner adds: \"The companies around us are embracing AI. They want to recruit from the best talent pool, so they home in on graduates with these specific skill sets. They cannot wait for them to come out the other end of the course, which puts our students in a strong position if they work hard and take advantage of all the opportunities the University of Derby offers.\n\n\"A common question we get is: 'Which career is this going to be relevant to?' But I think the question should actually be: 'Which careers do you think will not need AI?'\"", "source": {"uri": "ca.news.yahoo.com", "dataType": "news", "title": "Yahoo"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/University_of_Derby", "type": "org", "score": 5, "label": {"eng": "University of Derby"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Health_care", "type": "wiki", "score": 5, "label": {"eng": "Health care"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Ian_Turner_(Australian_political_activist)", "type": "person", "score": 4, "label": {"eng": "Ian Turner (Australian political activist)"}}, {"uri": "http://en.wikipedia.org/wiki/Computing", "type": "wiki", "score": 4, "label": {"eng": "Computing"}}, {"uri": "http://en.wikipedia.org/wiki/University", "type": "wiki", "score": 4, "label": {"eng": "University"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 3, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_(company)", "type": "org", "score": 3, "label": {"eng": "Amazon (company)"}}, {"uri": "http://en.wikipedia.org/wiki/Criminology", "type": "wiki", "score": 3, "label": {"eng": "Criminology"}}, {"uri": "http://en.wikipedia.org/wiki/Curriculum", "type": "wiki", "score": 3, "label": {"eng": "Curriculum"}}, {"uri": "http://en.wikipedia.org/wiki/Law_enforcement", "type": "wiki", "score": 3, "label": {"eng": "Law enforcement"}}, {"uri": "http://en.wikipedia.org/wiki/Digital_marketing", "type": "wiki", "score": 3, "label": {"eng": "Digital marketing"}}, {"uri": "http://en.wikipedia.org/wiki/Undergraduate_education", "type": "wiki", "score": 3, "label": {"eng": "Undergraduate education"}}, {"uri": "http://en.wikipedia.org/wiki/Psychology", "type": "wiki", "score": 3, "label": {"eng": "Psychology"}}, {"uri": "http://en.wikipedia.org/wiki/Bank", "type": "wiki", "score": 3, "label": {"eng": "Bank"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Science_fiction", "type": "wiki", "score": 3, "label": {"eng": "Science fiction"}}, {"uri": "http://en.wikipedia.org/wiki/Human_resources", "type": "org", "score": 3, "label": {"eng": "Human resources"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 2, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_model", "type": "wiki", "score": 2, "label": {"eng": "Generative model"}}, {"uri": "http://en.wikipedia.org/wiki/Cognitive_load", "type": "wiki", "score": 2, "label": {"eng": "Cognitive load"}}, {"uri": "http://en.wikipedia.org/wiki/Miscarriage_of_justice", "type": "wiki", "score": 2, "label": {"eng": "Miscarriage of justice"}}, {"uri": "http://en.wikipedia.org/wiki/Bachelor_of_Science", "type": "wiki", "score": 2, "label": {"eng": "Bachelor of Science"}}, {"uri": "http://en.wikipedia.org/wiki/Toyota", "type": "org", "score": 2, "label": {"eng": "Toyota"}}, {"uri": "http://en.wikipedia.org/wiki/Rolls-Royce_Limited", "type": "org", "score": 2, "label": {"eng": "Rolls-Royce Limited"}}, {"uri": "http://en.wikipedia.org/wiki/Derby", "type": "loc", "score": 2, "label": {"eng": "Derby"}, "location": {"type": "place", "label": {"eng": "Derby"}, "country": {"type": "country", "label": {"eng": "United Kingdom"}}}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Health/Mental_Health/Self-Help", "label": "dmoz/Health/Mental Health/Self-Help", "wgt": 100}, {"uri": "dmoz/Society/Advice", "label": "dmoz/Society/Advice", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 67}], "image": "https://media.zenfs.com/en/theguardian_763/755a619d352d94253ceb9a83ab2a1ba3", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.2705882352941176, "wgt": 148, "relevance": 1}
{"uri": "8259381502", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "03:52:42", "dateTime": "2024-08-05T03:52:42Z", "dateTimePub": "2024-08-05T03:52:07Z", "dataType": "news", "sim": 0.572549045085907, "url": "https://www.lexology.com/library/detail.aspx?g=d2b4f4f8-cfcb-4665-8d42-c022e80a7019", "title": "NIST Issues AI Risk-Management Guidance", "body": "AI-related consensus standards to provide guidance and cooperation across the world\n\nOn July 26, the U.S. government's National Institute of Standards and Technology (NIST) issued four guidance documents - three final versions and one draft open to public comment - related to artificial intelligence development and implementation. Each was issued pursuant to instructions under the Biden administration's AI Executive Order 14110, which directed several U.S. government agencies to promulgate guidance and regulations with respect to safe, secure, and trustworthy AI. The first guidance document, titled \"Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile\" (RMF GAI), describes and defines risks associated with generative AI (GAI) and how organizations can govern, manage, and mitigate such risks. The second document, titled \"Secure Software Development Practices for Generative AI and Dual-Use Foundation Models\" (SSDF), updates prior NIST software development guidance to add recommendations with respect to a framework for implementing secure development practices specifically tailored to generative AI systems. The third document, titled \"A Plan for Global Engagement on AI Standards\" (AI Plan), provides directives to drive worldwide development and implementation of AI-related consensus standards, cooperation, and information sharing. The fourth document, open to public comment through Sept. 9, 2024, titled \"Managing Misuse Risk for Dual-Use Foundation Models\" (MMRD), offers comprehensive guidelines for identifying, measuring, and mitigating misuse risks associated with powerful AI models.\n\nTogether, the documents attempt to define best practices to reduce risks that arise when developing and deploying AI models. While the NIST guidance is not legally binding, those developing or deploying AI models might take note, as deviation from prevailing practices or recommendations could introduce insurance or liability risks, particularly for those operating in accordance with federal information systems.\n\nThe RMF GAI profiles the functions and categories of NIST's 2023 AI Risk Management Framework (AI RMF) applications as they relate to specific GAI settings and usage. It covers the requirements, risk tolerance, and resources of framework users, as well as how AI RMF profiles can help organizations decide how to manage AI risks in alignment with their goals, considering legal and regulatory requirements, best practices, and risk management priorities. The document offers insights into managing risk across various stages of the AI lifecycle, specifically for GAI technology. The document provides a cross-sectoral profile of how to govern, map, measure, and manage risks related to activities or business processes that implement GAI. Moreover, the document's GAI insights can be applied across different sectors, such as the use of large language models, cloud-based services, or acquisitions. And such insights are prospective in that they address current concerns while looking forward to venues where GAI may be harmful.\n\nThe SSDF notes risks that may arise in AI model development and emphasizes secure practices for GAI and dual-use models. The scope covers the entire AI model development lifecycle, including data sourcing, model training, and integration with other software. High-level practices to secure AI elements, such as model weights and training data, are highlighted as a way of mitigating risks from malicious tampering during AI development and training to ensure AI model integrity and confidentiality.\n\nThe SSDF contains several detailed recommendations, best understood by reviewing the table set out in the document. Generally speaking, the SSDF leverages NIST's 2023 AI RMF, designed for the flexible yet secure development of AI, which encourages a risk-based approach tailored to each organization's needs. For example, the recommendations stress review of all source code during AI development and training, whether human-written or AI-generated, to detect, evaluate, and address any identified and/or potential vulnerabilities. The document also emphasizes collaboration among AI model producers, AI system producers, and acquirers, advocating for clear agreements on security responsibilities. The SSDF additionally highlights challenges in tracking AI model lineage and versioning, acknowledging the difficulty in securing all aspects of model development. The profile encourages organizations to document security gaps transparently and integrate secure practices where feasible, particularly in machine learning operations (MLOps) and continuous integration/continuous delivery (CI/CD) pipelines. The SSDF thus provides for comprehensive risk management, inclusive of data privacy and bias concerns, across the AI development lifecycle by providing a baseline via AI-specific recommendations.\n\nNIST's AI Plan further leverages the 2023 AI RMF, as the document is guided by principles set forth in the framework to manage AI-associated risks for individuals, organizations, and society. The AI Plan warns that for AI standards to be successful, they must be context-sensitive, performance-based, human-centered (e.g., accounting for people's need and how they interact with AI), and responsive to societal considerations. The document further indicates that AI standards should be developed in an open, transparent, and consensus-driven way to ensure standards are not only effective but also applicable to the dynamic real-world scenarios for which they will be needed. The document, however, notes that while striving for standardization, \"more work is needed on most or all sub-topics before standard can be developed.\" The document advises that some paths to certain standards may take longer than others, but measured approaches to such foundational work can reap a curated system that converges on governance and accountability across users, systems, and the very AI systems being implemented. Indeed, actionable guidance can be achieved for developers, project managers, senior leaders, and other AI actors, securing how such systems are developed and deployed in the world.\n\nIn the MMRD, NIST outlines guidelines for managing misuse of dual-use foundation models. Like SSDF, it contains several proposals. Some key recommendations include the following:\n\nGiven the breadth of its recommendations, the MMRD advises that organizations prioritize their AI development, implementation, and safeguards based on a dynamic set of factors, including context of use and resources used, collaboration between departments and/or third parties, and transparency. Accordingly, organizations should tailor the MMRD profile's recommended framework to fit their specific capabilities, risk profile, and/or current and evolving needs. Comments on the MMRD are due Sept. 9.\n\nThe guidance documents outline potential AI security, economic, health, and safety risks to users and the world at large, and provide prospective measures that may help ward off such concerns.", "source": {"uri": "lexology.com", "dataType": "news", "title": "Lexology"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Somali_Salvation_Democratic_Front", "type": "org", "score": 5, "label": {"eng": "Somali Salvation Democratic Front"}}, {"uri": "http://en.wikipedia.org/wiki/National_Institute_of_Standards_and_Technology", "type": "wiki", "score": 5, "label": {"eng": "National Institute of Standards and Technology"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Best_practice", "type": "wiki", "score": 4, "label": {"eng": "Best practice"}}, {"uri": "http://en.wikipedia.org/wiki/Software_development", "type": "wiki", "score": 4, "label": {"eng": "Software development"}}, {"uri": "http://en.wikipedia.org/wiki/Risk_management", "type": "wiki", "score": 4, "label": {"eng": "Risk management"}}, {"uri": "http://en.wikipedia.org/wiki/Executive_order_(United_States)", "type": "wiki", "score": 3, "label": {"eng": "Executive order (United States)"}}, {"uri": "http://en.wikipedia.org/wiki/Joe_Biden", "type": "person", "score": 3, "label": {"eng": "Joe Biden"}}, {"uri": "http://en.wikipedia.org/wiki/Federal_government_of_the_United_States", "type": "org", "score": 3, "label": {"eng": "Federal government of the United States"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 2, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Information_system", "type": "wiki", "score": 2, "label": {"eng": "Information system"}}, {"uri": "http://en.wikipedia.org/wiki/Business_process", "type": "wiki", "score": 2, "label": {"eng": "Business process"}}, {"uri": "http://en.wikipedia.org/wiki/Cloud_computing", "type": "wiki", "score": 2, "label": {"eng": "Cloud computing"}}, {"uri": "http://en.wikipedia.org/wiki/Confidentiality", "type": "wiki", "score": 2, "label": {"eng": "Confidentiality"}}, {"uri": "http://en.wikipedia.org/wiki/Continuous_integration", "type": "wiki", "score": 2, "label": {"eng": "Continuous integration"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 2, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/Insurance", "type": "wiki", "score": 2, "label": {"eng": "Insurance"}}, {"uri": "http://en.wikipedia.org/wiki/Foundation_models", "type": "wiki", "score": 1, "label": {"eng": "Foundation models"}}, {"uri": "http://en.wikipedia.org/wiki/Version_control", "type": "wiki", "score": 1, "label": {"eng": "Version control"}}, {"uri": "http://en.wikipedia.org/wiki/Outline_(list)", "type": "wiki", "score": 1, "label": {"eng": "Outline (list)"}}, {"uri": "http://en.wikipedia.org/wiki/Accounting", "type": "wiki", "score": 1, "label": {"eng": "Accounting"}}, {"uri": "http://en.wikipedia.org/wiki/Continuous_delivery", "type": "wiki", "score": 1, "label": {"eng": "Continuous delivery"}}], "categories": [{"uri": "dmoz/Computers/Software/Workflow", "label": "dmoz/Computers/Software/Workflow", "wgt": 100}, {"uri": "dmoz/Computers/Software/Data_Administration", "label": "dmoz/Computers/Software/Data Administration", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 76}], "image": "https://www.lexology.com/images/share/lexology-social-media.png", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-07-26", "textStart": 88, "textEnd": 95}, {"amb": false, "imp": true, "date": "2024-09-09", "textStart": 6860, "textEnd": 6867}], "sentiment": 0.4666666666666666, "wgt": 146, "relevance": 1}
{"uri": "8259964370", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "11:13:06", "dateTime": "2024-08-05T11:13:06Z", "dateTimePub": "2024-08-05T11:12:24Z", "dataType": "news", "sim": 0.572549045085907, "url": "https://www.finextra.com/blogposting/26562/ai-opportunities-challenges-and-the-future-of-financial-services", "title": "AI: Opportunities, Challenges, and the Future of Financial Services", "body": "Artificial Intelligence (AI) has made significant inroads across a wide range of industries, revolutionizing the way businesses operate and interact with consumers. From healthcare to retail, AI's ability to process vast amounts of data and create meaning has given way to new efficiencies and enhanced user experiences. The banking sector, a cornerstone of the global economy, is no exception. AI's integration into banking promises to transform the industry by streamlining operations, improving customer service, and enhancing security.\n\nThe Rise of AI in Banking\n\nTraditionally, banking relied heavily on human intervention for decision-making processes, customer interactions, and fraud detection. However, the digital age has ushered in a new era where data is king, and the ability to harness this data through AI has become a competitive advantage. Banks worldwide are increasingly adopting AI technologies to stay ahead in the competitive landscape. This shift is driven by the need for operational efficiency, enhanced customer experiences, and robust security measures.\n\nThere are numerous reports and articles out there alluding to the potential savings for banks through AI applications. Some projections are upwards of $1 trillion by 2030.\n\nOpportunities Presented by AI\n\nEnhanced Customer Service: One of the most visible applications of AI in banking is the use of chatbots and virtual assistants. These AI-driven tools provide 24/7 customer service, handling a range of inquiries from account balances to transaction histories. For example, Bank of America's virtual assistant, Erica, has become an integral part of its customer experience, providing financial advice and performing transactions upon request. AI's ability to analyze customer data and interactions enables banks to offer a more personalized service, ensuring that each customer receives relevant and timely assistance.\n\nFraud Detection and Prevention: Fraud is a persistent threat in the banking sector, with cybercriminals constantly devising new methods to breach security measures. AI has emerged as a powerful tool in the fight against fraud. Machine learning algorithms can analyze transaction patterns and detect anomalies that may indicate fraudulent activity. This proactive approach allows banks to prevent fraud before it occurs, saving millions of dollars and protecting customers' financial assets.\n\nPersonalized Banking Experience: AI's ability to process and analyze large volumes of data allows banks to offer a more personalized banking experience. By leveraging customer data, banks can tailor financial products and services to meet individual needs. This personalization extends to investment advice, where AI-driven robo-advisors provide customized portfolio recommendations based on a customer's financial goals and risk tolerance. This democratization of financial advice ensures that even customers with modest portfolios receive high-quality guidance, previously available only to high-net-worth individuals.\n\nOperational Efficiency: AI's automation capabilities extend beyond customer-facing applications to streamline back-office operations. Routine tasks such as document processing, compliance checks, and data entry can be automated using AI, freeing up human employees to focus on more strategic activities. This not only reduces operational costs but also minimizes the risk of human error. For instance, JPMorgan Chase's AI-powered system, COIN (short for Contract Intelligence), has significantly improved the bank's ability to process commercial-loan agreements, saving 360,000 hours of lawyers' time annually.\n\nChallenges Financial Institutions Face When Integrating AI\n\nData Privacy and Security: While AI offers numerous benefits, it also raises significant concerns, particularly regarding data privacy and security. Banks handle vast amounts of sensitive customer information, and the use of AI forces robust data protection measures. Ensuring compliance with regulations such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) is crucial to maintaining customer trust. Moreover, as AI systems become more sophisticated, the risk of cyberattacks targeting these systems also increases, forcing continuous vigilance and advanced security protocols.\n\nBias and Fairness: AI systems are only as good as the data they are trained on. If the training data contains biases, the AI systems may inadvertently perpetuate these biases, leading to unfair treatment of certain customer segments. For example, AI-driven credit scoring systems may disadvantage individuals from minority groups if the training data reflects historical biases. Addressing this issue requires a concerted effort to ensure that AI systems are trained on diverse and representative data sets. Moreover, ongoing monitoring and auditing of AI systems are essential to identify and mitigate any unintended biases.\n\nJob Displacement: The automation of routine tasks through AI has sparked concerns about job displacement within the banking sector. While AI can handle repetitive and time-consuming tasks, this shift may lead to a reduction in the demand for certain roles, such as tellers and administrative staff. However, it is essential to recognize that AI also creates new opportunities for employment, particularly in areas requiring specialized skills, such as AI system management and cybersecurity. Financial institutions must invest in reskilling and upskilling their workforce to navigate this transition successfully.\n\nThe Future of AI in Banking\n\nWhilst several banks have already successfully integrated AI into their operations, demonstrating its transformative potential, JPMorgan Chase's COIN and Bank of America's Erica for example, the integration of AI in banking is still in its early stages.\n\nFuture advancements in AI technology promise to enhance the capabilities of AI systems, making them more transparent and powerful. Explainable AI, which focuses on making AI decision-making processes understandable to humans, will be crucial in building trust and ensuring regulatory compliance. Meanwhile, quantum computing could revolutionize data processing, enabling banks to solve complex problems and optimize operations at unprecedented speeds.\n\nIn conclusion, AI is ready to revolutionize the banking industry, offering numerous opportunities to enhance customer service, improve fraud detection, personalize banking experiences, and increase operational efficiency. However, these benefits come with significant challenges, including data privacy concerns and the risk of bias. By addressing these challenges proactively and investing in the responsible development and deployment of AI, banks can harness its transformative power to create a more efficient, secure, and inclusive financial system. As AI continues to evolve, its impact on banking will undoubtedly shape the future of financial services.", "source": {"uri": "finextra.com", "dataType": "news", "title": "Finextra Research"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Fraud", "type": "wiki", "score": 5, "label": {"eng": "Fraud"}}, {"uri": "http://en.wikipedia.org/wiki/Bank", "type": "wiki", "score": 5, "label": {"eng": "Bank"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 4, "label": {"eng": "Virtual assistant"}}, {"uri": "http://en.wikipedia.org/wiki/Financial_adviser", "type": "wiki", "score": 4, "label": {"eng": "Financial adviser"}}, {"uri": "http://en.wikipedia.org/wiki/Customer_service", "type": "wiki", "score": 4, "label": {"eng": "Customer service"}}, {"uri": "http://en.wikipedia.org/wiki/Decision-making", "type": "wiki", "score": 3, "label": {"eng": "Decision-making"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Applications_of_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Applications of artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Information_Age", "type": "wiki", "score": 3, "label": {"eng": "Information Age"}}, {"uri": "http://en.wikipedia.org/wiki/Competitive_advantage", "type": "wiki", "score": 3, "label": {"eng": "Competitive advantage"}}, {"uri": "http://en.wikipedia.org/wiki/User_experience", "type": "wiki", "score": 3, "label": {"eng": "User experience"}}, {"uri": "http://en.wikipedia.org/wiki/World_economy", "type": "wiki", "score": 3, "label": {"eng": "World economy"}}, {"uri": "http://en.wikipedia.org/wiki/Health_care", "type": "wiki", "score": 3, "label": {"eng": "Health care"}}, {"uri": "http://en.wikipedia.org/wiki/California_Consumer_Privacy_Act", "type": "wiki", "score": 2, "label": {"eng": "California Consumer Privacy Act"}}, {"uri": "http://en.wikipedia.org/wiki/Robo-advisor", "type": "org", "score": 2, "label": {"eng": "Robo-advisor"}}, {"uri": "http://en.wikipedia.org/wiki/Cybercrime", "type": "wiki", "score": 2, "label": {"eng": "Cybercrime"}}, {"uri": "http://en.wikipedia.org/wiki/High-net-worth_individual", "type": "loc", "score": 2, "label": {"eng": "High-net-worth individual"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Back_office", "type": "wiki", "score": 2, "label": {"eng": "Back office"}}, {"uri": "http://en.wikipedia.org/wiki/Risk_aversion", "type": "wiki", "score": 2, "label": {"eng": "Risk aversion"}}, {"uri": "http://en.wikipedia.org/wiki/Human_error", "type": "wiki", "score": 2, "label": {"eng": "Human error"}}, {"uri": "http://en.wikipedia.org/wiki/Personalization", "type": "wiki", "score": 2, "label": {"eng": "Personalization"}}, {"uri": "http://en.wikipedia.org/wiki/Bank_of_America", "type": "org", "score": 2, "label": {"eng": "Bank of America"}}, {"uri": "http://en.wikipedia.org/wiki/JPMorgan_Chase", "type": "org", "score": 2, "label": {"eng": "JPMorgan Chase"}}], "categories": [{"uri": "dmoz/Society/Government/Finance", "label": "dmoz/Society/Government/Finance", "wgt": 100}, {"uri": "dmoz/Business/Financial_Services/Banking_Services", "label": "dmoz/Business/Financial Services/Banking Services", "wgt": 100}, {"uri": "dmoz/Business/Financial_Services/Merchant_Services", "label": "dmoz/Business/Financial Services/Merchant Services", "wgt": 100}, {"uri": "dmoz/Business/Financial_Services/Holding_Companies", "label": "dmoz/Business/Financial Services/Holding Companies", "wgt": 100}, {"uri": "dmoz/Business/Investing/Payment_Associations", "label": "dmoz/Business/Investing/Payment Associations", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 77}], "image": "https://www.finextra.com/finextra-images/member_photos/thumb_135631_luke_allchin_3.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.2784313725490195, "wgt": 146, "relevance": 1}
{"uri": "8260107436", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "12:42:46", "dateTime": "2024-08-05T12:42:46Z", "dateTimePub": "2024-08-05T12:41:55Z", "dataType": "news", "sim": 0.5647059082984924, "url": "https://analyticsindiamag.com/ai-origins-evolution/most-ai-startups-are-destined-to-fail-even-the-funded-ones/", "title": "Most AI Startups are Destined to Fail - Even the Funded Ones", "body": "For some, AI is a bubble, for some it is a tree. Regardless, many AI startups would burst or fall off that tree.\n\nEvery startup wants to be big someday, and most successful businesses were startups when they began. But the truth is, somewhere down the line most of them end up either dying, or getting acquired by big companies. This gets a notable exit for most investors, but the story for startups ends there.\n\n\"Most startups are destined to die. Even the funded ones,\" said Kunal Shah, the founder of CRED, adding that the success of a startup is mostly a miracle. \"And a miracle doesn't happen with a team that's looking for stability and dislikes ambiguity,\" he said, adding that startups need problem solvers.\n\nThe same is the case with the current AI startups, globally. The ones that started their journey a few years ago are now either getting acquired or gradually dying because of lack of funds. Only a few companies, such as OpenAI, Anthropic, Mistral, Hugging Face, and few others, are actively getting funded, which eventually will be known as the prodigies of the AI generation.\n\nWith Google recently acquiring the founders of CharacterAI, the case of AI startups sustaining for a long term is put into question. The same was the case with Mustafa Suleyman from Inflection AI joining Microsoft AI Research team, Amazon taking over Adept AI's team, Snowflake's acquisition of Neeva, or Canva's acquisition of Lenoardo.ai.\n\nGoing by that logic, Reka AI or even Cohere, might end up with the same fate. With Emad Mostaque leaving, Stability AI is also going through unstable times. The same could happen to Midjourney.\n\nWhat options do startups really have apart from getting acquired? As the discussion around the AI bubble intensifies, it gets tougher for companies to raise funds from investors as they get increasingly wary. The ones that were successful during the AI boom are now encountering difficulties.\n\nMost of these startups are also not making money. For example, Lensa, the AI photo generating company with a great product and marketing, was not able to differentiate itself even when it was generating revenue. Quickly, other companies started building similar offerings within their own products, making Lensa lack defensibility.\n\nThis is the problem with most of the AI startups. \"The problem with AI is that just as quickly as you can create a great product, another copycat can emerge and undercut you,\" said David Chen, the CEO of Kapsule. Apart from this, another problem he highlighted was the problem of finding use cases and distribution.\n\nWhile India is currently running as the AI use capital of the world, running on jugaad and not VC money, the long term strategy for them also seems questionable. Though they know how to run businesses without large investment, most of them have the inherent goal of getting acquired, as competing with big-tech is not what they strive to do.\n\nA few, such as Sarvam AI, Krutrim, TWO.AI, may have received a decent amount of funding, but long-term plans still remain unclear.\n\nSriharsha Putrevu, the co-founder of Retail Technology Group, said that the current AI startups would fail as they are not focused on value creation, but rather just the valuation. \"Startup is a repeatable, scalable, sustainable business model not just a cash burning, user acquiring business models in hope of making profits in decades,\" he said.\n\nWhen it comes to starting a company, raising funds is the relatively easy part (not easy in itself) as we have seen with a lot of current AI funds. The harder part is finding the right market, niche, and perfect fit for profit.\n\nThe problem cannot be solved by building the best version of an AI model as well, since any competitor would learn from it and create an even better one with the frontier of AI constantly moving. Though the cost of building AI models is shrinking which is helping the startups, it is also drawing in several competitors to the field.\n\nTake, for example, OpenAI's GPT-4 constantly getting dethroned by Meta's Llama 3 or Anthropic's Claude, or Google's Gemini. And these are the ones that are already competing for the top spot; what about the new startups?\n\nIf AI is like electricity, it is important for startups to build a niche and solve the problem in a specific field, since competing for 'best electricity' does not make sense. That is what the current Indian AI landscape is focused on - to build use cases of AI instead of building the next LLM. Maybe, this would help them sustain, but for how long is the question.\n\nMoreover, since the investors in India are extra wary of pouring money into startups, these companies have very low tailwinds. This is making them run low on money and get close to the point of acquisition, or maybe extinction.\n\nAll these problems can be solved with sales, for which startups need to move fast. For some, AI is a bubble, for some it is a tree. Regardless, many AI startups would burst or fall off that tree.", "source": {"uri": "analyticsindiamag.com", "dataType": "news", "title": "Analytics India Magazine"}, "authors": [{"uri": "mohit_pandey@analyticsindiamag.com", "name": "Mohit Pandey", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 5, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Anthropic", "type": "wiki", "score": 3, "label": {"eng": "Anthropic"}}, {"uri": "http://en.wikipedia.org/wiki/Hugging_Face", "type": "wiki", "score": 3, "label": {"eng": "Hugging Face"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 3, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Emad_Mostaque", "type": "wiki", "score": 2, "label": {"eng": "Emad Mostaque"}}, {"uri": "http://en.wikipedia.org/wiki/Cohere", "type": "wiki", "score": 2, "label": {"eng": "Cohere"}}, {"uri": "http://en.wikipedia.org/wiki/Stable_Diffusion", "type": "wiki", "score": 2, "label": {"eng": "Stable Diffusion"}}, {"uri": "http://en.wikipedia.org/wiki/Midjourney", "type": "wiki", "score": 2, "label": {"eng": "Midjourney"}}, {"uri": "http://en.wikipedia.org/wiki/AI_boom", "type": "wiki", "score": 2, "label": {"eng": "AI boom"}}, {"uri": "http://en.wikipedia.org/wiki/Snowflake_Inc.", "type": "wiki", "score": 2, "label": {"eng": "Snowflake Inc."}}, {"uri": "http://en.wikipedia.org/wiki/Canva", "type": "org", "score": 2, "label": {"eng": "Canva"}}, {"uri": "http://en.wikipedia.org/wiki/Mustafa_Suleyman", "type": "person", "score": 2, "label": {"eng": "Mustafa Suleyman"}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_(company)", "type": "org", "score": 2, "label": {"eng": "Amazon (company)"}}, {"uri": "http://en.wikipedia.org/wiki/Venture_capital", "type": "wiki", "score": 2, "label": {"eng": "Venture capital"}}, {"uri": "http://en.wikipedia.org/wiki/Logic", "type": "wiki", "score": 2, "label": {"eng": "Logic"}}, {"uri": "http://en.wikipedia.org/wiki/Business_model", "type": "wiki", "score": 2, "label": {"eng": "Business model"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 2, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Marketing", "type": "wiki", "score": 2, "label": {"eng": "Marketing"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 2, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/India", "type": "loc", "score": 2, "label": {"eng": "India"}, "location": {"type": "country", "label": {"eng": "India"}}}, {"uri": "http://en.wikipedia.org/wiki/GPT-4", "type": "wiki", "score": 1, "label": {"eng": "GPT-4"}}, {"uri": "http://en.wikipedia.org/wiki/Scalability", "type": "wiki", "score": 1, "label": {"eng": "Scalability"}}, {"uri": "http://en.wikipedia.org/wiki/Valuation_(finance)", "type": "wiki", "score": 1, "label": {"eng": "Valuation (finance)"}}, {"uri": "http://en.wikipedia.org/wiki/Electricity", "type": "wiki", "score": 1, "label": {"eng": "Electricity"}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Society/Issues/Business", "label": "dmoz/Society/Issues/Business", "wgt": 100}, {"uri": "dmoz/Business/Opportunities/Opposing_Views", "label": "dmoz/Business/Opportunities/Opposing Views", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 71}], "image": "https://analyticsindiamag.com/wp-content/uploads/2024/08/Mohits-Banners-36-1300x731.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.06666666666666665, "wgt": 144, "relevance": 1}
{"uri": "8259559507", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "06:41:46", "dateTime": "2024-08-05T06:41:46Z", "dateTimePub": "2024-08-05T06:41:25Z", "dataType": "news", "sim": 0.5607843399047852, "url": "https://www.techtimes.com/articles/307032/20240805/behind-the-breakthrough-ai-powered-strategies-speeding-up-drug-development.htm", "title": "Behind the Breakthrough: AI-Powered Strategies Speeding Up Drug Development", "body": "\"The future is already here -- it's just not evenly distributed,\" Maulik Mukeshbhai Patel, a seasoned biopharmaceutical expert, remarked at a recent industry conference.\n\nHis statement captures the essence of the transformative impact of artificial intelligence (AI) on drug development and underscores the uneven pace at which the health sector is adopting this technology. In pharmaceuticals, the integration of AI is not just a trend but a reshaping of how drugs are discovered, developed, and brought to market. In the pharmaceutical and biotechnology industries, few professionals have demonstrated the consistent growth and dedication exhibited by Patel.\n\nThe promise of AI in pharmaceuticals lies in its potential to drastically reduce the time and cost associated with drug development, a process traditionally fraught with high failure rates and billion-dollar investments.\n\nThe traditional drug development process can be lengthy and costly. Often, it takes over a decade and costs upwards of $2.8 billion. AI technologies are to disrupt this by enhancing the efficiency and effectiveness of drug discovery and development processes. AI can analyze vast datasets far quicker than humans, allowing it to identify potential drug candidates much faster than traditional methods.\n\nWith his extensive biopharmaceutical background working for various pharmaceutical companies, Patel emphasizes AI's significance in today's drug development landscape. \"AI is not just a tool but a shift in how we approach the discovery and development of new therapies,\" he explains and shares insights in his published article, \"Unveiling the Future of Life Sciences: Advances in Cell and Molecular Biology and the Role of AI in Drug Discovery.\" His work deeply impacted the traditional methods of research in genome editing, structural biology, and computational biology and provided pathways using modern models based on artificial intelligence that significantly reduce time and human efforts in drug development, ultimately benefiting patients.\n\nDespite the optimism surrounding AI in drug development, the technology is not without its critics. Some experts argue that while AI can accelerate specific processes, a more nuanced understanding of biological systems experienced researchers bring is needed.\n\n\"AI is a powerful tool, but it must be wielded wisely and with a clear understanding of its limitations,\" notes a researcher at a leading pharmaceutical company. She points out that the quality of AI models depends on the data they train on, and any biases in this data can cause flawed outcomes.\n\nThe adoption of AI in drug development also faces significant barriers. This includes high initial costs, data privacy concerns, and the need for substantial regulatory oversight. Patel acknowledges these challenges but remains optimistic. \"The road to integrating AI into pharma is complex and ladened with hurdles, yet the potential benefits for patient care and efficiency are too great to ignore,\" he says.\n\nAI will play a pivotal role in shaping the future of healthcare; as per Patel, \"We are on the brink of a new era in medicine, where AI-driven innovations could lead to safer, more effective, and more accessible treatments for all.\"\n\nHis article, \"Accelerating Regenerative Medicine: The Critical Convergence of AI, Discovery to Delivery and Path Forward,\" tackles the transformative impact of artificial intelligence (AI) on regenerative medicine. It highlights how AI is revolutionizing the field by enhancing the discovery of new therapies, optimizing the delivery of treatments, and streamlining the entire development process. AI algorithms are used to analyze complex biological data, predict the efficacy of regenerative treatments, and personalize therapies for individual patients.\n\nThis convergence of AI and regenerative medicine promises to accelerate the development of innovative treatments, ultimately improving patient outcomes and advancing the field significantly. Patel's work will continue to remain at the heart of this advancement.\n\nAI has transformative potential in the pharmaceutical industry. As it advances, its integration into drug development promises to redefine medicine. It also offers hope for faster and more efficient healthcare solutions.", "source": {"uri": "techtimes.com", "dataType": "news", "title": "Tech Times"}, "authors": [{"uri": "carl_williams@techtimes.com", "name": "Carl Williams", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Medication", "type": "wiki", "score": 5, "label": {"eng": "Medication"}}, {"uri": "http://en.wikipedia.org/wiki/Drug_development", "type": "wiki", "score": 5, "label": {"eng": "Drug development"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Biopharmaceutical", "type": "wiki", "score": 4, "label": {"eng": "Biopharmaceutical"}}, {"uri": "http://en.wikipedia.org/wiki/Biotechnology", "type": "wiki", "score": 3, "label": {"eng": "Biotechnology"}}, {"uri": "http://en.wikipedia.org/wiki/Pharmaceutical_industry", "type": "wiki", "score": 3, "label": {"eng": "Pharmaceutical industry"}}, {"uri": "http://en.wikipedia.org/wiki/Structural_biology", "type": "wiki", "score": 2, "label": {"eng": "Structural biology"}}, {"uri": "http://en.wikipedia.org/wiki/Biological_system", "type": "wiki", "score": 2, "label": {"eng": "Biological system"}}, {"uri": "http://en.wikipedia.org/wiki/Genome_editing", "type": "wiki", "score": 2, "label": {"eng": "Genome editing"}}, {"uri": "http://en.wikipedia.org/wiki/Computational_biology", "type": "wiki", "score": 2, "label": {"eng": "Computational biology"}}, {"uri": "http://en.wikipedia.org/wiki/Drug_discovery", "type": "wiki", "score": 2, "label": {"eng": "Drug discovery"}}, {"uri": "http://en.wikipedia.org/wiki/Regeneration_(biology)", "type": "wiki", "score": 1, "label": {"eng": "Regeneration (biology)"}}, {"uri": "http://en.wikipedia.org/wiki/Efficacy", "type": "wiki", "score": 1, "label": {"eng": "Efficacy"}}, {"uri": "http://en.wikipedia.org/wiki/Regenerative_medicine", "type": "wiki", "score": 1, "label": {"eng": "Regenerative medicine"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 1, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Health_care", "type": "wiki", "score": 1, "label": {"eng": "Health care"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 1, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Medicine", "type": "wiki", "score": 1, "label": {"eng": "Medicine"}}], "categories": [{"uri": "dmoz/Health/Specific_Substances", "label": "dmoz/Health/Specific Substances", "wgt": 100}, {"uri": "dmoz/Health/Specific_Substances/Tobacco", "label": "dmoz/Health/Specific Substances/Tobacco", "wgt": 100}, {"uri": "dmoz/Business/Biotechnology_and_Pharmaceuticals/Contract_Research_Organizations", "label": "dmoz/Business/Biotechnology and Pharmaceuticals/Contract Research Organizations", "wgt": 100}, {"uri": "dmoz/Health/Teen_Health/Drugs_and_Alcohol", "label": "dmoz/Health/Teen Health/Drugs and Alcohol", "wgt": 100}, {"uri": "dmoz/Health/Medicine/Pharmacology", "label": "dmoz/Health/Medicine/Pharmacology", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 74}], "image": "https://1734811051.rsc.cdn77.org/data/thumbs/full/449954/820/0/0/0/maulik-patel.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.08235294117647052, "wgt": 143, "relevance": 1}
{"uri": "2024-08-444299749", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "09:08:03", "dateTime": "2024-08-05T09:08:03Z", "dateTimePub": "2024-08-05T08:55:41Z", "dataType": "news", "sim": 0.5607843399047852, "url": "https://www.technology.org/2024/08/05/how-ai-is-enhancing-telehealth-services/", "title": "How AI Is Enhancing Telehealth Services", "body": "Artificial intelligence (AI) is slowly but surely changing every sector it touches, but so far, it has had an unequal impact on different industries. For example, while skilled trade work and traditional crafts remain largely untouched by AI (for now), healthcare is being transformed in every aspect.\n\nFrom AI-powered diagnostic tools that improve the accuracy of diagnoses to virtual health assistants that provide 24/7 access to medical advice, AI is enhancing medicine as a whole, both for patients and healthcare providers. Telehealth services, in particular, are reaping the benefits of rapidly evolving AI technologies.\n\nHere's how technology is enhancing healthcare today - and what this means for the future.\n\nDiagnostic Tools\n\nUntil relatively recently, AI has mostly been used for data processing. Today, it's used for so much more, including making diagnostic tools smarter and more accurate.\n\nWhile doctors today have access to vast amounts of data, what they don't have is unlimited time. This is where AI steps in - by analyzing complex data sets quickly (infinitely faster than any human could), it can spot patterns that a doctor could miss. And it does so faster, which leads to better patient outcomes. Mind you, this isn't just possible in theory - AI-powered diagnostic tools are already assisting in identifying diseases from medical imaging, improving accuracy and speed.\n\nVirtual Health Assistants\n\nVirtual health assistants are becoming common in telehealth. These AI-driven systems can answer patients' questions, remind them to take medication, and even book appointments for them.\n\nFor example, there are now numerous companies that use AI to offer 24/7 consultations. You describe your symptoms, and the AI provides preliminary advice before you see a doctor. If you plan on using these services, we recommend looking for platforms that provide HIPAA-compliant telehealth video chat and audio calls - this way, you know your chat is secure and confidential.\n\nPatient Data Analytics\n\nManaging and analyzing patient data is another area where AI is currently being used. Because telehealth platforms collect vast amounts of data, from vital signs to treatment outcomes, AI algorithms are used for sifting through this data to identify patterns and trends that might otherwise go unnoticed. AI can even be used for addressing unstructured patient data, such as doctor's notes, discharge summaries, etc.\n\nAs you can probably deduce, this is beneficial for one main reason: it leads to more personalized yet faster treatment plans. For example, AI can predict which patients are at risk of chronic conditions and then suggest preventive measures.\n\nThe Future of AI in Telehealth\n\nIn the future, the role of AI in telehealth will only grow. We expect even more advanced diagnostic tools, smarter virtual assistants, and even more sophisticated data analytics. AI will continue to enhance patient care, streamline operations, and make healthcare more accessible to everyone.\n\nAI-powered predictive analytics will become even more prevalent, enabling healthcare providers to foresee health issues before they become serious. For instance, AI might predict the likelihood of a patient developing a particular condition based on their data, allowing for earlier intervention.\n\nAI will also more than likely bring about various advancements in personalized medicine. By analyzing individual health data, AI will help create customized treatment plans tailored to each patient's unique needs, which should help improve outcomes.\n\nAs for telehealth platforms, they, too, will see improvements in user experience. With AI, virtual consultations will become more interactive and responsive, improving patient satisfaction.\n\nOverall, as AI technology improves - which is already happening at a rapid speed - so will its applications in telehealth, making healthcare smarter, faster, and more efficient.", "source": {"uri": "technology.org", "dataType": "news", "title": "Technology Org"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Telehealth", "type": "wiki", "score": 5, "label": {"eng": "Telehealth"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Health_care", "type": "wiki", "score": 5, "label": {"eng": "Health care"}}, {"uri": "http://en.wikipedia.org/wiki/Data_processing", "type": "wiki", "score": 3, "label": {"eng": "Data processing"}}, {"uri": "http://en.wikipedia.org/wiki/Medicine", "type": "wiki", "score": 3, "label": {"eng": "Medicine"}}, {"uri": "http://en.wikipedia.org/wiki/Medication", "type": "wiki", "score": 2, "label": {"eng": "Medication"}}, {"uri": "http://en.wikipedia.org/wiki/Videotelephony", "type": "wiki", "score": 2, "label": {"eng": "Videotelephony"}}, {"uri": "http://en.wikipedia.org/wiki/Medical_imaging", "type": "wiki", "score": 2, "label": {"eng": "Medical imaging"}}, {"uri": "http://en.wikipedia.org/wiki/Chronic_condition", "type": "wiki", "score": 1, "label": {"eng": "Chronic condition"}}, {"uri": "http://en.wikipedia.org/wiki/Vital_signs", "type": "wiki", "score": 1, "label": {"eng": "Vital signs"}}, {"uri": "http://en.wikipedia.org/wiki/Personalized_medicine", "type": "wiki", "score": 1, "label": {"eng": "Personalized medicine"}}, {"uri": "http://en.wikipedia.org/wiki/Predictive_analytics", "type": "wiki", "score": 1, "label": {"eng": "Predictive analytics"}}, {"uri": "http://en.wikipedia.org/wiki/User_experience", "type": "wiki", "score": 1, "label": {"eng": "User experience"}}, {"uri": "http://en.wikipedia.org/wiki/Analytics", "type": "wiki", "score": 1, "label": {"eng": "Analytics"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 1, "label": {"eng": "Algorithm"}}], "categories": [{"uri": "dmoz/Health/Education/Patient_Education", "label": "dmoz/Health/Education/Patient Education", "wgt": 19}, {"uri": "dmoz/Health/Public_Health_and_Safety/Patient_Safety", "label": "dmoz/Health/Public Health and Safety/Patient Safety", "wgt": 22}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 22}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 29}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 20}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 58}], "image": "https://lh7-rt.googleusercontent.com/docsz/AD_4nXeQDz2jHaZt4_6OI28ApGmCjUOyfZDm0YkeTi2fvqFW5I6lrSMJpOcor9Llk1lWfogtvyHj73YR5xvUqLvUUO7eiYi_idFuzBKzMx89PZ9C1zrUJWOLddKop5pDxDOrIaGfp_u2Q0c-YsxTvU_L3ClKs5UB?key=r00P6MwQgrBIjE-iBxeg1Q", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.1686274509803922, "wgt": 143, "relevance": 1}
{"uri": "8260008793", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "11:41:18", "dateTime": "2024-08-05T11:41:18Z", "dateTimePub": "2024-08-05T11:40:01Z", "dataType": "news", "sim": 0.5607843399047852, "url": "https://www.ndtvprofit.com/technology/75-leaders-believe-responsible-ai-can-improve-decision-making-governance-report", "title": "75% Leaders Believe Responsible AI Can Improve Decision-Making, Governance: Report", "body": "Three-fourth of industry leaders believe responsible artificial intelligence can improve decision-making and governance. To that end, 73% of the leaders support establishing a dedicated AI governance and ethics board within the corporate structure to oversee responsible AI practices, according to a report by Primus Partners.\n\nBased on insights from industry leaders and domain experts, the report shows that AI has the potential to contribute up to 10% to India's GDP by 2025, if governed responsibly.\n\nIt highlights the challenges of data quality and availability (including data scarcity, biases in datasets and complexities of data preparation and cleaning), noting that 76% of the industry views these as their top concerns in AI deployment.\n\nIt also emphasises that 61% of the industry prioritises privacy and security, including threats posed by deepfakes, as a crucial principle-based element in safe AI deployment.\n\nOther key findings from the report include:\n\nThe report recommends establishing a robust framework that supports innovation, while addressing the ethical challenges posed by AI. It calls for a collaborative approach between the government and the private sector to develop standards and practices that ensure AI benefits all segments of the society.\n\n\"India's current AI landscape reflects a segment full of opportunities. As we journey towards becoming a trillion-dollar digital economy, we must adopt a balanced approach to AI governance. This involves leveraging AI for its economic benefits, while ensuring robust regulatory frameworks that can prevent or curb risks such as deepfakes by promoting ethical standards,\" said Devroop Dhar, co-founder and managing director, Primus Partners.", "source": {"uri": "ndtvprofit.com", "dataType": "news", "title": "NDTV Profit"}, "authors": [{"uri": "ndtv_profit_tech@ndtvprofit.com", "name": "Ndtv Profit Tech", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Decision-making", "type": "wiki", "score": 3, "label": {"eng": "Decision-making"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/India", "type": "loc", "score": 3, "label": {"eng": "India"}, "location": {"type": "country", "label": {"eng": "India"}}}, {"uri": "http://en.wikipedia.org/wiki/Primus_(band)", "type": "org", "score": 2, "label": {"eng": "Primus (band)"}}, {"uri": "http://en.wikipedia.org/wiki/Gross_domestic_product", "type": "wiki", "score": 2, "label": {"eng": "Gross domestic product"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Deepfake", "type": "wiki", "score": 1, "label": {"eng": "Deepfake"}}, {"uri": "http://en.wikipedia.org/wiki/Digital_economy", "type": "wiki", "score": 1, "label": {"eng": "Digital economy"}}, {"uri": "http://en.wikipedia.org/wiki/Private_sector", "type": "wiki", "score": 1, "label": {"eng": "Private sector"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Society/Issues", "label": "dmoz/Society/Issues", "wgt": 100}, {"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Society/Issues/Economic", "label": "dmoz/Society/Issues/Economic", "wgt": 100}, {"uri": "dmoz/Society/Issues/Government_Operations", "label": "dmoz/Society/Issues/Government Operations", "wgt": 100}, {"uri": "dmoz/Society/Activism/In_Daily_Life", "label": "dmoz/Society/Activism/In Daily Life", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 63}], "image": "https://www.ndtvprofit.com/icons/apple-touch-icon.png", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.4352941176470588, "wgt": 143, "relevance": 1}
{"uri": "8259901020", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "10:33:02", "dateTime": "2024-08-05T10:33:02Z", "dateTimePub": "2024-08-05T10:32:24Z", "dataType": "news", "sim": 0.5607843399047852, "url": "https://www.intelligentcio.com/africa/2024/08/05/presight-leads-ai-enablement-workshop-for-top-ethiopian-government-officials/", "title": "Presight leads AI enablement workshop for top Ethiopian government officials  - Intelligent CIO Africa", "body": "Presight, one of the Middle East's leading big data analytics company powered by generative AI, hosted a workshop on the potential of Artificial Intelligence (AI) for the public sector and was attended by Ethiopia's Deputy Prime Minister Temesgen Tiruneh and several high-level Ethiopian Government officials.\n\nThe three-day workshop, held as part of the AI Enablement Initiative, took place in Addis Ababa from July 22 to July 24 and was put together in partnership with Open Innovation AI - an Abu Dhabi-based software company.\n\nDesigned to equip high-level government leaders with knowledge and insight into generative AI, the workshop covered big data analytics and other important technologies that could be deployed to support government decision making, policy, planning and other aspects of public sector work. It also highlighted the potential of generative AI to enhance public services and increase government efficiency.\n\nEthiopia's Deputy Prime Minister Temesgen Tiruneh, said: \"AI is transforming businesses, industries, government and societies, all around the world. For us, the timely and prudent use of AI applications is a strategic imperative for our nation's future competitiveness and growth. In that spirit, investing in AI education and training is essential to build a workforce capable of developing AI solutions and realising the full potential of this technology. Workshops such as these are a positive step towards achieving this.\n\nDr. Adel Alsharji, COO of Presight, said: \"The AI Enablement Initiative demonstrates Presight's dedication to supporting Ethiopia in its journey towards innovation and technological growth. Presight was honored to host senior representatives of the government to discuss the potential of AI in public services and share our international expertise in this area. We look forward to further initiatives as part of the program to continue to contribute to the Digital Transformation of government for the benefit of the citizens of Ethiopia.\"", "source": {"uri": "intelligentcio.com", "dataType": "news", "title": "Intelligent CIO"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Temesgen_Tiruneh", "type": "wiki", "score": 4, "label": {"eng": "Temesgen Tiruneh"}}, {"uri": "http://en.wikipedia.org/wiki/Deputy_prime_minister", "type": "wiki", "score": 4, "label": {"eng": "Deputy prime minister"}}, {"uri": "http://en.wikipedia.org/wiki/Public_sector", "type": "wiki", "score": 4, "label": {"eng": "Public sector"}}, {"uri": "http://en.wikipedia.org/wiki/Big_data", "type": "wiki", "score": 4, "label": {"eng": "Big data"}}, {"uri": "http://en.wikipedia.org/wiki/Government_of_Ethiopia", "type": "wiki", "score": 3, "label": {"eng": "Government of Ethiopia"}}, {"uri": "http://en.wikipedia.org/wiki/Middle_East", "type": "loc", "score": 3, "label": {"eng": "Middle East"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Addis_Ababa", "type": "loc", "score": 3, "label": {"eng": "Addis Ababa"}, "location": {"type": "place", "label": {"eng": "Addis Ababa"}, "country": {"type": "country", "label": {"eng": "Ethiopia"}}}}, {"uri": "http://en.wikipedia.org/wiki/Ethiopia", "type": "loc", "score": 3, "label": {"eng": "Ethiopia"}, "location": {"type": "country", "label": {"eng": "Ethiopia"}}}, {"uri": "http://en.wikipedia.org/wiki/Decision-making", "type": "wiki", "score": 2, "label": {"eng": "Decision-making"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 2, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/Digital_transformation", "type": "wiki", "score": 1, "label": {"eng": "Digital transformation"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_operating_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief operating officer"}}], "categories": [], "image": "https://www.intelligentcio.com/africa/wp-content/uploads/sites/5/2024/08/Image_Presight-Leads-AI-Enablement-Workshop-for-top-Ethiopian-Government-Officials.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-07-22", "dateEnd": "2024-07-24", "textStart": 412, "textEnd": 430}], "sentiment": 0.3960784313725489, "wgt": 143, "relevance": 1}
{"uri": "8259257090", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "01:07:39", "dateTime": "2024-08-05T01:07:39Z", "dateTimePub": "2024-08-05T01:06:26Z", "dataType": "news", "sim": 0.5568627715110779, "url": "https://s24526.pcdn.co/news/1663382/nepa-ai", "title": "NEPA-AI", "body": "The implementation of artificial intelligence is all around us in Northeast Pennsylvania, and it continues to expand. In part two of NEP-AI, business owners, educators and physicians discuss the ways in which their work has been influenced, for better or worse, by the increasing relevance of artificial intelligence.\n\nVizVibe\n\nIn addition to his role as the co-founder and CEO of VizVibe, Kevin Jones is also a professor of communication arts at Luzerne County Community College. In the practical sense, he probably faces the current discourse surrounding artificial intelligence more directly as an educator than he does at his own company, which specializes in interactive content and media through augmented reality (AR).\n\nIn either case, Jones is an advocate for staying up-to-date on the latest technologies. However, he's acutely aware of the bad press surrounding AI in certain circles, and shares some of the concerns that are swirling out there.\n\nFirst, there's the security and privacy concerns.\n\n\"There's more potential for people to steal your information, there's more scams, there's more fakes out there than ever before.\"\n\nThen, there are the creative concerns.\n\n\"I don't think this is a good thing, being an artist, but you can have somebody who has a horrible singing voice sound amazing with AI, or they don't even have to sing.\"\n\nAnd in his life as an educator, the academic concerns loom large.\n\n\"You have traditional educators who are freaked out, because they're like 'It could write the paper...,'\" Jones said of the frequent objection to AI appearing in the academic world.\n\nBut Jones believes that the negativity surrounding AI is not unique. He said that some of these same concerns were previously lobbed at other technologies, some of which we take for granted and now use all the time.\n\nJones is also aware that his approach to teaching, and AI in general, is untraditional. Where others may see pitfalls, Jones is seeing opportunities for AI to play a role in cross-discipline curriculum. In fact, for certain assignments in his classes, students are encouraged to use AI, but in a responsible manner.\n\n\"I let my students use ChatGPT or AI to do personas for projects. I let them do market research,\" Jones said. \"I let them... write some of their design briefs or some of their presentations [using artificial intelligence tools], but they have to tell me where they got the information from, and they have to vet it online to make sure it's accurate and it didn't hallucinate and give them some kind of false statistic.\"\n\nThere's some inevitability to the use of AI when it comes to the academic setting, and Jones intends to be ahead of the curve regarding his students' responsible use of it.\n\n\"These tools are going to be utilized, so if I'm not teaching the students how to properly use it, then I'm not really doing justice to the students.\"\n\nFidbak\n\nAfter establishing the soccer training app Fidbak, Julio Pertuz was needed to create a system that would be useful to players, and would provide some objectivity to the feedback process.\n\nAthletes can upload their videos onto Fidbak, where coaches can judge their technique. Players are given a \"scoring report\" by the coach who views the video, and are offered tips for how to enhance the skill they present in the video.\n\n\"The app is basically just a training tool for players to develop and grow their skills, and a showcase platform where they can show the world all their talents,\" Pertuz said of the app's broad goals. He said that, as of mid-July, the app had 225 users.\n\nPertuz is looking ahead, though. He sees growth in Fidbak's future. What happens when the app reaches 1,000 users? Or 5,000?\n\nThose are the numbers Pertuz is talking about, and he is fully aware of the demand that will follow them.\n\nIn preparation for Fidbak's future, Pertuz has already worked with two companies to build a prototype algorithm, showing off the ways in which machine learning and artificial intelligence can help. The first major step in developing this algorithm, at least from Pertuz's perspective, was considering the cost association. Pertuz knows that this technology is expensive.\n\nBut as far as the implementation is concerned, Pertuz has his eyes on using good data from the coaches that are currently working with Fidbak. By interpreting that good data, the AI will be able to serve a greater number of users, and serve them well.\n\n\"It's really not that impressive,\" said Pertuz of artificial intelligence's main function. \"If you think about it, what AI is doing right now is just repetitive tasks.\"\n\nHe continued: \"Whatever somebody can do, if you train AI to do that task, it'll do it better and quicker.\"\n\nWilkes University\n\nWilkes University, at large, is treating AI as an active phenomenon, not a looming one. Dr. Del Lucent, associate professor of physics in the department of mathematics and computer science at Wilkes, said that the unethical use of AI falls under the category of academic dishonesty and misconduct.\n\n\"Our official university policy, of course, is that use of any unauthorized tool is considered plagiarism. The student handbook describes how to deal with that.\"\n\nUnethical behavior, in this case, might manifest as a student using ChatGPT to write an entire essay on their behalf. For what it's worth, some professors, such as Lucent, are rather critical of the product that method will produce, especially in comparison to a student's original work.\n\n\"I think AI does a bang-up job of writing boilerplate, boring stuff. But in terms of teaching someone to think critically or teaching someone to express themselves, it's very poor,\" Lucent said. \"I would prefer to see something genuine and imperfect rather than something that is unoriginal and equally imperfect, but... in a much less useful way on the subject of learning.\"\n\nProfessors are still trying to figure out a coherent strategy to approach the topic of AI in the classroom. For Lucent, AI can be used as a learning tool when the system itself is turned on its head.\n\n\"In physics and computer science, one way that I like to do things is... you can say: 'These responses were generated by ChatGPT. Which one of them is wrong and why?'\"\n\nFor Dr. Evene Estwick, chair and associate professor of communication and media studies at Wilkes, the approach to AI will depend on both the class being taught and the professor who is teaching.\n\n\"Some classes might lend itself more naturally to the use of AI, and others might not,\" Estwick said. \"So that's really going to be determined by the individual faculty member.\"\n\nEstwick said that AI is very much a topic of the present, referencing the SAG-AFTRA and Writers Guild of America strikes of 2023. In both strikes, AI was at the forefront of the discussion. Creatives were concerned about how they would be compensated if their work was filtered through AI and used to generate content, and the topic was used as a bargaining tool.\n\nOn the topic of creativity, Eric Ruggiero, chair of integrative media, art and design at Wilkes, said that AI is at its most useful when it is applied as a brainstorming tool.\n\n\"We're digital content creators, so it's important for us to make things ourselves,\" said Ruggiero. \"In the AI world, right now, we're looking at it as a point of reference for creating ideas and generating those as we move forward.\"\n\nOtherwise, Ruggiero indicated that an over reliance on AI during the creative process, especially beyond its earliest stages, can end up being a waste of time. Trying to find the correct keywords -- and trying to get the AI to generate something beyond its capacity -- can result in a loop of unproductivity.\n\n\"If I had an initial idea and I needed to create something, I could probably do that pretty readily by myself.\"\n\nGeisinger\n\nAI has become an exceptionally helpful tool at Geisinger Wyoming Valley Medical Center, especially for physicians like Dr. Clemens Schirmer. He's the vice chair and a professor in the neurosurgery department, the program director of the Geisinger Neurosurgery Residency, and overseer of the interventional stroke ecosystem, at Geisinger Wyoming Valley Medical Center.\n\nThe infusion of artificial intelligence into the Geisinger system has sped up important processes, benefiting the physicians and, most critically, the patients.\n\n\"When patients come to us with acute problems, there's a need to rapidly identify and triage, if you will, the patient and what their needs are,\" said Schirmer. \"We use AI, essentially, as a backstop, or as a way of rapidly communicating the results to the clinicians that need that result at that particular minute.\"\n\nThe signature speed with which AI can work in the modern health care environment is especially critical when dealing with stroke patients, or those who are at-risk. Time, in those cases, is of the essence.\n\nOf particular note is Geisinger's use of AI when it comes to early detection and prevention cases.\n\n\"We developed a program where we're looking at all the active patients at Geisinger and we give them a risk score for cardiovascular events and stroke,\" Schirmer said. \"We look at the people that have the highest scores -- that top-risk batch -- if they have any, what we say, are simple care gaps.\"\n\nThe AI infrastructure at Geisinger is able to identify patterns that would place patients in the \"top-risk\" category. When those patients are identified, a medical professional from Geisinger can step in and ensure that the patient's medications are being used and are working effectively. If they are not, the necessary changes can be made.\n\nThere are roughly half a million active patients in the Geisinger system, so shuffling through the results of each patient to find warning signs would require hiring \"thousands of people,\" according to Schirmer. The AI system works quickly and precisely, without, as Schirmer put it, \"breaking the resource bank.\"\n\nOn the administrative side, Schirmer detailed Geisinger's use of AI in gathering medical information gathered during patient visits. This near automatic record-keeping allows the medical professionals to focus more on interacting with patients and less on the tedious pieces of their work.\n\n\"It helps the clinicians to be less behind on all these administrative tasks, which is a really big driver of unhappiness, burnout, and so on and so forth.\"\n\nThe Wright Center\n\nDr. Jignesh Sheth, M.D., FACP, MPH, serves as the chief medical and information officer and the senior vice president at The Wright Center for Community Health and Graduate Medical Education. In regards to the Wright Center's current AI program, he is meticulous when it comes to making sure that patient information is safe.\n\n\"What is the safest way of using the technology, helping the clinicians, without jeopardizing patient information?\" Sheth asked. \"We have to put a lot of parameters in place around security and privacy.\"\n\nLike Geisinger, the Wright Center uses AI to record patient meetings. The AI hears the conversation and transcribes it, allowing physicians to recall the meeting's content without having to manually take notes and risk losing concentration. Of course, all of this is done with patient consent.\n\n\"I think it has been an overall positive experience. I'm able to focus more on patients. I'm able to make more eye contact with patients. I'm still obligated to put labs and messages and medication refills in the computer, but that's the only amount of time I'm looking at a screen, rather than looking at the patient,\" Sheth said. \"One of the complaints, in the 21st century, that patients have is that doctors are too much on their computer -- less face-to-face. I think we will be able to eliminate that issue.\"\n\nThe AI tool Webex Assistant can transcribe meetings between the Wright Center's employees, too. Much like the interactions with patients, medical professionals like Sheth are able to review the detailed, accurate notes from meetings, all while being fully attentive in the moment.\n\n\"Now, I have a digital assistant that does not make mistakes. A digital assistant that's consistently able to listen, process it at a rate faster than we could, gives me a summary, totally allowing me to focus on the meeting instead of focusing on taking notes.\"\n\nSince the COVID-19 pandemic, the ability to take notes while on virtual calls, the main function of Webex, is incredibly useful. While the note-taking AI tools used by the Wright Center are highly accurate, according to Sheth, the transcriptions are always looked over.\n\n\"Any transcription that we use... the notes still have to be fully reviewed by the clinician, and approved that everything that was there was correct,\" said Sheth. \"Any AI scribed note has to be reviewed by the clinician and then signed off.\"\n\nThese tools are mainly used on the administrative side of the Wright Center's operations, but the company's patient and employee scores have both improved since their implementation. As tedious, repetitive tasks are shifted from employees to automation, work-related stress has declined, said Sheth. On both the patient and employee levels, the increase in happiness is objectively measured by survey results.\n\nEven Sheth has seen a difference in his workload thanks to the implementation of AI.", "source": {"uri": "s24526.pcdn.co", "dataType": "news", "title": "Times Leader"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Wilkes_University", "type": "org", "score": 5, "label": {"eng": "Wilkes University"}}, {"uri": "http://en.wikipedia.org/wiki/Education", "type": "wiki", "score": 5, "label": {"eng": "Education"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Mobile_app", "type": "wiki", "score": 5, "label": {"eng": "Mobile app"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 4, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 4, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Physician", "type": "wiki", "score": 4, "label": {"eng": "Physician"}}, {"uri": "http://en.wikipedia.org/wiki/Associate_professor", "type": "wiki", "score": 3, "label": {"eng": "Associate professor"}}, {"uri": "http://en.wikipedia.org/wiki/Luzerne_County_Community_College", "type": "org", "score": 3, "label": {"eng": "Luzerne County Community College"}}, {"uri": "http://en.wikipedia.org/wiki/Curriculum", "type": "wiki", "score": 3, "label": {"eng": "Curriculum"}}, {"uri": "http://en.wikipedia.org/wiki/Objectivity_(philosophy)", "type": "wiki", "score": 3, "label": {"eng": "Objectivity (philosophy)"}}, {"uri": "http://en.wikipedia.org/wiki/Confidence_trick", "type": "wiki", "score": 3, "label": {"eng": "Confidence trick"}}, {"uri": "http://en.wikipedia.org/wiki/Mass_communication", "type": "wiki", "score": 3, "label": {"eng": "Mass communication"}}, {"uri": "http://en.wikipedia.org/wiki/Northeastern_United_States", "type": "loc", "score": 3, "label": {"eng": "Northeastern United States"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Market_research", "type": "wiki", "score": 3, "label": {"eng": "Market research"}}, {"uri": "http://en.wikipedia.org/wiki/Physics", "type": "wiki", "score": 3, "label": {"eng": "Physics"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_science", "type": "wiki", "score": 3, "label": {"eng": "Computer science"}}, {"uri": "http://en.wikipedia.org/wiki/Augmented_reality", "type": "wiki", "score": 3, "label": {"eng": "Augmented reality"}}, {"uri": "http://en.wikipedia.org/wiki/Statistics", "type": "wiki", "score": 3, "label": {"eng": "Statistics"}}, {"uri": "http://en.wikipedia.org/wiki/Hallucination", "type": "wiki", "score": 3, "label": {"eng": "Hallucination"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 3, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Pennsylvania", "type": "loc", "score": 3, "label": {"eng": "Pennsylvania"}, "location": {"type": "place", "label": {"eng": "Pennsylvania"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Media_studies", "type": "wiki", "score": 2, "label": {"eng": "Media studies"}}], "categories": [{"uri": "dmoz/Health/Alternative", "label": "dmoz/Health/Alternative", "wgt": 100}, {"uri": "dmoz/Health/Reproductive_Health/Birth_Control", "label": "dmoz/Health/Reproductive Health/Birth Control", "wgt": 100}, {"uri": "dmoz/Health/Teen_Health/Teen_Pregnancy", "label": "dmoz/Health/Teen Health/Teen Pregnancy", "wgt": 100}, {"uri": "dmoz/Health/Public_Health_and_Safety/First_Aid", "label": "dmoz/Health/Public Health and Safety/First Aid", "wgt": 100}, {"uri": "dmoz/Society/Support_Groups/Twelve_Step", "label": "dmoz/Society/Support Groups/Twelve Step", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 69}], "image": "https://s24526.pcdn.co/wp-content/uploads/2024/08/130806886_web1_Geisinger.jpg.optimal.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.1764705882352942, "wgt": 142, "relevance": 1}
{"uri": "8259119489", "lang": "eng", "isDuplicate": false, "date": "2024-08-04", "time": "21:36:28", "dateTime": "2024-08-04T21:36:28Z", "dateTimePub": "2024-08-04T21:35:26Z", "dataType": "news", "sim": 0.5529412031173706, "url": "https://techbullion.com/ai-driven-cybersecurity-enhancing-threat-intelligence-and-response/", "title": "AI-Driven Cybersecurity: Enhancing Threat Intelligence and Response", "body": "Artificial Intelligence (AI-driven) cybersecurity is changing the way organizations detect and respond to threats. By enhancing threat intelligence, providing real-time response capabilities, and automating routine tasks, Artificial Intelligence (AI) enables organizations to stay ahead of cyber threats. However, it is essential to address the challenges and ethical considerations associated with AI to ensure its responsible and effective use. As AI technology continues to evolve, its role in cybersecurity will only become more critical, helping to create a safer digital landscape for all.\n\nThe Evolution of Cyber Threats:\n\nCyber threats have evolved significantly over the years. Hackers now use advanced techniques to bypass traditional security measures. These techniques include phishing, ransomware, and advanced persistent threats (APTs). Traditional cybersecurity tools, such as firewalls and antivirus software, struggle to keep up with these ever-evolving threats. This has created a need for more advanced and adaptive security solutions.\n\nUnderstanding AI-Driven Cybersecurity:\n\nAI-driven cybersecurity refers to the use of AI technologies to enhance threat detection, analysis, and response. AI systems can process vast amounts of data quickly and accurately, identifying patterns and anomalies that may indicate a potential threat. Unlike traditional systems, AI can learn and adapt over time, becoming more effective at identifying and mitigating threats.\n\nBenefits of AI-Driven Cybersecurity: The integration of AI into cybersecurity offers numerous benefits: Improved Threat Detection:\n\nAI can analyze large volumes of data at high speeds, identifying threats that might go unnoticed by human analysts. This leads to quicker and more accurate threat detection.\n\nEnhanced Threat Intelligence:\n\nAI systems gather and analyze threat data from multiple sources, providing valuable insights into emerging threats and attack vectors. This helps organizations stay ahead of cybercriminals.\n\nReal-Time Response:\n\nAI systems can respond to threats in real-time, reducing the time between threat detection and response. This minimizes potential damage and ensures faster recovery.\n\nReduced False Positives:\n\nTraditional security systems often generate numerous false positives, overwhelming security teams. AI systems are more accurate, reducing the number of false positives and allowing teams to focus on genuine threats.\n\nPredictive Capabilities:\n\nAI can predict future threats by analyzing patterns and trends in historical data. This proactive approach helps organizations prepare for potential attacks and strengthen their defenses.\n\nAutomation:\n\nAI automates routine security tasks, freeing up human analysts to focus on more complex issues. This improves overall efficiency and effectiveness.\n\nKey Applications of AI-Driven Cybersecurity:\n\nAI-driven cybersecurity is used in various ways to enhance threat intelligence and response. Some of the key applications include:\n\nBehavioral Analysis:\n\nAI monitors user behavior and identifies deviations from normal patterns. This helps in detecting insider threats and compromised accounts.\n\nMalware Detection:\n\nAI-powered systems can analyze files and code to identify malware, even if it has never been seen before. This is particularly useful in detecting zero-day attacks.\n\nPhishing Detection:\n\nAI can analyze emails and websites to identify phishing attempts. It can also educate users about potential phishing risks, reducing the likelihood of successful attacks.\n\nNetwork Security:\n\nAI monitors network traffic for suspicious activity, identifying potential threats and anomalies in real-time. This helps in preventing data breaches and unauthorized access.\n\nThreat Hunting:\n\nAI assists in proactive threat hunting by analyzing data and identifying potential indicators of compromise. This helps security teams identify and mitigate threats before they can cause significant damage.\n\nReal-World Examples of AI-Driven Cybersecurity: Several organizations are leveraging AI to enhance their cybersecurity measures. Here are a few examples: IBM's Watson for Cybersecurity:\n\nWatson uses AI to analyze vast amounts of security data and identify threats. It provides actionable insights to security analysts, helping them respond to threats more effectively.\n\nDarktrace:\n\nThis AI-powered cybersecurity company uses machine learning to detect and respond to threats in real-time. It monitors network traffic and identifies anomalies, helping organizations protect their data.\n\nCylance:\n\nCylance uses AI to prevent malware attacks. Its AI algorithms analyze files and code, identifying potential threats before they can cause harm.\n\nThe Future of AI-Driven Cybersecurity:\n\nThe future of AI-driven cybersecurity looks promising. As AI technology continues to evolve, its capabilities in threat intelligence and response will only improve. Here are some potential future developments:\n\nAdvanced Machine Learning Algorithms:\n\nAI systems will become more sophisticated, using advanced machine learning algorithms to identify even the most subtle threats.\n\nIntegration with Other Technologies:\n\nAI will be integrated with other emerging technologies, such as blockchain and the Internet of Things (IoT), to provide even more robust security solutions.\n\nIncreased Automation:\n\nAs AI becomes more advanced, it will automate more complex security tasks, further reducing the burden on human analysts.\n\nImproved User Education:\n\nAI will play a key role in educating users about cybersecurity risks and best practices, helping to create a more security-aware workforce.\n\nEnhanced Collaboration:\n\nAI systems will facilitate better collaboration between different security teams and organizations, sharing threat intelligence and improving overall security posture.\n\nChallenges and Ethical Considerations:\n\nWhile AI offers numerous benefits in cybersecurity, it also presents challenges and ethical considerations. These include:\n\nBias in AI Algorithms:\n\nAI systems can be biased, leading to unfair or inaccurate threat detection. It's crucial to ensure that AI algorithms are transparent and unbiased.\n\nPrivacy Concerns:\n\nAI systems often require access to vast amounts of data, raising privacy concerns. Organizations must ensure that they handle data responsibly and comply with privacy regulations.\n\nAdversarial AI:\n\nCybercriminals can use AI to develop more sophisticated attacks. It's essential to stay ahead of these threats and continuously improve AI security measures.\n\nConclusion:\n\nThe digital world is spreading at an high rate, bringing with it a surge in cyber threats. Traditional cybersecurity measures often fall short in identifying and mitigating these sophisticated threats. This is where AI-driven cybersecurity comes into play. By leveraging artificial intelligence (AI), organizations can enhance threat intelligence and response, ensuring a more robust defense against cyber attacks. In this article, we will explore how AI-driven cybersecurity is revolutionizing threat intelligence and response, its benefits, applications, and future potential.\n\nRelated Items:2024 Technology, AI in Cybersecurity, Artificial intelligence Recommended for you The Future of Cybersecurity: How AI is Shaping the Landscape How AI is Used in Cybersecurity to Detect and Prevent Threats The Role of AI in Modern Cybersecurity: An Overview", "source": {"uri": "techbullion.com", "dataType": "news", "title": "TechBullion"}, "authors": [{"uri": "angela_scott_briggs@techbullion.com", "name": "Angela Scott-Briggs", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Threat_(computer)", "type": "wiki", "score": 5, "label": {"eng": "Threat (computer)"}}, {"uri": "http://en.wikipedia.org/wiki/Real-time_computing", "type": "wiki", "score": 5, "label": {"eng": "Real-time computing"}}, {"uri": "http://en.wikipedia.org/wiki/Phishing", "type": "wiki", "score": 5, "label": {"eng": "Phishing"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 5, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Cyber_threat_intelligence", "type": "wiki", "score": 4, "label": {"eng": "Cyber threat intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Hacker", "type": "wiki", "score": 3, "label": {"eng": "Hacker"}}, {"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 3, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/Advanced_persistent_threat", "type": "wiki", "score": 3, "label": {"eng": "Advanced persistent threat"}}, {"uri": "http://en.wikipedia.org/wiki/Firewall_(computing)", "type": "wiki", "score": 3, "label": {"eng": "Firewall (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/Malware", "type": "wiki", "score": 3, "label": {"eng": "Malware"}}, {"uri": "http://en.wikipedia.org/wiki/Antivirus_software", "type": "wiki", "score": 3, "label": {"eng": "Antivirus software"}}, {"uri": "http://en.wikipedia.org/wiki/Ransomware", "type": "wiki", "score": 3, "label": {"eng": "Ransomware"}}, {"uri": "http://en.wikipedia.org/wiki/Indicator_of_compromise", "type": "wiki", "score": 2, "label": {"eng": "Indicator of compromise"}}, {"uri": "http://en.wikipedia.org/wiki/Network_traffic", "type": "wiki", "score": 2, "label": {"eng": "Network traffic"}}, {"uri": "http://en.wikipedia.org/wiki/Zero-day_(computing)", "type": "wiki", "score": 2, "label": {"eng": "Zero-day (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/Cybercrime", "type": "wiki", "score": 2, "label": {"eng": "Cybercrime"}}, {"uri": "http://en.wikipedia.org/wiki/Network_security", "type": "wiki", "score": 2, "label": {"eng": "Network security"}}, {"uri": "http://en.wikipedia.org/wiki/Data_breach", "type": "wiki", "score": 2, "label": {"eng": "Data breach"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 2, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/IBM", "type": "org", "score": 1, "label": {"eng": "IBM"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 100}, {"uri": "dmoz/Computers/Security/Intrusion_Detection_Systems", "label": "dmoz/Computers/Security/Intrusion Detection Systems", "wgt": 100}, {"uri": "dmoz/Computers/Security/Honeypots_and_Honeynets", "label": "dmoz/Computers/Security/Honeypots and Honeynets", "wgt": 100}, {"uri": "dmoz/Computers/Hacking/Cryptography", "label": "dmoz/Computers/Hacking/Cryptography", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 92}], "image": "https://techbullion.com/wp-content/uploads/2024/08/AI-Driven-Cybersecurity-Enhancing-Threat-Intelligence-and-Response.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.08235294117647052, "wgt": 141, "relevance": 1}
{"uri": "8259648406", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "07:48:16", "dateTime": "2024-08-05T07:48:16Z", "dateTimePub": "2024-08-05T07:46:51Z", "dataType": "news", "sim": 0.545098066329956, "url": "https://today.rtl.lu/news/luxembourg/a/2220571.html", "title": "Interview with Laurent Scheeck: Luxembourgish parliament passes AI code of ethics", "body": "Aligned with the recently passed EU Regulation on Artificial Intelligence, the AI code of ethics offers ten non-binding guidelines that seek to clarify the internal use of AI for parliamentarians and parliamentary staff.\n\nRTL's Fanny Kinsch spoke with Laurent Scheeck, General Secretary of the Parliament on the use of AI in parliament.\n\nFour years ago, the parliament began working on a framework on the use of AI, according to Laurent Scheeck. He underlined the importance of having a set of ethical guidelines on the use of AI, noting particularly that AI is no substitute for humans.\n\n\"That is categorically out of the question. This is why, with this code of ethics, we want to be as transparent as possible and ease people's worries.\"\n\nThe code of ethics affirms that AI should only be used in a supportive capacity. It aims to help parliamentarians and staff better understand and navigate the implications of using AI, stipulating that a risk analysis must be conducted prior to any use of AI.\n\n\"The goal here is to fully leverage the possibilities offered by AI while alleviating any fears.\"\n\nThe code does not cover how AI should be used for political work, instead it is primarily aimed at parliamentary staff. Currently, AI is being used in three areas of parliamentary work: transcribing, archiving and translating.\n\n\"We have made great progress in transcribing parliamentary debates, where we are already using a tool developed in collaboration with the University of Luxembourg.\"\n\nScheeck shared that the Parliament hopes to work with the university again in the field of translation.\n\n\"One of our priorities is to provide subtitles in the future, to better reflect the linguistic pluralism of our country.\"\n\nOne of the ways in which AI is used in archiving, is with AI's ability to identify sensitive data. This would help staff categorise and analyse documents more efficiently.", "source": {"uri": "today.rtl.lu", "dataType": "news", "title": "RTL Today"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Ethical_code", "type": "wiki", "score": 5, "label": {"eng": "Ethical code"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Parliament", "type": "wiki", "score": 4, "label": {"eng": "Parliament"}}, {"uri": "http://en.wikipedia.org/wiki/General_Secretary_of_the_Chinese_Communist_Party", "type": "wiki", "score": 3, "label": {"eng": "General Secretary of the Chinese Communist Party"}}, {"uri": "http://en.wikipedia.org/wiki/Parliament_of_the_United_Kingdom", "type": "wiki", "score": 3, "label": {"eng": "Parliament of the United Kingdom"}}, {"uri": "http://en.wikipedia.org/wiki/European_Union", "type": "loc", "score": 3, "label": {"eng": "European Union"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Risk_management", "type": "wiki", "score": 2, "label": {"eng": "Risk management"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 2, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/University_of_Luxembourg", "type": "org", "score": 1, "label": {"eng": "University of Luxembourg"}}, {"uri": "http://en.wikipedia.org/wiki/Pluralism_(political_philosophy)", "type": "wiki", "score": 1, "label": {"eng": "Pluralism (political philosophy)"}}, {"uri": "http://en.wikipedia.org/wiki/University", "type": "wiki", "score": 1, "label": {"eng": "University"}}], "categories": [{"uri": "dmoz/Computers/Hacking/Cryptography", "label": "dmoz/Computers/Hacking/Cryptography", "wgt": 100}, {"uri": "dmoz/Computers/Programming/Threads", "label": "dmoz/Computers/Programming/Threads", "wgt": 100}, {"uri": "dmoz/Computers/Data_Formats/Barcodes", "label": "dmoz/Computers/Data Formats/Barcodes", "wgt": 100}, {"uri": "news/Politics", "label": "news/Politics", "wgt": 60}], "image": "https://www.rtl.lu/sassets/rtl2008.lu/nt/p/2024/08/05/07/79e6e1f36d5461bdb8d954e8aadd8853.jpeg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.2313725490196079, "wgt": 139, "relevance": 1}
{"uri": "8259949392", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "11:04:04", "dateTime": "2024-08-05T11:04:04Z", "dateTimePub": "2024-08-05T11:03:27Z", "dataType": "news", "sim": 0.5411764979362488, "url": "https://www.informationweek.com/machine-learning-ai/are-enterprises-investing-too-much-or-too-little-in-ai-now-", "title": "Are Enterprises Investing Too Much or Too Little in AI Now?", "body": "The interest in AI is undeniable, but are enterprises putting enough into this growing tech space or is money getting ahead of the technology?\n\nMany companies continue to announce AI plans, either their intent to implement third-party resources or build something from within. What does that mean beyond headlines that declare a new AI platform or assistant is on the way?\n\nNew technologies can rise or stumble depending on the monetary investment put into its development. OpenAI introduced an enterprise API to go after more of the business market. Yet, there are reports the company might lose $5 billion this year and potentially run out of money in 12 months.\n\nIs AI investment a substantial part of current enterprise IT budgets? How does the investment trend in AI compare with other tech? Is AI investment just a cost with no clear path to an ROI?", "source": {"uri": "informationweek.com", "dataType": "news", "title": "InformationWeek"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/API", "type": "wiki", "score": 1, "label": {"eng": "API"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 1, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Information_technology", "type": "wiki", "score": 1, "label": {"eng": "Information technology"}}], "categories": [{"uri": "dmoz/Business/Investing", "label": "dmoz/Business/Investing", "wgt": 100}, {"uri": "dmoz/Business/Financial_Services/Cash_Flow", "label": "dmoz/Business/Financial Services/Cash Flow", "wgt": 100}, {"uri": "dmoz/Business/Opportunities", "label": "dmoz/Business/Opportunities", "wgt": 100}, {"uri": "dmoz/Business/Investing/Guides", "label": "dmoz/Business/Investing/Guides", "wgt": 100}], "image": "https://eu-images.contentstack.com/v3/assets/blt69509c9116440be8/blte558b2aedb201bf8/66ad1df72b42de76c847c0f6/AI_Investment-hirunlaowisit-AlamyStockPhoto.jpg?disable=upscale&width=1200&height=630&fit=crop", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.04313725490196085, "wgt": 138, "relevance": 1}
{"uri": "8259971917", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "11:17:58", "dateTime": "2024-08-05T11:17:58Z", "dateTimePub": "2024-08-05T11:16:59Z", "dataType": "news", "sim": 0.5411764979362488, "url": "https://www.uctoday.com/unified-communications/navigating-the-nexus-of-ai-data-protection-and-uc-allendevaux/", "title": "Navigating the Nexus of AI, Data Protection and UC", "body": "The evolving UC space introduces new challenges to overcome in terms of data protection, security, compliance, and governance\n\nThe world of unified communications (UC) has come a long way in recent years, transforming how businesses interact and share knowledge. Today, we have more opportunities than ever before to connect and collaborate across a multitude of channels, from voice and video, to text.\n\nThe rise of AI in the UC landscape marks the next transformation step in this industry, promising organizations access to intuitive assistants, solutions to enhance productivity and efficiency, and technology that streamlines the collection and evaluation of crucial data.\n\nUnfortunately, both the AI landscape, and the evolving UC space, introduce new challenges to overcome in terms of data protection, security, compliance, and governance. Here's your guide to what organizations must consider as we approach the nexus of AI, data protection, and UC.\n\nAs the way communication has evolved, so too have the threats facing today's companies, and the data they want to protect. The proliferation of endless new communications channels has left organizations with more data to categorize, safeguard, and store. While AI tools have the potential to assist in managing and classifying this data, AI tools face their own threats.\n\nAs advanced AI systems rely on vast volumes of data to operate effectively, they raise concerns about data security and privacy, particularly when used at scale. AI solutions also pose ethical risks, suffering regularly from issues like bias and AI hallucinations.\n\nAt the same time, both AI tools and the UC platforms they augment can be subject to attacks from malicious actors. The data gathered by UC systems is vulnerable to interception during transport, and the data stored by AI models can potentially be mined by bad actors.\n\nThese threats are leading to significant changes in governance and compliance standards. Concepts like digital communications governance are emerging in the UC sector, while in the AI world, regulators are working on new rules business leaders will need to follow, alongside existing standards like CCPA, GDPR, and HIPAA. Already, the EU has its AI Act, intended to regulate high-risk AI applications, and the US has the Executive Order of AI safety.\n\nThis evolution will lead to a fundamental shift in how companies design their ecosystems with a focus on security, compliance, and data governance.\n\nThe guidelines governing acceptable AI usage in the enterprise are still being formulated, but patterns are already emerging, Most of the standards emerging today require companies to focus on concepts such as:\n\nImplementing the right strategy for success will require a comprehensive and cautious approach, driven by careful research, risk analysis, and potential consultation with security experts. However, there are a few areas companies can focus on to improve their chances of success.\n\nPrivacy-by-design principles are likely to become essential when integrating AI into UC systems. This will mean businesses need to embed privacy considerations into the architecture of their tools from the outset. Business leaders will need to implement purpose specification and data minimization practices, and implement privacy-preservation settings in their applications. Thorough privacy and security assessments will help to guide the right design process.\n\n\"Embedding privacy safeguards from the very start of any AI implementation in UC systems is not just a regulatory requirement but a strategic advantage. Privacy by Design principles help build resilient user-centric solutions that can adapt to evolving threats and foster user trust\" says Rebekah Allendevaux from Allendevaux & Company.\n\nSince AI, UC systems, and risk factors are constantly evolving, maintaining the security and integrity of AI-driven systems will require organizations to conduct regular security audits, and conduct penetration testing assessments. These processes should allow organizations to evaluate not just their IT and UC infrastructure, but also all AI models, APIs, and data pipelines, offering comprehensive insights into potential vulnerabilities and emerging risks. (https://www.allendevaux.com/pentesting)\n\nHuman error is still a concern for companies implementing AI into UC solutions. Team members can only use AI safely and ethically if they understand the risks, and have the correct guidance. Holistic training programs that help staff to identify security threats, understand data protection best practices, and adapt to changing risks will be essential. As the landscape transforms, these training strategies will need to be regularly updated and refreshed.\n\nDPIAs, or Data Protection Impact Assessments will be mandatory for companies implementing AI into their Unified Communications systems. These assessments can help organizations identify the compliance risks associated with their data processing behaviors, providing insights into data flows, why and how information is collected, and how it is stored. DPIAs will also prompt companies to consider carefully how data is used for AI training purposes.\n\nFinally, consistent AI risk assessments will help organizations ensure their AI-driven UC systems continue to adhere to privacy and security standards as new regulations evolve. Carefully analyzing the potential for risks like bias, errors, or data leaks in AI models will help to mitigate a number of threats. Risk assessments will also help businesses to implement comprehensive governance frameworks they can use to remain compliant with data standards going forward.\n\nThere's no doubt that unified communications will continue to evolve, and artificial intelligence will have a significant impact on the UC landscape. However, as businesses continue to embrace more advanced UC tools and AI systems, they'll need to ensure they're putting the concepts of data protection, privacy, and compliance first.\n\nTaking a proactive approach to navigating the nexus of AI, UC, and data protection now could prevent businesses from facing significant risks, fines, and legal issues in the months to come. Now is the time for organizations to begin building their future-facing strategy, and ensuring they have the protections in place for a safe, secure, and ethical AI and UC convergence.\n\n\"To ensure compliance with AI laws being enacted globally, companies should be extending their data protection programs with AI governance frameworks such as ISO 42001; this ensures not only compliance with evolving legislation such as the EU AI Act, but fosters transparency, fairness, and lawful AI processing\", says Dr Scott Allendevaux from Allendevaux & Company.", "source": {"uri": "uctoday.com", "dataType": "news", "title": "UC Today"}, "authors": [{"uri": "rebekah_carter@uctoday.com", "name": "Rebekah Carter", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Information_privacy", "type": "wiki", "score": 5, "label": {"eng": "Information privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 5, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Unified_communications", "type": "wiki", "score": 3, "label": {"eng": "Unified communications"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 3, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Data_security", "type": "wiki", "score": 3, "label": {"eng": "Data security"}}, {"uri": "http://en.wikipedia.org/wiki/Hallucination", "type": "wiki", "score": 3, "label": {"eng": "Hallucination"}}, {"uri": "http://en.wikipedia.org/wiki/California_Consumer_Privacy_Act", "type": "wiki", "score": 2, "label": {"eng": "California Consumer Privacy Act"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy_by_design", "type": "wiki", "score": 2, "label": {"eng": "Privacy by design"}}, {"uri": "http://en.wikipedia.org/wiki/Applications_of_artificial_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Applications of artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Vulnerability", "type": "wiki", "score": 2, "label": {"eng": "Vulnerability"}}, {"uri": "http://en.wikipedia.org/wiki/General_Data_Protection_Regulation", "type": "wiki", "score": 2, "label": {"eng": "General Data Protection Regulation"}}, {"uri": "http://en.wikipedia.org/wiki/Data_governance", "type": "wiki", "score": 2, "label": {"eng": "Data governance"}}, {"uri": "http://en.wikipedia.org/wiki/Penetration_test", "type": "wiki", "score": 2, "label": {"eng": "Penetration test"}}, {"uri": "http://en.wikipedia.org/wiki/Health_Insurance_Portability_and_Accountability_Act", "type": "wiki", "score": 2, "label": {"eng": "Health Insurance Portability and Accountability Act"}}, {"uri": "http://en.wikipedia.org/wiki/Risk_management", "type": "wiki", "score": 2, "label": {"eng": "Risk management"}}, {"uri": "http://en.wikipedia.org/wiki/Bias", "type": "wiki", "score": 2, "label": {"eng": "Bias"}}, {"uri": "http://en.wikipedia.org/wiki/Evolution", "type": "wiki", "score": 2, "label": {"eng": "Evolution"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 2, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Ecosystem", "type": "wiki", "score": 2, "label": {"eng": "Ecosystem"}}, {"uri": "http://en.wikipedia.org/wiki/European_Union", "type": "loc", "score": 2, "label": {"eng": "European Union"}, "location": null}], "categories": [{"uri": "dmoz/Computers/Software/Master_Data_Management", "label": "dmoz/Computers/Software/Master Data Management", "wgt": 100}, {"uri": "dmoz/Computers/Intranet", "label": "dmoz/Computers/Intranet", "wgt": 100}, {"uri": "dmoz/Business/E-Commerce/Standards_and_Protocols", "label": "dmoz/Business/E-Commerce/Standards and Protocols", "wgt": 100}, {"uri": "dmoz/Computers/Software/Enterprise_Information_Integration", "label": "dmoz/Computers/Software/Enterprise Information Integration", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 68}], "image": "https://www.uctoday.com/wp-content/uploads/2024/08/Navigating-the-Nexus-of-AI-Data-Protection-and-UC.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.2705882352941176, "wgt": 138, "relevance": 1}
{"uri": "8259491875", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "05:44:52", "dateTime": "2024-08-05T05:44:52Z", "dateTimePub": "2024-08-05T05:44:22Z", "dataType": "news", "sim": 0.5411764979362488, "url": "https://www.abcmoney.co.uk/2024/08/dave-antrobus-the-future-of-telecommunications-with-ai/", "title": "Dave Antrobus: The Future Of Telecommunications With AI | ABC Money", "body": "Did you know that the telecom market might reach \u00a31.8 trillion by 2025? This growth is mostly because of advancements in AI. Digital innovation is changing the telecom scene. People like Dave Antrobus, from Inc & Co, are at the forefront. They are blending AI with telecom to change our future.\n\nHis vision is about using AI to boost connectivity and make communication better in the UK and elsewhere. Let's dive in and see how Dave Antrobus is taking telecom into a new age of tech.\n\nDave Antrobus is known for blending AI with telecommunications. His work has pushed forward new communication tech in the UK. He combines tech expertise with sharp business insight. This mix has made him key in evolving the telecom industry.\n\nAs a leader, Antrobus supports using AI to improve services and efficiency. His ideas guide telecom firms wanting to use new tech. He keeps the UK competitive by following global trends in communication.\n\nAI is changing how we handle phone calls, internet, and customer service today. It makes things more efficient and focused on what customers need. By using AI, companies are doing everyday tasks faster and cheaper. This cuts down on mistakes.\n\nAlso, AI helps fix network problems before they upset users. This ensures that everyone stays connected without interruption.\n\nAI also makes services more personal by understanding what each user likes. This makes people happier with the services they get. One example is how chatbots talk to customers right away. They offer help quickly and correctly, making customers feel valued.\n\nBesides, AI keeps our online world safe. It can spot dangers and stop hackers from stealing data. This protection is becoming more important as attacks get smarter.\n\nBut, using AI in this way is not easy. We must be careful about national security and keeping people's information private. Agencies argue for rules that keep everyone safe but also let new companies join in. This helps everyone grow without putting them at risk.\n\nTo wrap up, AI is really important for modern phones and internet. It's making services better, keeping us safe, and helping the industry grow. As we keep using AI, staying updated with research and rules will help us make the most of it.\n\nArtificial intelligence changes how we communicate in the telecom industry. It introduces smart chatbots and predictive network maintenance. These AI tools make our communications better and more reliable. They help to meet the growing need for internet and digital services.\n\nIn 2022, Delta Sharing became widely available. It led to more businesses using it to share data with partners and customers everywhere. Companies like Atlassian and Nasdaq are already sharing data globally. They do this using the D2O framework, which works on any computing platform.\n\nAI-driven tools, such as Delta Sharing, improve how organisations share data. They make working together easier, both inside the company and with external partners. Delta Sharing uses various open-source connectors. These include Python, Apache Spark, Microsoft Power BI, Excel, and Tableau. This shows AI's big role in changing telecom communications.\n\nNew connectors like the Tableau Delta Sharing one make analysing data easier. Companies can now turn their data into useful insights more smoothly. For systems without their own connectors, like BigQuery and Snowflake, the Python connector fills the gap. This is how AI improves how different systems work together.\n\nDatabricks' Delta Sharing REST API allows companies to design custom interfaces. These are for their own unique data sharing needs. This growth in tools and connectors shows AI's expanding role. It's making telecom communications more connected and driven by data.\n\nTo sum up, AI's merge into telecom is starting a wave of innovation. It's changing how we communicate and organise information. With smart solutions and better analysis, AI is making telecom services more effective and adaptable. This ensures they keep improving in our fast-changing digital world.\n\nThe UK market is changing fast, thanks to tech innovation. British firms are leading the pack. They're using new digital tech to change sectors like telecoms. AI is a key player in this change. It's making businesses more streamlined and efficient.\n\nThanks to this tech boost, new business models are popping up. These models meet changing consumer needs better. Firms like BT Group and Vodafone are using advanced AI. They improve customer service with chatbots and keep networks running smoothly. This shows how the UK is dedicated to staying top in digital growth.\n\nCompanies like SolarEdge are innovating in solar technology in the UK. They install systems that produce more energy and are safer. For example, the Montecosaro site's installation adds 106 kWp of solar power. This helps save energy and reduces carbon emissions. It shows tech's role in tackling environmental issues too.\n\nUK's tech progress is part of a bigger trend. It involves using AI and other new techs to solve various problems. This makes British firms competitive globally. It also puts them at the forefront of creating innovative solutions for different sectors.\n\nFuture communication is changing fast, thanks to AI. A key change is autonomous networks. They use AI to manage themselves, boost efficiency, and fix issues without human help.\n\nAI is also changing how customers interact with services. With smarter AI, conversations feel more personal and engaging. This means happier users who feel more connected.\n\nAI helps businesses understand what customers want before they ask. They can use this to give better, more suited services. This lifts the quality of user experiences.\n\nNew AI trends mean better connections and smarter chatting across different platforms. Tools like Natural Language Processing (NLP) help make chat with AI feel natural and smart.\n\nAs AI grows, we'll see more clever solutions in telecommunication. These changes promise to meet the needs of today's users in exciting ways.\n\nImplementing AI in the telecom sector brings big chances for better efficiency and new ideas. AI can handle daily tasks automatically. This lets workers tackle more important projects. Yet, introducing AI comes with hurdles too.\n\nData privacy is a major issue with AI. Since AI needs lots of data to work well, it's vital to protect this data from hacks. There are also ethical issues to consider with AI's growth. We must carefully use AI to stop any misuse.\n\nChanging the workforce is another big hurdle. As AI takes over some jobs, we must handle this change with care. It's important to teach employees new skills for an AI world. This prevents job losses and keeps company spirit high.\n\nDealing with AI's ethical issues needs careful thought. We need AI systems that are open and fair. This builds trust with the public. It also makes sure AI benefits are fairly shared by all.\n\nAI can also help the environment. For example, Lam Cryo 3.0 technology cuts energy use by up to 40% for each wafer. It also reduces emissions by up to 90% compared to normal methods. This shows AI can be both effective and green.\n\nTo sum up, using AI in telecom brings many pros like improved efficiency and creativity. But, there are big cons too, like ensuring data safety, adapting the workforce, and facing ethical issues.\n\nAI dramatically changes telecommunication, improving many areas. It makes network management better. By studying large amounts of data, AI lets telecom companies watch their networks all the time. This spotting of problems early on leads to quicker fixes, which makes services more reliable.\n\nAI helps save on costs too, by doing routine tasks. This cuts down on the need for people to do these jobs, saving money. Tools like machine learning predict how much network will be used. This helps in using resources well and reduces waste.\n\nAI also makes services better by knowing what customers like. Telecom companies can offer services that fit what different users want. AI chatbots and virtual assistants offer quick help, answering questions fast.\n\nTo wrap it up, AI is key in changing telecommunication services. It helps manage networks better, saves money, and makes customers happier. AI is essential for the future of the telecom sector.\n\nThe telecommunication industry is about to change a lot because of artificial intelligence. AI is making it quicker to respond to customers and making services more personal. CelcomDigi is leading with its 5G network. It's the biggest and most modern in Malaysia. They use AI to make customer experiences better, which helps keep customers happy and loyal.\n\nNew, exciting tools are being used to share data and work together better. This strengthens the part AI plays in making customers happy. The Delta Sharing service is an example. It came out in 2022. Big companies like Atlassian and Nasdaq use it to work together easily. Delta Sharing works well with Python, Apache Spark, and Microsoft Power BI. This shows how safe and efficient it is to manage data in this industry.\n\nThese steps forward are key in meeting what customers need and want. Using Delta Sharing, companies can improve their services. They do this by looking into data and using new tech. CelcomDigi is also making ready for a future with 5G. This will help create societies that are powered by AI. As things move forward, AI will be very important in making customers very satisfied.\n\nThe benefits of AI are plentiful for telecom companies aiming to stay ahead. They're catching up in a fast-changing digital scene. AI boosts operational efficiency. It does this by making routine and complex tasks easier. This allows telecom workers to do their jobs better, saving time and resources. AI also helps predict future problems. This means companies can fix issues before they get worse. It leads to more reliable services and happier customers.\n\nMoreover, AI opens up new ways for telecom companies to make money. They can create new and exciting services. For example, they offer custom experiences and cutting-edge data services to business clients. This not only sets telecom firms apart but also prepares them for new chances in the digital world.\n\nIn these tough times for the tech world, AI is crucial. In 2024, many tech jobs were lost. For example, there were 19,350 layoffs in January, 15,589 in February, and 22,153 in April. Despite this, telecom firms that use AI can keep going strong. They do this by facing fewer disruptions and making the most of their teams. This makes their business model stronger even when times are hard.\n\nLooking at how UK telecommunication firms have adopted AI reveals a lot. Companies like BT, Vodafone, and Three are using AI to get better at what they do. They're improving their services, making operations more efficient, and inventing new ways to stay ahead.\n\nBT is a leading example, using AI to change how it deals with customers. They've introduced AI chatbots and virtual helpers, cutting down the time it takes to respond to customers. This makes their service quicker and more personal for everyone.\n\nVodafone has raised the bar with AI for predicting and fixing network issues before they disrupt service. Their smart use of AI means fewer interruptions and more reliable service for their customers. It's a game-changer for ensuring networks run smoothly all the time.\n\nThree has also stepped up, using AI to understand huge amounts of data better. This lets them offer services that match what customers really want. By using AI to sift through data, they provide better, more tailored services efficiently.\n\nThe stories of how these firms are adopting AI offer a glimpse into the future of telecoms in the UK. As AI tech gets even better, it's set to make services more reliable, improve networks, and offer customers new and innovative options. It's an exciting time for the industry, with AI paving the way for advancements.\n\nDave Antrobus talks about the bright future of AI in telecoms. He sees it changing how networks operate and grow. AI is set to make things run smoothly and spark new ideas in the sector.\n\nAccording to him, AI will make telecoms better and more focused on what customers need. He thinks AI will make the networks smarter and more flexible. This will help companies work better and encourage more creativity, pushing the whole industry forward.\n\nDave Antrobus imagines a world where systems talk to each other and adapt to what people and markets want. With AI, telecoms can spot and fix problems early. This means everyone gets a more dependable service.\n\nHe also dreams of creating ecosystems that reach everyone, everywhere. These systems will offer better services to people of all backgrounds. His idea is to make technology available for all, which could close the gap in digital access.\n\nDave Antrobus highlights how crucial AI literacy is in telecommunications. This literacy is more than just knowing the tech. It's about having a mindset ready for change, innovation, and the telecom field's future.\n\nAbout 91.5% of ICT specialist jobs could be impacted by artificial intelligence. Thus, AI literacy is essential to protect these jobs. A third of common ICT jobs are greatly influenced by AI. This means over 70% of needed skills will shift. Another 57.5% of jobs will also see significant skill changes.\n\nAll senior ICT positions will see some changes due to AI. Many mid-level and entry-level jobs will change a lot. Yet, 87% of bosses think AI will enhance jobs, not replace them. The AI-Enabled ICT Workforce Consortium, including big names like Cisco and Google, promotes AI literacy.\n\nIn Australia, the AI workforce grew from 800 in 2014 to 33,000 in 2023. It's expected to reach 200,000 by 2030. This shows the urgency for telecom companies to train their teams in AI. Enhancing AI literacy can fill the gap in AI skills, keeping the sector competitive.\n\nFor the future, increasing AI training options and skills is vital. Skilled migration could help fill the skills gap. By encouraging ongoing learning, businesses can prepare their teams for an AI-driven future.\n\nDave Antrobus has expertly shown how AI can change the telecommunications industry. By adding artificial intelligence, this sector could see major improvements in how we connect, work, and engage with customers. AI brings new tools like predictive maintenance and chatbots that can truly alter communication strategies for the better.\n\nThe data on how companies are using AI shows its huge impact. Reports and surveys show that businesses expect high quality and effective communication from AI. This proves telecommunication companies must keep up with AI knowledge and innovations. Doing so will prepare their teams to make the most of these technologies.\n\nThe growth of AI is clear, with projects using new tech like the AMD Radeon RX 7900 XT GPU for smarter operations. Also, companies like Millicom International Cellular are investing in AI for growth and to reach more people digitally. These steps show a move towards more AI use in the telecom industry, which could lead to exciting changes.", "source": {"uri": "abcmoney.co.uk", "dataType": "news", "title": "ABC Money"}, "authors": [{"uri": "danielle_trigg@abcmoney.co.uk", "name": "Danielle Trigg", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Telecommunications", "type": "wiki", "score": 5, "label": {"eng": "Telecommunications"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 5, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Delta_Air_Lines", "type": "org", "score": 5, "label": {"eng": "Delta Air Lines"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Internet", "type": "wiki", "score": 5, "label": {"eng": "Internet"}}, {"uri": "http://en.wikipedia.org/wiki/United_Kingdom", "type": "loc", "score": 5, "label": {"eng": "United Kingdom"}, "location": {"type": "country", "label": {"eng": "United Kingdom"}}}, {"uri": "http://en.wikipedia.org/wiki/Python_(programming_language)", "type": "wiki", "score": 4, "label": {"eng": "Python (programming language)"}}, {"uri": "http://en.wikipedia.org/wiki/Customer_service", "type": "wiki", "score": 4, "label": {"eng": "Customer service"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 4, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft_Power_BI", "type": "wiki", "score": 3, "label": {"eng": "Microsoft Power BI"}}, {"uri": "http://en.wikipedia.org/wiki/Nasdaq", "type": "wiki", "score": 3, "label": {"eng": "Nasdaq"}}, {"uri": "http://en.wikipedia.org/wiki/Hacker", "type": "wiki", "score": 3, "label": {"eng": "Hacker"}}, {"uri": "http://en.wikipedia.org/wiki/Databricks", "type": "org", "score": 3, "label": {"eng": "Databricks"}}, {"uri": "http://en.wikipedia.org/wiki/Data_sharing", "type": "wiki", "score": 3, "label": {"eng": "Data sharing"}}, {"uri": "http://en.wikipedia.org/wiki/Apache_Spark", "type": "wiki", "score": 3, "label": {"eng": "Apache Spark"}}, {"uri": "http://en.wikipedia.org/wiki/BigQuery", "type": "wiki", "score": 3, "label": {"eng": "BigQuery"}}, {"uri": "http://en.wikipedia.org/wiki/Atlassian", "type": "org", "score": 3, "label": {"eng": "Atlassian"}}, {"uri": "http://en.wikipedia.org/wiki/BT_Group", "type": "org", "score": 3, "label": {"eng": "BT Group"}}, {"uri": "http://en.wikipedia.org/wiki/Representational_state_transfer", "type": "wiki", "score": 3, "label": {"eng": "Representational state transfer"}}, {"uri": "http://en.wikipedia.org/wiki/Computing_platform", "type": "wiki", "score": 3, "label": {"eng": "Computing platform"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft_Excel", "type": "wiki", "score": 3, "label": {"eng": "Microsoft Excel"}}, {"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 3, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Vodafone", "type": "org", "score": 3, "label": {"eng": "Vodafone"}}, {"uri": "http://en.wikipedia.org/wiki/Business_model", "type": "wiki", "score": 3, "label": {"eng": "Business model"}}, {"uri": "http://en.wikipedia.org/wiki/National_security", "type": "wiki", "score": 3, "label": {"eng": "National security"}}, {"uri": "http://en.wikipedia.org/wiki/CelcomDigi", "type": "wiki", "score": 2, "label": {"eng": "CelcomDigi"}}, {"uri": "http://en.wikipedia.org/wiki/Millicom", "type": "org", "score": 1, "label": {"eng": "Millicom"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 1, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Malaysia", "type": "loc", "score": 1, "label": {"eng": "Malaysia"}, "location": {"type": "country", "label": {"eng": "Malaysia"}}}, {"uri": "http://en.wikipedia.org/wiki/Australia", "type": "loc", "score": 1, "label": {"eng": "Australia"}, "location": {"type": "country", "label": {"eng": "Australia"}}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Business/Opportunities", "label": "dmoz/Business/Opportunities", "wgt": 100}, {"uri": "dmoz/Business/E-Commerce/Marketplaces", "label": "dmoz/Business/E-Commerce/Marketplaces", "wgt": 100}, {"uri": "dmoz/Business/Telecommunications/Cost_Management", "label": "dmoz/Business/Telecommunications/Cost Management", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 80}], "image": "https://www.abcmoney.co.uk/wp-content/uploads/2024/08/daria-nepriakhina-_XR5rkprHQU-unsplash-1024x577.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "date": "2015-01-", "textStart": 10338, "textEnd": 10349}], "sentiment": 0.192156862745098, "wgt": 138, "relevance": 1}
{"uri": "8259428380", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "04:43:52", "dateTime": "2024-08-05T04:43:52Z", "dateTimePub": "2024-08-05T04:43:00Z", "dataType": "news", "sim": 0.5411764979362488, "url": "https://economictimes.indiatimes.com/tech/artificial-intelligence/china-is-closing-the-ai-gap-with-the-united-states/articleshow/112277121.cms", "title": "China is closing the AI gap with the United States", "body": "While the United States has had a head start on AI development, China is catching up. In recent weeks, several Chinese companies have unveiled AI technologies that rival leading American systems. And these technologies are already in the hands of consumers, businesses and independent software developers across the globe.At the World Artificial Intelligence Conference in Shanghai in July, startup founder Qu Dongqi showed off a video he had recently posted online. It displayed an old photograph of a woman with two toddlers. Then the photo sprang to life as the woman lifted the toddlers up in her arms and they laughed with surprise.\n\nThe video was created by AI technology from Chinese internet company Kuaishou. The technology was reminiscent of a video generator, called Sora, that American startup OpenAI unveiled this year. But unlike Sora, it was available to the general public.\n\n\"My American friends still can't use Sora,\" Qu said. \"But we already have better solutions here.\"\n\nWhile the United States has had a head start on AI development, China is catching up. In recent weeks, several Chinese companies have unveiled AI technologies that rival leading American systems. And these technologies are already in the hands of consumers, businesses and independent software developers across the globe.\n\nWhile many American companies are worried that AI technologies could accelerate the spread of disinformation or cause other serious harm, Chinese companies are more willing to release their technologies to consumers or even share the underlying software code with other businesses and software developers. This kind of sharing of computer code, called open source, allows others to more quickly build and distribute their own products using the same technologies.\n\nOpen source has been a cornerstone of the development of computer software, the internet and, now, artificial intelligence. The idea is that technology advances faster when its computer code is freely available for anyone to examine, use and improve upon.\n\nChina's efforts could have enormous implications as AI technology continues to develop in the years to come. The technology could increase the productivity of workers, fuel future innovations and power a new wave of military technologies, including autonomous weapons.\n\nWhen OpenAI kicked off the AI boom in late 2022 with the release of the online chatbot ChatGPT, China struggled to compete with technologies emerging from American companies such as OpenAI and Google. (The New York Times has sued OpenAI and its partner, Microsoft, claiming copyright infringement of news content related to AI systems.) But China's progress is now accelerating.\n\nKuaishou released its video generator, Kling, in China more than a month ago and to users worldwide on Wednesday. Just before Kling's arrival, 01.AI, a startup co-founded by Kai-Fu Lee, an investor and technologist who helped build Chinese offices for both Google and Microsoft, released chatbot technology that scored nearly as well as the leading American technologies on common benchmark tests that rate the performance of the world's chatbots.\n\nNew technology from Chinese tech giant Alibaba has also leaped to the top of a leaderboard that rates open-source AI systems. \"We have disproved the commonplace belief that China doesn't have the talent or the technology to compete with the U.S.,\" Lee said. \"That belief is simply wrong.\"\n\nIn interviews, a dozen technologists and researchers at Chinese tech companies said open-source technologies were a key reason that China's AI development has advanced so quickly. They saw open-source AI as an opportunity for the country to take a lead.\n\nBut that will not be easy. The United States remains at the forefront of AI research. And U.S. officials have resolved to keep it that way.\n\nThe White House has instituted a trade embargo designed to prevent Chinese companies from using the most powerful versions of computer chips that are essential to building artificial intelligence. A group of lawmakers has introduced a bill that would make it easier for the White House to control the export of AI software built in the United States. Others are trying to limit the progress of open-source technologies that have helped fuel the rise of similar systems in China.\n\nThe top American companies are also exploring new technologies that aim to eclipse the powers of today's chatbots and video generators.\n\n\"Chinese companies are good at replicating and improving what the U.S. already has,\" said Yiran Chen, a professor of electrical and computer engineering at Duke University in North Carolina. \"They are not as good at inventing something completely new that will bypass the U.S. in five to 10 years.\"\n\nBut many in China's tech industry believe that open-source technology could help them grow despite those constraints. And if U.S. regulators stifle the progress of American open-source projects (as some lawmakers are discussing) China could gain a significant edge. If the best open-source technologies come from China, U.S. developers could end up building their systems atop Chinese technologies.\n\n\"Open-source AI is the foundation of AI development,\" said Cl\u00e9ment Delangue, CEO of Hugging Face, a company that houses many of the world's open-source AI projects. The U.S. built its leadership in AI through collaboration between companies and researchers, he said, \"and it looks like China could do the same thing.\"\n\nWhile anyone with a computer can change open-source software code, it takes a lot of data, skill and computing power to fundamentally alter an AI system. When it comes to AI, open source typically means that a system's building blocks serve as a foundation that allows others to build something new, said Fu Hongyu, director of AI governance at Alibaba's research institute, AliResearch.\n\nAs in other countries, in China there is an intense debate over whether the latest technological advances should be made accessible to anyone or kept as closely held company secrets. Some, including Robin Li, the CEO of Baidu, one of the few companies in China building its own AI technology entirely from scratch, think the technology is most profitable and secure in the hands of a limited few.\n\nAI systems require enormous resources: talent, data and computing power. Beijing has made it clear that the benefits accruing from such investments should be shared. The Chinese government has poured money into AI projects and subsidized resources like computing centers.\n\nBut Chinese tech companies face a major constraint on the development of their AI systems: compliance with Beijing's strict censorship regime, which extends to generative AI technologies.\n\nKuaishou's new video generator Kling appears to have been trained to follow the rules. Text prompts with any mention of China's president, Xi Jinping, or controversial topics such as feminism and the country's real estate crisis yielded error messages. An image prompt of this year's National People's Congress yielded a video of the delegates shifting in their seats.\n\nKuaishou did not respond to questions about what steps the company took to prevent Kling from creating harmful, fake or politically sensitive content.\n\nBy making their most advanced AI technologies freely available, China's tech giants are demonstrating their willingness to contribute to the country's overall technological advancement as Beijing has established that the power and profit of the tech industry should be channeled toward the goal of self sufficiency.\n\nThe concern for some in China is that the country will struggle to amass the computing chips it needs to build increasingly powerful technologies. But that has not yet prevented Chinese companies from building powerful new technologies that can compete with U.S. systems.\n\nAt the end of last year, Lee's company, 01.AI, was ridiculed on social media when someone discovered that the company had built its AI system using open-source technology originally built by Meta, owner of Facebook and Instagram. Some saw it as a symbol of China's dependence on American ingenuity.\n\nSix months later, 01.AI unveiled a new version of its technology. It now sits near the top of the leaderboard that ranks the world's best technologies. Around the same time, a team from Stanford University in California unveiled Llama 3-V, claiming it outperformed other leading models. But a Chinese researcher soon noticed that the model was based on an open-source system originally built in China.\n\nIt was the reverse of the controversy surrounding 01.AI last year: Rather than Chinese developers building atop American technology, U.S. developers built atop Chinese technology.\n\nIf regulators limit open-source projects in the United States and Chinese open-source technologies become the gold standard, Delangue said, this kind of thing could become the norm.\n\n\"If the trend continues, it becomes more and more of a challenge for the U.S.,\" he said.", "source": {"uri": "economictimes.indiatimes.com", "dataType": "news", "title": "Economic Times"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 5, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 5, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 5, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Software_development", "type": "wiki", "score": 5, "label": {"eng": "Software development"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 5, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_program", "type": "wiki", "score": 5, "label": {"eng": "Computer program"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/United_States", "type": "loc", "score": 5, "label": {"eng": "United States"}, "location": {"type": "country", "label": {"eng": "United States"}}}, {"uri": "http://en.wikipedia.org/wiki/China", "type": "loc", "score": 5, "label": {"eng": "China"}, "location": {"type": "country", "label": {"eng": "China"}}}, {"uri": "http://en.wikipedia.org/wiki/Kuaishou", "type": "wiki", "score": 4, "label": {"eng": "Kuaishou"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 4, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Internet", "type": "wiki", "score": 4, "label": {"eng": "Internet"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 4, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Kai-Fu_Lee", "type": "person", "score": 3, "label": {"eng": "Kai-Fu Lee"}}, {"uri": "http://en.wikipedia.org/wiki/Disinformation", "type": "wiki", "score": 3, "label": {"eng": "Disinformation"}}, {"uri": "http://en.wikipedia.org/wiki/Alibaba_Group", "type": "org", "score": 3, "label": {"eng": "Alibaba Group"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 3, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 3, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/White_House", "type": "wiki", "score": 3, "label": {"eng": "White House"}}, {"uri": "http://en.wikipedia.org/wiki/Shanghai", "type": "loc", "score": 3, "label": {"eng": "Shanghai"}, "location": {"type": "place", "label": {"eng": "Shanghai"}, "country": {"type": "country", "label": {"eng": "China"}}}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Technology_company", "type": "wiki", "score": 2, "label": {"eng": "Technology company"}}, {"uri": "http://en.wikipedia.org/wiki/Military_technology", "type": "wiki", "score": 2, "label": {"eng": "Military technology"}}, {"uri": "http://en.wikipedia.org/wiki/Economic_sanctions", "type": "wiki", "score": 2, "label": {"eng": "Economic sanctions"}}, {"uri": "http://en.wikipedia.org/wiki/Duke_University", "type": "org", "score": 2, "label": {"eng": "Duke University"}}, {"uri": "http://en.wikipedia.org/wiki/Computing", "type": "wiki", "score": 2, "label": {"eng": "Computing"}}, {"uri": "http://en.wikipedia.org/wiki/Copyright_infringement", "type": "wiki", "score": 2, "label": {"eng": "Copyright infringement"}}, {"uri": "http://en.wikipedia.org/wiki/Electrical_engineering", "type": "wiki", "score": 2, "label": {"eng": "Electrical engineering"}}, {"uri": "http://en.wikipedia.org/wiki/North_Carolina", "type": "loc", "score": 2, "label": {"eng": "North Carolina"}, "location": {"type": "place", "label": {"eng": "North Carolina"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Beijing", "type": "loc", "score": 2, "label": {"eng": "Beijing"}, "location": {"type": "place", "label": {"eng": "Beijing"}, "country": {"type": "country", "label": {"eng": "China"}}}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 1, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/Robin_Li", "type": "person", "score": 1, "label": {"eng": "Robin Li"}}, {"uri": "http://en.wikipedia.org/wiki/Xi_Jinping", "type": "person", "score": 1, "label": {"eng": "Xi Jinping"}}, {"uri": "http://en.wikipedia.org/wiki/Baidu", "type": "org", "score": 1, "label": {"eng": "Baidu"}}, {"uri": "http://en.wikipedia.org/wiki/Stanford_University", "type": "org", "score": 1, "label": {"eng": "Stanford University"}}, {"uri": "http://en.wikipedia.org/wiki/Instagram", "type": "org", "score": 1, "label": {"eng": "Instagram"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 1, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/California", "type": "loc", "score": 1, "label": {"eng": "California"}, "location": {"type": "place", "label": {"eng": "California"}, "country": {"type": "country", "label": {"eng": "United States"}}}}], "categories": [{"uri": "dmoz/Computers/Virtual_Reality", "label": "dmoz/Computers/Virtual Reality", "wgt": 100}, {"uri": "dmoz/Computers/Security/Biometrics", "label": "dmoz/Computers/Security/Biometrics", "wgt": 100}, {"uri": "dmoz/Society/Disabled/Assistive_Technology", "label": "dmoz/Society/Disabled/Assistive Technology", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 98}], "image": "https://img.etimg.com/thumb/msid-112277154,width-1200,height-630,imgsize-68686,overlay-ettech/photo.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.2784313725490195, "wgt": 138, "relevance": 1}
{"uri": "8259939507", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "10:57:50", "dateTime": "2024-08-05T10:57:50Z", "dateTimePub": "2024-08-05T10:57:19Z", "dataType": "news", "sim": 0.5372549295425415, "url": "https://betanews.com/2024/08/05/ais-aggressive-development-is-a-security-disaster-waiting-to-happen/", "title": "AI's aggressive development is a security disaster waiting to happen", "body": "Tech C-suites' chronic fear of being left behind has ballooned as the AI race reaches fever pitch. Companies with the bandwidth to do so are developing their own AI systems or converting existing ones over to AI as fast as they can. This behavior is motivated far less by a fundamental belief in AI's ability to improve given aspects of their product than it is by reputation management.\n\nNo major player wants to look as though they hesitated at the wrong time and were left behind as their competitors innovated to newer heights and the accompanying adulation.\n\nThe problem with this reputation-minded AI mania is its flipside: hasty integration and innovation opens their AI to cybersecurity risks that could cause them serious reputational damage. This fact has been simply waved away, however, in the push to get programmers to build as fast as possible. The current state of AI is one in which development is an all-hands-on-deck scenario and cybersecurity has been left idling. This can't go on. The idea that AI can undergo a grand retooling without an equally grand retooling of associated security measures is foolish at best.\n\nThis all amounts to a major attack waiting to happen. In fact, it's already happening. A bug in ChatGPT's open-source library led to a major data breach last year. Moreover, the legacy tools and strategies of vulnerability scanning, pentesting and monitoring tools have been made obsolete by advancements of the AI programs they were initially designed to protect.\n\nOnly generative AI-based cybersecurity is up for the task, with its large-scale attack simulations, automated penetration testing, and adaptive detection methods. The cybersecurity used for AI has to match the speed and scale of the AI itself. The failure to build resilience and risk management into the very fabric of AI development and deployment will cause the kind of reputational damage that makes being slightly behind the curve look quaint. And it's now or never for tech C-suites to realize this.", "source": {"uri": "betanews.com", "dataType": "news", "title": "BetaNews"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Bandwidth_(computing)", "type": "wiki", "score": 3, "label": {"eng": "Bandwidth (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 3, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Programmer", "type": "wiki", "score": 2, "label": {"eng": "Programmer"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_model", "type": "wiki", "score": 1, "label": {"eng": "Generative model"}}, {"uri": "http://en.wikipedia.org/wiki/Resilience_(network)", "type": "wiki", "score": 1, "label": {"eng": "Resilience (network)"}}, {"uri": "http://en.wikipedia.org/wiki/Vulnerability_scanner", "type": "wiki", "score": 1, "label": {"eng": "Vulnerability scanner"}}, {"uri": "http://en.wikipedia.org/wiki/Software_bug", "type": "wiki", "score": 1, "label": {"eng": "Software bug"}}, {"uri": "http://en.wikipedia.org/wiki/Data_breach", "type": "wiki", "score": 1, "label": {"eng": "Data breach"}}, {"uri": "http://en.wikipedia.org/wiki/Penetration_test", "type": "wiki", "score": 1, "label": {"eng": "Penetration test"}}, {"uri": "http://en.wikipedia.org/wiki/Library_(computing)", "type": "wiki", "score": 1, "label": {"eng": "Library (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 1, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Risk_management", "type": "wiki", "score": 1, "label": {"eng": "Risk management"}}], "categories": [{"uri": "dmoz/Society/Relationships/Anger_Management", "label": "dmoz/Society/Relationships/Anger Management", "wgt": 100}, {"uri": "dmoz/Health/Teen_Health/Teen_Pregnancy", "label": "dmoz/Health/Teen Health/Teen Pregnancy", "wgt": 100}, {"uri": "dmoz/Computers/Software/Year_2000", "label": "dmoz/Computers/Software/Year 2000", "wgt": 100}, {"uri": "dmoz/Computers/Programming/Threads", "label": "dmoz/Computers/Programming/Threads", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 75}], "image": "https://betanews.com/wp-content/uploads/2023/12/Artificial-Intelligence-1.webp?w=640", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": -0.06666666666666665, "wgt": 137, "relevance": 1}
{"uri": "8260098653", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "12:37:16", "dateTime": "2024-08-05T12:37:16Z", "dateTimePub": "2024-08-05T12:36:20Z", "dataType": "news", "sim": 0.5372549295425415, "url": "https://www.itnewsafrica.com/2024/08/top-5-must-invest-in-ai-stocks-revealed-2024/", "title": "Top 5 Must-Invest In AI Stocks Revealed: 2024", "body": "NVIDIA's shares surged by 12.81% on July 31, 2024, following Microsoft's announcement of increased capital investment in AI for the new fiscal year.\n\nFor investors interested in investing in AI technologies, there are plenty of opportunities to capitalize on AI's rapid growth. Even if one chooses not to invest in AI stocks for his/ her portfolio, the success of these companies will likely impact the businesses you monitor.\n\nNvidia had a record year in 2023, profiting from the boom of OpenAI's large language model software, ChatGPT. The company's graphics cards are some of the most valuable semiconductors available, partly driving Nvidia's valuation past $1 trillion last year, which has now surpassed $2.88 trillion (\u00a32.24 trillion) as of August 2024. Competitors such as AMD and Intel are worth only a fraction of that figure, leaving Nvidia head and shoulders above its competition in 2024.\n\n2. Altair Engineering (ALTR)\n\nThe company posted strong revenue figures in 2023 -- a 12.3% increase YoY -- and nearly tripled its free cash flow from $5.2 to $14.7 million (\u00a311.7 million). The future looks bright for the company, as it also released its updated AI-powered data analytics tool, RapidMiner, in November 2023.\n\n3. C3.ai (AI)\n\nC3.ai's stock price fell from last year's high of $44.49 to under $30 at the start of 2024. Analysts' projections place C3.ai's revenue to grow by 19.8% this year and 23.6% in 2025, up from 14.7% in 2023. However, the stock isn't expected to reach profitability until the end of its 2025 fiscal year. It's now a question of whether or not to bet on the cloud software provider's potential upside. C3.ai has a lot of room to grow if it can recover to its post-IPO price of $119.58 in December 2020.\n\n4. Palantir (PLTR)\n\nPalantir had a successful 2023, with its stock price rising from $6.40 to a high of $20.27 in December 2023. Both its revenue and earnings per share are expected to grow by about 20% this year, so there's no reason the stock won't continue to thrive as enterprise AI solutions remain in demand.\n\n5. Upstart (UPST)\n\nAs an AI-powered lending assistant, Upstart's revenue is closely linked with US federal interest rates. Despite high rates being one of the reasons the company failed to reach revenue forecasts in 2023, the Federal Reserve is expected to begin cutting interest rates in 2024. This means more individuals may be looking to borrow money this year, and Upstart's services could be in higher demand.\n\nHead of Market Research at City Index, Matt Weller comments, \"In 2024, the landscape of AI stocks presents intriguing opportunities for investors. Companies at the forefront of artificial intelligence, such as Nvidia and Altair Engineering, are worth watching closely. These firms have demonstrated exceptional innovation and a strategic vision that aligns with the evolving demands of the market.\"\n\n\"AI's ability to swiftly process information, coupled with predictive analytics, allows investors to stay ahead of the curve in an ever-changing market landscape. The integration of natural language processing has not only amplified our understanding of market sentiment but has also opened doors to new dimensions of data interpretation.\" he adds\n\n\"As the demand for AI solutions continues to surge, these companies are well-positioned to capitalise on the market trends, making them compelling choices for investors looking to navigate the dynamic landscape of AI stocks in the coming years.\" concludes Weller\n\nWhat AI means for the stock market\n\nWhen choosing the best AI stocks, we focused on the companies building the infrastructure for the AI revolution. The stocks on this list power AI and LLMs either by manufacturing the graphics processing units (GPUs) used in hyperscale data centres or by providing data analytics software integrating generative AI for big tech companies like Apple and Microsoft. You can trade these and other top AI stocks in one fund with the AI index available on City Index.\n\nAI has revolutionized the stock market, placing algorithmic trading and predictive analytics at the forefront. Algorithms powered by AI swiftly analyze market data, enabling rapid trade execution. Meanwhile, predictive analytics, driven by AI models, forecast stock prices and market trends by scrutinizing historical data deeply. Utilizing AI to harness the power of big data may provide traders and investors with the tactical advantage they need to navigate an increasingly unpredictable market.\n\nCFDs- Contract For Difference are complex instruments and come with a high risk of losing money rapidly due to leverage. 69% of retail investor accounts lose money when trading CFDs with this provider. You should consider whether you understand how CFDs work and whether you can afford to take the high risk of losing your money.", "source": {"uri": "itnewsafrica.com", "dataType": "news", "title": "ITNewsAfrica.com"}, "authors": [{"uri": "vusi_melane@itnewsafrica.com", "name": "Vusi Melane", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/C3.ai", "type": "wiki", "score": 5, "label": {"eng": "C3.ai"}}, {"uri": "http://en.wikipedia.org/wiki/Nvidia", "type": "org", "score": 5, "label": {"eng": "Nvidia"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Fiscal_year", "type": "wiki", "score": 4, "label": {"eng": "Fiscal year"}}, {"uri": "http://en.wikipedia.org/wiki/Stock", "type": "wiki", "score": 4, "label": {"eng": "Stock"}}, {"uri": "http://en.wikipedia.org/wiki/AMD", "type": "wiki", "score": 3, "label": {"eng": "AMD"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 3, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 3, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/RapidMiner", "type": "wiki", "score": 3, "label": {"eng": "RapidMiner"}}, {"uri": "http://en.wikipedia.org/wiki/Palantir_Technologies", "type": "org", "score": 3, "label": {"eng": "Palantir Technologies"}}, {"uri": "http://en.wikipedia.org/wiki/Altair_Engineering", "type": "org", "score": 3, "label": {"eng": "Altair Engineering"}}, {"uri": "http://en.wikipedia.org/wiki/Valuation_(finance)", "type": "wiki", "score": 3, "label": {"eng": "Valuation (finance)"}}, {"uri": "http://en.wikipedia.org/wiki/Intel", "type": "org", "score": 3, "label": {"eng": "Intel"}}, {"uri": "http://en.wikipedia.org/wiki/Semiconductor", "type": "wiki", "score": 3, "label": {"eng": "Semiconductor"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 3, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 3, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/Interest_rate", "type": "wiki", "score": 3, "label": {"eng": "Interest rate"}}, {"uri": "http://en.wikipedia.org/wiki/Investment", "type": "wiki", "score": 3, "label": {"eng": "Investment"}}, {"uri": "http://en.wikipedia.org/wiki/Cash_flow", "type": "wiki", "score": 3, "label": {"eng": "Cash flow"}}, {"uri": "http://en.wikipedia.org/wiki/Federal_Reserve", "type": "org", "score": 2, "label": {"eng": "Federal Reserve"}}, {"uri": "http://en.wikipedia.org/wiki/Predictive_analytics", "type": "wiki", "score": 2, "label": {"eng": "Predictive analytics"}}, {"uri": "http://en.wikipedia.org/wiki/Cloud_computing", "type": "wiki", "score": 2, "label": {"eng": "Cloud computing"}}, {"uri": "http://en.wikipedia.org/wiki/Analytics", "type": "wiki", "score": 2, "label": {"eng": "Analytics"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Big_Tech", "type": "wiki", "score": 1, "label": {"eng": "Big Tech"}}, {"uri": "http://en.wikipedia.org/wiki/Apple_Inc.", "type": "org", "score": 1, "label": {"eng": "Apple Inc."}}], "categories": [{"uri": "dmoz/Business/Investing", "label": "dmoz/Business/Investing", "wgt": 100}, {"uri": "dmoz/Business/Investing/Stocks_and_Bonds", "label": "dmoz/Business/Investing/Stocks and Bonds", "wgt": 100}, {"uri": "dmoz/Business/Investing/Research_and_Analysis", "label": "dmoz/Business/Investing/Research and Analysis", "wgt": 100}, {"uri": "dmoz/Business/Investing/Brokerages", "label": "dmoz/Business/Investing/Brokerages", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 83}], "image": "https://www.itnewsafrica.com/wp-content/uploads/2024/03/ITNA_Logo-1.png", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "date": "2020-12-", "textStart": 1727, "textEnd": 1740}], "sentiment": 0.4274509803921569, "wgt": 137, "relevance": 1}
{"uri": "8259630577", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "07:35:15", "dateTime": "2024-08-05T07:35:15Z", "dateTimePub": "2024-08-05T07:34:26Z", "dataType": "news", "sim": 0.5372549295425415, "url": "https://techbullion.com/using-ai-to-fill-the-skill-gap-and-shape-the-future-workforce/", "title": "Using AI to fill the skill gap and shape the future workforce", "body": "In today's rapidly changing job market, the gap between the skills employers need and the skills workers possess is widening. This skills gap not only slows economic progress but also limits career growth for many individuals. However, Artificial Intelligence (AI) is emerging as a game-changer, offering innovative solutions to bridge this divide. By leveraging AI, we can create more effective training programs, personalize learning experiences, and ensure that both businesses and employees have the skills they need to thrive in the future.\n\nThe Skills Gap: A Growing Concern\n\nThe skills gap is a multifaceted issue affecting industries worldwide. According to the World Economic Forum, over 54% of all employees will require significant reskilling and upskilling by 2022. Additionally, a report by the McKinsey Global Institute predicts that up to 375 million workers (14% of the global workforce) may need to switch occupational categories by 2030 due to automation and AI.\n\nThese statistics highlight the urgency of addressing the skills gap. Traditional education and training methods struggle to keep pace with the rapid technological advancements, necessitating innovative solutions.\n\nHow AI is Transforming Skill Development?\n\nAI is revolutionizing the way we approach skill development and education. Here are some key ways AI is making a difference:\n\nPersonalized Learning: AI-powered platforms can tailor educational content to individual learning styles and paces. By analyzing data on how users interact with materials, these systems can adapt lessons to meet specific needs, enhancing comprehension and retention. For example, platforms like Coursera and Udacity use AI to recommend courses and materials based on learners' progress and interests. Automated Skill Assessment: AI can evaluate an individual's current skill level and identify gaps more efficiently than traditional methods. Tools like LinkedIn's Skill Assessments and Pymetrics use AI algorithms to assess abilities and provide feedback, helping individuals understand their strengths and areas for improvement. On-the-Job Training: AI can facilitate continuous learning in the workplace. Intelligent systems can recommend relevant training modules based on employees' roles and performance data. For instance, IBM's Watson offers personalized learning experiences, suggesting courses and resources to help employees develop the skills needed for their current and future roles. Predictive Analytics: AI can analyze labor market trends and predict future skill requirements. This insight allows educational institutions and training providers to design curricula that align with industry needs. Companies can also use predictive analytics to identify potential skill shortages and proactively train employees, ensuring a steady supply of qualified talent. Virtual Mentorship and Coaching: AI-powered chatbots and virtual assistants can provide real-time feedback and guidance, acting as virtual mentors. These systems can answer questions, offer tips, and provide resources, helping individuals navigate their career development journeys. Platforms like Replika and Woebot demonstrate the potential of AI-driven mentorship and support. Real-World Examples of AI Bridging the Skills Gap\n\nSeveral organizations are leveraging AI to address the skills gap with impressive results:\n\nGoogle's AI for Everyone: Google launched an initiative to democratize AI education through its free online courses. These courses, powered by AI-driven personalized learning, have reached millions of learners worldwide, equipping them with essential AI and machine learning skills. AT&T's Future Ready Initiative: AT&T invested $1 billion in reskilling its workforce, leveraging AI to identify skill gaps and recommend personalized learning paths. As a result, over 140,000 employees have completed training programs, ensuring they are prepared for the jobs of the future. Accenture's Skills to Succeed Academy: Accenture's AI-driven platform offers interactive training modules and personalized learning plans to help individuals develop job-ready skills. Since its launch, the academy has provided training to over 1.2 million people, improving their employability and career prospects. Challenges and Considerations\n\nWhile AI holds great promise for closing the skills gap, it is not without challenges. Privacy concerns, data security, and the potential for bias in AI algorithms are significant issues that must be addressed. Ensuring equitable access to AI-powered learning tools is also crucial to prevent further widening of the skills gap.\n\nMoreover, the human touch remains essential in education and training. AI should augment, not replace, human educators and mentors. Combining the strengths of AI with human empathy and expertise can create a more effective and holistic approach to skill development.\n\nConclusion\n\nThe skills gap is a pressing issue that requires innovative solutions. AI, with its ability to personalize learning, assess skills, and predict future needs, offers a powerful tool to bridge this divide. By leveraging AI, businesses can ensure a steady supply of qualified talent, and individuals can access the training they need to thrive in the modern workforce.\n\nAs we move forward, it is essential to address the challenges and ethical considerations associated with AI in education. With thoughtful implementation and collaboration, AI can play a pivotal role in closing the skills gap, creating a more dynamic and resilient workforce ready to meet the demands of the future.\n\nReferences World Economic Forum. (2020). The Future of Jobs Report 2020. Retrieved from weforum.org. McKinsey Global Institute. (2017). Jobs Lost, Jobs Gained: Workforce Transitions in a Time of Automation. Retrieved from mckinsey.com. Coursera. (2021). How AI is Transforming Online Learning. Retrieved from coursera.org. IBM. (2019). IBM Watson: AI for Business. Retrieved from ibm.com. Google. (2021). AI for Everyone. Retrieved from ai.google. AT&T. (2018). AT&T's Workforce Transformation. Retrieved from att.com. Accenture. (2020). Skills to Succeed Academy. Retrieved from accenture.com. About the Author\n\nKiran Kumar Reddy Yanamala is a Architect known for enhancing HR systems with automation and innovation. Kiran hold a Master's in Information Systems and a B.Tech in Computer Science. Kiran's expertise in Workday development has led to significant improvements in talent management and system analysis. Kiran is recognized for the leadership and mentorship within the professional community.\n\nRelated Items:AI to fill the skill gap, Skill Gap Recommended for you How Can Startups Overcome AI Skill Gaps in Their Teams? Navigating the Skill Gap in Technology: Flourishing in a Competitive Employment Landscape", "source": {"uri": "techbullion.com", "dataType": "news", "title": "TechBullion"}, "authors": [{"uri": "angela_scott_briggs@techbullion.com", "name": "Angela Scott-Briggs", "type": "author", "isAgency": false}, {"uri": "prime_star@techbullion.com", "name": "Prime Star", "type": "author", "isAgency": false}, {"uri": "ethan_lee@techbullion.com", "name": "Ethan Lee", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Personalized_learning", "type": "wiki", "score": 4, "label": {"eng": "Personalized learning"}}, {"uri": "http://en.wikipedia.org/wiki/Labour_economics", "type": "wiki", "score": 4, "label": {"eng": "Labour economics"}}, {"uri": "http://en.wikipedia.org/wiki/Learning_styles", "type": "wiki", "score": 3, "label": {"eng": "Learning styles"}}, {"uri": "http://en.wikipedia.org/wiki/Udacity", "type": "wiki", "score": 3, "label": {"eng": "Udacity"}}, {"uri": "http://en.wikipedia.org/wiki/World_Economic_Forum", "type": "wiki", "score": 3, "label": {"eng": "World Economic Forum"}}, {"uri": "http://en.wikipedia.org/wiki/Mentorship", "type": "wiki", "score": 3, "label": {"eng": "Mentorship"}}, {"uri": "http://en.wikipedia.org/wiki/Predictive_analytics", "type": "wiki", "score": 3, "label": {"eng": "Predictive analytics"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 3, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/McKinsey_&_Company", "type": "org", "score": 3, "label": {"eng": "McKinsey & Company"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/IBM_Watson", "type": "wiki", "score": 2, "label": {"eng": "IBM Watson"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 2, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Coursera", "type": "wiki", "score": 2, "label": {"eng": "Coursera"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 2, "label": {"eng": "Virtual assistant"}}, {"uri": "http://en.wikipedia.org/wiki/Educational_technology", "type": "wiki", "score": 2, "label": {"eng": "Educational technology"}}, {"uri": "http://en.wikipedia.org/wiki/Real-time_computing", "type": "wiki", "score": 2, "label": {"eng": "Real-time computing"}}, {"uri": "http://en.wikipedia.org/wiki/Accenture", "type": "org", "score": 2, "label": {"eng": "Accenture"}}, {"uri": "http://en.wikipedia.org/wiki/Curriculum", "type": "wiki", "score": 2, "label": {"eng": "Curriculum"}}, {"uri": "http://en.wikipedia.org/wiki/AT&T", "type": "org", "score": 2, "label": {"eng": "AT&T"}}, {"uri": "http://en.wikipedia.org/wiki/IBM", "type": "org", "score": 2, "label": {"eng": "IBM"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 2, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Automation", "type": "wiki", "score": 2, "label": {"eng": "Automation"}}, {"uri": "http://en.wikipedia.org/wiki/LinkedIn", "type": "org", "score": 2, "label": {"eng": "LinkedIn"}}, {"uri": "http://en.wikipedia.org/wiki/Workday,_Inc.", "type": "org", "score": 1, "label": {"eng": "Workday, Inc."}}, {"uri": "http://en.wikipedia.org/wiki/Holism", "type": "wiki", "score": 1, "label": {"eng": "Holism"}}, {"uri": "http://en.wikipedia.org/wiki/Empathy", "type": "wiki", "score": 1, "label": {"eng": "Empathy"}}, {"uri": "http://en.wikipedia.org/wiki/Human_resources", "type": "org", "score": 1, "label": {"eng": "Human resources"}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Business/Management", "label": "dmoz/Business/Management", "wgt": 100}, {"uri": "dmoz/Society/Work/Career_and_Job_Advancement", "label": "dmoz/Society/Work/Career and Job Advancement", "wgt": 100}, {"uri": "dmoz/Business/Management/Organizational_Change", "label": "dmoz/Business/Management/Organizational Change", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 81}], "image": "https://techbullion.com/wp-content/uploads/2024/08/WhatsApp-Image-2024-08-05-at-12.12.18-AM.jpeg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3254901960784313, "wgt": 137, "relevance": 1}
{"uri": "2024-08-444261418", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "08:34:17", "dateTime": "2024-08-05T08:34:17Z", "dateTimePub": "2024-08-05T08:11:20Z", "dataType": "news", "sim": 0.5372549295425415, "url": "https://airevolution.medium.com/ai-in-space-exploration-enhancing-research-and-discovery-26d8f4e50f13", "title": "# AI in Space Exploration: Enhancing Research and Discovery", "body": "Hello space enthusiasts and technology pioneers!\n\nToday, we explore how Artificial Intelligence (AI) is revolutionizing space exploration and scientific research. From autonomous spacecraft to data analysis, AI is transforming how we study the cosmos, uncovering new insights, and enhancing our understanding of the universe. This post will delve into the various applications of AI in space exploration and its impact on research and discovery.\n\n### Autonomous Spacecraft\n\nAI enables autonomous spacecraft to navigate and make decisions without human intervention. This allows for more efficient and accurate exploration of distant celestial bodies, reducing the need for constant communication with mission control.\n\n### Analyzing Space Data\n\nAI systems process vast amounts of space data collected by telescopes and satellites. Machine learning algorithms identify patterns and anomalies, helping scientists uncover new celestial phenomena and better understand the universe.\n\n### Optimizing Mission Planning\n\nAI assists in mission planning by simulating various scenarios and optimizing resource allocation. This ensures that space missions are conducted efficiently, maximizing scientific output and minimizing risks.\n\n### Identifying Exoplanets\n\nAI algorithms analyze data from telescopes to identify potential exoplanets. By detecting subtle changes in starlight, AI helps astronomers discover new planets beyond our solar system, expanding our knowledge of potential habitable worlds.\n\n### Studying Cosmic Phenomena\n\nAI aids in studying cosmic phenomena such as black holes, supernovae, and gravitational waves. By analyzing data from observatories, AI systems help scientists gain deeper insights into these mysterious events.\n\n### Supporting Astrobiology\n\nAI supports astrobiology research by analyzing environmental data from planets and moons. This helps scientists assess the potential for life beyond Earth and understand the conditions necessary for life to thrive.\n\n### Human-AI Collaboration\n\nThe future of space exploration will involve increased collaboration between humans and AI. AI will assist astronauts in making decisions, conducting experiments, and maintaining spacecraft systems, enhancing the efficiency and safety of space missions.\n\n### Expanding Our Reach\n\nAI will enable humanity to explore more distant and challenging environments, such as the moons of Jupiter and Saturn or the surface of Mars. By leveraging AI, we can expand our reach and deepen our understanding of the cosmos.\n\n### Advancing Scientific Knowledge\n\nAs AI technologies continue to advance, their impact on space exploration and scientific research will grow. AI will enable us to uncover new insights, solve complex challenges, and push the boundaries of what is possible in our quest to explore the universe.\n\nAI is revolutionizing space exploration by enhancing research and discovery. From autonomous spacecraft and data analysis to identifying exoplanets and studying cosmic phenomena, AI is driving innovation and shaping the future of space exploration. As we continue to advance AI technologies, the possibilities for discovery and exploration are limitless.", "source": {"uri": "airevolution.medium.com", "dataType": "news", "title": "Medium"}, "authors": [{"uri": "andrew_d@airevolution.medium.com", "name": "Andrew D.", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Space_exploration", "type": "wiki", "score": 5, "label": {"eng": "Space exploration"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Spacecraft", "type": "wiki", "score": 4, "label": {"eng": "Spacecraft"}}, {"uri": "http://en.wikipedia.org/wiki/Universe", "type": "wiki", "score": 4, "label": {"eng": "Universe"}}, {"uri": "http://en.wikipedia.org/wiki/Cosmos", "type": "loc", "score": 3, "label": {"eng": "Cosmos"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Telescope", "type": "wiki", "score": 3, "label": {"eng": "Telescope"}}, {"uri": "http://en.wikipedia.org/wiki/Scientific_method", "type": "wiki", "score": 3, "label": {"eng": "Scientific method"}}, {"uri": "http://en.wikipedia.org/wiki/Astronomical_object", "type": "wiki", "score": 3, "label": {"eng": "Astronomical object"}}, {"uri": "http://en.wikipedia.org/wiki/Exoplanet", "type": "wiki", "score": 2, "label": {"eng": "Exoplanet"}}, {"uri": "http://en.wikipedia.org/wiki/Supernova", "type": "wiki", "score": 2, "label": {"eng": "Supernova"}}, {"uri": "http://en.wikipedia.org/wiki/Gravitational_wave", "type": "wiki", "score": 2, "label": {"eng": "Gravitational wave"}}, {"uri": "http://en.wikipedia.org/wiki/Astrobiology", "type": "wiki", "score": 2, "label": {"eng": "Astrobiology"}}, {"uri": "http://en.wikipedia.org/wiki/Astronomer", "type": "wiki", "score": 2, "label": {"eng": "Astronomer"}}, {"uri": "http://en.wikipedia.org/wiki/Solar_System", "type": "wiki", "score": 2, "label": {"eng": "Solar System"}}, {"uri": "http://en.wikipedia.org/wiki/Black_hole", "type": "wiki", "score": 2, "label": {"eng": "Black hole"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 2, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Star", "type": "wiki", "score": 2, "label": {"eng": "Star"}}, {"uri": "http://en.wikipedia.org/wiki/Satellite", "type": "wiki", "score": 2, "label": {"eng": "Satellite"}}, {"uri": "http://en.wikipedia.org/wiki/Galilean_moons", "type": "wiki", "score": 1, "label": {"eng": "Galilean moons"}}, {"uri": "http://en.wikipedia.org/wiki/Natural_satellite", "type": "wiki", "score": 1, "label": {"eng": "Natural satellite"}}, {"uri": "http://en.wikipedia.org/wiki/Saturn", "type": "wiki", "score": 1, "label": {"eng": "Saturn"}}], "categories": [{"uri": "dmoz/Science/Technology/Space", "label": "dmoz/Science/Technology/Space", "wgt": 30}, {"uri": "dmoz/Business/Aerospace_and_Defense/Space", "label": "dmoz/Business/Aerospace and Defense/Space", "wgt": 28}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 24}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 30}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 26}, {"uri": "news/Science", "label": "news/Science", "wgt": 75}], "image": "https://miro.medium.com/v2/resize:fit:1024/1*UvCnX7YYPq1-e1u3tv17Yg@2x.jpeg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3176470588235294, "wgt": 137, "relevance": 1}
{"uri": "8259801800", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "09:32:05", "dateTime": "2024-08-05T09:32:05Z", "dateTimePub": "2024-08-05T09:29:36Z", "dataType": "news", "sim": 0.5372549295425415, "url": "https://mashable.com/deals/august-5-ai-courses", "title": "Learn the hottest AI tools for $30  --  ChatGPT, DALL-E 3, and Midjourney master classes", "body": "We have a theory: Everyone who hates AI is secretly experiencing FOMO. If that's you, droning on about how much you hate ChatGPT even though you've never used it, we're gonna try to change your mind. Because AI is part of the future, whether you like it or not.\n\nPlus, we have good news. ChatGPT isn't the only AI tool out there these days, and this online learning bundle can help you master the best AI tools for only $29.99 (reg. $152).\n\nOur first point of persuasion is that AI could save you time at work, period. If you write a lot of, well, anything -- emails, reports, blogs, ad copy, etc. -- tools like Quillbot AI and ChatGPT can help take some of the stress off of your shoulders.\n\nA huge part of using AI is understanding its limitations, and your instructor (Skill Success) helps you understand that these tools won't do your job for you but rather help you write faster and more confidently by brainstorming ideas, revising your writing, or summarizing a large amount of information into a shorter format.\n\nThe same goes for generating AI images, which can sometimes create whack results (like people with twenty fingers). These courses cover DALL-E 3, Midjourney, and Leonardo AI and how to get the most out of them, hopefully inspiring accurate images and graphics that don't have too many digits.\n\nIf you want to keep up without missing out, you should probably learn AI. This 8-course online learning bundle is a great place to start at $29.99 (reg. $152).", "source": {"uri": "mashable.com", "dataType": "news", "title": "Mashable"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 5, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Psychological_stress", "type": "wiki", "score": 2, "label": {"eng": "Psychological stress"}}, {"uri": "http://en.wikipedia.org/wiki/Educational_technology", "type": "wiki", "score": 2, "label": {"eng": "Educational technology"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 2, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Midjourney", "type": "wiki", "score": 1, "label": {"eng": "Midjourney"}}, {"uri": "http://en.wikipedia.org/wiki/DALL-E", "type": "wiki", "score": 1, "label": {"eng": "DALL-E"}}, {"uri": "http://en.wikipedia.org/wiki/Leonardo_da_Vinci", "type": "person", "score": 1, "label": {"eng": "Leonardo da Vinci"}}], "categories": [{"uri": "dmoz/Recreation/Humor/Useless_Pages", "label": "dmoz/Recreation/Humor/Useless Pages", "wgt": 100}, {"uri": "dmoz/Society/Advice", "label": "dmoz/Society/Advice", "wgt": 100}, {"uri": "dmoz/Society/Relationships/Romance", "label": "dmoz/Society/Relationships/Romance", "wgt": 100}], "image": "https://helios-i.mashable.com/imagery/articles/02EeULI9lTrbHWwjSPkI9zV/hero-image.fill.size_1200x675.v1722622733.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.2549019607843137, "wgt": 137, "relevance": 1}
{"uri": "8260081940", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "12:27:39", "dateTime": "2024-08-05T12:27:39Z", "dateTimePub": "2024-08-05T12:25:52Z", "dataType": "news", "sim": 0.5333333611488342, "url": "https://www.urdupoint.com/en/pakistan/google-for-startups-launches-ai-academy-to-pr-1850506.html", "title": "Google For Startups Launches AI Academy To Propel AI Innovation In Pakistan - UrduPoint", "body": "ISLAMABAD, (UrduPoint / Pakistan Point News - 5th Aug, 2024) Google for Startups Monday announced the launch of AI Academy, a new programme designed to support and accelerate the growth of AI startups in Pakistan and the Asia-Pacific (APAC) region.\n\nThe program will bring together more than 20 startups that are developing AI technologies, which will foster a vibrant AI community within APAC and ignite cross-border innovation and partnerships.\n\nAccording to a news release, the collaborative environment will encourage exchanging ideas, expertise, and resources, accelerating the development of cutting-edge AI solutions and establishing APAC as a global hub in AI advancements.\n\nSelected startups will receive, tailored mentorship: Access to Google's world-class AI experts for personalized guidance and support.\n\nGoogle Cloud credits: Up to $350,000 in Google Cloud credits to fuel their AI development and experimentation. Community building opportunities: Opportunities to connect and collaborate with other AI startups across the APAC region.\n\nUniquely, AI academy is designed to fast-track startups to market by enabling them to build a \"proof of concept\" and product roadmap, rapidly validating and enhancing their AI solutions.\n\nBy applying Google Cloud tools to their data, startups can build a \"proof of concept\" and develop a product roadmap for clear and immediate integration into their existing products. This accelerated approach will both speed up their path to success and demonstrate the tangible value of their AI innovations.", "source": {"uri": "urdupoint.com", "dataType": "news", "title": "UrduPoint"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 5, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Asia-Pacific", "type": "loc", "score": 5, "label": {"eng": "Asia-Pacific"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Pakistan", "type": "loc", "score": 5, "label": {"eng": "Pakistan"}, "location": {"type": "country", "label": {"eng": "Pakistan"}}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 4, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Google_Cloud_Platform", "type": "wiki", "score": 3, "label": {"eng": "Google Cloud Platform"}}, {"uri": "http://en.wikipedia.org/wiki/Islamabad", "type": "loc", "score": 3, "label": {"eng": "Islamabad"}, "location": {"type": "place", "label": {"eng": "Islamabad"}, "country": {"type": "country", "label": {"eng": "Pakistan"}}}}, {"uri": "http://en.wikipedia.org/wiki/Global_city", "type": "wiki", "score": 2, "label": {"eng": "Global city"}}, {"uri": "http://en.wikipedia.org/wiki/Mentorship", "type": "wiki", "score": 2, "label": {"eng": "Mentorship"}}, {"uri": "http://en.wikipedia.org/wiki/Proof_of_concept", "type": "wiki", "score": 1, "label": {"eng": "Proof of concept"}}], "categories": [{"uri": "dmoz/Computers/Human-Computer_Interaction/Companies_and_Consultants", "label": "dmoz/Computers/Human-Computer Interaction/Companies and Consultants", "wgt": 100}, {"uri": "dmoz/Home/Do-It-Yourself", "label": "dmoz/Home/Do-It-Yourself", "wgt": 100}, {"uri": "dmoz/Computers/Robotics/Robots", "label": "dmoz/Computers/Robotics/Robots", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 65}], "image": "https://photo-cdn.urdupoint.com/images/UrduPoint-English-22.png", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": {"type": "place", "label": {"eng": "Islamabad"}, "country": {"type": "country", "label": {"eng": "Pakistan"}}}, "extractedDates": null, "sentiment": 0.5607843137254902, "wgt": 136, "relevance": 1}
{"uri": "8259654230", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "07:52:30", "dateTime": "2024-08-05T07:52:30Z", "dateTimePub": "2024-08-05T07:50:51Z", "dataType": "news", "sim": 0.5333333611488342, "url": "https://www.zdnet.com/article/these-experts-believe-ai-can-help-us-win-the-cybersecurity-battle/", "title": "These experts believe AI can help us win the cybersecurity battle", "body": "The arrival of artificial intelligence (AI) in many cybersecurity products can't come too soon, according to the founder of prominent cybersecurity vendor Palo Alto Networks, who sees the spiraling threat landscape as too complex to be managed by human efforts alone.\n\n\"They are going to try a million ways to get in,\" said Nir Zuk, the chief technologist and co-founder of Palo Alto Networks, regarding malicious actors.\n\nAlso: AI-powered 'narrative attacks' a growing threat: 3 defense strategies for business leaders\n\nAs for the threat hunters, he said: \"You can't be correct a million out of a million times -- that doesn't scale.\"\n\nThat's where AI comes in. Zuk and Palo Alto's Chief Product Officer, Lee Klarich, sat down with ZDNET recently to discuss how AI is changing cybersecurity.\n\nAlso: The best VPN services (and how to choose the right one for you)\n\nPalo Alto began almost 18 years ago as a network security vendor competing with numerous firewall specialists and intrusion detection and prevention companies and eventually moved into cloud security and managed services.\n\nZuk, a mathematician by training, has a long history running technology for cybersecurity outfits, having previously served as CTO at Juniper Networks, and before that founding cybersecurity startup OneSecure (later sold to NetScreen Technologies, which was sold to Juniper).\n\nAlso: Generative AI is new attack vector endangering enterprises, says CrowdStrike CTO\n\nKlarich was previously director of product management for Juniper, and head of firewall technology at NetScreen before that.\n\nThe flash point for AI and security, said Zuk, is the security operations center, or SOC, which watches what happens on the network and tries to detect and stop malicious behavior.\n\nThe chief information society officer (CISO) and their team are outgunned. \"If you look at the numbers for respond, recover, remediate,\" the main things a CISO does following a breach -- those numbers are horrible,\" said Zuk.\n\n\"When the SEC [US Securities and Exchange Commission] announced that it expects public companies to report within four days about a major breach, everybody had an, 'Oh, crap' moment,\" he said. He noted the security team can't even close routine IT tickets from that day: \"They're looking for a needle in a haystack.\"\n\nBecause there aren't enough engineers, or hours in the day, \"the idea of AI in the SOC is to do the things that humans do,\" but in \"the most scalable way and faster,\" said Zuk, to reduce the \"mean time to detect\" a breach to minutes.\n\nAlso: Intel sees AI in enterprise on a 'three to five-year path'\n\n\"I think that there's an opportunity where AI effectively automates a majority of how cybersecurity is deployed, configured, and operationalized,\" said Zuk, because, \"it's become so complex for people to do.\"\n\nAutomation is a broad, general term that is widely used. The aim of using emerging technology in the SOC is for the AI model to discover what \"normal\" means. The CISO and their teams spend their time hunting for traces of suspicious behavior, said Zuk. This effort takes hours, days and, weeks.\n\nIt would be better if the machine could find what normal looks like in the enterprise, said Zuk, so that anything malicious stands out.\n\n\"Let's use AI to learn what's not normal in the organization, irrespective of which attack technique posted,\" said Zuk. \"I don't care how they broke in and I don't care how they move laterally and so on; if I can detect the abnormal within the organization, which humans cannot, and AI can in a scalable way, it gives me an advantage that they don't have today.\"\n\nZuk and Klarich see an advantage in using software's breadth to find the normal. The training and the generation of predictions in AI require the integration of sensor data from many sources.\n\nAlso: As AI agents spread, so do the risks, scholars say\n\n\"You can't collect data into data silos and then expect to run AI on it. It works much better when the sensors and the AI come from the same vendor,\" said Klarich.\n\n\"The more data sources it has, the more accurate the picture of normal is going to be in order to be able to determine what unusual activity looks like.\"\n\nThe concentration of data means that Palo Alto believes AI may fuel consolidation in the cybersecurity industry, which is classically fragmented across vendors.\n\n\"Cybersecurity is largely toward one end of the extreme in terms of having a huge number of smaller point product vendors,\" said Klarich.\n\n\"It's not that you need to go from a hundred different security solutions to one, it's that you need to go from a hundred to a lot less. You can't expect to collect data into silos, and then expect to run AI on it.\"\n\nAlso: The best VPN services for iPhone and iPad (yes, you need to use one)\n\nComplexity is rising, of course, as the attacks from errant actors become automated.\n\n\"We do assume, in terms of how we think about our technologies, that there will be new attack techniques that they will come up with, and, increasingly, automated attacks,\" said Zuk.\n\n\"That dramatically changes the scale with which attacks can be carried out because they'll no longer be limited by their human resources in terms of their capacity, but rather they'll also be able to use AI to carry out attacks in parallel.\"\n\nThe legitimate use of AI also increases the \"threat surface\", according to Zuk and Klarich. A programmer who uses a programming \"copilot\" to write code exposes more of their company's source files to a remote service.\n\n\"That's intellectual property that just left the control of the enterprise, right?\", said Zuk. \"And that's one of hundreds of new AI applications that exist that run the same risk.\"\n\nThe good news is Zuk said he believes the forces of good can win out in the battle of AI.\n\n\"I personally think that AI is going to help the defenders more than it's going to help the attackers,\" he said.", "source": {"uri": "zdnet.com", "dataType": "news", "title": "ZDNet"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Palo_Alto_Networks", "type": "org", "score": 5, "label": {"eng": "Palo Alto Networks"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_technology_officer", "type": "wiki", "score": 5, "label": {"eng": "Chief technology officer"}}, {"uri": "http://en.wikipedia.org/wiki/Juniper_Networks", "type": "org", "score": 5, "label": {"eng": "Juniper Networks"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 5, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Palo_Alto,_California", "type": "loc", "score": 5, "label": {"eng": "Palo Alto, California"}, "location": {"type": "place", "label": {"eng": "Palo Alto, California"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/NetScreen_Technologies", "type": "org", "score": 4, "label": {"eng": "NetScreen Technologies"}}, {"uri": "http://en.wikipedia.org/wiki/Firewall_(computing)", "type": "wiki", "score": 4, "label": {"eng": "Firewall (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/System_on_a_chip", "type": "wiki", "score": 4, "label": {"eng": "System on a chip"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_information_security_officer", "type": "wiki", "score": 4, "label": {"eng": "Chief information security officer"}}, {"uri": "http://en.wikipedia.org/wiki/Cloud_computing_security", "type": "wiki", "score": 3, "label": {"eng": "Cloud computing security"}}, {"uri": "http://en.wikipedia.org/wiki/Intrusion_detection_system", "type": "wiki", "score": 3, "label": {"eng": "Intrusion detection system"}}, {"uri": "http://en.wikipedia.org/wiki/Network_security", "type": "wiki", "score": 3, "label": {"eng": "Network security"}}, {"uri": "http://en.wikipedia.org/wiki/Vector_graphics", "type": "wiki", "score": 3, "label": {"eng": "Vector graphics"}}, {"uri": "http://en.wikipedia.org/wiki/Managed_services", "type": "wiki", "score": 3, "label": {"eng": "Managed services"}}, {"uri": "http://en.wikipedia.org/wiki/Scalability", "type": "wiki", "score": 3, "label": {"eng": "Scalability"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_private_network", "type": "wiki", "score": 3, "label": {"eng": "Virtual private network"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/U.S._Securities_and_Exchange_Commission", "type": "wiki", "score": 3, "label": {"eng": "U.S. Securities and Exchange Commission"}}, {"uri": "http://en.wikipedia.org/wiki/CrowdStrike", "type": "org", "score": 3, "label": {"eng": "CrowdStrike"}}, {"uri": "http://en.wikipedia.org/wiki/Emerging_technologies", "type": "wiki", "score": 2, "label": {"eng": "Emerging technologies"}}, {"uri": "http://en.wikipedia.org/wiki/Public_company", "type": "wiki", "score": 2, "label": {"eng": "Public company"}}, {"uri": "http://en.wikipedia.org/wiki/Intel", "type": "org", "score": 2, "label": {"eng": "Intel"}}, {"uri": "http://en.wikipedia.org/wiki/Automation", "type": "wiki", "score": 2, "label": {"eng": "Automation"}}, {"uri": "http://en.wikipedia.org/wiki/Information_technology", "type": "wiki", "score": 2, "label": {"eng": "Information technology"}}, {"uri": "http://en.wikipedia.org/wiki/Programmer", "type": "wiki", "score": 1, "label": {"eng": "Programmer"}}, {"uri": "http://en.wikipedia.org/wiki/Human_resources", "type": "org", "score": 1, "label": {"eng": "Human resources"}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Recreation/Humor/Useless_Pages", "label": "dmoz/Recreation/Humor/Useless Pages", "wgt": 100}, {"uri": "dmoz/Society/Advice", "label": "dmoz/Society/Advice", "wgt": 100}, {"uri": "dmoz/Computers/Internet/Abuse", "label": "dmoz/Computers/Internet/Abuse", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 57}], "image": "https://www.zdnet.com/a/img/resize/b653275a7ffc47da7f24205cde93697898deba8e/2024/08/05/d75e78be-1e6a-4f5b-9b95-77408de6be85/gettyimages-1483076236-2.jpg?auto=webp&fit=crop&height=675&width=1200", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": -0.05882352941176472, "wgt": 136, "relevance": 1}
{"uri": "8259736019", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "08:47:41", "dateTime": "2024-08-05T08:47:41Z", "dateTimePub": "2024-08-05T08:47:08Z", "dataType": "news", "sim": 0.5333333611488342, "url": "https://www.finextra.com/newsarticle/44540/lloyds-hires-aws-exec-to-head-up-new-ai-and-analytics-unit", "title": "Lloyds hires AWS exec to head up new AI and analytics unit", "body": "This content has been selected, created and edited by the Finextra editorial team based upon its relevance and interest to our community.\n\nIn this newly established role, Rohit Dhawan will lead the UK bank's AI Centre of Excellence , bringing together experts in data ccience, behavioral science, ML engineering, advanced analytics and AI ethics. He will be responsible for shaping the overall AI, ML and advanced analytics strategy and promoting the adoption of AI enabled products and services for the bank's 27 million customers.\n\nRohit, who holds a PhD in artificial intelligence from the University of Sydney, joins from Amazon Web Services, where he served as the head of data and AI strategy across the Asia-Pacific region. In this role he spearheaded a number of strategic developments, including the integration of AI into customer and operational processes and establishing a multi-disciplinary data and AI function.\n\nRanil Boteju, chief data and analytics officer at Lloyds Banking Group says: \"Rohit's appointment is a significant boost for the strategic development of AI technology and capabilities within Lloyds Banking Group, with his wealth of experience delivering technology and change, at pace and scale. Rohit will work across the business to further integrate AI outcomes into business priorities, helping us to scale AI in a consistent way and deliver against our strategy.\"\n\nLloyds is currently trailing over 50 use cases for AI across the business, including increasing the speed of support, quality of chatbot tools and detecting early warning signs of fraud.\n\nSo far this year the bank has recruited another 1,500 technology and data specialists, taking the total to more than 4,000 over the past two and a half years.\n\nSays Dhawan: \"I'm excited to work for an organisation undergoing one of the largest transformations in financial services and look at how we can transform the way we use data and tech to respond to changing customer needs.\"", "source": {"uri": "finextra.com", "dataType": "news", "title": "Finextra Research"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Analytics", "type": "wiki", "score": 5, "label": {"eng": "Analytics"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 4, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Ethics of artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Lloyds_Banking_Group", "type": "org", "score": 3, "label": {"eng": "Lloyds Banking Group"}}, {"uri": "http://en.wikipedia.org/wiki/Engineering", "type": "wiki", "score": 3, "label": {"eng": "Engineering"}}, {"uri": "http://en.wikipedia.org/wiki/United_Kingdom", "type": "loc", "score": 3, "label": {"eng": "United Kingdom"}, "location": {"type": "country", "label": {"eng": "United Kingdom"}}}, {"uri": "http://en.wikipedia.org/wiki/University_of_Sydney", "type": "org", "score": 2, "label": {"eng": "University of Sydney"}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_Web_Services", "type": "org", "score": 2, "label": {"eng": "Amazon Web Services"}}, {"uri": "http://en.wikipedia.org/wiki/Interdisciplinarity", "type": "wiki", "score": 2, "label": {"eng": "Interdisciplinarity"}}, {"uri": "http://en.wikipedia.org/wiki/Doctor_of_Philosophy", "type": "wiki", "score": 2, "label": {"eng": "Doctor of Philosophy"}}, {"uri": "http://en.wikipedia.org/wiki/Asia-Pacific", "type": "loc", "score": 2, "label": {"eng": "Asia-Pacific"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 1, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Fraud", "type": "wiki", "score": 1, "label": {"eng": "Fraud"}}, {"uri": "http://en.wikipedia.org/wiki/Financial_services", "type": "wiki", "score": 1, "label": {"eng": "Financial services"}}], "categories": [{"uri": "dmoz/Business/Financial_Services", "label": "dmoz/Business/Financial Services", "wgt": 100}, {"uri": "dmoz/Business/Financial_Services/Banking_Services", "label": "dmoz/Business/Financial Services/Banking Services", "wgt": 100}, {"uri": "dmoz/Business/Financial_Services/Holding_Companies", "label": "dmoz/Business/Financial Services/Holding Companies", "wgt": 100}, {"uri": "dmoz/Business/Financial_Services/Employment", "label": "dmoz/Business/Financial Services/Employment", "wgt": 100}, {"uri": "dmoz/Business/Financial_Services/Information_Services", "label": "dmoz/Business/Financial Services/Information Services", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 57}], "image": "https://www.finextra.com/finextra-images/top_pics/xl/lloyds-banking-logo-new.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.4745098039215687, "wgt": 136, "relevance": 1}
{"uri": "8259959913", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "11:10:43", "dateTime": "2024-08-05T11:10:43Z", "dateTimePub": "2024-08-05T11:09:33Z", "dataType": "news", "sim": 0.5254902243614197, "url": "https://www.devdiscourse.com/article/sports-games/3042278-the-role-of-ai-in-enhancing-online-gaming-experiences", "title": "The Role of AI in Enhancing Online Gaming Experiences | Sports-Games", "body": "Artificial Intelligence (AI) has revolutionized various industries, and the online gaming industry is no exception. From improving gameplay and personalizing user experiences to enhancing security and developing smarter NPCs (non-player characters), AI transforms how we play and interact with online games. In this article, we will explore the role of AI in enhancing online gaming experiences, with specific examples from online rummy platforms.\n\nArtificial Intelligence is the simulation of human intelligence in machines programmed to think, learn, and problem-solve like humans. In online gaming, AI can analyze vast amounts of data to enhance various aspects of the gaming experience. This includes personalizing gameplay, improving game design, detecting and preventing cheating, and providing real-time support.\n\nOne of AI's most significant contributions to online gaming is its ability to personalize each player's gaming experience. By analyzing player behavior, preferences, and in-game actions, AI can adjust the game to suit individual players.\n\nAI algorithms can analyze how players interact with the game, including their preferred strategies, skill levels, and in-game choices. This allows the game to adapt dynamically and provide challenges. For example, in online rummy apps, AI can adjust the difficulty level of opponents to match the player's skill, ensuring a balanced and enjoyable gaming experience.\n\nAI can also provide personalized recommendations for games, tournaments, and in-game purchases. By analyzing a player's past behavior and preferences, AI can suggest new games or in-game items likely to interest the player. This enhances the overall gaming experience and keeps players engaged.\n\nAI is crucial in game design and development, helping developers create more immersive and engaging games.\n\nContent generation uses AI algorithms to dynamically create game content such as levels, maps, and quests. This allows for a virtually infinite variety of game scenarios, keeping the gameplay fresh and exciting.\n\nAI enables the development of smarter and more realistic NPCs that can interact with players in a lifelike manner. These NPCs can adapt to player actions, make strategic decisions, and provide a more challenging and immersive gaming experience.\n\nAI-powered chatbots and virtual assistants are transforming in-game support, providing players with real-time assistance and enhancing their gaming experience.\n\nAI chatbots can provide instant support to players, answering common queries, resolving issues, and guiding them through the game. This ensures players enjoy a seamless gaming experience without waiting for human support.\n\nAI can also create personalized training sessions and tutorials based on a player's skill level and progress. By analyzing the player's performance, AI can identify areas for improvement and provide targeted training modules.\n\nAI is instrumental in ensuring security and fair play in online gaming. AI helps maintain a safe and trustworthy gaming environment by detecting and preventing cheating and fraud.\n\nAI algorithms can analyze gameplay data to identify patterns and behaviors associated with cheating. By detecting anomalies and suspicious activities, AI can flag potential cheaters and prevent them from disrupting the game.\n\nAI can also enhance security by detecting fraudulent activities such as account hacking and payment fraud. AI can identify and block suspicious activities in real time by analyzing transaction patterns and player behavior.\n\nAI helps increase player engagement and retention by providing a more personalized and enjoyable gaming experience.\n\nAI can deliver dynamic and personalized content based on player preferences and behavior. This includes personalized challenges, rewards, and in-game events that keep players engaged and returning for more.\n\nAI can enhance gamification elements within the game, such as achievements, leaderboards, and rewards. AI can create personalized gamification strategies that motivate players and improve their gaming experience by analyzing player behavior.\n\nThe role of AI in online gaming is continuously evolving, with new advancements and innovations on the horizon.\n\nAI will play a crucial role in enhancing AR and VR gaming experiences. AI will take online gaming to new heights by creating more realistic and immersive environments. Players can expect more interactive and lifelike gaming experiences in the future.\n\nFuture advancements in AI will enable even more advanced personalization in online gaming. AI can analyze a wider range of data points to create highly tailored gaming experiences that cater to individual player preferences and behaviors.\n\nAI will continue to enhance security measures in online gaming with more sophisticated algorithms for detecting and preventing cheating and fraud. This will ensure a safe and trustworthy gaming environment for all players.\n\nAI will enable the development of even smarter and more realistic NPCs and game characters. These characters will be able to interact with players in more complex and lifelike ways, enhancing the overall gaming experience.\n\nAI enhances online gaming experiences by personalizing gameplay, improving game design, providing real-time support, ensuring security, and increasing player engagement. Online rummy apps leverage AI to offer more engaging, enjoyable, and secure gaming experiences. As AI continues to evolve, we can expect even more exciting advancements and innovations in the online gaming industry, taking our gaming experiences to new levels of immersion and enjoyment.\n\nAuthor Bio: Mithilesh Singh is a digital marketing consultant, blogger, founder of Celebrity News, and co-founder of Stock Market News.", "source": {"uri": "devdiscourse.com", "dataType": "news", "title": "Devdiscourse"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Non-player_character", "type": "wiki", "score": 5, "label": {"eng": "Non-player character"}}, {"uri": "http://en.wikipedia.org/wiki/Online_game", "type": "wiki", "score": 5, "label": {"eng": "Online game"}}, {"uri": "http://en.wikipedia.org/wiki/Gameplay", "type": "wiki", "score": 5, "label": {"eng": "Gameplay"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Game_design", "type": "wiki", "score": 4, "label": {"eng": "Game design"}}, {"uri": "http://en.wikipedia.org/wiki/Real-time_computing", "type": "wiki", "score": 4, "label": {"eng": "Real-time computing"}}, {"uri": "http://en.wikipedia.org/wiki/Cheating_in_video_games", "type": "wiki", "score": 4, "label": {"eng": "Cheating in video games"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 4, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Game_balance", "type": "wiki", "score": 3, "label": {"eng": "Game balance"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Simulation", "type": "wiki", "score": 3, "label": {"eng": "Simulation"}}, {"uri": "http://en.wikipedia.org/wiki/Intelligence", "type": "wiki", "score": 3, "label": {"eng": "Intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Microtransaction", "type": "wiki", "score": 2, "label": {"eng": "Microtransaction"}}, {"uri": "http://en.wikipedia.org/wiki/Tutorial", "type": "wiki", "score": 2, "label": {"eng": "Tutorial"}}, {"uri": "http://en.wikipedia.org/wiki/Gamification", "type": "wiki", "score": 2, "label": {"eng": "Gamification"}}, {"uri": "http://en.wikipedia.org/wiki/Fraud", "type": "wiki", "score": 2, "label": {"eng": "Fraud"}}, {"uri": "http://en.wikipedia.org/wiki/Hacker", "type": "wiki", "score": 1, "label": {"eng": "Hacker"}}, {"uri": "http://en.wikipedia.org/wiki/Immersion_(virtual_reality)", "type": "wiki", "score": 1, "label": {"eng": "Immersion (virtual reality)"}}, {"uri": "http://en.wikipedia.org/wiki/Score_(game)", "type": "wiki", "score": 1, "label": {"eng": "Score (game)"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_reality", "type": "wiki", "score": 1, "label": {"eng": "Virtual reality"}}], "categories": [{"uri": "dmoz/Games", "label": "dmoz/Games", "wgt": 100}, {"uri": "dmoz/Games/Video_Games/Browser_Based", "label": "dmoz/Games/Video Games/Browser Based", "wgt": 100}, {"uri": "dmoz/Games/Board_Games", "label": "dmoz/Games/Board Games", "wgt": 100}, {"uri": "dmoz/Games/Board_Games/Print_and_Play", "label": "dmoz/Games/Board Games/Print and Play", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 71}], "image": "https://www.devdiscourse.com/remote.axd?https://devdiscourse.blob.core.windows.net/devnews/05_08_2024_16_16_15_9138088.jpg?width=920&format=jpeg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3098039215686275, "wgt": 134, "relevance": 1}
{"uri": "8259815623", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "09:40:04", "dateTime": "2024-08-05T09:40:04Z", "dateTimePub": "2024-08-05T09:38:58Z", "dataType": "news", "sim": 0.5176470875740051, "url": "https://fortune.com/asia/2024/08/05/unlocking-ai-close-three-gaps-confidence-expertise-confidence-brainstorm-ai-singapore/", "title": "Companies will need to close three gaps -- value, confidence and expertise -- if they want to make AI useful", "body": "Company leaders, at least on earnings calls, say they want to use generative AI to boost the bottom line, and Microsoft recently estimated that nearly 60% of Fortune 500 companies are using its Copilot AI assistant.\n\nBut speakers at Fortune Brainstorm AI Singapore last week warned that companies need to overcome a gaps in value, confidence and expertise if they want to leverage the benefits of employing generative AI.\n\n\"There's a lot of excitement about AI, but translating that into business outcomes is not easy,\" said Debanjan Saha, CEO of DataRobot, referring to what he called the \"value gap.\"\n\nWhen it comes to the \"confidence gap,\" businesses are \"not confident enough to take those AI applications or models to production because they are not sure about the accuracy,\" he continued.\n\nFortunately, Saha noted, companies don't need their workforce to have a deep level of expertise with AI and building models. Instead, \"you really need people who can use these models to actually solve business problems.\"\n\nAnother important element of the \"confidence\" gap? Figuring out how to \"stay out of jail,\" Saha said.\n\nBut government scrutiny isn't stopping companies from trying to adopt AI. \"Surprisingly, the industries which are more regulated are actually using [AI] a lot, contrary to what you might think,\" said Vivek Luthra, senior managing director for growth markets and ANZ data at Accenture. (Accenture is a founding partner of Brainstorm AI)\n\nLuthra said that companies can approach the gaps in AI from a workforce transformation perspective. Companies need to think ahead, determine what work they will be doing in the future, and then cultivate the workers they'll need to achieve that.\n\nTraining the right talent could result in huge value for a firm. Luthra cited the example of a food and beverages company, an Accenture client, that used AI to create a year's worth of marketing content in just eight days.\n\n\"That is phenomenal in terms of productivity enhancement,\" he said.\n\nBut workers will need to be trained in more than just generative AI and large language models. \"To be able to scale, you need to think about the competencies. Having a large language model is a small part of that,\" Luthra said.\n\nBoth speakers warned that not every firm will be able to adopt AI at the same rate. Tech and asset-light companies can be nimbler, while asset-heavy firms like manufacturing may need more time to use the new technologies.\n\nSaha reminded attendees that the point of generative AI is to return value to businesses, and that the \"honeymoon period\" is not going to last long.\n\n\"Showing near-term value and showing some return on investment, showing some early successes -- I think that's very, very important,\" Saha said.", "source": {"uri": "fortune.com", "dataType": "news", "title": "Fortune"}, "authors": [{"uri": "lionel_lim@fortune.com", "name": "Lionel Lim", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 3, "label": {"eng": "Virtual assistant"}}, {"uri": "http://en.wikipedia.org/wiki/Fortune_(magazine)", "type": "wiki", "score": 3, "label": {"eng": "Fortune (magazine)"}}, {"uri": "http://en.wikipedia.org/wiki/Accenture", "type": "org", "score": 3, "label": {"eng": "Accenture"}}, {"uri": "http://en.wikipedia.org/wiki/Fortune_500", "type": "wiki", "score": 3, "label": {"eng": "Fortune 500"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 3, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Leverage_(finance)", "type": "wiki", "score": 3, "label": {"eng": "Leverage (finance)"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Singapore", "type": "loc", "score": 3, "label": {"eng": "Singapore"}, "location": {"type": "country", "label": {"eng": "Singapore"}}}, {"uri": "http://en.wikipedia.org/wiki/Applications_of_artificial_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Applications of artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 1, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 1, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Marketing", "type": "wiki", "score": 1, "label": {"eng": "Marketing"}}], "categories": [{"uri": "dmoz/Society/Issues/Business", "label": "dmoz/Society/Issues/Business", "wgt": 100}, {"uri": "dmoz/Business/Opportunities", "label": "dmoz/Business/Opportunities", "wgt": 100}, {"uri": "dmoz/Business/Opportunities/Opposing_Views", "label": "dmoz/Business/Opportunities/Opposing Views", "wgt": 100}, {"uri": "dmoz/Business/Marketing_and_Advertising/Relationship_Marketing", "label": "dmoz/Business/Marketing and Advertising/Relationship Marketing", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 52}], "image": "https://fortune.com/img-assets/wp-content/uploads/2024/08/53891054348_0234e71b3c_o-e1722845436669.jpg?resize=1200,600", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.2862745098039217, "wgt": 132, "relevance": 1}
{"uri": "8259821303", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "09:43:38", "dateTime": "2024-08-05T09:43:38Z", "dateTimePub": "2024-08-05T09:42:45Z", "dataType": "news", "sim": 0.5137255191802979, "url": "https://www.bizcommunity.com/article/5-reasons-why-creative-agencies-need-to-embrace-ai-now-149606a", "title": "5 reasons why creative agencies need to embrace AI now", "body": "This reluctance stems from a blend of apprehension and misconceptions, yet, paradoxically, the transformative potential of AI for creative endeavours has never been more critical.\n\nThe core of a creative agency's value lies in its ability to produce unique and imaginative content. The widespread fear is that AI, perceived as a tool of automation and standardisation, might erode the human touch that defines true creativity.\n\nThe concern is that reliance on algorithms could lead to homogenised outputs, devoid of the nuances that human creativity offers. But this doesn't necessarily have to be the case.\n\nAt the same time, the adoption of AI requires a substantial investment in time and resources. The technology is complex, and there is a steep learning curve involved in integrating AI systems into existing workflows.\n\nFor many agencies, this seems like a daunting challenge, especially when coupled with the fear of not achieving immediate returns on investment.\n\nHere are several compelling reasons why agencies should embrace AI now.\n\nThe industry is increasingly competitive, and early adopters of AI are already reaping the benefits.\n\nAgencies that delay embracing AI risk falling behind their competitors who leverage these technologies to deliver faster, more innovative, and data-driven solutions.\n\nThe integration of AI in creative agencies is not a threat but an opportunity to redefine the creative process and achieve new heights of innovation and efficiency.\n\nWhile the fears surrounding AI are understandable, they are largely rooted in misconceptions.\n\nBy adopting a strategic approach and embracing the transformative potential of AI, creative agencies can not only stay relevant but also lead the charge in the next wave of digital creativity.\n\nThe time to learn and adapt is now; those who do will undoubtedly shape the future of the industry.", "source": {"uri": "bizcommunity.com", "dataType": "news", "title": "Bizcommunity.com"}, "authors": [{"uri": "lindsey_schutters@bizcommunity.com", "name": "Lindsey Schutters", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Creativity", "type": "wiki", "score": 4, "label": {"eng": "Creativity"}}, {"uri": "http://en.wikipedia.org/wiki/Automation", "type": "wiki", "score": 3, "label": {"eng": "Automation"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 3, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Return_on_investment", "type": "wiki", "score": 2, "label": {"eng": "Return on investment"}}, {"uri": "http://en.wikipedia.org/wiki/Workflow", "type": "wiki", "score": 2, "label": {"eng": "Workflow"}}, {"uri": "http://en.wikipedia.org/wiki/Early_adopter", "type": "wiki", "score": 1, "label": {"eng": "Early adopter"}}, {"uri": "http://en.wikipedia.org/wiki/Leverage_(finance)", "type": "wiki", "score": 1, "label": {"eng": "Leverage (finance)"}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Health/Mental_Health/Self-Help", "label": "dmoz/Health/Mental Health/Self-Help", "wgt": 100}, {"uri": "dmoz/Society/Future/Transhumanism", "label": "dmoz/Society/Future/Transhumanism", "wgt": 100}, {"uri": "dmoz/Society/Work/Rethinking_Work", "label": "dmoz/Society/Work/Rethinking Work", "wgt": 100}, {"uri": "dmoz/Society/Activism/In_Daily_Life", "label": "dmoz/Society/Activism/In Daily Life", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 60}], "image": "https://biz-file.com/c/2408/746471-1200x624.jpg?5", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.223529411764706, "wgt": 131, "relevance": 1}
{"uri": "8260093265", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "12:34:23", "dateTime": "2024-08-05T12:34:23Z", "dateTimePub": "2024-08-05T12:33:07Z", "dataType": "news", "sim": 0.5137255191802979, "url": "https://www.pymnts.com/news/investment-tracker/2024/chinese-ai-startup-moonshot-reaches-3-billion-valuation/", "title": "Chinese AI Startup Moonshot Reaches $3 Billion Valuation", "body": "Chinese generative AI startup Moonshot has reportedly raised $300 million in a new funding round.\n\nThe round, which included participation by Tencent Holdings, lifted Moonshot's valuation to $3.3 billion, Bloomberg News reported Monday (Aug. 5), citing sources familiar with the matter.\n\nThe report notes that the investments mark a surge in new deals for Chinese artificial intelligence companies hoping to eventually create their country's answer to OpenAI's ChatGPT. Earlier this year, Tencent rival Alibaba led a record $1 billion funding round for Moonshot, while both companies more recently invested in AI firm Baichuan, which is valued at $2.8 billion.\n\nMeanwhile, China is leading the U.S. in the AI race, at least in some respects. A study by AI and analytics software company SAS and Coleman Parkes Research showed that 83% of Chinese respondents in a range of industries use generative AI, compared to just 65% of Americans and a global average of 54%.\n\nAnd a recent report by the United Nations' World Intellectual Property Organization showed that China is also ahead of the U.S. in generative AI patents, filing more than 38,000 patents between 2014 and 2023, compared to 6,276 filed by the United States in the same timeframe. As PYMNTS wrote last month, China's regulatory landscape has played a crucial role.\n\n\"China's approach to regulation has not surprisingly taken a China-first approach,\" Nicholas Rioux, CTO of Labviva, an AI procurement technology company for life sciences, told PYMNTS. \"Regulations are being implemented to ensure local market dominance within the Chinese market for local firms. This gives local companies, aligned with regulators, an unfair advantage over foreign and less aligned local competitors.\"\n\nMeanwhile, American tech giants' AI efforts have begun getting a largely negative reaction from Wall Street, with Amazon, Google and Microsoft all seeing their share prices drop in the wake of their most recent earnings report, Bloomberg reported last week.\n\nThat report argued these companies have failed to demonstrate that their AI infrastructure investments were translating into sales.\n\nOne exception: Meta, whose second-quarter revenue surpassed expectations, with CEO Mark Zuckerberg saying that the company's investment in AI has led to better ad targeting and content recommendations.\n\nZuckerberg also predicted that AI would one day generate personalized ads, letting advertisers specify business objectives and budgets, with Meta's AI doing the rest.\n\n\"Advertisers will basically just be able to tell us a business objective and a budget, and we're going to go do the rest for them,\" he said. \"We're going to get there incrementally over time, but I think this is going to be a very big deal.\"", "source": {"uri": "pymnts.com", "dataType": "news", "title": "PYMNTS.com"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Tencent", "type": "org", "score": 5, "label": {"eng": "Tencent"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/China", "type": "loc", "score": 5, "label": {"eng": "China"}, "location": {"type": "country", "label": {"eng": "China"}}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 3, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Bloomberg_News", "type": "org", "score": 3, "label": {"eng": "Bloomberg News"}}, {"uri": "http://en.wikipedia.org/wiki/Alibaba_Group", "type": "org", "score": 3, "label": {"eng": "Alibaba Group"}}, {"uri": "http://en.wikipedia.org/wiki/Valuation_(finance)", "type": "wiki", "score": 3, "label": {"eng": "Valuation (finance)"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Patent", "type": "wiki", "score": 3, "label": {"eng": "Patent"}}, {"uri": "http://en.wikipedia.org/wiki/Technology_company", "type": "wiki", "score": 2, "label": {"eng": "Technology company"}}, {"uri": "http://en.wikipedia.org/wiki/World_Intellectual_Property_Organization", "type": "wiki", "score": 2, "label": {"eng": "World Intellectual Property Organization"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_technology_officer", "type": "wiki", "score": 2, "label": {"eng": "Chief technology officer"}}, {"uri": "http://en.wikipedia.org/wiki/Analytics", "type": "wiki", "score": 2, "label": {"eng": "Analytics"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 2, "label": {"eng": "Software"}}, {"uri": "http://en.wikipedia.org/wiki/United_Nations", "type": "org", "score": 2, "label": {"eng": "United Nations"}}, {"uri": "http://en.wikipedia.org/wiki/United_States", "type": "loc", "score": 2, "label": {"eng": "United States"}, "location": {"type": "country", "label": {"eng": "United States"}}}, {"uri": "http://en.wikipedia.org/wiki/Meta_AI", "type": "wiki", "score": 1, "label": {"eng": "Meta AI"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 1, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_(company)", "type": "org", "score": 1, "label": {"eng": "Amazon (company)"}}, {"uri": "http://en.wikipedia.org/wiki/Wall_Street", "type": "wiki", "score": 1, "label": {"eng": "Wall Street"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 1, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Mark_Zuckerberg", "type": "person", "score": 1, "label": {"eng": "Mark Zuckerberg"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 1, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief executive officer"}}], "categories": [{"uri": "dmoz/Society/Issues/Business", "label": "dmoz/Society/Issues/Business", "wgt": 100}, {"uri": "dmoz/Business/Opportunities/Opposing_Views", "label": "dmoz/Business/Opportunities/Opposing Views", "wgt": 100}, {"uri": "dmoz/Business/Investing/Guides", "label": "dmoz/Business/Investing/Guides", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 94}], "image": "https://www.pymnts.com/wp-content/uploads/2024/03/China-vouchers-AI.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-08-05", "textStart": 237, "textEnd": 243}], "sentiment": 0.2784313725490195, "wgt": 131, "relevance": 1}
{"uri": "8259853046", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "10:04:09", "dateTime": "2024-08-05T10:04:09Z", "dateTimePub": "2024-08-05T10:03:17Z", "dataType": "news", "sim": 0.5098039507865906, "url": "https://www.forbes.com/sites/forbestechcouncil/2024/08/05/practical-steps-to-overcome-the-fear-of-ai-replacement/", "title": "Council Post: Practical Steps To Overcome The Fear Of AI Replacement", "body": "AI is poised to replace some jobs, change most and create entirely new ones. While one can be optimistic about the collective long-term outcomes, the reality is that periods of change always produce winners and losers. The pressing question is: Do we have a say in which category we fall into? Can we influence how this change affects us, or are big tech companies solely dictating our future?\n\nTo understand our current situation, let's look back at a similar period of technological upheaval: the Industrial Revolution and the Luddite movement.\n\nThe Luddites, skilled textile workers in 19th-century England, protested against the introduction of machinery that threatened their livelihoods. They famously destroyed textile machines in what is now seen as a futile attempt to stop technological progress.\n\nOne could say they were trying to weave their own destiny but ended up spinning their wheels instead. Let's face it -- being a Luddite about AI might be about as effective as trying to stop a computer virus with chicken soup!\n\nHowever, history shows us that the Luddites' fears weren't unfounded. Many did lose their jobs and their lives changed dramatically. Textile workers in 19th-century England had specialized, in-demand skill sets that gave them considerable power. They even famously celebrated \"St. Monday,\" taking Mondays off to recover from weekend revelries -- a luxury unimaginable to many workers today.\n\nFast forward to today and we're experiencing our own technological revolution. The closest parallel to the Luddites' \"St. Mondays\" is perhaps the flexibility introduced by the Covid-19 pandemic, which many of us now appreciate: flexible work locations and hours and a greater recognition of individual skills and contributions.\n\nHowever, we can't take these benefits for granted. Destroying nascent AI agents is not a viable solution, so I believe the answer lies in actively participating in creating the new AI reality. The World Economic Forum predicts that \"by 2025, 85 million jobs may be displaced by a shift in the division of labour between humans and machines, while 97 million new roles may emerge.\" Employees can have a say in what gets created and what types of lives we all lead in the new AI world.\n\nThe danger of not engaging with AI today is arguably higher than the danger of engaging with it. It's the difference between being able to steer your own ship versus hoping for a seat in the lifeboat.\n\nNavigating change requires a solid foundation. To gain control over your career path in the age of AI, start by identifying your strengths. Reflect on what you excel at, your accomplishments and the unique contributions others recognize in you. Consider your natural talents and what comes effortlessly to you.\n\nIt's now more important than ever to understand your uniquely human skills. There are a few psychometric assessments that can further help with this. StrengthsFinder and DiSC are great for identifying your strengths and unique traits, while the ISPI assessment helps you understand how you react to change. Assessments such as my company's Job Impact Analysis can help determine which of your technical skills are least impacted by AI. Spend some time understanding yourself better to create a strong anchor in this evolving landscape.\n\nHave AI work for you. This strategy is often overlooked but is perhaps one of the easiest and most practical approaches.\n\nFirst, identify AI tools that can augment your existing skills. For example, if you're a graphic designer, explore AI-powered design software like Adobe Sensei that can automate repetitive tasks and generate creative ideas. If you're a developer, consider automated AI-driven analytics tools like Auto-PyTorch or Auto-Sklearn to find the most appropriate AI pipeline to gain deeper insights into data and enhance your coding efficiency.\n\nHow can these tools make you better at what you already do well? By leveraging AI tools to enhance your current strengths, you can start your AI transition from a position of confidence and competence.\n\nSelect a few and start experimenting with them. One activity that used to take my team and me a long time was updating our website, involving tedious cycles of wording changes and updates in Figma. We discovered several tools that could streamline this process, but many were behind a paywall. We allocated a small $30 budget to test a few solutions. By dedicating a few hours for a couple of weeks to explore and integrate these tools, we found the most effective solution for our needs. This experience taught us the value of investing time in learning and playing with new tools to enhance our efficiency.\n\nThe AI revolution doesn't have to be something that merely happens to us. Unlike the Luddites, who fought against the tide of change, we have the opportunity to ride the wave of AI innovation. By understanding AI's impact on our specific roles and proactively integrating AI tools into our work, we can shape our own futures.\n\nForbes Technology Council is an invitation-only community for world-class CIOs, CTOs and technology executives. Do I qualify?", "source": {"uri": "forbes.com", "dataType": "news", "title": "Forbes"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Luddite", "type": "wiki", "score": 5, "label": {"eng": "Luddite"}}, {"uri": "http://en.wikipedia.org/wiki/Textile", "type": "wiki", "score": 5, "label": {"eng": "Textile"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/England", "type": "loc", "score": 4, "label": {"eng": "England"}, "location": {"type": "place", "label": {"eng": "England"}, "country": {"type": "country", "label": {"eng": "United Kingdom"}}}}, {"uri": "http://en.wikipedia.org/wiki/Big_Tech", "type": "wiki", "score": 3, "label": {"eng": "Big Tech"}}, {"uri": "http://en.wikipedia.org/wiki/History_of_technology", "type": "wiki", "score": 3, "label": {"eng": "History of technology"}}, {"uri": "http://en.wikipedia.org/wiki/Industrial_Revolution", "type": "wiki", "score": 3, "label": {"eng": "Industrial Revolution"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_virus", "type": "wiki", "score": 3, "label": {"eng": "Computer virus"}}, {"uri": "http://en.wikipedia.org/wiki/Spinning_(textiles)", "type": "wiki", "score": 3, "label": {"eng": "Spinning (textiles)"}}, {"uri": "http://en.wikipedia.org/wiki/Chicken", "type": "wiki", "score": 3, "label": {"eng": "Chicken"}}, {"uri": "http://en.wikipedia.org/wiki/Coronavirus", "type": "wiki", "score": 2, "label": {"eng": "Coronavirus"}}, {"uri": "http://en.wikipedia.org/wiki/Division_of_labour", "type": "wiki", "score": 2, "label": {"eng": "Division of labour"}}, {"uri": "http://en.wikipedia.org/wiki/World_Economic_Forum", "type": "wiki", "score": 2, "label": {"eng": "World Economic Forum"}}, {"uri": "http://en.wikipedia.org/wiki/Figma_(software)", "type": "wiki", "score": 1, "label": {"eng": "Figma (software)"}}, {"uri": "http://en.wikipedia.org/wiki/Adobe_Inc.", "type": "org", "score": 1, "label": {"eng": "Adobe Inc."}}, {"uri": "http://en.wikipedia.org/wiki/Psychometrics", "type": "wiki", "score": 1, "label": {"eng": "Psychometrics"}}, {"uri": "http://en.wikipedia.org/wiki/Paywall", "type": "wiki", "score": 1, "label": {"eng": "Paywall"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_information_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief information officer"}}, {"uri": "http://en.wikipedia.org/wiki/Pipeline_transport", "type": "wiki", "score": 1, "label": {"eng": "Pipeline transport"}}, {"uri": "http://en.wikipedia.org/wiki/Analytics", "type": "wiki", "score": 1, "label": {"eng": "Analytics"}}, {"uri": "http://en.wikipedia.org/wiki/Forbes", "type": "org", "score": 1, "label": {"eng": "Forbes"}}, {"uri": "http://en.wikipedia.org/wiki/Graphic_design", "type": "wiki", "score": 1, "label": {"eng": "Graphic design"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 1, "label": {"eng": "Software"}}], "categories": [{"uri": "dmoz/Society/Relationships", "label": "dmoz/Society/Relationships", "wgt": 100}, {"uri": "dmoz/Recreation/Humor/Useless_Pages", "label": "dmoz/Recreation/Humor/Useless Pages", "wgt": 100}, {"uri": "dmoz/Health/Mental_Health/Self-Help", "label": "dmoz/Health/Mental Health/Self-Help", "wgt": 100}, {"uri": "dmoz/Society/Advice", "label": "dmoz/Society/Advice", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 70}], "image": "https://imageio.forbes.com/specials-images/imageserve/65e76b7effb157a20411c827/0x0.jpg?format=jpg&height=600&width=1200&fit=bounds", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": -0.04313725490196074, "wgt": 130, "relevance": 1}
{"uri": "8259782334", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "09:18:01", "dateTime": "2024-08-05T09:18:01Z", "dateTimePub": "2024-08-05T09:17:10Z", "dataType": "news", "sim": 0.5098039507865906, "url": "https://www.technologyreview.com/2024/08/05/1095600/we-need-to-prepare-for-addictive-intelligence/", "title": "We need to prepare for 'addictive intelligence'", "body": "However, we foresee a different, but no less urgent, class of risks: those stemming from relationships with nonhuman agents. AI companionship is no longer theoretical -- our analysis of a million ChatGPT interaction logs reveals that the second most popular use of AI is sexual role-playing. We are already starting to invite AIs into our lives as friends, lovers, mentors, therapists, and teachers.\n\nWill it be easier to retreat to a replicant of a deceased partner than to navigate the confusing and painful realities of human relationships? Indeed, the AI companionship provider Replika was born from an attempt to resurrect a deceased best friend and now provides companions to millions of users. Even the CTO of OpenAI warns that AI has the potential to be \"extremely addictive.\"\n\nWe're seeing a giant, real-world experiment unfold, uncertain what impact these AI companions will have either on us individually or on society as a whole. Will Grandma spend her final neglected days chatting with her grandson's digital double, while her real grandson is mentored by an edgy simulated elder? AI wields the collective charm of all human history and culture with infinite seductive mimicry. These systems are simultaneously superior and submissive, with a new form of allure that may make consent to these interactions illusory. In the face of this power imbalance, can we meaningfully consent to engaging in an AI relationship, especially when for many the alternative is nothing at all?\n\nAs AI researchers working closely with policymakers, we are struck by the lack of interest lawmakers have shown in the harms arising from this future. We are still unprepared to respond to these risks because we do not fully understand them. What's needed is a new scientific inquiry at the intersection of technology, psychology, and law -- and perhaps new approaches to AI regulation.\n\nAs addictive as platforms powered by recommender systems may seem today, TikTok and its rivals are still bottlenecked by human content. While alarms have been raised in the past about \"addiction\" to novels, television, internet, smartphones, and social media, all these forms of media are similarly limited by human capacity. Generative AI is different. It can endlessly generate realistic content on the fly, optimized to suit the precise preferences of whoever it's interacting with.\n\nThe allure of AI lies in its ability to identify our desires and serve them up to us whenever and however we wish. AI has no preferences or personality of its own, instead reflecting whatever users believe it to be -- a phenomenon known by researchers as \"sycophancy.\" Our research has shown that those who perceive or desire an AI to have caring motives will use language that elicits precisely this behavior. This creates an echo chamber of affection that threatens to be extremely addictive. Why engage in the give and take of being with another person when we can simply take? Repeated interactions with sycophantic companions may ultimately atrophy the part of us capable of engaging fully with other humans who have real desires and dreams of their own, leading to what we might call \"digital attachment disorder.\"\n\nAddressing the harm that AI companions could pose requires a thorough understanding of the economic and psychological incentives pushing forward their development. Until we appreciate these drivers of AI addiction, it will remain impossible for us to create effective policies.\n\nIt is no accident that internet platforms are addictive -- deliberate design choices, known as \"dark patterns,\" are made to maximize user engagement. We expect similar incentives to ultimately create AI companions that provide hedonism as a service. This raises two separate questions related to AI. What design choices will be used to make AI companions engaging and ultimately addictive? And how will these addictive companions affect the people who use them?\n\nInterdisciplinary study that builds on research into dark patterns in social media is needed to understand this psychological dimension of AI. For example, our research already shows that people are more likely to engage with AIs emulating people they admire, even if they know the avatar to be fake.", "source": {"uri": "technologyreview.com", "dataType": "news", "title": "MIT Technology Review"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 3, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_technology_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief technology officer"}}, {"uri": "http://en.wikipedia.org/wiki/Role-playing", "type": "wiki", "score": 3, "label": {"eng": "Role-playing"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/TikTok", "type": "wiki", "score": 2, "label": {"eng": "TikTok"}}, {"uri": "http://en.wikipedia.org/wiki/Recommender_system", "type": "wiki", "score": 2, "label": {"eng": "Recommender system"}}, {"uri": "http://en.wikipedia.org/wiki/Sycophancy", "type": "wiki", "score": 2, "label": {"eng": "Sycophancy"}}, {"uri": "http://en.wikipedia.org/wiki/Mimicry", "type": "wiki", "score": 2, "label": {"eng": "Mimicry"}}, {"uri": "http://en.wikipedia.org/wiki/Dominance_and_submission", "type": "wiki", "score": 2, "label": {"eng": "Dominance and submission"}}, {"uri": "http://en.wikipedia.org/wiki/Addiction", "type": "wiki", "score": 2, "label": {"eng": "Addiction"}}, {"uri": "http://en.wikipedia.org/wiki/Scientific_method", "type": "wiki", "score": 2, "label": {"eng": "Scientific method"}}, {"uri": "http://en.wikipedia.org/wiki/Psychology", "type": "wiki", "score": 2, "label": {"eng": "Psychology"}}, {"uri": "http://en.wikipedia.org/wiki/Internet", "type": "wiki", "score": 2, "label": {"eng": "Internet"}}, {"uri": "http://en.wikipedia.org/wiki/Smartphone", "type": "wiki", "score": 2, "label": {"eng": "Smartphone"}}, {"uri": "http://en.wikipedia.org/wiki/Echo_chamber_(media)", "type": "wiki", "score": 1, "label": {"eng": "Echo chamber (media)"}}, {"uri": "http://en.wikipedia.org/wiki/Customer_engagement", "type": "wiki", "score": 1, "label": {"eng": "Customer engagement"}}, {"uri": "http://en.wikipedia.org/wiki/Avatar_(computing)", "type": "wiki", "score": 1, "label": {"eng": "Avatar (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/Hedonism", "type": "wiki", "score": 1, "label": {"eng": "Hedonism"}}], "categories": [{"uri": "dmoz/Society/Relationships", "label": "dmoz/Society/Relationships", "wgt": 100}, {"uri": "dmoz/Health/Mental_Health/Self-Help", "label": "dmoz/Health/Mental Health/Self-Help", "wgt": 100}, {"uri": "dmoz/Society/Advice", "label": "dmoz/Society/Advice", "wgt": 100}, {"uri": "dmoz/Society/Future/Transhumanism", "label": "dmoz/Society/Future/Transhumanism", "wgt": 100}, {"uri": "dmoz/Society/Disabled/Lifestyle", "label": "dmoz/Society/Disabled/Lifestyle", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 55}], "image": "https://wp.technologyreview.com/wp-content/uploads/2024/08/MIT-Tech-Review001-up.jpg?resize=1200,600", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.1137254901960785, "wgt": 130, "relevance": 1}
{"uri": "8259316050", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "02:33:47", "dateTime": "2024-08-05T02:33:47Z", "dateTimePub": "2024-08-05T02:32:46Z", "dataType": "news", "sim": 0.5058823823928833, "url": "https://www.thestar.com.my/tech/tech-news/2024/08/05/the-fuss-about-ai", "title": "The fuss about AI", "body": "The explosion of artificial intelligence in the years following the launch of ChatGPT has not been free of controversy. -- The Star\n\nWith the jury still out on whether artificial intelligence (AI) has been a net positive or loss for humanity, there's been a host of debates surrounding the technology alongside its rapid development and adoption.\n\nIn the EU, for instance, companies are running into regulatory roadblocks over their non-compliance with data privacy regulations in the region.\n\nMeta announced back in June that it would be incorporating European users' social media posts into its AI training data for the Llama AI model. With Llama being a multimodal AI, this would include everything from text and images to video and audio.\n\nSoon after, the Irish Data Protection Commission (DPC) requested that the social media giant refrain from utilising the region's social media content to train large language models, prompting Meta to delay its AI launch in the EU to the joy of other European regulators.\n\nUsers in the UK and EU have the \"right to object\", which would effectively opt them out from having their data used by Meta in training its AI model. However, the process has been described as tedious and awkward.\n\nMeanwhile, those in other regions without data protection regulations as stringent as the GDPR do not have this option, according to a report from online tech publication Mashable.\n\nX (formerly Twitter) made a similar move to utilise user posts in training its Grok AI model at the end of July, prompting the DPC and the UK's Information Commissioner's Office to question the platform over the data harvesting.\n\nThe Elon Musk-owned platform had users opt-in by default to allow for AI training on their data, which goes against the UK's General Data Protection Regulations (GDPR) according to a report from The Guardian.\n\nUnder UK's GDPR, companies are not allowed to implement consent by default, which is the case in X's settings page.\n\nMired in controversy\n\nReports over the contents of training data fed into AI models have also been extensive, covering allegations of stolen and illicit content.\n\nBack in December last year, researchers from the Stanford Internet Observatory found that the Laion-5B dataset contained 1,679 illegal images consisting of child sexual abuse material (CSAM) scraped from social media posts and popular adult websites.This dataset was used to train the popular AI image generator Stable Diffusion.\n\nFurther discussion over the datasets in AI training involves where the content is sourced from. Nonprofit EleutherAI compiled a massive dataset named \"The Pile\" which was reported in July to contain the captions of over 170,000 YouTube videos.\n\nThese captions were taken without permission and allegedly used by major companies like Anthropic, Nvidia, and Salesforce.\n\nInitial reports had listed Apple as having used this stolen data in AI training, but the company has since refuted such claims.\n\nContent from influencers such as MrBeast, PewDiePie, Marques Brownlee and Jacksepticeye were included in the dataset, alongside various talk shows and news outlets such as The Wall Street Journal, NPR, and the BBC.\n\nBrownlee's videos were also allegedly subject to further use as training data for an AI video generation tool developed by Runway without consent, according to reports in late July. Reports say that 1,709 videos of his videos were used for AI training.\n\nClaims of outright copyright violation have also been the subject of legal battles in the AI space, with a coalition of music companies including Universal Music Group, Sony Music, and Warner Records alleging that AI music generation companies Udio and Suno infringed on their copyright.\n\nThe lawsuit claims that the AI firms trained their music-generation models using copyrighted materials owned by the music labels, seeking US$150,000 (RM674,805) in damages per song used in training.\n\nA similar lawsuit was also launched by The New York Times in the case of journalistic content against ChatGPT-maker OpenAI (and its owner Microsoft) last December and is currently ongoing.\n\nClaims from The New York Times allege that copyrighted content from the American newspaper had been unlawfully used in developing artificial intelligence products that \"threatens the Times' ability to provide that service\".\n\nBoth OpenAI and Microsoft have shot back that its products do not serve as a substitute for the reporting offered by the publication, requesting courts to dismiss the lawsuit.\n\nOther news providers such as the Associated Press, Axel Springer, FT Group, News Corp, and Vox Media have reached licensing deals with OpenAI, allowing their content to be used in the training of the company's large language models (LLMs).\n\nMore direct claims of plagiarism came from magazines Forbes and Wired in June, with accusations that AI search and chatbot startup Perplexity had been scraping content from the magazines' respective websites.\n\nForbes claimed that Perplexity had utilised AI to generate an article, podcast, and YouTube video based on a story that the publication put up on its website. This was done without permission from and attributing credit to Forbes for the original report.\n\nThe publication further alleged to have found other plagiarised stories republished by Perplexity with uncited information sourced from Bloomberg and CNBC.\n\nWired on the other hand claimed that Perplexity had been ignoring \"robots.txt\", a file used in the Robots Exclusion Protocol intended to disallow web scrapers and crawlers, which the AI company said it honoured.\n\nIn a report, the tech magazine claims that it monitored network traffic to its website and linked it to bots associated with Perplexity, following a prompt about an article published on its site.\n\nIt further drew a comparison to OpenAI's ChatGPT and Anthropic's Claude, which offered a hypothesis about the story in question, but explicitly stated that they did not have access to it.\n\nOn July 30, the startup reached an agreement with several outlets including the Times, Fortune, and Wordpress on a revenue-sharing programme that would pay the publications for articles cited in AI-generated responses.", "source": {"uri": "thestar.com.my", "dataType": "news", "title": "The Star "}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 5, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/General_Data_Protection_Regulation", "type": "wiki", "score": 5, "label": {"eng": "General Data Protection Regulation"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/European_Union", "type": "loc", "score": 5, "label": {"eng": "European Union"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Social_media", "type": "wiki", "score": 5, "label": {"eng": "Social media"}}, {"uri": "http://en.wikipedia.org/wiki/Information_privacy", "type": "wiki", "score": 4, "label": {"eng": "Information privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 3, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Information_Commissioner's_Office", "type": "wiki", "score": 3, "label": {"eng": "Information Commissioner's Office"}}, {"uri": "http://en.wikipedia.org/wiki/Mashable", "type": "wiki", "score": 3, "label": {"eng": "Mashable"}}, {"uri": "http://en.wikipedia.org/wiki/Child_pornography", "type": "wiki", "score": 3, "label": {"eng": "Child pornography"}}, {"uri": "http://en.wikipedia.org/wiki/Twitter", "type": "org", "score": 3, "label": {"eng": "Twitter"}}, {"uri": "http://en.wikipedia.org/wiki/United_Kingdom", "type": "loc", "score": 3, "label": {"eng": "United Kingdom"}, "location": {"type": "country", "label": {"eng": "United Kingdom"}}}, {"uri": "http://en.wikipedia.org/wiki/EleutherAI", "type": "wiki", "score": 2, "label": {"eng": "EleutherAI"}}, {"uri": "http://en.wikipedia.org/wiki/Stable_Diffusion", "type": "wiki", "score": 2, "label": {"eng": "Stable Diffusion"}}, {"uri": "http://en.wikipedia.org/wiki/Salesforce", "type": "wiki", "score": 2, "label": {"eng": "Salesforce"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 2, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/World_Trade_Center_site", "type": "wiki", "score": 2, "label": {"eng": "World Trade Center site"}}, {"uri": "http://en.wikipedia.org/wiki/Internet_celebrity", "type": "wiki", "score": 2, "label": {"eng": "Internet celebrity"}}, {"uri": "http://en.wikipedia.org/wiki/Nvidia", "type": "org", "score": 2, "label": {"eng": "Nvidia"}}, {"uri": "http://en.wikipedia.org/wiki/NPR", "type": "org", "score": 2, "label": {"eng": "NPR"}}, {"uri": "http://en.wikipedia.org/wiki/The_Wall_Street_Journal", "type": "wiki", "score": 2, "label": {"eng": "The Wall Street Journal"}}, {"uri": "http://en.wikipedia.org/wiki/Nonprofit_organization", "type": "wiki", "score": 2, "label": {"eng": "Nonprofit organization"}}, {"uri": "http://en.wikipedia.org/wiki/Stanford_University", "type": "org", "score": 2, "label": {"eng": "Stanford University"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 2, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/The_New_York_Times", "type": "wiki", "score": 2, "label": {"eng": "The New York Times"}}, {"uri": "http://en.wikipedia.org/wiki/Lawsuit", "type": "wiki", "score": 2, "label": {"eng": "Lawsuit"}}, {"uri": "http://en.wikipedia.org/wiki/Apple_Inc.", "type": "org", "score": 2, "label": {"eng": "Apple Inc."}}, {"uri": "http://en.wikipedia.org/wiki/The_Guardian", "type": "wiki", "score": 2, "label": {"eng": "The Guardian"}}, {"uri": "http://en.wikipedia.org/wiki/BBC", "type": "org", "score": 2, "label": {"eng": "BBC"}}, {"uri": "http://en.wikipedia.org/wiki/Warner_Records", "type": "org", "score": 1, "label": {"eng": "Warner Records"}}, {"uri": "http://en.wikipedia.org/wiki/Sony_Music", "type": "org", "score": 1, "label": {"eng": "Sony Music"}}, {"uri": "http://en.wikipedia.org/wiki/Axel_Springer_SE", "type": "org", "score": 1, "label": {"eng": "Axel Springer SE"}}, {"uri": "http://en.wikipedia.org/wiki/Universal_Music_Group", "type": "org", "score": 1, "label": {"eng": "Universal Music Group"}}, {"uri": "http://en.wikipedia.org/wiki/Forbes", "type": "org", "score": 1, "label": {"eng": "Forbes"}}, {"uri": "http://en.wikipedia.org/wiki/Bloomberg_L.P.", "type": "org", "score": 1, "label": {"eng": "Bloomberg L.P."}}, {"uri": "http://en.wikipedia.org/wiki/CNBC", "type": "org", "score": 1, "label": {"eng": "CNBC"}}, {"uri": "http://en.wikipedia.org/wiki/Associated_Press", "type": "org", "score": 1, "label": {"eng": "Associated Press"}}, {"uri": "http://en.wikipedia.org/wiki/United_States", "type": "loc", "score": 1, "label": {"eng": "United States"}, "location": {"type": "country", "label": {"eng": "United States"}}}], "categories": [{"uri": "dmoz/Society/Issues/Business", "label": "dmoz/Society/Issues/Business", "wgt": 100}, {"uri": "dmoz/Society/Activism/Media", "label": "dmoz/Society/Activism/Media", "wgt": 100}, {"uri": "dmoz/Society/Issues/Intellectual_Property", "label": "dmoz/Society/Issues/Intellectual Property", "wgt": 100}, {"uri": "dmoz/Computers/Internet/Abuse", "label": "dmoz/Computers/Internet/Abuse", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 92}], "image": "https://apicms.thestar.com.my/uploads/images/2024/08/05/2840696.jpeg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-07-30", "textStart": 5979, "textEnd": 5986}], "sentiment": 0.1372549019607843, "wgt": 129, "relevance": 1}
{"uri": "8260016284", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "11:45:32", "dateTime": "2024-08-05T11:45:32Z", "dateTimePub": "2024-08-05T11:44:46Z", "dataType": "news", "sim": 0.5058823823928833, "url": "https://www.lexology.com/library/detail.aspx?g=8bfb6031-e65b-4bdf-b485-18cdf4455796", "title": "Top Competition Enforcers in the US, EU, and UK Release Joint Statement on AI Competition - AI: The Washington Report", "body": "The statement is silent on specific enforcement actions, but the release of the statement suggests potential future activity and increased scrutiny of AI competition by the enforcers.\n\nOn July 23, the top competition enforcers at the US Federal Trade Commission (FTC) and Department of Justice (DOJ), the UK Competition and Markets Authority (CMA), and the European Commission (EC) released a Joint Statement on Competition in Generative AI Foundation Models and AI products. The statement outlines risks in the AI ecosystem and shared principles for protecting and fostering competition.\n\nWhile the statement does not lay out specific enforcement actions, the statement's release suggests that the top competition enforcers in all three jurisdictions are focusing on AI's effects on competition in general and competition within the AI ecosystem -- and are likely to take concrete action in the near future.\n\nA Shared Focus on AI\n\nThe competition enforcers did not just discover AI. In recent years, the top competition enforcers in the US, UK, and EU have all been examining both the effects AI may have on competition in various sectors as well as competition within the AI ecosystem. In September 2023, the CMA released a report on AI Foundation Models, which described the \"significant impact\" that AI technologies may have on competition and consumers, followed by an updated April 2024 report on AI. In June 2024, French competition authorities released a report on Generative AI, which focused on competition issues related to AI. At its January 2024 Tech Summit, the FTC examined the \"real-world impacts of AI on consumers and competition.\"\n\nAI as a Technological Inflection Point\n\nIn the new joint statement, the top enforcers described the recent evolution of AI technologies, including foundational models and generative AI, as \"a technological inflection point.\" As \"one of the most significant technological developments of the past couple decades,\" AI has the potential to increase innovation and economic growth and benefit the lives of citizens around the world.\n\nBut with any technological inflection point, which may create \"new means of competing\" and catalyze innovation and growth, the enforcers must act \"to ensure the public reaps the full benefits\" of the AI evolution. The enforcers are concerned that several risks, described below, could undermine competition in the AI ecosystem. According to the enforcers, they are \"committed to using our available powers to address any such risks before they become entrenched or irreversible harms.\"\n\nRisks to Competition in the AI Ecosystem\n\nThe top enforcers highlight three main risks to competition in the AI ecosystem.\n\nBeyond these three main risks, the statement also acknowledges that other competition and consumer risks are also associated with AI. Algorithms may \"allow competitors to share competitively sensitive information\" and engage in price discrimination and fixing. Consumers may be harmed, too, by AI. As the CMA, DOJ, and the FTC have consumer protection authority, these authorities will \"also be vigilant of any consumer protection threats that may derive from the use and application of AI.\"\n\nSovereign Jurisdictions but Shared Concerns\n\nWhile the enforcers share areas of concern, the joint statement recognizes that the EU, UK, and US's \"legal powers and jurisdictions contexts differ, and ultimately, our decisions will always remain sovereign and independent.\" Nonetheless, the competition enforcers assert that \"if the risks described [in the statement] materialize, they will likely do so in a way that does not respect international boundaries,\" making it necessary for the different jurisdictions to \"share an understanding of the issues\" and be \"committed to using our respective powers where appropriate.\"\n\nThree Unifying Principles\n\nWith the goal of acting together, the enforcers outline three shared principles that will \"serve to enable competition and foster innovation.\"\n\nConclusion: Potential Future Activity\n\nWhile the statement does not address specific enforcement tools and actions the enforcers may take, the statement's release suggests that the enforcers may all be gearing up to take action related to AI competition in the near future. Interested stakeholders, especially international ones, should closely track potential activity from these enforcers. We will continue to closely monitor and analyze activity by the DOJ and FTC on AI competition issues.", "source": {"uri": "lexology.com", "dataType": "news", "title": "Lexology"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Federal_Trade_Commission", "type": "wiki", "score": 5, "label": {"eng": "Federal Trade Commission"}}, {"uri": "http://en.wikipedia.org/wiki/Ecosystem", "type": "wiki", "score": 5, "label": {"eng": "Ecosystem"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Inflection", "type": "wiki", "score": 4, "label": {"eng": "Inflection"}}, {"uri": "http://en.wikipedia.org/wiki/United_Kingdom", "type": "loc", "score": 4, "label": {"eng": "United Kingdom"}, "location": {"type": "country", "label": {"eng": "United Kingdom"}}}, {"uri": "http://en.wikipedia.org/wiki/Competition_and_Markets_Authority", "type": "wiki", "score": 3, "label": {"eng": "Competition and Markets Authority"}}, {"uri": "http://en.wikipedia.org/wiki/Jurisdiction", "type": "wiki", "score": 3, "label": {"eng": "Jurisdiction"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Justice", "type": "wiki", "score": 3, "label": {"eng": "United States Department of Justice"}}, {"uri": "http://en.wikipedia.org/wiki/Evolution", "type": "wiki", "score": 3, "label": {"eng": "Evolution"}}, {"uri": "http://en.wikipedia.org/wiki/European_Commission", "type": "org", "score": 3, "label": {"eng": "European Commission"}}, {"uri": "http://en.wikipedia.org/wiki/European_Union", "type": "loc", "score": 3, "label": {"eng": "European Union"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/AI_Foundation", "type": "wiki", "score": 2, "label": {"eng": "AI Foundation"}}, {"uri": "http://en.wikipedia.org/wiki/French_language", "type": "wiki", "score": 2, "label": {"eng": "French language"}}, {"uri": "http://en.wikipedia.org/wiki/Consumer_protection", "type": "wiki", "score": 2, "label": {"eng": "Consumer protection"}}, {"uri": "http://en.wikipedia.org/wiki/Economic_growth", "type": "wiki", "score": 2, "label": {"eng": "Economic growth"}}, {"uri": "http://en.wikipedia.org/wiki/Outline_(list)", "type": "wiki", "score": 1, "label": {"eng": "Outline (list)"}}, {"uri": "http://en.wikipedia.org/wiki/Independent_politician", "type": "org", "score": 1, "label": {"eng": "Independent politician"}}, {"uri": "http://en.wikipedia.org/wiki/Price_discrimination", "type": "wiki", "score": 1, "label": {"eng": "Price discrimination"}}, {"uri": "http://en.wikipedia.org/wiki/Monarchy_of_the_United_Kingdom", "type": "wiki", "score": 1, "label": {"eng": "Monarchy of the United Kingdom"}}, {"uri": "http://en.wikipedia.org/wiki/Stakeholder_(corporate)", "type": "wiki", "score": 1, "label": {"eng": "Stakeholder (corporate)"}}, {"uri": "http://en.wikipedia.org/wiki/Sovereignty", "type": "wiki", "score": 1, "label": {"eng": "Sovereignty"}}], "categories": [{"uri": "dmoz/Society/Issues", "label": "dmoz/Society/Issues", "wgt": 100}, {"uri": "dmoz/Business/Opportunities/Opposing_Views", "label": "dmoz/Business/Opportunities/Opposing Views", "wgt": 100}, {"uri": "dmoz/Home/Personal_Finance/Philanthropy", "label": "dmoz/Home/Personal Finance/Philanthropy", "wgt": 100}, {"uri": "dmoz/Society/Activism/In_Daily_Life", "label": "dmoz/Society/Activism/In Daily Life", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 54}], "image": "https://www.lexology.com/images/share/lexology-social-media.png", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-07-23", "textStart": 188, "textEnd": 195}], "sentiment": 0.3411764705882352, "wgt": 129, "relevance": 1}
{"uri": "8259982690", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "11:24:42", "dateTime": "2024-08-05T11:24:42Z", "dateTimePub": "2024-08-05T11:23:21Z", "dataType": "news", "sim": 0.5058823823928833, "url": "https://www.forbes.com/sites/forbesbusinesscouncil/2024/08/05/industry-40-plenty-of-data-yet-still-not-enough-ai/", "title": "Council Post: Industry 4.0: Plenty Of Data, Yet Still Not Enough AI", "body": "Massimiliano Melis is the COO of AITEM, a company specialized in AI development and owner of LAIKA, the first veterinarian copilot.\n\nIn the past five years, several hundreds of millions have been invested by companies to introduce Industry 4.0 equipment, with a market size reaching roughly $140 billion.\n\nHowever, as reported by a McKinsey study, \"a large majority remain stuck in pilot purgatory, struggling to capture the full potential of their transformation efforts or deliver a satisfactory return on investment.\"\n\nWhile the introduction of machines capable of collecting vast amounts of data is a remarkable step ahead, the missing exploitation of data potential is, on the one hand, a loss so far. But on the other hand, it's a great opportunity for companies developing AI now, as they can leverage machine learning (ML), large language models (LLMs) and other techniques to develop new use cases to bring advancement to the industry.\n\nOne key obstacle to overcome is the \"we've always done it like this\" approach, typical of the industry, especially in manufacturing. In this industry, any change should be carefully evaluated to avoid production disruption. Anyhow, AI implementation can be done gradually, at first demonstrating the potential benefits and then making the leap, unleashing its full potential.\n\nIt's estimated that around 2.5 quintillion bytes worth of data are generated around the world every day. Based on my own experience in the field, I estimate 1.5 exabytes are generated by industry. This impressive volume of data clearly represents huge industry investments.\n\nUnfortunately, however, few companies are really unleashing the potential of their data, and a ring of the chain is missing. That is how to leverage data to improve efficiency, accuracy and productivity.\n\nThe majority of data application today is in quality controls, predictive maintenance and process optimization. While large corporations are pushing for the adoption of AI with Industry 4.0 machines, I estimate based on different research I've gathered that only 30% of SMEs are doing the same.\n\nThe motivation may vary. In my own discussions with business leaders and owners, the feedback I hear is that SMEs don't have a company function dedicated to AI. Sometimes owners think it may be too expensive. Other times, while high-level knowledge is available, a practical example for its implementation is missing.\n\nSo, let's try to depict what might be some practical use cases.\n\n* Quality Controls: In today's fiercely competitive global marketplace, quality control goes beyond being a mere compliance requirement for manufacturing companies. It has become a cornerstone of success, a catalyst for substantial cost savings and a driver of customer satisfaction.\n\nA robust QC process can prevent costly product recalls, reduce warranty claims and skyrocket customer satisfaction. It directly impacts your brand reputation, operational efficiency and bottom-line performance.\n\nBut this is where the situation shifts: AI. The integration of AI into quality control processes is revolutionizing the manufacturing sector, taking it to unimaginable heights of efficiency and effectiveness.\n\nI've seen a real example of this in the casting machine industry. A quality control system that used AI to analyze images of the castings and live data from the manufacturing execution system was implemented; AI identified defects that would have taken human inspectors hours to find. The result? Valuable time saved, improved product quality and significant cost savings of $250,000 a year.\n\n* Assembly Robot Controls: A case study from General Motors highlights the use of AI in the assembly line where one minute that the assembly line stops can cost GM around $20,000. GM implemented a system that, by means of cameras, is capable of monitoring 7,000 robots in real time, avoiding expensive stops.\n\n* AI-Based Nesting: The textile industry is still subjected to several manual steps. Nesting is one of the operations that many companies still perform manually. Nesting in the textile industry refers to the process of arranging patterns on fabric in the most efficient manner to minimize waste. This technique is crucial for optimizing material usage, reducing costs, ensuring quality and improving production efficiency.\n\nThis manual operation for a piece of leather, for instance, lasts 32 minutes on average. With AI, it can be done efficiently in 10 seconds, resulting in a terrific cost improvement for the manufacturer.\n\nWe've identified some real use cases. So how can companies actually get started? Here is a short list that, of course, may vary between companies and domains.\n\n1. Define goals and requirements. Identify issues to address with the utmost accuracy and desired outcomes. Consider production volume, data availability and integration with existing systems to create a road map.\n\n2. Collect data in preparation. Gather relevant data like photographs and sensor readings. Ensure the data is diverse, representative and clean to provide high-quality input for AI training.\n\n3. Select the right AI provider. Evaluate AI applications based on accuracy, scalability, integration ease and vendor support. Choose providers with a successful track record in defect analysis.\n\n4. Integrate it with your existing infrastructure. Ensure the AI application integrates with your facility's systems, collaborating with IT teams and solution providers for smooth integration.\n\n5. Train and validate. Train the AI with collected data, validate its performance against manual inspections or historical data and continuously optimize based on feedback.\n\n6. Address challenges. Overcome issues like employee acceptance and system reliability through thorough testing, involving staff and ensuring proper training and communication.\n\nAI is a disruptive technology that accelerated its penetration in the market incredibly in 2023 and is moving faster than any other technology to date. As in any technological revolution, there's a population of employees and workers scared by the pace of change and the unknown.\n\nBut remember that AI should be perceived as a tool to augment what we do. We should leverage this powerful technology to improve our output, to improve our skills and to improve our productivity.\n\nForbes Business Council is the foremost growth and networking organization for business owners and leaders. Do I qualify?", "source": {"uri": "forbes.com", "dataType": "news", "title": "Forbes"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Quality_control", "type": "wiki", "score": 5, "label": {"eng": "Quality control"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Use_case", "type": "wiki", "score": 4, "label": {"eng": "Use case"}}, {"uri": "http://en.wikipedia.org/wiki/Byte", "type": "wiki", "score": 4, "label": {"eng": "Byte"}}, {"uri": "http://en.wikipedia.org/wiki/Leverage_(finance)", "type": "wiki", "score": 4, "label": {"eng": "Leverage (finance)"}}, {"uri": "http://en.wikipedia.org/wiki/Fourth_Industrial_Revolution", "type": "wiki", "score": 4, "label": {"eng": "Fourth Industrial Revolution"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 3, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Small_and_medium-sized_enterprises", "type": "wiki", "score": 3, "label": {"eng": "Small and medium-sized enterprises"}}, {"uri": "http://en.wikipedia.org/wiki/Return_on_investment", "type": "wiki", "score": 3, "label": {"eng": "Return on investment"}}, {"uri": "http://en.wikipedia.org/wiki/Customer_satisfaction", "type": "wiki", "score": 3, "label": {"eng": "Customer satisfaction"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 3, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/General_Motors", "type": "org", "score": 3, "label": {"eng": "General Motors"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_operating_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief operating officer"}}, {"uri": "http://en.wikipedia.org/wiki/McKinsey_&_Company", "type": "org", "score": 3, "label": {"eng": "McKinsey & Company"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_industry", "type": "wiki", "score": 2, "label": {"eng": "Machine industry"}}, {"uri": "http://en.wikipedia.org/wiki/Process_optimization", "type": "wiki", "score": 2, "label": {"eng": "Process optimization"}}, {"uri": "http://en.wikipedia.org/wiki/Manufacturing_execution_system", "type": "wiki", "score": 2, "label": {"eng": "Manufacturing execution system"}}, {"uri": "http://en.wikipedia.org/wiki/Predictive_maintenance", "type": "wiki", "score": 2, "label": {"eng": "Predictive maintenance"}}, {"uri": "http://en.wikipedia.org/wiki/Casting", "type": "wiki", "score": 2, "label": {"eng": "Casting"}}, {"uri": "http://en.wikipedia.org/wiki/Textile_industry", "type": "wiki", "score": 2, "label": {"eng": "Textile industry"}}, {"uri": "http://en.wikipedia.org/wiki/Assembly_line", "type": "wiki", "score": 2, "label": {"eng": "Assembly line"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 2, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Quebec", "type": "loc", "score": 2, "label": {"eng": "Quebec"}, "location": {"type": "place", "label": {"eng": "Quebec"}, "country": {"type": "country", "label": {"eng": "Canada"}}}}, {"uri": "http://en.wikipedia.org/wiki/Forbes", "type": "org", "score": 1, "label": {"eng": "Forbes"}}], "categories": [{"uri": "dmoz/Business", "label": "dmoz/Business", "wgt": 100}, {"uri": "dmoz/Business/Business_Services/Physical_Asset_Management", "label": "dmoz/Business/Business Services/Physical Asset Management", "wgt": 100}, {"uri": "dmoz/Business/Industrial_Goods_and_Services/Factory_Automation", "label": "dmoz/Business/Industrial Goods and Services/Factory Automation", "wgt": 100}, {"uri": "dmoz/Business/Industrial_Goods_and_Services/Consulting", "label": "dmoz/Business/Industrial Goods and Services/Consulting", "wgt": 100}, {"uri": "dmoz/Business/E-Commerce/Marketplaces", "label": "dmoz/Business/E-Commerce/Marketplaces", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 96}], "image": "https://imageio.forbes.com/specials-images/imageserve/66ad13a55a38c12b910e07d9/0x0.jpg?format=jpg&height=600&width=1200&fit=bounds", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.1607843137254903, "wgt": 129, "relevance": 1}
{"uri": "2024-08-443089353", "lang": "eng", "isDuplicate": false, "date": "2024-08-03", "time": "19:20:59", "dateTime": "2024-08-03T19:20:59Z", "dateTimePub": "2024-08-03T19:15:00Z", "dataType": "news", "sim": 0.5058823823928833, "url": "https://venturebeat.com/ai/act-2-in-gen-ai-lets-get-ready-now/", "title": "Are we prepared for 'Act 2' of gen AI?", "body": "Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More\n\nWith every demonstration and experiment, the breathless excitement surrounding generative AI grows in a nearly unprecedented manner. Across healthcare, finance, transportation manufacturing, media, retail and energy, gen AI is virtually rewriting the rules for the very way we work and think.\n\nOf course, we've previously seen rapid adoption curves for game-changing technologies: The internet, smartphones, social media, robotics, streaming media and electric vehicles all provide lessons and models with varying degrees of relevance. The crucial difference: Those technologies largely automated tasks and communication to provide their substantial benefits -- that is, the power to send and receive messages in real time, faster manufacturing and assembly, safer and smarter transportation. But with gen AI, we are automating (and profoundly accelerating) human analysis and insights. That places greater demands, constraints and challenges before us.\n\nWe are only in what I'd call \"Act 1\" of the gen AI story. Previously unimaginable amounts of data and compute have created models that demonstrate (a key word) what gen AI can deliver. However, these early experiments have also brought compromises, exceptions, cost concerns and, yes, errors. After all, fast-evolving technologies are inherently fragile at the start.\n\nHowever, we must ensure we don't remain mired in Act 1. Much more work remains on the pragmatics of operationalizing gen AI. This work -- what I'd call \"Act 2\" -- may be less glamourous, but it is no less essential to the success of this technology.\n\nThink about it. The major breakthrough technologies of the past 30-plus years created some of the best-known names in business: Facebook, Tesla, Netflix or even my own company Amazon. Those successes certainly provide a useful roadmap, but they became household names only after they built out their businesses that proved their value, after they created the infrastructure, applications, systems and processes that turned head-turning innovation into sustainable and scalable businesses.\n\nTime to roll up our sleeves\n\nIn gen AI, that transition to Act 2 is just getting underway. We can't point to four or five life-changing applications -- yet. Reality has not caught up to the hype -- yet. Why is that? Quite simply, it's because Act 2 is really hard. In any segment of the technology industry, building a sustainable, scalable business requires years of heavy lifting. But in gen AI, with its higher profile and higher stakes, that work will be exponentially more challenging. Act 1 has shown us clearly the areas we must address:\n\nAre you in act 1 or act 2 of gen AI?\n\nDecades ago, the world immediately recognized that the jet engine represented an exponential improvement in transportation, one that would forever change the world through its ability to shrink distances and times and democratize the world of travel.\n\nBut the jet engine alone wasn't anywhere near a complete solution. We needed to integrate it into robust vehicles with aerodynamic wings and space-efficient cabins, optimized fuels, maintenance procedures and safety protocols. We had to redesign runways and airports to accommodate these vehicles and their greater numbers of passengers. We had to upgrade air-traffic control systems. And we had to commit to safety as the primary directive. The engine alone wasn't of great value without all of these supporting innovations and resources.\n\nThe lesson is clear: Life-changing applications require infrastructure. It's a mistake to assume that an Act 1 AI demonstration will be enterprise-ready. In Act 2, we must take dazzling AI technology and develop it into a mature, ubiquitous system backed by a robust and reliable infrastructure that will integrate with almost every area of our lives. For companies moving into Act 2, the logical question arises: How do you accelerate that journey to broadly deployed gen AI and reap its benefits?\n\nIn my view, there are five keys to ensuring you don't remain stuck in Act 1 -- and for succeeding in the coming Act 2 for gen AI:\n\nDifferentiate with data\n\nEven in gen AI's Act 1, the importance of data quickly becomes clear. The quality of gen AI is heavily dependent on the quality of training data. The data is your asset -- your added value, so devote proper resources to data-cleansing routines. Whether it's using multiple sources or enforcing security and access privileges, a sound and thoughtful data strategy makes a big difference.\n\nChoose the right hybrid mixture of models\n\nIt's both logical and tempting to design your AI usage around one large model. You might think you can simply take a giant large language model (LLM) from your Act 1 initiatives and just get moving. However, the better approach is to assemble and integrate a mixture of several models. Just as a human's frontal cortex handles logic and reasoning while the limbic system deals with fast, spontaneous responses, a good AI system brings together multiple models in a heterogeneous architecture. No two LLMs are alike -- and no single model can \"do it all.\" What's more, there are cost considerations. The most accurate model might be more expensive and slower.\n\nFor instance, a faster model might produce a concise answer in one second -- something ideal for a chatbot. However, a different but similar model might produce a more comprehensive (but equally accurate) answer to the same question within 15 seconds, which might be better suited for a customer-service agent. That's why many companies are identifying, evaluating and deploying a blended portfolio of models to support their various AI initiatives. Invest the time to fully analyze your options and choose the right mixture.\n\nIntegrate AI responsibly\n\nEven in its early days, gen AI quickly presented scenarios and demonstrations that underscore the critical importance of standards and practices that emphasize ethics and responsible use. Gen AI should take a people-centric approach that prioritizes education and integrity by detecting and preventing harmful or inappropriate content -- in both user input and model output. For example, invisible watermarks can help reduce the spread of disinformation.\n\nFocus on cost, performance and scale\n\nSuccess in gen AI will depend on a low-cost, highly performant ML infrastructure that provides rapid training. This encompasses both purpose-built hardware and resilient software optimized for scalability, fault tolerance and more, enabling you to build, train, tune and deploy models in a cost-feasible manner. It's also important to recognize that scaling an application inevitably exposes unexpected scenarios that can sidetrack generative AI expansion. And since the scale is much higher, any failures will have a very high profile. Enterprises must account for these scenarios and build in the plans and infrastructure to accommodate these deployments.\n\nPromote usability and accessibility\n\nTo succeed, gen AI must be broadly accessible (within security parameters) and intuitively usable within existing workflows. Direct your efforts toward non-experts and non-coders, and enable business analysts, finance pros, citizen data analysts and brand managers to tap into AI's full power. For instance, we can reimagine the patient-physician encounter to eliminate most manual work and documentation tasks, analyze the conversation, create clinical summaries and more. That increases accuracy, improves outcomes and enables physicians to help more patients.\n\nConclusion\n\nTo be sure, the path from Act 1 to Act 2 will not be a straight one. It will require effort we haven't seen before. In some ways, we've seen this exact same challenge: Moving along the maturity curve from an exciting technology demonstration with hype and promise to a mature, reliable, proven and cost-effective solution that can be broadly adopted. The fact that gen AI's hype may outpace almost any other preceding innovation only underscores the importance and difficulty of our work to bring the technology into Act 2 -- and the need to roll up our sleeves and catch up to the hype.", "source": {"uri": "venturebeat.com", "dataType": "news", "title": "VentureBeat"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Scalability", "type": "wiki", "score": 4, "label": {"eng": "Scalability"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Tesla,_Inc.", "type": "org", "score": 3, "label": {"eng": "Tesla, Inc."}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_(company)", "type": "org", "score": 3, "label": {"eng": "Amazon (company)"}}, {"uri": "http://en.wikipedia.org/wiki/Pragmatics", "type": "wiki", "score": 3, "label": {"eng": "Pragmatics"}}, {"uri": "http://en.wikipedia.org/wiki/Real-time_computing", "type": "wiki", "score": 3, "label": {"eng": "Real-time computing"}}, {"uri": "http://en.wikipedia.org/wiki/Jet_engine", "type": "wiki", "score": 3, "label": {"eng": "Jet engine"}}, {"uri": "http://en.wikipedia.org/wiki/Robotics", "type": "wiki", "score": 3, "label": {"eng": "Robotics"}}, {"uri": "http://en.wikipedia.org/wiki/Exponential_growth", "type": "wiki", "score": 3, "label": {"eng": "Exponential growth"}}, {"uri": "http://en.wikipedia.org/wiki/Electric_vehicle", "type": "wiki", "score": 3, "label": {"eng": "Electric vehicle"}}, {"uri": "http://en.wikipedia.org/wiki/Finance", "type": "wiki", "score": 3, "label": {"eng": "Finance"}}, {"uri": "http://en.wikipedia.org/wiki/Streaming_media", "type": "wiki", "score": 3, "label": {"eng": "Streaming media"}}, {"uri": "http://en.wikipedia.org/wiki/Health_care", "type": "wiki", "score": 3, "label": {"eng": "Health care"}}, {"uri": "http://en.wikipedia.org/wiki/Internet", "type": "wiki", "score": 3, "label": {"eng": "Internet"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 3, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Netflix", "type": "wiki", "score": 3, "label": {"eng": "Netflix"}}, {"uri": "http://en.wikipedia.org/wiki/Smartphone", "type": "wiki", "score": 3, "label": {"eng": "Smartphone"}}, {"uri": "http://en.wikipedia.org/wiki/Social_media", "type": "wiki", "score": 3, "label": {"eng": "Social media"}}, {"uri": "http://en.wikipedia.org/wiki/Air_traffic_control", "type": "wiki", "score": 2, "label": {"eng": "Air traffic control"}}, {"uri": "http://en.wikipedia.org/wiki/Aerodynamics", "type": "wiki", "score": 2, "label": {"eng": "Aerodynamics"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 1, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 1, "label": {"eng": "Chatbot"}}], "categories": [{"uri": "dmoz/Recreation/Models/Scale", "label": "dmoz/Recreation/Models/Scale", "wgt": 18}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 19}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 26}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 19}, {"uri": "dmoz/Computers/Software/Data_Administration", "label": "dmoz/Computers/Software/Data Administration", "wgt": 19}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 98}], "image": "https://venturebeat.com/wp-content/uploads/2024/08/DDM-Sat.jpeg?w=1024?w=1200&strip=all", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3333333333333333, "wgt": 129, "relevance": 1}
{"uri": "8259940155", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "10:58:30", "dateTime": "2024-08-05T10:58:30Z", "dateTimePub": "2024-08-05T10:57:45Z", "dataType": "news", "sim": 0.5058823823928833, "url": "https://www.infoworld.com/article/3480944/turning-ai-hype-into-reality.html", "title": "Turning AI hype into reality", "body": "Enterprises are overwhelmed by AI dreams and employees who lack the skills to make them come true. May I suggest a hackathon?\n\nThe clouds can't stop spending on AI, even if their customers are starting to question their own investments. Such disillusionment may be temporary, as Amazon CEO Andy Jassy suggests. In his words, today the vast majority of enterprise workloads remain tethered to on-premises data centers, but AI promises to change that. He says, \"The ability to use AI more effectively is going to be one of the many drivers\" that convince enterprises to move applications to the cloud.\n\nThis makes it clear why the cloud vendors are so focused on enabling AI workloads. They, along with Meta, have collectively spent more than $100 billion this year on capital expenditures, while signaling plans to spend even more. As Alphabet/Google CEO Sundar Pichai put it, \"When [the industry is] going through transitions like this ... the risk of underinvesting [in AI] is dramatically higher than overinvesting.\" Okay, but although it's great the clouds are building more and more infrastructure and services, what's even more important is guidance on how customers can use AI effectively. There's still way too much hype about possibilities, and not nearly enough substance.\n\nSo, what are some practical ways an enterprise can develop its AI expertise?", "source": {"uri": "infoworld.com", "dataType": "news", "title": "InfoWorld"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Andy_Jassy", "type": "person", "score": 3, "label": {"eng": "Andy Jassy"}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_(company)", "type": "org", "score": 3, "label": {"eng": "Amazon (company)"}}, {"uri": "http://en.wikipedia.org/wiki/Hackathon", "type": "wiki", "score": 3, "label": {"eng": "Hackathon"}}, {"uri": "http://en.wikipedia.org/wiki/Cloud_computing", "type": "wiki", "score": 3, "label": {"eng": "Cloud computing"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 2, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/Data_center", "type": "wiki", "score": 2, "label": {"eng": "Data center"}}, {"uri": "http://en.wikipedia.org/wiki/Alphabet_Inc.", "type": "org", "score": 1, "label": {"eng": "Alphabet Inc."}}, {"uri": "http://en.wikipedia.org/wiki/Sundar_Pichai", "type": "person", "score": 1, "label": {"eng": "Sundar Pichai"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 1, "label": {"eng": "Google"}}], "categories": [{"uri": "dmoz/Recreation/Humor/Useless_Pages", "label": "dmoz/Recreation/Humor/Useless Pages", "wgt": 100}, {"uri": "dmoz/Society/Transgendered/Coming_Out", "label": "dmoz/Society/Transgendered/Coming Out", "wgt": 100}, {"uri": "dmoz/Society/Advice", "label": "dmoz/Society/Advice", "wgt": 100}, {"uri": "dmoz/Health/Teen_Health/Teen_Pregnancy", "label": "dmoz/Health/Teen Health/Teen Pregnancy", "wgt": 100}, {"uri": "dmoz/Society/Work/Workweek_Reduction", "label": "dmoz/Society/Work/Workweek Reduction", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 79}], "image": "https://www.infoworld.com/wp-content/uploads/2024/08/3480944-0-50306400-1722847575-shutterstock_1937300755-100927748-orig.jpg?quality=50&strip=all&w=1024", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3568627450980393, "wgt": 129, "relevance": 1}
{"uri": "8259634895", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "07:38:27", "dateTime": "2024-08-05T07:38:27Z", "dateTimePub": "2024-08-05T07:37:16Z", "dataType": "news", "sim": 0.501960813999176, "url": "https://www.financemagnates.com/trending/the-ai-arms-race-tech-titans-triumphs-and-tribulations/", "title": "An AI Arms Race: Tech Titans' Triumphs and Tribulations", "body": "Meta's AI-powered Metaverse vision fuels stock spikes amid persistent doubts.\n\nIn the world of tech, artificial intelligence is both the golden goose and a thorny predicament. Microsoft's aggressive AI bets, Apple's cautious integration, and Meta's metaverse dreams all in some way illustrate the rocky road of AI adoption. Each of these tech behemoths faces its unique set of challenges and triumphs as they navigate this confusing (and expensive) new world.\n\nMicrosoft's Q4 earnings reveal a company playing the long game with artificial intelligence (AI Artificial Intelligence (AI) Artificial Intelligence (AI) is a term coined by in 1956, which defines the automation of robotics to the actual process of robotics.The evolution of technology has since led to the gradual adoption of AI in several aspects of our lives. One of the most pertinent is its impact in the financial services industry, which provides a wide range of possibilities moving forward.Ways AI Can Transform FinanceAI has the potential to transform the financial services industry forever. This can take shape in Artificial Intelligence (AI) is a term coined by in 1956, which defines the automation of robotics to the actual process of robotics.The evolution of technology has since led to the gradual adoption of AI in several aspects of our lives. One of the most pertinent is its impact in the financial services industry, which provides a wide range of possibilities moving forward.Ways AI Can Transform FinanceAI has the potential to transform the financial services industry forever. This can take shape in Read this Term). Despite impressive revenue figures, their profits were pinched by massive AI-related expenses. The tech giant's heavy investment in AI infrastructure and development signals a commitment to future dominance, even if it means absorbing short-term financial hits. Investors appear divided, with some lauding the forward-thinking approach while others fret over immediate profit margins.\n\nThe scale of Microsoft's AI ambition cannot be understated. The company's significant investments span various facets, from enhancing their cloud Cloud The cloud or cloud computing helps provides data and applications that can be accessed from nearly any location in the world so long as a stable Internet connection exists. Categorized into three cloud services, cloud computing is segmented into Software as a Service (SaaS), Infrastructure as a Service (IaaS), and Platform as a Service (PaaS). In terms of trading, the versatility of the cloud service allows retail traders the ability to test out new trading strategies, backtest pre-existing conc The cloud or cloud computing helps provides data and applications that can be accessed from nearly any location in the world so long as a stable Internet connection exists. Categorized into three cloud services, cloud computing is segmented into Software as a Service (SaaS), Infrastructure as a Service (IaaS), and Platform as a Service (PaaS). In terms of trading, the versatility of the cloud service allows retail traders the ability to test out new trading strategies, backtest pre-existing conc Read this Term computing capabilities with Azure to integrating AI into everyday products like Office 365. These moves are part of a broader strategy to position Microsoft as a leader in AI technology, but they come with a hefty price tag. This strategic choice reflects a belief in AI's transformative potential to drive future growth, even if it dampens current profits.\n\nWhile some investors are optimistic, viewing these expenditures as essential for staying ahead in the tech race, others are wary. The immediate financial strain raises concerns about when these investments will translate into substantial returns. Microsoft's challenge lies in balancing this long-term vision with short-term financial performance, a tightrope act that will be scrutinized closely by Wall Street.\n\nApple's recent earnings report painted a mixed picture. While the company continues to subtly weave AI into its ecosystem, broader economic challenges in China have cast a shadow over its performance. The combination of supply chain woes and shifting consumer sentiments means that Apple's AI advancements, though significant, are not enough to sway Wall Street's cautious outlook entirely. The tech darling's careful AI strategy highlights a company that is both ambitious and wary of overpromising.\n\nApple's strategic integration of AI is seen in features like enhanced Siri functionalities and sophisticated computational photography in its devices. However, the economic headwinds from China, a crucial market, pose significant challenges. Economic slowdowns and regulatory hurdles in China have impacted Apple's sales and, by extension, its ability to invest aggressively in AI without reassessing its broader financial strategy.\n\nInvestors have shown mixed reactions to Apple's AI trajectory. Some appreciate the company's cautious and methodical approach, ensuring that AI enhancements are robust and meaningful. Others, however, are frustrated by the slower pace compared to rivals like Microsoft and Google, fearing that Apple might miss out on critical AI advancements.\n\nBut let's not forget, this was a great quarter for the company, with revenue up 5% year on year. Uncertainty is one thing, but Apple is still Apple.\n\nThen there's Meta, the artist formerly known as Facebook, which is doubling down on its metaverse vision powered by AI. This bold strategy has seen its stock spike, reflecting investor excitement about future prospects. However, skepticism remains. Critics argue that the metaverse is still a nebulous concept, and Meta's vast expenditures in this area are seen as risky. The company's unwavering belief in an AI-driven virtual future is both its biggest strength and potential Achilles' heel.\n\nMeta's ongoing pivot to the metaverse is an audacious bet on the future of digital interaction. By leveraging AI to create immersive virtual environments, Meta aims to revolutionize how we connect, work, and play. This vision is ambitious, with plans for virtual reality (VR) headsets, augmented reality (AR) experiences, and a fully-fledged metaverse ecosystem.\n\nDespite the incredible potential, the path is fraught with challenges. Building the metaverse requires substantial AI advancements and vast financial investments. Critics argue that the metaverse is more hype than substance at this stage, with practical applications and widespread adoption still years away. Meta's stock has seen volatility as investors weigh the potential against the uncertainties.\n\nEach of these tech giants exemplifies a different approach to AI, showcasing the diverse strategies and inevitable risks. Microsoft's all-in strategy, Apple's measured pace, and Meta's plunge into the metaverse reveal the multifaceted nature of AI adoption seen in companies around the world. For investors, these moves are a reminder that while AI holds immense promise, the path to realizing its full potential is fraught with challenges.\n\nThe AI revolution is here, and it's reshaping the fortunes of the tech industry's - and the world's - biggest players. Microsoft, Apple, and Meta each offer a glimpse into the varied paths companies can take -- whether it's through bold investments, cautious integration, or visionary leaps. As these companies continue to innovate and adapt, one thing is clear: the AI arms race is far from over, and the stakes have never been higher.", "source": {"uri": "financemagnates.com", "dataType": "news", "title": "Finance Magnates"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Metaverse", "type": "wiki", "score": 5, "label": {"eng": "Metaverse"}}, {"uri": "http://en.wikipedia.org/wiki/Cloud_computing", "type": "wiki", "score": 5, "label": {"eng": "Cloud computing"}}, {"uri": "http://en.wikipedia.org/wiki/Automation", "type": "wiki", "score": 5, "label": {"eng": "Automation"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 5, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Apple_Inc.", "type": "org", "score": 5, "label": {"eng": "Apple Inc."}}, {"uri": "http://en.wikipedia.org/wiki/Financial_services", "type": "wiki", "score": 5, "label": {"eng": "Financial services"}}, {"uri": "http://en.wikipedia.org/wiki/Robotics", "type": "wiki", "score": 4, "label": {"eng": "Robotics"}}, {"uri": "http://en.wikipedia.org/wiki/Evolution", "type": "wiki", "score": 4, "label": {"eng": "Evolution"}}, {"uri": "http://en.wikipedia.org/wiki/Platform_as_a_service", "type": "wiki", "score": 3, "label": {"eng": "Platform as a service"}}, {"uri": "http://en.wikipedia.org/wiki/Infrastructure_as_a_service", "type": "wiki", "score": 3, "label": {"eng": "Infrastructure as a service"}}, {"uri": "http://en.wikipedia.org/wiki/Software_as_a_service", "type": "wiki", "score": 3, "label": {"eng": "Software as a service"}}, {"uri": "http://en.wikipedia.org/wiki/Internet_access", "type": "wiki", "score": 3, "label": {"eng": "Internet access"}}, {"uri": "http://en.wikipedia.org/wiki/China", "type": "loc", "score": 3, "label": {"eng": "China"}, "location": {"type": "country", "label": {"eng": "China"}}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft_365", "type": "org", "score": 2, "label": {"eng": "Microsoft 365"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft_Azure", "type": "wiki", "score": 2, "label": {"eng": "Microsoft Azure"}}, {"uri": "http://en.wikipedia.org/wiki/Computing", "type": "wiki", "score": 2, "label": {"eng": "Computing"}}, {"uri": "http://en.wikipedia.org/wiki/Wall_Street", "type": "wiki", "score": 2, "label": {"eng": "Wall Street"}}, {"uri": "http://en.wikipedia.org/wiki/Ecosystem", "type": "wiki", "score": 2, "label": {"eng": "Ecosystem"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 1, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_reality_headset", "type": "wiki", "score": 1, "label": {"eng": "Virtual reality headset"}}, {"uri": "http://en.wikipedia.org/wiki/Technology_company", "type": "wiki", "score": 1, "label": {"eng": "Technology company"}}, {"uri": "http://en.wikipedia.org/wiki/Siri", "type": "wiki", "score": 1, "label": {"eng": "Siri"}}, {"uri": "http://en.wikipedia.org/wiki/Arms_race", "type": "wiki", "score": 1, "label": {"eng": "Arms race"}}, {"uri": "http://en.wikipedia.org/wiki/Supply_chain", "type": "wiki", "score": 1, "label": {"eng": "Supply chain"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 1, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 1, "label": {"eng": "Google"}}], "categories": [{"uri": "dmoz/Business", "label": "dmoz/Business", "wgt": 100}, {"uri": "dmoz/Society/Issues/Business", "label": "dmoz/Society/Issues/Business", "wgt": 100}, {"uri": "dmoz/Business/Opportunities", "label": "dmoz/Business/Opportunities", "wgt": 100}, {"uri": "dmoz/Society/Activism/Anti-Corporation", "label": "dmoz/Society/Activism/Anti-Corporation", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 95}], "image": "https://images.financemagnates.com/images/AI_id_f83847e2-7f94-4f71-95e1-f58b40d3ce42_size900.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.2549019607843137, "wgt": 128, "relevance": 1}
{"uri": "8259446673", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "05:03:35", "dateTime": "2024-08-05T05:03:35Z", "dateTimePub": "2024-08-05T05:03:02Z", "dataType": "news", "sim": 0.501960813999176, "url": "https://www.ukauthority.com/articles/nhs-staff-and-the-public-support-ai-in-healthcare/", "title": "NHS staff and the public 'support AI in healthcare' | UKAuthority", "body": "More than three quarters of NHS staff (76%) support the use of AI to help with patient care, with 81% also in favour of its use for administrative tasks, according to a survey by the Health Foundation.\n\nThe healthcare research charity added that the public is also broadly receptive to the use of the technology, with 54% supporting its use in patient care and 61% for administrative purposes.\n\nIts survey involved 1,292 NHS staff members and 7,200 nationally representative members of the UK public aged 16 years and older - said to be one of the largest of its kind in the world.\n\nOther findings included that significant minorities of the public and NHS staff - 18% and 11% respectively - think that AI reduces the quality of care, and that young people (aged 16-24) are less likely to believe it will improve the quality of care. Also, women are less likely than men to believe it will improve care.\n\nTwo major concerns were identified by the survey. One is around the potential impact of AI on the accuracy of decision making, with 30% of the public thinking that healthcare staff will not question its outputs and may miss errors.\n\nThe other is that 53% think AI will make them feel more distant from healthcare staff, while 65% of staff think it will make them more distant from patients.\n\nA majority of 57% of NHS staff were looking forward to using AI as part of their role.\n\nPublication of the survey follows the Health Foundation's call for a dedicated strategy for AI in healthcare. This would involve focusing developments and deployments in the right areas, underpinning the use of AI with high quality testing and evaluation, and the introduction of a clear and consistent regulatory regime.\n\nTim Horton, assistant director (insight and analysis) at the Health Foundation, said: \"Capitalising on the potential of AI will require a dedicated strategy to create agreement on priorities and provide greater direction for the NHS and industry. And engaging people in decisions about how AI should be used must be at the heart of this.\n\n\"If AI is to be accepted, and the benefits fully realised, it will have to command the confidence of patients, the public and NHS staff. The Health Foundation's research suggests the public and NHS staff, on balance, support the use of AI for clinical and administrative purposes. But some remain unconvinced, and so it's crucial to engage people in a conversation about the future of health care - in order to understand and address their concerns.\n\n\"It's clear the public want a human to remain 'in the loop' for many uses of AI in healthcare, and they want AI technologies to be designed and used in ways that protect the human dimension of care.\n\n\"Our research also suggests the impact of AI will be felt differently across roles in healthcare, and so in helping staff adjust to the rise of AI, policy makers and NHS leaders will need to tailor the support they provide.\"", "source": {"uri": "ukauthority.com", "dataType": "news", "title": "UKAuthority"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/National_Health_Service", "type": "wiki", "score": 5, "label": {"eng": "National Health Service"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Health_professional", "type": "wiki", "score": 3, "label": {"eng": "Health professional"}}, {"uri": "http://en.wikipedia.org/wiki/Charitable_organization", "type": "wiki", "score": 3, "label": {"eng": "Charitable organization"}}, {"uri": "http://en.wikipedia.org/wiki/Health_care", "type": "wiki", "score": 3, "label": {"eng": "Health care"}}, {"uri": "http://en.wikipedia.org/wiki/United_Kingdom", "type": "loc", "score": 3, "label": {"eng": "United Kingdom"}, "location": {"type": "country", "label": {"eng": "United Kingdom"}}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence_in_healthcare", "type": "wiki", "score": 2, "label": {"eng": "Artificial intelligence in healthcare"}}, {"uri": "http://en.wikipedia.org/wiki/Decision-making", "type": "wiki", "score": 2, "label": {"eng": "Decision-making"}}, {"uri": "http://en.wikipedia.org/wiki/Tim_Horton", "type": "person", "score": 1, "label": {"eng": "Tim Horton"}}], "categories": [{"uri": "dmoz/Health", "label": "dmoz/Health", "wgt": 100}, {"uri": "dmoz/Health/Reproductive_Health", "label": "dmoz/Health/Reproductive Health", "wgt": 100}, {"uri": "dmoz/Society/Issues/Health", "label": "dmoz/Society/Issues/Health", "wgt": 100}, {"uri": "dmoz/Health/Reproductive_Health/Birth_Control", "label": "dmoz/Health/Reproductive Health/Birth Control", "wgt": 100}, {"uri": "dmoz/Health/Public_Health_and_Safety/First_Aid", "label": "dmoz/Health/Public Health and Safety/First Aid", "wgt": 100}], "image": "https://www.ukauthority.com/media/14055/ai-healthcare-istock-1646106148-graphic-designer.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.388235294117647, "wgt": 128, "relevance": 1}
{"uri": "8259535041", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "06:22:34", "dateTime": "2024-08-05T06:22:34Z", "dateTimePub": "2024-08-05T06:21:42Z", "dataType": "news", "sim": 0.4980392158031464, "url": "https://www.lexology.com/library/detail.aspx?g=4d5171b2-b64b-433e-ae79-a76e1a61a7a0", "title": "EU AI Act - Key Implications for Businesses", "body": "Find out more about Lexology or get in touch by visiting our About page.\n\nThe EU AI Act, effective August 1, 2024, establishes stringent standards for AI risk management, transparency, and oversight. In response, regular training and policy updates are crucial for ensuring compliance and maintaining a competitive edge. This alert explores the Act's key elements and their impact on EU businesses, highlighting the importance of risk assessment, data management updates, and dynamic strategies.\n\n1. Overview\n\nThe European Union has officially implemented the groundbreaking EU AI Act, which came into effect on August 1, 2024. This legislation establishes rigorous standards for the development and deployment of artificial intelligence across its member states. Designed to drive technological innovation, the AI Act ensures that AI systems operate safely, transparently, and in alignment with the core principles of human rights. This legal alert delves into the crucial elements of the Act and explores its profound implications for businesses throughout the EU, providing clarity on the new landscape and assisting organizations in navigating these comprehensive regulations.\n\n2. Implementation Timeline\n\nThe implementation of the EU AI Act is staged in phases to provide organizations with sufficient time to comply with its provisions:\n\nThe Act mandates that AI providers maintain detailed records to trace AI decision-making processes, ensuring that AI operations are transparent and understandable to users (Article 13).\n\n3.3. Data Governance\n\nEmphasizes the need for high-quality, representative data to train AI systems, aiming to minimize biases and ensure fairness across AI operations (Article 10).\n\n3.4. Human Oversight\n\nRequires that high-risk AI applications to incorporate effective human oversight mechanisms to mitigate the risk of harm and ensure ethical usage (Article 14).\n\n3.5. Market Surveillance and Enforcement\n\nEstablishes robust surveillance mechanisms and significant penalties for non-compliance, reflecting the serious commitment of the EU to enforce these regulations (Articles 71-73).\n\nThe EU AI Act establishes stringent standards for risk management, transparency, and human oversight. To comply with these regulations, organizations must undertake detailed risk assessments, update data management practices, and adopt dynamic risk strategies. Additionally, regular employee training and policy revisions are crucial. Meeting these requirements is essential for ensuring both compliance and competitive advantage in the evolving regulatory landscape.", "source": {"uri": "lexology.com", "dataType": "news", "title": "Lexology"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/European_Union", "type": "loc", "score": 5, "label": {"eng": "European Union"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 3, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Risk_management", "type": "wiki", "score": 3, "label": {"eng": "Risk management"}}, {"uri": "http://en.wikipedia.org/wiki/Decision-making", "type": "wiki", "score": 2, "label": {"eng": "Decision-making"}}, {"uri": "http://en.wikipedia.org/wiki/Data_management", "type": "wiki", "score": 2, "label": {"eng": "Data management"}}, {"uri": "http://en.wikipedia.org/wiki/Innovation", "type": "wiki", "score": 2, "label": {"eng": "Innovation"}}, {"uri": "http://en.wikipedia.org/wiki/Risk_assessment", "type": "wiki", "score": 2, "label": {"eng": "Risk assessment"}}, {"uri": "http://en.wikipedia.org/wiki/Member_state_of_the_European_Union", "type": "wiki", "score": 2, "label": {"eng": "Member state of the European Union"}}, {"uri": "http://en.wikipedia.org/wiki/Human_rights", "type": "wiki", "score": 2, "label": {"eng": "Human rights"}}, {"uri": "http://en.wikipedia.org/wiki/Competitive_advantage", "type": "wiki", "score": 1, "label": {"eng": "Competitive advantage"}}, {"uri": "http://en.wikipedia.org/wiki/Surveillance", "type": "wiki", "score": 1, "label": {"eng": "Surveillance"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 1, "label": {"eng": "Ethics"}}], "categories": [{"uri": "dmoz/Society/Government/Multilateral", "label": "dmoz/Society/Government/Multilateral", "wgt": 100}, {"uri": "dmoz/Computers/Security/Policy", "label": "dmoz/Computers/Security/Policy", "wgt": 100}, {"uri": "dmoz/Science/Environment/Impact_Assessment", "label": "dmoz/Science/Environment/Impact Assessment", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 46}], "image": "https://www.lexology.com/images/share/lexology-social-media.png", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3019607843137255, "wgt": 127, "relevance": 1}
{"uri": "8259756541", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "09:01:23", "dateTime": "2024-08-05T09:01:23Z", "dateTimePub": "2024-08-05T09:00:26Z", "dataType": "news", "sim": 0.4941176474094391, "url": "https://www.nationalmortgagenews.com/news/how-ai-is-fixing-pain-points-in-lender-servicer-call-centers", "title": "How lenders and servicers are using AI in call centers", "body": "Calling a mortgage servicer or subservicer to find out details about a loan is often time consuming for both the consumer and the company representative aiming to help.\n\nThat is why mortgage lenders and servicers are evaluating ways to streamline and automate the experience for customers. Companies operating in the servicing space are starting to dip their toes into using artificial intelligence to solve lingering call center-related problems and shave down the amount of time each call takes.\n\nCompanies are largely cautious in their deployment of AI today, opting for such as having an help a call center agent answer customer questions, or using AI to pull tidbits of information from a recorded conversation to find areas of customer support improvement.\n\nBut the overarching goal -- if the regulatory environment allows it and the technology is developed -- is for AI to have full blown conversations with consumers, companies interviewed said.\n\nSergey Dyakin, chief information officer at Celink, says the reverse mortgage servicer has instituted a number of technology initiatives to streamline its call center, including using tools that speed up a borrower's ability to reach relevant information and those that help identify customer sentiment.\n\n\"We used analytical and machine learning tools to look at the call transcripts and discovered that up to a third of our customers who successfully authenticate on [interactive voice response] are asked to repeat this process with a live agent, which added on average 50 seconds per call, impacting both the customer experience and also the agent productivity,\" he said. \"We identified that this is a specific pain point, and we implemented changes based on those insights. Training agents to recognize system messages and having the reports helped us reduce the need for re-authentication and actually markedly improved call times.\"\n\nCelink is also experimenting with using AI to rate calls.\n\n\"This AI tool scores the majority of a customer call, and it not only identifies the sentiment, but it also looks for some key situations,\" Dyakin said. \"So for example, if the conversation mentions fraud, the tool can escalate the call for the intervention.\"\n\nAlso, though not necessarily AI related, Celink has slowed down its interactive voice response to serve its customer base.\n\n\"Borrowers have different communication preferences and while many of them utilize online tools, we understand that for our demographics where the average age is above 70, they often prefer traditional methods like phone calls,\" said Dyakin. \"We have slowed our IVR system records to 85% speed for easier comprehension and have added extra wait times after each system prompt.\"\n\nDan Binowitz, managing director at Loandepot, notes the company is currently exploring a number of AI-related options to beef up its call center experience. It is in the process of choosing a vendor.\n\nThe first implementation will likely be call monitoring and recording, which could take from three to four months to get off the ground, Binowitz predicts.\n\n\"One AI application we're looking at would take all of our calls and convert them to text,\" Loandepot's managing director said. \"It has the ability to test and consider tone, engagement, speed of conversation and provide reporting back.\"\n\nThe converted text can then be reviewed \"to determine whether there are areas of opportunity we're missing... is the caller interested in a new loan, or is there something else that we might be able to assist them with?\" he said.\n\nLoandepot is also considering implementing an AI-powered chatbot system to help customers on its website. Currently the lender uses \"an algorithmic-based chat system that is linked into the customer portal, it is not AI as of today,\" Binowitz added.\n\nOther lenders such as Newrez have also gone the chatbot route, launching an internally facing one last quarter for its call center employees. Its goal is to help call center representatives quickly find answers to caller questions.\n\nCenlar, a subservicer, is also in the process of developing an AI chatbot to help its agents quickly access its knowledge base and answer customer inquiries.\n\n\"Our company has hundreds of clients with different nuances in their loans, so agents have to be subject matter experts,\" said Josh Reicher, chief digital officer at Cenlar. Having an AI chatbot to work alongside an agent will save everyone time, he added.\n\nLast year Cenlar implemented a dialer machine learning system, highlighting another unique use case of AI. It analyzes patterns, demographics, and \"hundreds of other metrics\" to figure out when the best time to call a delinquent customer could be.\n\nUnited Wholesale Mortgage earlier this year launched an AI-powered initiative to have an \"overview of all of the calls that come in.\"\n\n\"We could actually start to get an inflection and tone in how people were talking and it would be analyzed,\" said Jason Bressler, chief technology officer at UWM. \"We could see if customers or team members were angry and if they were happy and pleasant, so that we could really start to change the overall training of our customer service platform.\"\n\nLenders interviewed see a future in which an artificial intelligence bot could hypothetically have conversations with customers via phone, though most have cautioned that there are and data privacy concerns.\n\nBinowitz said that while he is pondering the notion of one day implementing AI that can engage with customers, there is some reticence.\n\n\"The Consumer Financial Protection Bureau has raised the concern of AI bias and that gives me a little bit of hesitation. I want to ensure that we have everything fully controlled and so that there is no bias,\" Loandepot's executive said.\n\nReicher had similar sentiments, noting that companies using a voice AI assistant have to be \"mindful of information provided back\" and that the company is looking further into what AI can do if its hallucinations are fixed.\n\n\"If there is confidence we would [likely move into that space],\" he said. \"We're just getting started, we're not at a loss of opportunities [in how AI can be implemented].\"\n\nBressler said that for now there isn't an AI voice assistant product out there that truly understands the financial services space and can be used with confidence.\n\n\"What will happen very shortly is that with the advent of true virtual and voice AI assistance, we'll be able to start to have AI answer calls and have human interactive conversations and then have them transferred properly and appropriately,\" Bressler said. \"The models are not yet in a place yet where you can offer real customer service.\"", "source": {"uri": "nationalmortgagenews.com", "dataType": "news", "title": "National Mortgage News"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Interactive_voice_response", "type": "wiki", "score": 5, "label": {"eng": "Interactive voice response"}}, {"uri": "http://en.wikipedia.org/wiki/Call_centre", "type": "wiki", "score": 5, "label": {"eng": "Call centre"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Mortgage_loan", "type": "wiki", "score": 5, "label": {"eng": "Mortgage loan"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Reverse_mortgage", "type": "wiki", "score": 3, "label": {"eng": "Reverse mortgage"}}, {"uri": "http://en.wikipedia.org/wiki/Customer_support", "type": "wiki", "score": 3, "label": {"eng": "Customer support"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_information_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief information officer"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 3, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Authentication", "type": "wiki", "score": 3, "label": {"eng": "Authentication"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 3, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Customer_experience", "type": "wiki", "score": 3, "label": {"eng": "Customer experience"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Fraud", "type": "wiki", "score": 2, "label": {"eng": "Fraud"}}, {"uri": "http://en.wikipedia.org/wiki/Knowledge_base", "type": "wiki", "score": 1, "label": {"eng": "Knowledge base"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_assistant", "type": "wiki", "score": 1, "label": {"eng": "Virtual assistant"}}, {"uri": "http://en.wikipedia.org/wiki/Consumer_Financial_Protection_Bureau", "type": "wiki", "score": 1, "label": {"eng": "Consumer Financial Protection Bureau"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_technology_officer", "type": "wiki", "score": 1, "label": {"eng": "Chief technology officer"}}, {"uri": "http://en.wikipedia.org/wiki/Customer_service", "type": "wiki", "score": 1, "label": {"eng": "Customer service"}}, {"uri": "http://en.wikipedia.org/wiki/Bias", "type": "wiki", "score": 1, "label": {"eng": "Bias"}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Society/Issues/Business", "label": "dmoz/Society/Issues/Business", "wgt": 100}, {"uri": "dmoz/Recreation/Humor/Useless_Pages", "label": "dmoz/Recreation/Humor/Useless Pages", "wgt": 100}, {"uri": "dmoz/Society/Issues/Fraud", "label": "dmoz/Society/Issues/Fraud", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 93}], "image": "https://arizent.brightspotcdn.com/dims4/default/009e94a/2147483647/strip/true/crop/7253x4080+0+0/resize/1200x675!/quality/90/?url=https%3A%2F%2Fsource-media-brightspot.s3.us-east-1.amazonaws.com%2F1c%2F82%2Fbfb0456746d88579a579d082b3e2%2Fcall-center.jpeg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3803921568627451, "wgt": 126, "relevance": 1}
{"uri": "8260067508", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "12:18:25", "dateTime": "2024-08-05T12:18:25Z", "dateTimePub": "2024-08-05T12:16:26Z", "dataType": "news", "sim": 0.4941176474094391, "url": "https://www.app.com.pk/national/google-for-startups-launches-ai-academy-to-propel-ai-innovation-in-pakistan/", "title": "Google for Startups launches AI academy to propel AI innovation in Pakistan", "body": "Farhan S. Qureshi, Google Pakistan's country director, said: \"Our latest AI Academy program is a testament to Google's commitment to fostering the growth of AI across the Asia-Pacific. With Pakistan being an important market, we hope that local startups will use this opportunity to supercharge their AI solutions and further strengthen the AI ecosystem in APAC.\"", "source": {"uri": "app.com.pk", "dataType": "news", "title": "Associated Press Of Pakistan"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 4, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Pakistan", "type": "loc", "score": 4, "label": {"eng": "Pakistan"}, "location": {"type": "country", "label": {"eng": "Pakistan"}}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 1, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Asia-Pacific", "type": "loc", "score": 1, "label": {"eng": "Asia-Pacific"}, "location": null}], "categories": [{"uri": "dmoz/Society/Issues/Warfare_and_Conflict", "label": "dmoz/Society/Issues/Warfare and Conflict", "wgt": 100}, {"uri": "dmoz/Society/Religion_and_Spirituality/Sikhism", "label": "dmoz/Society/Religion and Spirituality/Sikhism", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 58}], "image": "https://www.app.com.pk/wp-content/uploads/2024/06/Google-Pakistan.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.7568627450980392, "wgt": 126, "relevance": 1}
{"uri": "8259945390", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "11:01:49", "dateTime": "2024-08-05T11:01:49Z", "dateTimePub": "2024-08-05T11:01:04Z", "dataType": "news", "sim": 0.4941176474094391, "url": "https://techcrunch.com/2024/08/05/ai-chip-startup-groq-lands-640m-to-challenge-nvidia/", "title": "AI chip startup Groq lands $640M to challenge Nvidia | TechCrunch", "body": "Groq, a startup developing chips to run generative AI models faster than conventional processors, said on Monday that it's raised $640 million in a new funding round led by Blackrock. Neuberger Berman, Type One Ventures, Cisco, KDDI and Samsung Catalyst Fund also participated.\n\nThe tranche, which brings Groq's total raised to over $1 billion and values the company at $2.8 billion, is a major win for Groq, which reportedly was originally looking to raise $300 million at a slightly lower ($2.5 billion) valuation. It more than doubles Groq's previous valuation (~$1 billion) in April 2021, when the company raised $300 million in a round led by Tiger Global Management and D1 Capital Partners.\n\nMeta chief AI scientist Yann LeCun will serve as a technical advisor to Groq and Stuart Pann, the former head of Intel's foundry business and ex-CIO at HP, will join the startup as chief operating officer, Groq also announced today. LeCun's appointment is a bit unexpected, given Meta's investments in its own AI chips -- but it undoubtedly gives Groq a powerful ally in a cutthroat space.\n\nGroq, which emerged from stealth in 2016, is creating what it calls an LPU (language processing unit) inference engine. The company claims its LPUs can run existing generative AI models similar in architecture to OpenAI's ChatGPT and GPT-4o at 10x the speed and on-tenth the energy.\n\nGroq CEO Jonathan Ross' claim to fame is helping to invent the tensor processing unit (TPU), Google's custom AI accelerator chip used to train and run models. Ross teamed up with Douglas Wightman, an entrepreneur and former engineer at Google parent company Alphabet's X moonshot lab, to co-found Groq close to a decade ago.\n\nGroq provides an LPU-powered developer platform called GroqCloud that offers \"open\" models like Meta's Llama 3.1 family, Google's Gemma, OpenAI's Whisper and Mistral's Mixtral, as well as an API that allows customers to use its chips in cloud instances. (Groq also hosts a playground for AI-powered chatbots, GroqChat, that it launched late last year.) As of July, GroqCloud had over 356,000 developers; Groq says that a portion of the proceeds from the round will be used to scale capacity and add new models and features.\n\n\"Many of these developers are at large enterprises,\" Stuart Pann, Groq's COO, told TechCrunch. \"By our estimates, over 75% of the Fortune 100 are represented.\"\n\nAs the generative AI boom continues, Groq faces increasing competition from both rival AI chip upstarts and Nvidia, the formidable incumbent in the AI hardware sector.\n\nNvidia controls an estimated 70% to 95% of the market for AI chips used to train and deploy generative AI models, and the firm's taking aggressive steps to maintain its dominance.\n\nNvidia has committed to releasing a new AI chip architecture every year, rather than every other year as was the case historically. And it's reportedly establishing a new business unit focused on designing bespoke chips for cloud computing firms and others, including AI hardware.\n\nBeyond Nvidia, Groq competes with Amazon, Google and Microsoft, all of which offer -- or will soon offer -- custom chips for AI workloads in the cloud. Amazon has its Trainium, Inferentia and Graviton processors, available through AWS; Google Cloud customers can use the aforementioned TPUs and, in time, Google's Axion chip; and Microsoft recently launched Azure instances in preview for its Cobalt 100 CPU, with Maia 100 AI Accelerator instances to come in the next several months.\n\nGroq could consider Arm, Intel, AMD and a growing number of startups rivals, too, in an AI chip market that could be reach $400 billion in annual sales in the next five years, according to some analysts. Arm and AMD in particular have blossoming AI chip businesses, thanks to soaring capital spending by cloud vendors to meet the capacity demand for generative AI.\n\nD-Matrix late last year raised $110 million to commercialize what it's characterizing as a first-of-its-kind inference compute platform. In June, Etched emerged from stealth with $120 million for a processor custom-built to speed up the dominant generative AI model architecture today, the transformer. SoftBank's Masayoshi Son is reportedly looking to raise $100 billion for a chip venture to compete Nvidia. And OpenAI is said to be in talks with investment firms to launch an AI chip-making initiative.\n\nTo carve out its niche, Groq is investing heavily in enterprise and government outreach.\n\nIn March, Groq acquired Definitive Intelligence, a Palo Alto-based firm offering a range of business-oriented AI solutions, to form a new business unit called Groq Systems. Within Groq Systems' purview is serving organizations, including U.S. government agencies and sovereign nations, that wish to add Groq's chips to existing data centers or build new data centers using Groq processors.\n\nMore recently, Groq partnered with Carahsoft, a government IT contractor, to sell its solutions to public sector clients through Carahsoft's reseller partners, and the startup has a letter of intent to install tens of thousands of its LPUs at European firm Earth Wind & Power's Norway datacenter.\n\nGroq is also collaborating with Saudi Arabian consulting firm Aramco Digital to install LPUs in future datacenters in the Middle East.\n\nAt the same time it's establishing customer relationships, Mountain View, California-based Groq is marching toward the next generation of its chip. Last August, the company announced that it would contract with semiconductor firm Global Foundries to manufacture 4nm LPUs, which are expected to deliver performance and efficiency gains over Groq's first-gen 13nm chips.\n\nGroq says it plans to deploy over 108,000 LPUs by the end of Q1 2025.", "source": {"uri": "techcrunch.com", "dataType": "news", "title": "TechCrunch"}, "authors": [{"uri": "kyle_wiggers@techcrunch.com", "name": "Kyle Wiggers", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Nvidia", "type": "org", "score": 5, "label": {"eng": "Nvidia"}}, {"uri": "http://en.wikipedia.org/wiki/Valuation_(finance)", "type": "wiki", "score": 5, "label": {"eng": "Valuation (finance)"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 5, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 5, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Tensor_Processing_Unit", "type": "wiki", "score": 4, "label": {"eng": "Tensor Processing Unit"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 4, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Yann_LeCun", "type": "person", "score": 4, "label": {"eng": "Yann LeCun"}}, {"uri": "http://en.wikipedia.org/wiki/Cloud_computing", "type": "wiki", "score": 4, "label": {"eng": "Cloud computing"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_operating_officer", "type": "wiki", "score": 4, "label": {"eng": "Chief operating officer"}}, {"uri": "http://en.wikipedia.org/wiki/Cisco", "type": "wiki", "score": 3, "label": {"eng": "Cisco"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 3, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 3, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/Tiger_Global_Management", "type": "wiki", "score": 3, "label": {"eng": "Tiger Global Management"}}, {"uri": "http://en.wikipedia.org/wiki/KDDI", "type": "org", "score": 3, "label": {"eng": "KDDI"}}, {"uri": "http://en.wikipedia.org/wiki/Inference_engine", "type": "wiki", "score": 3, "label": {"eng": "Inference engine"}}, {"uri": "http://en.wikipedia.org/wiki/Intel", "type": "org", "score": 3, "label": {"eng": "Intel"}}, {"uri": "http://en.wikipedia.org/wiki/Hewlett-Packard", "type": "org", "score": 3, "label": {"eng": "Hewlett-Packard"}}, {"uri": "http://en.wikipedia.org/wiki/Samsung", "type": "org", "score": 3, "label": {"eng": "Samsung"}}, {"uri": "http://en.wikipedia.org/wiki/BlackRock", "type": "org", "score": 3, "label": {"eng": "BlackRock"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/AMD", "type": "wiki", "score": 2, "label": {"eng": "AMD"}}, {"uri": "http://en.wikipedia.org/wiki/API", "type": "wiki", "score": 2, "label": {"eng": "API"}}, {"uri": "http://en.wikipedia.org/wiki/AI_accelerator", "type": "wiki", "score": 2, "label": {"eng": "AI accelerator"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 2, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_(company)", "type": "org", "score": 2, "label": {"eng": "Amazon (company)"}}, {"uri": "http://en.wikipedia.org/wiki/Fortune_500", "type": "wiki", "score": 2, "label": {"eng": "Fortune 500"}}, {"uri": "http://en.wikipedia.org/wiki/Central_processing_unit", "type": "wiki", "score": 2, "label": {"eng": "Central processing unit"}}, {"uri": "http://en.wikipedia.org/wiki/TechCrunch", "type": "wiki", "score": 2, "label": {"eng": "TechCrunch"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 2, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/SoftBank_Group", "type": "org", "score": 1, "label": {"eng": "SoftBank Group"}}, {"uri": "http://en.wikipedia.org/wiki/Masayoshi_Son", "type": "person", "score": 1, "label": {"eng": "Masayoshi Son"}}, {"uri": "http://en.wikipedia.org/wiki/GlobalFoundries", "type": "org", "score": 1, "label": {"eng": "GlobalFoundries"}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_Web_Services", "type": "org", "score": 1, "label": {"eng": "Amazon Web Services"}}, {"uri": "http://en.wikipedia.org/wiki/Saudi_Aramco", "type": "org", "score": 1, "label": {"eng": "Saudi Aramco"}}, {"uri": "http://en.wikipedia.org/wiki/Middle_East", "type": "loc", "score": 1, "label": {"eng": "Middle East"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Federal_government_of_the_United_States", "type": "org", "score": 1, "label": {"eng": "Federal government of the United States"}}, {"uri": "http://en.wikipedia.org/wiki/Mountain_View,_California", "type": "loc", "score": 1, "label": {"eng": "Mountain View, California"}, "location": {"type": "place", "label": {"eng": "Mountain View, California"}, "country": {"type": "country", "label": {"eng": "United States"}}}}, {"uri": "http://en.wikipedia.org/wiki/Saudi_Arabia", "type": "loc", "score": 1, "label": {"eng": "Saudi Arabia"}, "location": {"type": "country", "label": {"eng": "Saudi Arabia"}}}, {"uri": "http://en.wikipedia.org/wiki/Norway", "type": "loc", "score": 1, "label": {"eng": "Norway"}, "location": {"type": "country", "label": {"eng": "Norway"}}}], "categories": [{"uri": "dmoz/Computers/Hardware", "label": "dmoz/Computers/Hardware", "wgt": 100}, {"uri": "dmoz/Computers/Hardware/Buses", "label": "dmoz/Computers/Hardware/Buses", "wgt": 100}, {"uri": "dmoz/Computers/Hardware/Systems", "label": "dmoz/Computers/Hardware/Systems", "wgt": 100}, {"uri": "dmoz/Computers/Hardware/Components", "label": "dmoz/Computers/Hardware/Components", "wgt": 100}, {"uri": "dmoz/Computers/Hardware/Programmable_Logic", "label": "dmoz/Computers/Hardware/Programmable Logic", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 51}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 49}], "image": "https://techcrunch.com/wp-content/uploads/2020/08/GettyImages-1216725141.jpg?w=1000", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.2941176470588236, "wgt": 126, "relevance": 1}
{"uri": "8259734199", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "08:47:05", "dateTime": "2024-08-05T08:47:05Z", "dateTimePub": "2024-08-05T08:46:00Z", "dataType": "news", "sim": 0.4823529422283173, "url": "https://www.lexology.com/library/detail.aspx?g=c8e7fff9-2b83-48d1-b7c7-4b5a1693cbbe", "title": "Podcast - Barry Scannell and Kai Zenner Discuss Financial Sector AI Act Implications", "body": "Barry Scannell and Kai Zenner, the Head of Office and Digital Policy Advisor to MEP Axel Voss, discuss the new EU AI Act.\n\nAs the Act comes into force, they dive into its implications for the financial sector, the role of AI legislation in transportation, the extra-territorial effect of the AI Act, and the evolving landscape of AI liability and copyright laws. Kai provides insights on the complexities and challenges businesses face in navigating these new regulations, and what's next as the AI Act's rules begin to apply. Don't miss this essential episode for anyone involved in AI policy, law, or tech.", "source": {"uri": "lexology.com", "dataType": "news", "title": "Lexology"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Axel_Voss", "type": "person", "score": 3, "label": {"eng": "Axel Voss"}}, {"uri": "http://en.wikipedia.org/wiki/Member_of_the_European_Parliament", "type": "wiki", "score": 3, "label": {"eng": "Member of the European Parliament"}}, {"uri": "http://en.wikipedia.org/wiki/European_Union", "type": "loc", "score": 3, "label": {"eng": "European Union"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Financial_services", "type": "wiki", "score": 2, "label": {"eng": "Financial services"}}], "categories": [{"uri": "dmoz/Society/Law", "label": "dmoz/Society/Law", "wgt": 100}, {"uri": "dmoz/Society/Law/Legal_Information", "label": "dmoz/Society/Law/Legal Information", "wgt": 100}, {"uri": "dmoz/Society/Issues/Property_Rights", "label": "dmoz/Society/Issues/Property Rights", "wgt": 100}, {"uri": "news/Politics", "label": "news/Politics", "wgt": 46}], "image": "https://www.lexology.com/images/share/lexology-social-media.png", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": -0.003921568627450966, "wgt": 123, "relevance": 1}
{"uri": "8259735957", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "08:47:42", "dateTime": "2024-08-05T08:47:42Z", "dateTimePub": "2024-08-05T08:47:03Z", "dataType": "news", "sim": 0.4823529422283173, "url": "https://www.politicshome.com/thehouse/article/government-lean-new-eu-ai-act", "title": "The government should lean into the new EU AI Act", "body": "In order not to land flat on its face, the new Labour government would do well to look closely at continental efforts.\n\nTo understand the European Union's philosophy when it comes to regulating technology, Labour should consider the proverb: \"Fool me once, shame on you; fool me twice, shame on me.\" It could also crib the attitude of Alfred Einstein, who famously quipped: \"Insanity is doing the same thing over and over again and expecting different results.\"\n\nWhichever saying best fits the government's eye, the message from the EU to the major tech companies commercialising AI - via the new EU AI Act, in force this week - is this: You must regain our trust and learn the lessons of the serial data protection failures and information chaos caused by the rapid adoption and growth of online commerce and social media platforms.\n\nAnd while the temptation for Labour in their search for economic growth might be to hew closely to the American approach to AI - all-in on innovation, light touch on regulation - the new government would do well to consider the EU alternative. There is good reason to do so. The major technology companies are no longer plucky upstarts in need of a permissive regulatory framework; they are now industry behemoths, which spend tens of millions of dollars to lobby governments around the world. And these giants need to be reined in, for their own good and that of society.\n\nThe change in size and influence of the major tech platforms matters. Unlike the early days of the internet, the commercialisation of AI is being pursued, arms-race style, by some of the world's most wealthy and powerful corporations, with an eager and interested China competing alongside. This could easily become a recipe for disaster. And no, this isn't a reference to fantastical killer robots or AI suddenly extinguishing the world (although this might happen!).\n\nNo, the more mundane threats from AI are why former Prime Minister Rishi Sunak was right to convene all the major players for last year's groundbreaking AI Summit. A collective framework and common understanding of recent history is essential in the context of a technology that could profoundly alter labour markets, narrow the scope of consumer choices (from healthcare to financial services if AI models decide what is best for us), potentially complicate our collective ability to address climate challenge (AI is energy and water hungry when renewable supply remains limited and water stress is rising), and seriously unsettle the bonds of trust and truth (through deep fakes and other synthetic information). We have to get this right, and right on the first time of asking.\n\nEven though large parts of the world (with the notable exception of China) have thus far taken a lighter-touch approach to regulating AI than the EU, nearly all leading AI players will pursue EU private and public sector customers. After all, the 27-member bloc is the second largest economy in the world by GDP after the United States. And with a \u00a320+ bn shortfall in the government's books - following the EU's example will ensure UK firms developing AI technology have quick and seamless access to that market.\n\nSceptics within Labour need only to look at the GDPR and the spectacular global success the EU had in setting the regulatory approach to personal data: over a dozen countries from Canada and Brazil to Nigeria and South Africa have incorporated elements of the law into their national data protection. History could quite easily repeat itself with AI, as the GDPR will be a central regulatory tool for AI involving the processing of personal data, a point that is often overlooked. This gives the EU an in-built advantage on setting the regulatory pace. The UK is likely to remain closely aligned to the EU approach on data protection to ensure that the regime continues to be viewed as adequate by the EU. This convergence is an opportunity for the Starmer government to also seize for itself a global leadership role on AI regulations.\n\nThe regulatory winds are shifting, and the major tech platforms will cry foul (and lobby accordingly), but we must learn from our history; the chaos that flowed from the addition of a simple 'like' button to social media platforms was bad enough; what harms might we get from a technology with more power, able to be manipulated by everyone, that can expand at an exponential rate? Freedom always comes with responsible constraints.\n\nMore to the point, applying a sensible regulatory regime, like the EU has done with GDPR, but at an earlier stage, will promote more buy-in from consumers on AI-enabled services and technology. It will also provide a degree of regulatory certainty for innovators. In other words, we will help AI grow by giving it proper guardrails. It is both the best and correct thing to do to foster sustainable and responsible innovation.\n\nMegha Kumar is a Partner at CyXcel managing the firm's risk analysis and threat protection capabilities for clients.\n\nPoliticsHome Newsletters", "source": {"uri": "politicshome.com", "dataType": "news", "title": "Politics Home"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Labour_Party_(UK)", "type": "org", "score": 5, "label": {"eng": "Labour Party (UK)"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/European_Union", "type": "loc", "score": 5, "label": {"eng": "European Union"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Alfred_Einstein", "type": "person", "score": 3, "label": {"eng": "Alfred Einstein"}}, {"uri": "http://en.wikipedia.org/wiki/E-commerce", "type": "wiki", "score": 3, "label": {"eng": "E-commerce"}}, {"uri": "http://en.wikipedia.org/wiki/Nazi_Germany", "type": "loc", "score": 3, "label": {"eng": "Nazi Germany"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Economic_growth", "type": "wiki", "score": 3, "label": {"eng": "Economic growth"}}, {"uri": "http://en.wikipedia.org/wiki/Information_privacy", "type": "wiki", "score": 3, "label": {"eng": "Information privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Philosophy", "type": "wiki", "score": 3, "label": {"eng": "Philosophy"}}, {"uri": "http://en.wikipedia.org/wiki/Social_media", "type": "wiki", "score": 3, "label": {"eng": "Social media"}}, {"uri": "http://en.wikipedia.org/wiki/United_States", "type": "loc", "score": 3, "label": {"eng": "United States"}, "location": {"type": "country", "label": {"eng": "United States"}}}, {"uri": "http://en.wikipedia.org/wiki/China", "type": "loc", "score": 3, "label": {"eng": "China"}, "location": {"type": "country", "label": {"eng": "China"}}}, {"uri": "http://en.wikipedia.org/wiki/Deepfake", "type": "wiki", "score": 2, "label": {"eng": "Deepfake"}}, {"uri": "http://en.wikipedia.org/wiki/Rishi_Sunak", "type": "person", "score": 2, "label": {"eng": "Rishi Sunak"}}, {"uri": "http://en.wikipedia.org/wiki/General_Data_Protection_Regulation", "type": "wiki", "score": 2, "label": {"eng": "General Data Protection Regulation"}}, {"uri": "http://en.wikipedia.org/wiki/Water_scarcity", "type": "wiki", "score": 2, "label": {"eng": "Water scarcity"}}, {"uri": "http://en.wikipedia.org/wiki/Labour_economics", "type": "wiki", "score": 2, "label": {"eng": "Labour economics"}}, {"uri": "http://en.wikipedia.org/wiki/Bond_(finance)", "type": "wiki", "score": 2, "label": {"eng": "Bond (finance)"}}, {"uri": "http://en.wikipedia.org/wiki/Health_care", "type": "wiki", "score": 2, "label": {"eng": "Health care"}}, {"uri": "http://en.wikipedia.org/wiki/Robot", "type": "wiki", "score": 2, "label": {"eng": "Robot"}}, {"uri": "http://en.wikipedia.org/wiki/Corporation", "type": "wiki", "score": 2, "label": {"eng": "Corporation"}}, {"uri": "http://en.wikipedia.org/wiki/Internet", "type": "wiki", "score": 2, "label": {"eng": "Internet"}}, {"uri": "http://en.wikipedia.org/wiki/Financial_services", "type": "wiki", "score": 2, "label": {"eng": "Financial services"}}, {"uri": "http://en.wikipedia.org/wiki/United_Kingdom", "type": "loc", "score": 2, "label": {"eng": "United Kingdom"}, "location": {"type": "country", "label": {"eng": "United Kingdom"}}}, {"uri": "http://en.wikipedia.org/wiki/Keir_Starmer", "type": "person", "score": 1, "label": {"eng": "Keir Starmer"}}, {"uri": "http://en.wikipedia.org/wiki/Public_sector", "type": "wiki", "score": 1, "label": {"eng": "Public sector"}}, {"uri": "http://en.wikipedia.org/wiki/Risk_management", "type": "wiki", "score": 1, "label": {"eng": "Risk management"}}, {"uri": "http://en.wikipedia.org/wiki/Exponential_growth", "type": "wiki", "score": 1, "label": {"eng": "Exponential growth"}}, {"uri": "http://en.wikipedia.org/wiki/Gross_domestic_product", "type": "wiki", "score": 1, "label": {"eng": "Gross domestic product"}}, {"uri": "http://en.wikipedia.org/wiki/South_Africa", "type": "loc", "score": 1, "label": {"eng": "South Africa"}, "location": {"type": "country", "label": {"eng": "South Africa"}}}, {"uri": "http://en.wikipedia.org/wiki/Nigeria", "type": "loc", "score": 1, "label": {"eng": "Nigeria"}, "location": {"type": "country", "label": {"eng": "Nigeria"}}}, {"uri": "http://en.wikipedia.org/wiki/Canada", "type": "loc", "score": 1, "label": {"eng": "Canada"}, "location": {"type": "country", "label": {"eng": "Canada"}}}, {"uri": "http://en.wikipedia.org/wiki/Brazil", "type": "loc", "score": 1, "label": {"eng": "Brazil"}, "location": {"type": "country", "label": {"eng": "Brazil"}}}], "categories": [{"uri": "dmoz/Society/Issues", "label": "dmoz/Society/Issues", "wgt": 100}, {"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Society/Issues/Economic", "label": "dmoz/Society/Issues/Economic", "wgt": 100}, {"uri": "dmoz/Society/Issues/Business", "label": "dmoz/Society/Issues/Business", "wgt": 100}, {"uri": "dmoz/Society/Activism/In_Daily_Life", "label": "dmoz/Society/Activism/In Daily Life", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 62}], "image": "https://res.cloudinary.com/dyw8mv3b0/image/upload/q_85,w_1200,h_1200,c_limit/v1/news/2024_08/2WE8KHY_bpkvzp.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.06666666666666665, "wgt": 123, "relevance": 1}
{"uri": "8260062148", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "12:14:31", "dateTime": "2024-08-05T12:14:31Z", "dateTimePub": "2024-08-05T12:13:20Z", "dataType": "news", "sim": 0.4823529422283173, "url": "http://theconversation.com/google-gemini-ad-controversy-where-should-we-draw-the-line-between-ai-and-human-involvement-in-content-creation-236060", "title": "Google Gemini ad controversy: Where should we draw the line between AI and human involvement in content creation?", "body": "Toronto Metropolitan University provides funding as a member of The Conversation CA-FR.\n\nAfter widespread backlash, Google pulled its \"Dear Sydney\" Gemini ad from Olympics coverage. The ad featured its generative AI chatbot tool, Gemini, formerly known as Bard.\n\nThe advertisement featured a father and his daughter, a fan of United States Olympic track and field athlete Sydney McLaughlin-Levrone. The father, despite considering himself \"pretty good with words,\" uses Gemini to help his daughter to write a fan letter to Sydney, saying that when something needs to be done \"just right,\" Gemini is the better choice.\n\nThis advertisement sparked widespread backlash online about the growing role of generative AI tools and their impact on human creativity, productivity and communication. As media professor Shelly Palmer wrote in a blog post:\n\n\"As more and more people rely on AI to generate their content, it is easy to imagine a future where the richness of human language and culture erode.\"\n\nCritics argue that relying on AI for tasks traditionally done by humans will undermine the value of human effort and originality, leading to a future where machine-generated content overshadows human output.\n\nThe controversy brings up key questions about the preservation of human skills, and the ethical and social implications of integrating generative AI tools into everyday tasks. The question here is where the line should be drawn between AI and human involvement in content creation, and whether such a dividing line is necessary at all.\n\nAnthropomorphic AI\n\nAI tools are effectively integrated in almost all aspects of our daily activities, from entertainment to financial services.\n\nOver the past few years, generative AI has appeared to become more contextually aware and anthropomorphic, meaning its responses and behaviour are more human-like. This has led more people to integrate the technology into their daily activities and workflows.\n\nMany people, however, are struggling to strike a balance when it comes to using these tools. On the one hand, given enough human oversight, advanced models of ChatGPT and Gemini can deliver cohesive, relevant responses. In addition, the pressure to use these tools is strong, and some people fear that not using them will set them back professionally.\n\nBut, on the other hand, AI-generated content lacks a unique, human touch. Even as prompts improve, there remains a generic quality to AI responses.\n\nTo better understand the implications of AI-generated content on human communication, and the issues that stem from them, it's important to adopt a balanced approach that avoids both uncritical optimism and pessimism. The elaboration likelihood model of persuasion can help us achieve this.\n\nThe nature of persuasion\n\nThe elaboration likelihood model of persuasion suggests there are two routes of persuasion: the central route and the peripheral route.\n\nWhen individuals process information through the central route, they engage in thoughtful and critical evaluation of information. In contrast, the peripheral route involves a superficial assessment based on external cues, rather than the content's quality or relevance.\n\nIn the context of AI-generated content, there is a risk that both creators and recipients will increasingly rely on the peripheral route. For creators, using AI tools might reduce the effort invested in crafting messages, knowing that the technology will handle the details.\n\nFor recipients, the polished nature of AI-generated content might lead to a surface-level engagement without deeper consideration. This superficial engagement could result in the undermining of the quality of communication and the authenticity of human connections.\n\nThis phenomenon is particularly evident in hiring. Generative AI tools can produce cover letters based on job descriptions and resumes, but they often lack the personal touch and genuine passion that human-crafted letters might convey.\n\nAs hiring managers receive an increasing number of AI-generated applications, they are finding it difficult to uncover the true capabilities and motivations of candidates, which is resulting in less-informed hiring decisions.\n\nWhere do we go from here?\n\nThis leaves us at a crossroad. While arguments can be made for the effective integration of AI with human oversight, there is also a significant concern that the perceived value of messages and our communication is diminishing.\n\nIt is increasingly apparent that AI tools are here to stay. Our collective line of inquiry needs to shift towards exploring a state of interdependence, where society can maximize the benefits of these tools while maintaining human autonomy and creativity.\n\nAchieving this balance is challenging and begins with education that emphasizes foundational human capabilities such as writing, reading and critical thinking. Additionally, there should be a focus on developing subject matter expertise to help individuals to better use these tools and extract maximum value.\n\nClarifying the limits of AI integration is equally important. This may involve avoiding AI usage in personal communication, while accepting its role in organizational public communication, such as industry reports where AI can enhance readability and quality.\n\nIt is of timely essence to understand that our collective societal decisions will have significant future impacts. This moment calls for fellow researchers to deepen the exploration of the interdependence between humans and AI, allowing technology to be used in ways that complement and enhance human capabilities, rather than replace them.", "source": {"uri": "theconversation.com", "dataType": "news", "title": "The Conversation"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Project_Gemini", "type": "wiki", "score": 5, "label": {"eng": "Project Gemini"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Sydney", "type": "loc", "score": 5, "label": {"eng": "Sydney"}, "location": {"type": "place", "label": {"eng": "Sydney"}, "country": {"type": "country", "label": {"eng": "Australia"}}}}, {"uri": "http://en.wikipedia.org/wiki/Persuasion", "type": "wiki", "score": 4, "label": {"eng": "Persuasion"}}, {"uri": "http://en.wikipedia.org/wiki/Anthropomorphism", "type": "wiki", "score": 4, "label": {"eng": "Anthropomorphism"}}, {"uri": "http://en.wikipedia.org/wiki/Toronto_Metropolitan_University", "type": "wiki", "score": 3, "label": {"eng": "Toronto Metropolitan University"}}, {"uri": "http://en.wikipedia.org/wiki/Elaboration_likelihood_model", "type": "wiki", "score": 3, "label": {"eng": "Elaboration likelihood model"}}, {"uri": "http://en.wikipedia.org/wiki/The_Conversation_(website)", "type": "org", "score": 3, "label": {"eng": "The Conversation (website)"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 3, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Bard", "type": "wiki", "score": 3, "label": {"eng": "Bard"}}, {"uri": "http://en.wikipedia.org/wiki/Creativity", "type": "wiki", "score": 3, "label": {"eng": "Creativity"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 3, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 3, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/Language", "type": "wiki", "score": 3, "label": {"eng": "Language"}}, {"uri": "http://en.wikipedia.org/wiki/Track_and_field", "type": "wiki", "score": 3, "label": {"eng": "Track and field"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 3, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/United_States", "type": "loc", "score": 3, "label": {"eng": "United States"}, "location": {"type": "country", "label": {"eng": "United States"}}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Human_communication", "type": "wiki", "score": 2, "label": {"eng": "Human communication"}}, {"uri": "http://en.wikipedia.org/wiki/Pessimism", "type": "wiki", "score": 2, "label": {"eng": "Pessimism"}}, {"uri": "http://en.wikipedia.org/wiki/Strike_action", "type": "wiki", "score": 2, "label": {"eng": "Strike action"}}, {"uri": "http://en.wikipedia.org/wiki/Systems_theory", "type": "wiki", "score": 1, "label": {"eng": "Systems theory"}}], "categories": [{"uri": "dmoz/Health/Mental_Health/Self-Help", "label": "dmoz/Health/Mental Health/Self-Help", "wgt": 100}, {"uri": "dmoz/Society/Future", "label": "dmoz/Society/Future", "wgt": 100}, {"uri": "dmoz/Society/Future/Transhumanism", "label": "dmoz/Society/Future/Transhumanism", "wgt": 100}, {"uri": "dmoz/Society/Activism/In_Daily_Life", "label": "dmoz/Society/Activism/In Daily Life", "wgt": 100}, {"uri": "dmoz/Society/Future/Essays", "label": "dmoz/Society/Future/Essays", "wgt": 100}], "image": "https://images.theconversation.com/files/611166/original/file-20240802-17-589clp.jpg?ixlib=rb-4.1.0&rect=11%2C443%2C3982%2C1988&q=45&auto=format&w=1356&h=668&fit=crop", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3333333333333333, "wgt": 123, "relevance": 1}
{"uri": "8259394236", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "04:08:15", "dateTime": "2024-08-05T04:08:15Z", "dateTimePub": "2024-08-05T04:07:11Z", "dataType": "news", "sim": 0.47843137383461, "url": "https://www.securitymagazine.com/articles/100883-ai-security-safeguarding-schools-beyond-surveillance", "title": "AI security: Safeguarding schools beyond surveillance", "body": "To bring surveillance systems up to date, schools are beginning to explore the potential of artificial intelligence.\n\nSurveillance cameras have been a core component of safeguarding schools for decades by extending the capabilities of school security officials, allowing them to monitor activity across school campuses from a centralized location. Recent surveys show that\u202f91% of schools\u202fnow rely on surveillance cameras to support their security efforts.\n\nHowever, as security threats have evolved, surveillance systems have struggled to keep pace. The number of threat events has increased significantly over the past decade, putting much higher demands on security personnel.\n\nIn 2023, for example, there were more than 346\u202fschool shooting incidents\u202fin the United States. By comparison, there were only 34 incidents in 2013.\n\nTo bring surveillance systems up to date, schools are beginning to explore the potential of artificial intelligence. Integrating AI with modern surveillance results in proactive warning systems that strengthen schools' security measures, giving them the capability to address far more than just immediate threats.\n\nTraditional surveillance systems allow security personnel to passively watch as threats unfold, and while they extend the reach of security systems, they don't empower proactive threat detection. AI transforms traditional systems by giving them the capability to proactively analyze, interpret and respond to potential threats in real time by injecting intelligence into existing systems to enhance and fortify the security they can offer.\n\nAutomated weapons detection is one of the key capabilities that AI brings to surveillance. AI systems are trained on vast datasets, empowering sophisticated algorithms that can recognize the visual signatures of virtually any weapon. Size, shape and material composition can reveal the presence of a weapon even before it is visible in its entirety.\n\nAI's advanced visual recognition capabilities also allow for potential threats to be assessed in the context of their surroundings, meaning it won't simply sound the alarm when someone carries any metal object into a classroom. As an intelligent sentinel, AI will first determine if the object is a wrench in the hands of a custodian or a gun in the hands of a potential shooter.\n\nThe capabilities of\u202fAI-driven security\u202fdo not end with automated threat detection. AI empowers a holistic approach to security by identifying and mitigating risks, as the security training provided to AI allows it to detect anomalies in the school environment and monitor the school for signs of weapons as well as any unusual or unexpected behavior that might indicate a safety concern.\n\nFor example, AI can learn the normal traffic patterns in school hallways, allowing it to identify when the movement of a student is normal and when it is suspicious. It can even identify anomalies like doors that are closed when they should be open or lights that are off when they should be on. Rather than simply log this activity as traditional surveillance systems do, AI can identify them as a safety concern and reach out appropriately.\n\nAdvanced training can allow AI to assess the data it gathers through surveillance systems to identify potential weaknesses. If access policies create security vulnerabilities, AI can identify them and make suggestions for improving security. If security policies are being ignored, AI can detect violations and alert security personnel to the need for more effective training.\n\nAdding AI to conventional surveillance systems also improves their capability for facilitating an effective security response. When a threat is detected, AI can trigger notifications to all appropriate personnel, including school security staff, teachers, administrators and any other officials as predetermined by the school's security team.\n\nAI enhances the\u202fsecurity response\u202fin several ways. First, it provides clear communication that is not adversely affected by emotions or unclear thinking. Even for the most seasoned security professional, an active shooter situation can be unnerving. AI is not rattled by a threat, allowing it to quickly and clearly communicate the situation as it is detected.\n\nAI systems also improve security response by providing dynamic video or photos of the threat until it is addressed. This allows security personnel to see exactly what has triggered concern and to track the concern as it moves through the school.\n\nSurveillance will always be a crucial component of school security, but without the advanced capabilities AI integrations provide, traditional surveillance methods will struggle to address the modern threat landscape. AI transforms conventional surveillance into a modern tool that can detect and address the threats that challenge today's school security frameworks.", "source": {"uri": "securitymagazine.com", "dataType": "news", "title": "Security Magazine"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Closed-circuit_television", "type": "wiki", "score": 5, "label": {"eng": "Closed-circuit television"}}, {"uri": "http://en.wikipedia.org/wiki/Surveillance", "type": "wiki", "score": 5, "label": {"eng": "Surveillance"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/United_States", "type": "loc", "score": 3, "label": {"eng": "United States"}, "location": {"type": "country", "label": {"eng": "United States"}}}, {"uri": "http://en.wikipedia.org/wiki/Real-time_computing", "type": "wiki", "score": 2, "label": {"eng": "Real-time computing"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_vision", "type": "wiki", "score": 2, "label": {"eng": "Computer vision"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 2, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Security", "type": "wiki", "score": 2, "label": {"eng": "Security"}}, {"uri": "http://en.wikipedia.org/wiki/Metal", "type": "wiki", "score": 2, "label": {"eng": "Metal"}}, {"uri": "http://en.wikipedia.org/wiki/Active_shooter", "type": "wiki", "score": 1, "label": {"eng": "Active shooter"}}, {"uri": "http://en.wikipedia.org/wiki/Vulnerability_(computing)", "type": "wiki", "score": 1, "label": {"eng": "Vulnerability (computing)"}}], "categories": [{"uri": "dmoz/Computers/Security", "label": "dmoz/Computers/Security", "wgt": 100}, {"uri": "dmoz/Computers/Security/Intrusion_Detection_Systems", "label": "dmoz/Computers/Security/Intrusion Detection Systems", "wgt": 100}, {"uri": "dmoz/Home/Home_Improvement/Safety_and_Security", "label": "dmoz/Home/Home Improvement/Safety and Security", "wgt": 100}, {"uri": "dmoz/Computers/Hacking/Exploits", "label": "dmoz/Computers/Hacking/Exploits", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 57}], "image": "https://www.securitymagazine.com/ext/resources/Issues/2024/08-August/SEC-0824-Strategic-Feat-Slide1-1170x658.jpg?height=418&t=1721921779&width=800", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3333333333333333, "wgt": 122, "relevance": 1}
{"uri": "8259412420", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "04:26:21", "dateTime": "2024-08-05T04:26:21Z", "dateTimePub": "2024-08-05T04:25:37Z", "dataType": "news", "sim": 0.47843137383461, "url": "https://www.digitalnewsasia.com/startups/google-startups-launches-ai-academy-propel-ai-innovation-malaysia-asia", "title": "Google for Startups launches AI Academy to propel AI innovation in", "body": "Aims to gather 20+ AI startups for cross-border innovation, partnerships\n\nGoogle for Startups have announced the launch of AI Academy, a new programme designed to support and accelerate the growth of AI startups across the Asia-Pacific (APAC) region including Malaysia.\n\nAccording to the firm, this programme will bring together more than 20 startups that are developing technologies based on AI, which will not only foster a vibrant AI community within APAC, but also ignite cross-border innovation and partnerships. Additionally, the collaborative environment will encourage the exchange of ideas, expertise, and resources, accelerating the development of cutting-edge AI solutions and establishing APAC as a global hub in AI advancements.\n\nSelected startups will receive:\n\nThe AI Academy is designed to fast-track startups to market by enabling them to build a \"proof of concept\" and product roadmap, rapidly validating and enhancing their AI solutions. By applying Google Cloud tools to their own data, startups will be able to build a \"proof of concept\" and develop a product roadmap for clear and immediate integration into their existing products. This accelerated approach will both speed up their path to success and demonstrate the tangible value of their AI innovations.\n\nApplications are now open and will close on Aug 16, 2024. For more information and to apply, please visit https://startup.google.com/programs/ai-academy/apac/", "source": {"uri": "digitalnewsasia.com", "dataType": "news", "title": "Digital News Asia"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 5, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Asia-Pacific", "type": "loc", "score": 5, "label": {"eng": "Asia-Pacific"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 3, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Malaysia", "type": "loc", "score": 3, "label": {"eng": "Malaysia"}, "location": {"type": "country", "label": {"eng": "Malaysia"}}}, {"uri": "http://en.wikipedia.org/wiki/Proof_of_concept", "type": "wiki", "score": 2, "label": {"eng": "Proof of concept"}}, {"uri": "http://en.wikipedia.org/wiki/Global_city", "type": "wiki", "score": 2, "label": {"eng": "Global city"}}, {"uri": "http://en.wikipedia.org/wiki/Google_Cloud_Platform", "type": "wiki", "score": 1, "label": {"eng": "Google Cloud Platform"}}], "categories": [{"uri": "dmoz/Computers/Human-Computer_Interaction/Companies_and_Consultants", "label": "dmoz/Computers/Human-Computer Interaction/Companies and Consultants", "wgt": 100}, {"uri": "dmoz/Home/Do-It-Yourself", "label": "dmoz/Home/Do-It-Yourself", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 74}], "image": "https://www.digitalnewsasia.com/sites/default/files/styles/social_media_share/public/Google%20Startups.png?itok=MteRu41Z", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "date": "2016-08-", "textStart": 1327, "textEnd": 1333}], "sentiment": 0.4588235294117646, "wgt": 122, "relevance": 1}
{"uri": "8259749612", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "08:57:23", "dateTime": "2024-08-05T08:57:23Z", "dateTimePub": "2024-08-05T08:55:32Z", "dataType": "news", "sim": 0.47843137383461, "url": "https://www.thetidenewsonline.com/2024/08/05/stopping-hiv-infection-by-2030-still-long-way-off-aswhan/", "title": "Stopping HIV Infection By 2030 Still Long Way Off - ASWHAN - :::...The Tide News Online:::...", "body": "Uniport Calls For Inclusion Of AI In Nigeria's Educational System\n\nThe Department of Computer Science, University of Port Harcourt, has advocated for the advancement of Artificial intelligence (Al) in Nigeria's educational system.\n\nThe initiative was highlighted during a National Artificial lntelligence workshop which took place at the University of Port Harcourt, last weekend.\n\nThe workshop was sponsored by the International Development Research Center, Canada, and Swedish International Development Cooperation Agency,SIDA, with funding managed by African Center For Technology Studies (ACTS), under the Artificial lntelligence For Development Africa initiative.\n\nThe Head of Department, Computer Science, at the University of Port Harcout, Dr. Ugochi A. Okengwu, in her opening remarks, emphasized the need to accelerate the advancement of Artificial lntelligence in Nigeria and across Africa.\n\nDr. Okengwu, who is also the branch Co-ordinator of the Organization of Women In Science for the Developing World, Uniport Chapter, said that AI was a revolution and urged the federal government to create an enabling environment ensure its growth.\n\n\"We are trying to see how Al development will be faster in Africa, because Africa is a very crucial place, because we have the population. It is a good ground for a lot of technological advancement to come in.\n\n\"So, Al as we said earlier, it's not just technological advancement, it is a revolution\", she said.\n\nAlso speaking, the Director, Center for Information and Telecommunication Engineering (CITE), at the University of Port Harcourt, Prof. Bourdillon Omijeh, said plans had been concluded to launch a catch-them-young programme for children in primary and secondary schools in few weeks time.\n\nHe, therefore, enjoined the general public to embrace Artificial lntelligence to ensure that Nigerian youths were not left behind in the rapidly advancing world.\n\nEarlier, the Vice Chancellor of the University of Port Harcourt, Professor Owunari A. Georgewill, in his welcome address, had urged the participants to take the workshop seriously, saying the world is rapidly shifting towards AI.\n\nDr. T.P. Singh of Bennett University who delivered the keynote speech, discussed the benefits and challenges of AI.\n\nHe highlighted AI's applications across various fields and addressed some of the challenges it presents.\n\nTonye Lekara from Rivers State gave a technical presentation on AI in health applications. He also covered topics such as AI in health has a lot of setups, role in detecting medical imaging analysis, to detecting cancer, malaria parasites, and other health challenges, its applications in other fields.\n\nAccording to him, AI in health involves using advanced algorithms, hardware systems.\n\nKaggle, fig.1, Humata are AI Assisted Research Tools.\n\nHe also talked about Future Trends and Roles of Government.\n\nA question-and-answer session followed, allowing participants to interact with the facilitators and ask relevant questions, which were addressed comprehensively by the speakers.\n\nThe second technical presentation focused on the application of AI in research, delivered by Ediong Umoh from Nigeria.\n\nHe discussed the importance of AI tools such as plagiarism checkers, reference managers like Zotero, and AI writing assistants like QuillBot and Trinka, Grammar for enhancing research quality and data representation.\n\nThe third technical presentation on AI in agriculture was done by Tonye Lekara.\n\nHe demonstrated how AI could be used to analyze agricultural images using apps like Picture, Pop apps used in teaching farmers how to manage machine and other toolkits such as plantify, plantix used to identify crop, plants, analysis of images for signs of mold, rot, insects and other threats.\n\nSecond question-and-answer session followed, with participants engaging with the lecturer and having their queries addressed.\n\nThe panel session on AI ethics, moderated by Dr. C.B. Marcus, featured Dr. Legbors Barikpoa Emmanuel, Professor Laeticia N. Onyejegbu, and Dr. Ugochi A. Okengwu.\n\nThe panelists who were subjected to thorough questioning on AI ethics, responded adeptly.\n\nProf. Omijeh discussed the topic: \"Embedded AI and Education 4.0,\" explaining how the fourth industrial revolution (4IR) is driven by digital technologies such as AI, machine learning, the Internet of Things, and robotics.\n\nHe encouraged collaboration between the faculties of engineering and computer science to integrate AI into education.\n\nIn his vote of thanks, the Dean of the Faculty of Computing, Professor Laeticia N. Onyejegbu thanked all those that contributed to the success of the workshop.", "source": {"uri": "thetidenewsonline.com", "dataType": "news", "title": "Envato"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Swedish_International_Development_Cooperation_Agency", "type": "wiki", "score": 5, "label": {"eng": "Swedish International Development Cooperation Agency"}}, {"uri": "http://en.wikipedia.org/wiki/University_of_Port_Harcourt", "type": "org", "score": 5, "label": {"eng": "University of Port Harcourt"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Africa", "type": "loc", "score": 5, "label": {"eng": "Africa"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Nigeria", "type": "loc", "score": 5, "label": {"eng": "Nigeria"}, "location": {"type": "country", "label": {"eng": "Nigeria"}}}, {"uri": "http://en.wikipedia.org/wiki/Computer_science", "type": "wiki", "score": 4, "label": {"eng": "Computer science"}}, {"uri": "http://en.wikipedia.org/wiki/Federal_government_of_the_United_States", "type": "org", "score": 3, "label": {"eng": "Federal government of the United States"}}, {"uri": "http://en.wikipedia.org/wiki/Canada", "type": "loc", "score": 3, "label": {"eng": "Canada"}, "location": {"type": "country", "label": {"eng": "Canada"}}}, {"uri": "http://en.wikipedia.org/wiki/Telecommunications", "type": "wiki", "score": 2, "label": {"eng": "Telecommunications"}}, {"uri": "http://en.wikipedia.org/wiki/Chancellor_(education)", "type": "wiki", "score": 2, "label": {"eng": "Chancellor (education)"}}, {"uri": "http://en.wikipedia.org/wiki/Secondary_school", "type": "wiki", "score": 2, "label": {"eng": "Secondary school"}}, {"uri": "http://en.wikipedia.org/wiki/Injunction", "type": "wiki", "score": 2, "label": {"eng": "Injunction"}}, {"uri": "http://en.wikipedia.org/wiki/Medical_imaging", "type": "wiki", "score": 2, "label": {"eng": "Medical imaging"}}, {"uri": "http://en.wikipedia.org/wiki/Rivers_State", "type": "loc", "score": 2, "label": {"eng": "Rivers State"}, "location": {"type": "place", "label": {"eng": "Rivers State"}, "country": {"type": "country", "label": {"eng": "Nigeria"}}}}, {"uri": "http://en.wikipedia.org/wiki/Checkers", "type": "wiki", "score": 1, "label": {"eng": "Checkers"}}, {"uri": "http://en.wikipedia.org/wiki/Internet_of_things", "type": "wiki", "score": 1, "label": {"eng": "Internet of things"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Ethics of artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Kaggle", "type": "org", "score": 1, "label": {"eng": "Kaggle"}}, {"uri": "http://en.wikipedia.org/wiki/Ficus", "type": "wiki", "score": 1, "label": {"eng": "Ficus"}}, {"uri": "http://en.wikipedia.org/wiki/Lecturer", "type": "wiki", "score": 1, "label": {"eng": "Lecturer"}}, {"uri": "http://en.wikipedia.org/wiki/Plagiarism", "type": "wiki", "score": 1, "label": {"eng": "Plagiarism"}}, {"uri": "http://en.wikipedia.org/wiki/Faculty_(division)", "type": "wiki", "score": 1, "label": {"eng": "Faculty (division)"}}, {"uri": "http://en.wikipedia.org/wiki/Robotics", "type": "wiki", "score": 1, "label": {"eng": "Robotics"}}, {"uri": "http://en.wikipedia.org/wiki/Malaria", "type": "wiki", "score": 1, "label": {"eng": "Malaria"}}, {"uri": "http://en.wikipedia.org/wiki/Industrial_Revolution", "type": "wiki", "score": 1, "label": {"eng": "Industrial Revolution"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 1, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Engineering", "type": "wiki", "score": 1, "label": {"eng": "Engineering"}}], "categories": [{"uri": "dmoz/Science", "label": "dmoz/Science", "wgt": 100}, {"uri": "dmoz/Computers/Robotics/Research", "label": "dmoz/Computers/Robotics/Research", "wgt": 100}, {"uri": "dmoz/Computers/Artificial_Intelligence", "label": "dmoz/Computers/Artificial Intelligence", "wgt": 100}, {"uri": "dmoz/Science/Technology/Research_Groups_and_Centers", "label": "dmoz/Science/Technology/Research Groups and Centers", "wgt": 100}, {"uri": "dmoz/Computers/Artificial_Intelligence/Academic_Departments", "label": "dmoz/Computers/Artificial Intelligence/Academic Departments", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 92}], "image": null, "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.1843137254901961, "wgt": 122, "relevance": 1}
{"uri": "8260026511", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "11:53:18", "dateTime": "2024-08-05T11:53:18Z", "dateTimePub": "2024-08-05T11:51:57Z", "dataType": "news", "sim": 0.4745098054409027, "url": "https://mmnews.tv/google-for-startups-opens-ai-academy-in-pakistan/", "title": "Google for Startups opens AI Academy in Pakistan", "body": "Google for Startups has launched its AI Academy in Pakistan and the Asia-Pacific region to support and expedite the growth of businesses in the artificial intelligence sector.\n\nThe new 2024 initiative aims to assist AI entrepreneurs in the Asia-Pacific area, providing faster market access for their AI-based products.\n\nThe program will gather over 20 startups developing AI-based technologies, fostering a vibrant AI community and sparking new cross-border collaborations and discoveries.\n\nSelected firms will receive personalized advice from Google's global AI experts, up to $350,000 in Google Cloud Credit, and opportunities to connect and collaborate with other APAC AI startups.\n\nFarhan S Qureshi, Director of Google Pakistan, stressed the program's significance, stating it reflects Google's dedication to advancing AI development across the Asia-Pacific region.\n\nHe urged local startups to seize the opportunity to enhance their AI solutions and strengthen the ecosystem.\n\nEarlier in May, Google announced plans to establish 50 smart schools in Islamabad, equipped with 30,000 Google for Education IDs, and featuring AI and digital tools for improved collaboration and productivity.", "source": {"uri": "mmnews.tv", "dataType": "news", "title": "MM NEWS"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Asia-Pacific", "type": "loc", "score": 5, "label": {"eng": "Asia-Pacific"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 5, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Startup_company", "type": "wiki", "score": 3, "label": {"eng": "Startup company"}}, {"uri": "http://en.wikipedia.org/wiki/Entrepreneurship", "type": "wiki", "score": 3, "label": {"eng": "Entrepreneurship"}}, {"uri": "http://en.wikipedia.org/wiki/Pakistan", "type": "loc", "score": 3, "label": {"eng": "Pakistan"}, "location": {"type": "country", "label": {"eng": "Pakistan"}}}, {"uri": "http://en.wikipedia.org/wiki/Google_Cloud_Platform", "type": "wiki", "score": 2, "label": {"eng": "Google Cloud Platform"}}, {"uri": "http://en.wikipedia.org/wiki/Google_for_Education", "type": "wiki", "score": 1, "label": {"eng": "Google for Education"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 1, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Islamabad", "type": "loc", "score": 1, "label": {"eng": "Islamabad"}, "location": {"type": "place", "label": {"eng": "Islamabad"}, "country": {"type": "country", "label": {"eng": "Pakistan"}}}}], "categories": [{"uri": "dmoz/Science/Social_Sciences/Geography", "label": "dmoz/Science/Social Sciences/Geography", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 73}], "image": "https://mmnews.tv/wp-content/uploads/2024/05/Google.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.4745098039215687, "wgt": 121, "relevance": 1}
{"uri": "8254425504", "lang": "eng", "isDuplicate": false, "date": "2024-08-01", "time": "14:49:31", "dateTime": "2024-08-01T14:49:31Z", "dateTimePub": "2024-08-01T14:48:54Z", "dataType": "news", "sim": 0.4705882370471954, "url": "https://www.cautiousoptimism.news/p/good-news-for-open-source-ai-as-the", "title": "Good news for open-source AI as the market screams for Fed action", "body": "The debate between closed-source and open-source AI development is one of the most interesting in technology today. Proponents of closed-source AI models contend that it's important to keep their guts private so as to fend off rival international powers who want to surpass domestic technological prowess. Advocates of open-source AI argue that the models will leak anyway, so a more transparent approach will allow the state of the art to move ahead more quickly and ensure robust competition.\n\nYou can already tell by my summary which side I put more stock behind. But no matter what I think, the Biden admin just made lots of folks happy in startup-land by coming out in favor of open-ish AI development", "source": {"uri": "cautiousoptimism.news", "dataType": "news", "title": "cautiousoptimism.news"}, "authors": [{"uri": "alex_wilhelm@cautiousoptimism.news", "name": "Alex Wilhelm", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Proprietary_software", "type": "wiki", "score": 5, "label": {"eng": "Proprietary software"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 4, "label": {"eng": "Open-source software"}}], "categories": [{"uri": "dmoz/Society/Relationships", "label": "dmoz/Society/Relationships", "wgt": 100}, {"uri": "dmoz/Health/Mental_Health/Self-Help", "label": "dmoz/Health/Mental Health/Self-Help", "wgt": 100}, {"uri": "dmoz/Society/Advice", "label": "dmoz/Society/Advice", "wgt": 100}, {"uri": "dmoz/Society/Activism/In_Daily_Life", "label": "dmoz/Society/Activism/In Daily Life", "wgt": 100}, {"uri": "dmoz/Computers/Open_Source/Open_Content", "label": "dmoz/Computers/Open Source/Open Content", "wgt": 100}], "image": "https://substackcdn.com/image/fetch/f_auto,q_auto:best,fl_progressive:steep/https%3A%2F%2Falexwrites.substack.com%2Fapi%2Fv1%2Fpost_preview%2F147236049%2Ftwitter.jpg%3Fversion%3D4", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3490196078431373, "wgt": 120, "relevance": 1}
{"uri": "8259852142", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "10:03:20", "dateTime": "2024-08-05T10:03:20Z", "dateTimePub": "2024-08-05T10:02:37Z", "dataType": "news", "sim": 0.4666666686534882, "url": "https://www.channelnewsasia.com/east-asia/china-anti-spy-agency-warning-artificial-intelligence-tools-national-security-4527141", "title": "'A \"pen\" for many office workers': China's anti-spy agency warns of security risks from AI writing tools", "body": "SINGAPORE: China's anti-spy agency has issued a fresh warning of the security risks posed by artificial intelligence (AI) when handling sensitive or confidential information, taking specific aim at AI writing apps as such tools are increasingly used nationwide.\n\nAccording to the Ministry of State Security on Sunday (Aug 4), there have been cases of sensitive information being leaked in recent years due to the use of online office programmes. These include cloud storage platforms, AI writing tools as well as image or text recognition apps.\n\nThese online office tools are popular methods for getting work done due to their convenience and speed, and have \"become the first choice for many office workers to handle daily (work) affairs\", the ministry pointed out in a notice on its official WeChat account.\n\nIt highlighted AI writing tools, pointing out their utility in producing articles at speed.\n\n\"In recent years, AI writing tools have flourished and have become a 'pen' for many office workers. Articles can be generated simply with the input of specific prompts,\" the ministry noted.\n\nOften used for writing and proofreading, the use of AI chatbots has been gaining traction around the world, including in China.\n\nAccording to a Bloomberg report in May, ByteDance's Doubao is China's most popular AI chatbot, being the most downloaded on Apple's iOS with about 9 million downloads in the year to April. Baidu's counterpart Ernie Bot followed up with 8 million downloads.\n\nData also showed that Doubao had the most monthly active users at more than 4 million a month, Bloomberg reported.\n\nIn its Sunday notice, the Ministry of State Security cautioned that using such AI tools runs the risk of leaking confidential information and state secrets.\n\nThe ministry described a scenario where workers handling sensitive information \"illegally\" input confidential information into AI writing apps to generate articles. They did it to save time, believing there was no risk of a leak as they were only extracting excerpts.\n\nBut the ministry claimed these apps would automatically collect the information entered to train their AI models, and the relevant data could be easily stolen by foreign agencies. It did not identify any specific AI tools, or whether they're homegrown or developed overseas.", "source": {"uri": "channelnewsasia.com", "dataType": "news", "title": "CNA"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/China", "type": "loc", "score": 4, "label": {"eng": "China"}, "location": {"type": "country", "label": {"eng": "China"}}}, {"uri": "http://en.wikipedia.org/wiki/Ministry_of_State_Security_(China)", "type": "wiki", "score": 3, "label": {"eng": "Ministry of State Security (China)"}}, {"uri": "http://en.wikipedia.org/wiki/Cloud_storage", "type": "wiki", "score": 3, "label": {"eng": "Cloud storage"}}, {"uri": "http://en.wikipedia.org/wiki/Confidentiality", "type": "wiki", "score": 3, "label": {"eng": "Confidentiality"}}, {"uri": "http://en.wikipedia.org/wiki/Singapore", "type": "loc", "score": 3, "label": {"eng": "Singapore"}, "location": {"type": "country", "label": {"eng": "Singapore"}}}, {"uri": "http://en.wikipedia.org/wiki/ByteDance", "type": "org", "score": 2, "label": {"eng": "ByteDance"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 2, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/WeChat", "type": "wiki", "score": 2, "label": {"eng": "WeChat"}}, {"uri": "http://en.wikipedia.org/wiki/Bloomberg_L.P.", "type": "org", "score": 2, "label": {"eng": "Bloomberg L.P."}}, {"uri": "http://en.wikipedia.org/wiki/Active_users", "type": "wiki", "score": 1, "label": {"eng": "Active users"}}, {"uri": "http://en.wikipedia.org/wiki/Classified_information", "type": "loc", "score": 1, "label": {"eng": "Classified information"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Baidu", "type": "org", "score": 1, "label": {"eng": "Baidu"}}, {"uri": "http://en.wikipedia.org/wiki/IOS", "type": "wiki", "score": 1, "label": {"eng": "IOS"}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Society/Crime/Theft", "label": "dmoz/Society/Crime/Theft", "wgt": 100}, {"uri": "dmoz/Society/Issues/Fraud", "label": "dmoz/Society/Issues/Fraud", "wgt": 100}, {"uri": "dmoz/Computers/Internet/Abuse", "label": "dmoz/Computers/Internet/Abuse", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 49}], "image": "https://onecms-res.cloudinary.com/image/upload/s--O1G1iAMj--/f_auto,q_auto/c_fill,g_auto,h_676,w_1200/v1/mediacorp/cna/image/2024/06/25/istock-1160694912.jpg?itok=apU3TSGw", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": {"type": "country", "label": {"eng": "China"}}, "extractedDates": [{"amb": false, "imp": true, "date": "2024-08-04", "textStart": 318, "textEnd": 323}], "sentiment": 0.2156862745098038, "wgt": 119, "relevance": 1}
{"uri": "8259389144", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "04:02:34", "dateTime": "2024-08-05T04:02:34Z", "dateTimePub": "2024-08-05T04:02:05Z", "dataType": "news", "sim": 0.4627451002597809, "url": "https://www.ft.com/content/a4979794-2f79-48b8-911b-222f335096d8", "title": "Lloyds hires Amazon Web Services executive as its new AI chief", "body": "Lloyds Banking Group has poached Amazon Web Services executive Rohit Dhawan to head its artificial intelligence strategy, a new role the UK high-street bank is creating as part of its digitisation efforts.\n\nLloyds on Monday said it had hired Dhawan as its first group director of AI and advanced analytics.\n\nDhawan, who has a PhD in AI from the University of Sydney, previously headed AWS's data and AI strategy in the Asia-Pacific region. He will report to Lloyds' chief data and analytics officer Ranil Boteju.\n\nThe move comes as banks are looking to roll out AI and machine learning on a wider scale to make productivity gains and reduce costs. Some experts have warned that incumbents have been slow to implement the technology due to regulatory fears. Morgan Stanley was one of the first lenders to appoint a group head of AI in March.\n\n\"Rohit's appointment is a significant boost for the strategic development of AI technology and capabilities within Lloyds Banking Group,\" said Boteju. \"Rohit will work across the business to further integrate AI outcomes into business priorities, helping us to scale AI in a consistent way and deliver against our strategy.\"\n\nThe bank said Dhawan would be tasked with supervising the integration of AI into customer and operational processes as well as creating a new data and AI function within the bank.\n\nHe would also oversee an \"AI Centre of Excellence\" comprised of experts in data science, behavioural science, machine learning engineering and AI ethics, the bank said.\n\n\"It's a privilege to join Lloyds Banking Group, and I'm excited to work for an organisation undergoing one of the largest transformations in financial services and look at how we can transform the way we use data and tech to respond to changing customer needs,\" said Dhawan.\n\nThe bank is more than two years into implementing a strategic plan that has involved reviewing thousands of middle-management positions in an effort to digitise its operations and improve returns.\n\nLloyds said it had recruited 1,500 technology and data specialists this year and that it was trialling 50 AI use cases to help deliver quicker customer support, improve its chatbots and detect early warning signs of fraud.\n\nThe group said it uses machine learning algorithms to help triage and prioritise customers' calls and for income verification when customers take out mortgages, which it said reduced the process from three weeks to a few seconds.\n\nLloyds, which also has an insurance and pensions arm, also used AI to register insurance claims following storms in January, which it said freed up time for urgent phone calls from customers.", "source": {"uri": "ft.com", "dataType": "news", "title": "Financial Times News"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Amazon_Web_Services", "type": "org", "score": 5, "label": {"eng": "Amazon Web Services"}}, {"uri": "http://en.wikipedia.org/wiki/Lloyds_Banking_Group", "type": "org", "score": 5, "label": {"eng": "Lloyds Banking Group"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Analytics", "type": "wiki", "score": 4, "label": {"eng": "Analytics"}}, {"uri": "http://en.wikipedia.org/wiki/Digitization", "type": "wiki", "score": 3, "label": {"eng": "Digitization"}}, {"uri": "http://en.wikipedia.org/wiki/University_of_Sydney", "type": "org", "score": 3, "label": {"eng": "University of Sydney"}}, {"uri": "http://en.wikipedia.org/wiki/Doctor_of_Philosophy", "type": "wiki", "score": 3, "label": {"eng": "Doctor of Philosophy"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 3, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 3, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Asia-Pacific", "type": "loc", "score": 3, "label": {"eng": "Asia-Pacific"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/United_Kingdom", "type": "loc", "score": 3, "label": {"eng": "United Kingdom"}, "location": {"type": "country", "label": {"eng": "United Kingdom"}}}, {"uri": "http://en.wikipedia.org/wiki/Data_science", "type": "wiki", "score": 2, "label": {"eng": "Data science"}}, {"uri": "http://en.wikipedia.org/wiki/Morgan_Stanley", "type": "org", "score": 2, "label": {"eng": "Morgan Stanley"}}, {"uri": "http://en.wikipedia.org/wiki/Chatbot", "type": "wiki", "score": 1, "label": {"eng": "Chatbot"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Ethics of artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Engineering", "type": "wiki", "score": 1, "label": {"eng": "Engineering"}}, {"uri": "http://en.wikipedia.org/wiki/Fraud", "type": "wiki", "score": 1, "label": {"eng": "Fraud"}}, {"uri": "http://en.wikipedia.org/wiki/Mortgage_loan", "type": "wiki", "score": 1, "label": {"eng": "Mortgage loan"}}, {"uri": "http://en.wikipedia.org/wiki/Pension", "type": "wiki", "score": 1, "label": {"eng": "Pension"}}, {"uri": "http://en.wikipedia.org/wiki/Insurance", "type": "wiki", "score": 1, "label": {"eng": "Insurance"}}, {"uri": "http://en.wikipedia.org/wiki/Financial_services", "type": "wiki", "score": 1, "label": {"eng": "Financial services"}}], "categories": [{"uri": "dmoz/Society/Government/Finance", "label": "dmoz/Society/Government/Finance", "wgt": 100}, {"uri": "dmoz/Business/Financial_Services/Banking_Services", "label": "dmoz/Business/Financial Services/Banking Services", "wgt": 100}, {"uri": "dmoz/Business/Financial_Services/Holding_Companies", "label": "dmoz/Business/Financial Services/Holding Companies", "wgt": 100}, {"uri": "dmoz/Business/Financial_Services/Employment", "label": "dmoz/Business/Financial Services/Employment", "wgt": 100}, {"uri": "dmoz/Business/Investing/Payment_Associations", "label": "dmoz/Business/Investing/Payment Associations", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 80}], "image": "https://www.ft.com/__origami/service/image/v2/images/raw/https%3A%2F%2Fwww.ft.com%2F__origami%2Fservice%2Fimage%2Fv2%2Fimages%2Fraw%2Fhttps%253A%252F%252Fd1e00ek4ebabms.cloudfront.net%252Fproduction%252Fc999d4e8-7ab0-4669-8dbe-f755447e1d7f.jpg%3Fsource%3Dnext-article%26fit%3Dscale-down%26quality%3Dhighest%26width%3D700%26dpr%3D1?source=next-opengraph&fit=scale-down&width=900", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.2078431372549019, "wgt": 118, "relevance": 1}
{"uri": "2024-08-444080775", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "05:07:23", "dateTime": "2024-08-05T05:07:23Z", "dateTimePub": "2024-08-05T05:00:24Z", "dataType": "news", "sim": 0.4627451002597809, "url": "https://uk.finance.yahoo.com/news/monitoring-workers-ai-wont-boost-performance-050024289.html", "title": "Why monitoring workers with AI won't boost performance", "body": "Ask an employee about what they think about artificial intelligence (AI), and more likely than not, they'll tell you they're afraid of losing their job. And while research suggests more employers are turning to AI, they're not using it to replace people. Instead, they're using it to watch them.\n\nWorkplace surveillance technology took off during the pandemic as more people began to work remotely. Now, a number of high-profile employers, including Starbucks (SBUX), Walmart (WMT) and AstraZeneca (AZN.L), are among those using AI to keep tabs on messages sent between employees.\n\nSurveillance can include monitoring of emails, files and webcams on work computers, as well as tracking how much someone is typing. Some programmes log keystrokes, take surreptitious screenshots and even activate employees' webcams without them knowing.\n\nAccording to a TUC poll conducted in 2023, at least 60% of UK workers believe they have been subjected to surveillance and monitoring while working.\n\nKnowing you're being watched can have negative psychological effects, such as anxiety and stress. And new research suggests that AI -- more so than human monitoring -- can make people want to quit their jobs. Rachel Schlund and Emily Zitek, researchers from Cornell University, found that using AI to monitor employees' behaviour and productivity can lead them to complain more, be less productive and want to quit -- unless the technology can be framed as supporting their development.\n\nRead more: How to manage summer holidays as a working parent\n\nProblems can occur when AI monitoring is used to evaluate an employee's performance because it may not provide enough context. If AI is measuring productivity by keystrokes, an employee who isn't typing because they're in meetings, researching or even listening to training sessions may be unfairly penalised. Often, it's hard to measure how well someone is performing simply by tracking their output.\n\n\"Employees may express concerns about AI's ability to evaluate their performance accurately,\" explains Schlund. \"They may worry that AI might misinterpret their behaviour or lack the human discretion needed to understand context, leading to potentially unfair evaluations.\"\n\nThe negative connotations surrounding AI can also affect how we feel about it. A lot of the discourse around AI is centred on the replacement of humans and ultimately, job losses.\n\n\"There is a fear in some fields that AI might put people out of work, which could cause some other general negative views of AI in the workplace in certain contexts,\" says Schlund.\n\nAlso, monitoring employees can undermine autonomy and make an employee feel like they aren't trusted. A Danish study of more than 4,000 people found a positive association between job autonomy -- being able to work independently -- and psychological wellbeing.\n\nRead more: What is time optimism and why are more of us falling prey to it at work?\n\nMeanwhile, as worker surveillance has increased, so have feelings of distrust and low morale among workers. It can feel ethically murky, especially if an employee isn't aware they are being watched. And this invasion of privacy can have a negative effect on job satisfaction, happiness, and productivity.\n\n\"What is new about AI surveillance is that workers are sometimes not aware of it, or how the data collected is being used,\" says Professor Carl Benedikt Frey, future-of-work director at the Oxford Martin School, Oxford University. \"And in many instances, monitoring might happen in our homes and environments we consider to be private. We can be monitored around the clock, and around the world, regardless of where we are and what we do.\"\n\nSimply using AI to make sure people are being productive can backfire as it can lead to presenteeism. According to a survey by Express VPN, 38% of employees feel more pressure to be actively online than doing actual productive work. A fifth said they felt dehumanised and more than a quarter said they felt unappreciated and resentful towards their employer.\n\nOne of the key problems is that workers don't always know how the data is being used. There are many legitimate reasons why an employer may choose to monitor workers, for example, to ensure people are complying with company policies or to protect sensitive information.\n\nIndeed, Schlund highlights that monitoring can be helpful -- and people are more receptive to it -- if it is used in an assistive capacity, like how a smartwatch tracks steps to help people reach daily fitness goals.\n\nRead more: Why 'mouse jiggling' is a symptom of a bigger work problem\n\nYet research by Resume Now found that two-thirds of employees have some fears around AI tech. \"It can also foster distrust among employees, especially if there is a lack of transparency about how the monitoring is being conducted and how the data may be utilised to analyse performance and work tasks,\" says Heather O'Neill, career expert at Resume Now.\n\n\"This lack of transparency can lead employees to feel like they are under constant scrutiny without a basic understanding of how AI may help each individual employee.\"\n\nAlso, relying solely on AI can lead employers to overlook the human problems that contribute to low productivity, says Sophie O'Brien, founder of Pollen Careers.\n\n\"If an employee isn't as productive, then a human manager can delve a little deeper into why that might be, are they feeling debilitated by stress or do they have something more personal going on? There's room for context with humans, which seems to be missing from AI monitoring software,\" she says.\n\n\"Personally, I think it's more effective to give employees the independence and responsibility to answer for themselves. Let them take ownership and responsibility for their roles. I think it's also important for their development to take responsibility for their own workload and how they get work done. After all, they're adults and should be treated as such.\"", "source": {"uri": "uk.finance.yahoo.com", "dataType": "news", "title": "Yahoo! Finance"}, "authors": [{"uri": "lydia_smith@uk.finance.yahoo.com", "name": "Lydia Smith", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Surveillance", "type": "wiki", "score": 5, "label": {"eng": "Surveillance"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Webcam", "type": "wiki", "score": 4, "label": {"eng": "Webcam"}}, {"uri": "http://en.wikipedia.org/wiki/Productivity", "type": "wiki", "score": 4, "label": {"eng": "Productivity"}}, {"uri": "http://en.wikipedia.org/wiki/Remote_work", "type": "wiki", "score": 3, "label": {"eng": "Remote work"}}, {"uri": "http://en.wikipedia.org/wiki/Keystroke_logging", "type": "wiki", "score": 3, "label": {"eng": "Keystroke logging"}}, {"uri": "http://en.wikipedia.org/wiki/Autonomy", "type": "wiki", "score": 3, "label": {"eng": "Autonomy"}}, {"uri": "http://en.wikipedia.org/wiki/Screenshot", "type": "wiki", "score": 3, "label": {"eng": "Screenshot"}}, {"uri": "http://en.wikipedia.org/wiki/Starbucks", "type": "org", "score": 3, "label": {"eng": "Starbucks"}}, {"uri": "http://en.wikipedia.org/wiki/AstraZeneca", "type": "org", "score": 3, "label": {"eng": "AstraZeneca"}}, {"uri": "http://en.wikipedia.org/wiki/Walmart", "type": "org", "score": 3, "label": {"eng": "Walmart"}}, {"uri": "http://en.wikipedia.org/wiki/Cornell_University", "type": "org", "score": 3, "label": {"eng": "Cornell University"}}, {"uri": "http://en.wikipedia.org/wiki/Psychology", "type": "wiki", "score": 3, "label": {"eng": "Psychology"}}, {"uri": "http://en.wikipedia.org/wiki/Computer", "type": "wiki", "score": 3, "label": {"eng": "Computer"}}, {"uri": "http://en.wikipedia.org/wiki/Anxiety", "type": "wiki", "score": 3, "label": {"eng": "Anxiety"}}, {"uri": "http://en.wikipedia.org/wiki/United_Kingdom", "type": "loc", "score": 3, "label": {"eng": "United Kingdom"}, "location": {"type": "country", "label": {"eng": "United Kingdom"}}}, {"uri": "http://en.wikipedia.org/wiki/Right_to_privacy", "type": "wiki", "score": 2, "label": {"eng": "Right to privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Job_satisfaction", "type": "wiki", "score": 2, "label": {"eng": "Job satisfaction"}}, {"uri": "http://en.wikipedia.org/wiki/University_of_Oxford", "type": "org", "score": 2, "label": {"eng": "University of Oxford"}}, {"uri": "http://en.wikipedia.org/wiki/Denmark", "type": "loc", "score": 2, "label": {"eng": "Denmark"}, "location": {"type": "country", "label": {"eng": "Denmark"}}}, {"uri": "http://en.wikipedia.org/wiki/Carl_Benedikt_Frey", "type": "person", "score": 1, "label": {"eng": "Carl Benedikt Frey"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_mouse", "type": "wiki", "score": 1, "label": {"eng": "Computer mouse"}}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 1, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Independence", "type": "wiki", "score": 1, "label": {"eng": "Independence"}}, {"uri": "http://en.wikipedia.org/wiki/Physical_fitness", "type": "wiki", "score": 1, "label": {"eng": "Physical fitness"}}, {"uri": "http://en.wikipedia.org/wiki/Smartwatch", "type": "wiki", "score": 1, "label": {"eng": "Smartwatch"}}, {"uri": "http://en.wikipedia.org/wiki/Virtual_private_network", "type": "wiki", "score": 1, "label": {"eng": "Virtual private network"}}, {"uri": "http://en.wikipedia.org/wiki/Software", "type": "wiki", "score": 1, "label": {"eng": "Software"}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 26}, {"uri": "dmoz/Computers/Software/Human_Resources", "label": "dmoz/Computers/Software/Human Resources", "wgt": 22}, {"uri": "dmoz/Business/Human_Resources", "label": "dmoz/Business/Human Resources", "wgt": 24}, {"uri": "dmoz/Business/Human_Resources/Employee_Relations", "label": "dmoz/Business/Human Resources/Employee Relations", "wgt": 30}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 24}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 85}], "image": "https://s.yimg.com/ny/api/res/1.2/l72_H7UkIrLFMtYwj4d9Ew--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD05MDA7Y2Y9d2VicA--/https://s.yimg.com/os/creatr-uploaded-images/2024-07/29549de0-4e56-11ef-93fb-ce0c37cd2fff", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.01960784313725483, "wgt": 118, "relevance": 1}
{"uri": "8259807759", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "09:34:29", "dateTime": "2024-08-05T09:34:29Z", "dateTimePub": "2024-08-05T09:33:41Z", "dataType": "news", "sim": 0.4470588266849518, "url": "https://finance.yahoo.com/news/wall-street-will-support-heavy-ai-spending-as-long-as-everything-else-is-going-great-093003176.html", "title": "Wall Street will support heavy AI spending as long as everything else is going great", "body": "Sifting through the financial wreckage of last week's pullback illuminates an evolution in the AI trade.\n\nAs Big Tech giants reported results this earnings season, Wall Street didn't mind heavy AI spending, but with one key caveat: Everything else in the business had to be humming along.\n\nThe big winner of this shift was Meta (META), with its CEO Mark Zuckerberg -- fully embracing his post-metaverse, gold chain glow-up -- showing that investors won't automatically shy away from massive investments with an uncertain future.\n\n\"While we do not intend to provide any quantitative guidance for 2025 until the fourth quarter call, we expect infrastructure costs will be a significant driver of expense growth next year,\" CFO Susan Li said in a statement.\n\nThe warning of bigger AI outlays didn't deter Wall Street.\n\nThat's because Zuckerberg and company delivered on the top and bottom lines, flashing financial strength even as they pushed the tech world's boundaries for capital expenditures. Revenue grew 22% in the second quarter and income grew 58%.\n\nAnd despite losses at its Reality Labs segment reaching $4.5 billion during the quarter, this spending fell to 31% from almost 40% as a share of its total income from operations.\n\nAs Zuckerberg told analysts on a conference call last week, \"We are in the fortunate position where the strong results that we're seeing in our core products and business give us the opportunity to make deep investments for the future. And I plan to fully seize that opportunity.\"\n\nBut as soon as tech companies confessed some weakness in their core operations, that's when the trouble started. And Meta's peers revealed the flip side of that dynamic.\n\nReactions to earnings from Alphabet (GOOG, GOOGL), Microsoft (MSFT), and Amazon (AMZN) showed AI investments can become a liability when key business lines fail to meet expectations.\n\nThursday's report from Amazon, which disclosed a weaker sales and profit outlook, wrapped a wave of Big Tech results that highlighted impatience over massive AI spending.\n\nCloud rival and AI competitor Microsoft (MSFT) beat expectations on the top and bottom lines but missed on cloud revenue, sending shares lower. Prior to that disappointment, Google parent Alphabet posted lower-than-expected YouTube ad revenue, which also sent investors fleeing.\n\nThe key difference -- as the broader market contends with last week's bruising jobs report -- is that Facebook's parent company dazzled at the basics, making its outsized spending seem like an ambitious proposition instead of a misguided adventure.\n\nFor Alphabet CEO Sundar Pichai, AI spending is necessary for such a promising, long-term bet. Underinvesting, in his view, is the riskier path, since the downside is falling behind while the rest of the industry and the world transforms.\n\nBut investors and analysts are no longer taking daring AI plans at face value.\n\nIronically, Facebook's outlandish pivot to the metaverse several years ago serves as a cautionary tale -- in 2022, Meta stock fell over 60%.\n\nSkeptics liken the recent frenzy over generative AI to Zuckerberg's prior pet project, which also cost a lot of money and dragged the company's share price into deep water. Wedbush analysts, standing in for AI bulls, say the analogy doesn't fit. They see AI development as a genuine inflection point.\n\n\"Is accelerated capex a good or bad thing?\" the firm wrote in a note to clients on Friday. \"We strongly contrast this is not Meta/Zuckerberg spending on metaverse from 2 years ago, instead this is an AI arms race taking place in the US, China, and around the globe for building out the enterprise and consumer AI ecosystem.\"\n\nZuckerberg appears to have learned his lesson, sticking his neck out knowing he's on solid footing with an unstoppable ads machine.\n\nFor everyone else talking up their big, expensive AI plans, Wall Street's message is more circumspect: We'll believe you, but show us the money in the meantime.\n\nHamza Shaban is a reporter for Yahoo Finance covering markets and the economy. Follow Hamza on X @hshaban.\n\nClick here for the latest technology news that will impact the stock market", "source": {"uri": "finance.yahoo.com", "dataType": "news", "title": "Yahoo! Finance"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Mark_Zuckerberg", "type": "person", "score": 5, "label": {"eng": "Mark Zuckerberg"}}, {"uri": "http://en.wikipedia.org/wiki/Big_Tech", "type": "wiki", "score": 4, "label": {"eng": "Big Tech"}}, {"uri": "http://en.wikipedia.org/wiki/Wall_Street", "type": "wiki", "score": 4, "label": {"eng": "Wall Street"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 3, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/Alphabet_Inc.", "type": "org", "score": 3, "label": {"eng": "Alphabet Inc."}}, {"uri": "http://en.wikipedia.org/wiki/Amazon_(company)", "type": "org", "score": 3, "label": {"eng": "Amazon (company)"}}, {"uri": "http://en.wikipedia.org/wiki/Evolution", "type": "wiki", "score": 3, "label": {"eng": "Evolution"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 3, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_financial_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief financial officer"}}, {"uri": "http://en.wikipedia.org/wiki/Revenue", "type": "wiki", "score": 3, "label": {"eng": "Revenue"}}, {"uri": "http://en.wikipedia.org/wiki/Chief_executive_officer", "type": "wiki", "score": 3, "label": {"eng": "Chief executive officer"}}, {"uri": "http://en.wikipedia.org/wiki/Gold", "type": "wiki", "score": 3, "label": {"eng": "Gold"}}, {"uri": "http://en.wikipedia.org/wiki/Reality_Labs", "type": "wiki", "score": 2, "label": {"eng": "Reality Labs"}}, {"uri": "http://en.wikipedia.org/wiki/Capital_expenditure", "type": "wiki", "score": 2, "label": {"eng": "Capital expenditure"}}, {"uri": "http://en.wikipedia.org/wiki/Cloud_computing", "type": "wiki", "score": 2, "label": {"eng": "Cloud computing"}}, {"uri": "http://en.wikipedia.org/wiki/Facebook", "type": "org", "score": 2, "label": {"eng": "Facebook"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 2, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/YouTube", "type": "wiki", "score": 2, "label": {"eng": "YouTube"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 1, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence_arms_race", "type": "wiki", "score": 1, "label": {"eng": "Artificial intelligence arms race"}}, {"uri": "http://en.wikipedia.org/wiki/Metaverse", "type": "wiki", "score": 1, "label": {"eng": "Metaverse"}}, {"uri": "http://en.wikipedia.org/wiki/Sundar_Pichai", "type": "person", "score": 1, "label": {"eng": "Sundar Pichai"}}, {"uri": "http://en.wikipedia.org/wiki/Yahoo!_Finance", "type": "wiki", "score": 1, "label": {"eng": "Yahoo! Finance"}}, {"uri": "http://en.wikipedia.org/wiki/Analogy", "type": "wiki", "score": 1, "label": {"eng": "Analogy"}}, {"uri": "http://en.wikipedia.org/wiki/Adventure_game", "type": "wiki", "score": 1, "label": {"eng": "Adventure game"}}, {"uri": "http://en.wikipedia.org/wiki/Ecosystem", "type": "wiki", "score": 1, "label": {"eng": "Ecosystem"}}, {"uri": "http://en.wikipedia.org/wiki/Stock_market", "type": "wiki", "score": 1, "label": {"eng": "Stock market"}}, {"uri": "http://en.wikipedia.org/wiki/China", "type": "loc", "score": 1, "label": {"eng": "China"}, "location": {"type": "country", "label": {"eng": "China"}}}], "categories": [{"uri": "dmoz/Business/Investing/Stocks_and_Bonds", "label": "dmoz/Business/Investing/Stocks and Bonds", "wgt": 100}, {"uri": "dmoz/Society/Issues/Business", "label": "dmoz/Society/Issues/Business", "wgt": 100}, {"uri": "dmoz/Business/Opportunities/Opposing_Views", "label": "dmoz/Business/Opportunities/Opposing Views", "wgt": 100}, {"uri": "dmoz/Home/Personal_Finance/Investing", "label": "dmoz/Home/Personal Finance/Investing", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 62}], "image": "https://s.yimg.com/ny/api/res/1.2/GLoC4BqEJXf.6zVUldlg.Q--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDI7Y2Y9d2VicA--/https://s.yimg.com/os/creatr-uploaded-images/2024-08/3e8a7eb0-50f8-11ef-bfed-8c56a996e8ac", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.2784313725490195, "wgt": 114, "relevance": 1}
{"uri": "8259815337", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "09:39:12", "dateTime": "2024-08-05T09:39:12Z", "dateTimePub": "2024-08-05T09:38:46Z", "dataType": "news", "sim": 0.4470588266849518, "url": "https://www.fnr.lu/research-with-impact-fnr-highlight/spotlight-on-young-researchers-artificial-intelligence-for-the-digitalisation-of-courts/", "title": "Spotlight on Young Researchers: Artificial Intelligence for the Digitalisation of Courts", "body": "The field of Artificial Intelligence (AI) and Law is increasingly gaining interest due to the introduction of AI applications in our everyday lives, including systems for digital governance. Legal researchers have been examining the use of AI systems by state institutions to process citizens' information for various purposes, including tax administration, social benefits distribution, and crime control. Research has highlighted the impact of the processing of citizens' data through AI systems on privacy and personal data protection. However, the automation of the justice sector through AI systems and its effects on access to justice have not received equal attention.\n\nKalliopi Terzidou, Doctoral Researcher at the Department of Law of University of Luxembourg, examines how AI can help citizens access an independent and impartial justice system.\n\nThe scope of her research covers all EU Member States, where rule of law, access to justice, and the right to a fair trial constitute fundamental principles in the respective legal systems. Citizens must be able to stay informed on laws and decisions that affect their rights and obligations and must have an effective opportunity to initiate and participate in court proceedings.", "source": {"uri": "fnr.lu", "dataType": "news", "title": "FNR - Luxembourg National Research Fund"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Personal_data", "type": "wiki", "score": 2, "label": {"eng": "Personal data"}}, {"uri": "http://en.wikipedia.org/wiki/Automation", "type": "wiki", "score": 2, "label": {"eng": "Automation"}}, {"uri": "http://en.wikipedia.org/wiki/Welfare", "type": "wiki", "score": 2, "label": {"eng": "Welfare"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/University_of_Luxembourg", "type": "org", "score": 1, "label": {"eng": "University of Luxembourg"}}, {"uri": "http://en.wikipedia.org/wiki/Right_to_a_fair_trial", "type": "wiki", "score": 1, "label": {"eng": "Right to a fair trial"}}, {"uri": "http://en.wikipedia.org/wiki/Rule_of_law", "type": "wiki", "score": 1, "label": {"eng": "Rule of law"}}, {"uri": "http://en.wikipedia.org/wiki/Research", "type": "wiki", "score": 1, "label": {"eng": "Research"}}, {"uri": "http://en.wikipedia.org/wiki/Member_state_of_the_European_Union", "type": "wiki", "score": 1, "label": {"eng": "Member state of the European Union"}}], "categories": [{"uri": "dmoz/Society/Law", "label": "dmoz/Society/Law", "wgt": 100}, {"uri": "dmoz/Society/Law/Legal_Information", "label": "dmoz/Society/Law/Legal Information", "wgt": 100}, {"uri": "dmoz/Society/Law/Products", "label": "dmoz/Society/Law/Products", "wgt": 100}], "image": "https://www.fnr.lu/wp-content/uploads/2024/08/AdobeStock_757635178-300x169.jpeg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.5450980392156863, "wgt": 114, "relevance": 1}
{"uri": "8259618551", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "07:27:00", "dateTime": "2024-08-05T07:27:00Z", "dateTimePub": "2024-08-05T07:25:32Z", "dataType": "news", "sim": 0.4431372582912445, "url": "https://kuenselonline.com/ai-dilemma-balancing-tradition-and-technology/", "title": "AI dilemma: Balancing tradition and technology", "body": "Bhutan was recently ranked the top country to use ChatGPT, with approximately 15.96 percent of its population using the Artificial Intelligence (AI) tool, according to an analysis by Coinjournal.net.\n\nSpeaking at a session on 'Preservation of human intelligence in the age of AI' yesterday at Bhutan Echoes:Drukyul Literature and Arts festival at the Royal University of Bhutan, the Founder of Curiouser.AI, Sonam Pelden, addressed the growing intersection of artificial intelligence and human intelligence.\n\nCuriouser.AI, unlike ChatGPT, is an AI tool designed to enhance human capabilities by encouraging exploration through questions rather than providing direct answers.\n\nDuring the session, Sonam Pelden stressed on the importance of human involvement in shaping AI and explained that the quality of AI's output is intrinsically tied to the data it is trained on.\n\n\"Though it's called artificial intelligence, it is created, built, and deployed by people,\" she said. \"Therefore, it matters who these people are and whether they bring a diverse range of perspectives and experiences to their work,\" she said.\n\nShe said that AI, at its core, lacks inherent biases but can mimic its surroundings like a parrot. This issue is exacerbated by the dominance of white male engineers in the AI field, which can lead to the technology reflecting their biases.\n\n\"If they are the ones teaching AI how to think and understand the world, the technology they create will reflect their blind spots and their biases, therefore making the technology less effective and our society less equal,\" she added.\n\nSonam Pelden also highlighted the issue of self-censorship in Bhutan, which has contributed to a perception that Bhutan is isolated from the global community. She challenged this notion by pointing out that Bhutanese people use American cell phones, drive Japanese cars, and engage with Chinese social media apps.\n\n\"If we really want to debate what is authentically Bhutanese, we must acknowledge that these elements are not traditionally Bhutanese either,\" she said.\n\nShe argued that embracing modernity rather than clinging on outdated traditions is counterproductive.\n\nDuring the session, she also demonstrated a biased Twitter thread response generated by ChatGPT on the topic of justice for Palestine and Israel. This example highlighted the potential for AI to spread disinformation and erode public trust in technology.\n\nShe shared that AI threatens free expression by supercharging the dissemination of disinformation leading to people losing trust in technology altogether.\n\nSonam Pelden highlighted that technology overlooks the needs of certain cultures and societies altogether. She attributed this to self-interest and a reluctance to abandon the views that they are familiar with, making it challenging to determine whose values should be prioritised in technology development.\n\nShe warned of the potential negative impact of AI on future generations, particularly the risk of diminishing cognitive abilities due to overreliance on tools like ChatGPT. This could hinder the development of critical thinking and problem-solving skills, she added.\n\nShe emphasised the importance of maintaining human control over AI, if not, it could lead to technology shaping human identity and values. \"And if this current trend continues, we will soon reach a point where humans will humbly wait for an algorithm to tell them what to do and how to think,\" she said.\n\nShe said that preserving Bhutanese identity in the age of AI requires maintaining unique human qualities by ensuring that AI systems, which are trained on diverse data, can recognise and appreciate multiple forms of beauty and value.", "source": {"uri": "kuenselonline.com", "dataType": "news", "title": "Kuensel"}, "authors": [{"uri": "bhutan_s_daily_newspaper@kuenselonline.com", "name": "Bhutan's Daily Newspaper", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 5, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Intelligence", "type": "wiki", "score": 5, "label": {"eng": "Intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Bhutan", "type": "loc", "score": 5, "label": {"eng": "Bhutan"}, "location": {"type": "country", "label": {"eng": "Bhutan"}}}, {"uri": "http://en.wikipedia.org/wiki/Royal_University_of_Bhutan", "type": "org", "score": 3, "label": {"eng": "Royal University of Bhutan"}}, {"uri": "http://en.wikipedia.org/wiki/Intersectionality", "type": "wiki", "score": 3, "label": {"eng": "Intersectionality"}}, {"uri": "http://en.wikipedia.org/wiki/Demographics_of_Bhutan", "type": "wiki", "score": 2, "label": {"eng": "Demographics of Bhutan"}}, {"uri": "http://en.wikipedia.org/wiki/Self-censorship", "type": "wiki", "score": 2, "label": {"eng": "Self-censorship"}}, {"uri": "http://en.wikipedia.org/wiki/Disinformation", "type": "wiki", "score": 2, "label": {"eng": "Disinformation"}}, {"uri": "http://en.wikipedia.org/wiki/Japanese_language", "type": "wiki", "score": 2, "label": {"eng": "Japanese language"}}, {"uri": "http://en.wikipedia.org/wiki/Perception", "type": "wiki", "score": 2, "label": {"eng": "Perception"}}, {"uri": "http://en.wikipedia.org/wiki/Mobile_phone", "type": "wiki", "score": 2, "label": {"eng": "Mobile phone"}}, {"uri": "http://en.wikipedia.org/wiki/Social_media", "type": "wiki", "score": 2, "label": {"eng": "Social media"}}, {"uri": "http://en.wikipedia.org/wiki/United_States", "type": "loc", "score": 2, "label": {"eng": "United States"}, "location": {"type": "country", "label": {"eng": "United States"}}}, {"uri": "http://en.wikipedia.org/wiki/China", "type": "loc", "score": 2, "label": {"eng": "China"}, "location": {"type": "country", "label": {"eng": "China"}}}, {"uri": "http://en.wikipedia.org/wiki/Self", "type": "wiki", "score": 1, "label": {"eng": "Self"}}, {"uri": "http://en.wikipedia.org/wiki/Modernity", "type": "wiki", "score": 1, "label": {"eng": "Modernity"}}, {"uri": "http://en.wikipedia.org/wiki/Critical_thinking", "type": "wiki", "score": 1, "label": {"eng": "Critical thinking"}}, {"uri": "http://en.wikipedia.org/wiki/Cognition", "type": "wiki", "score": 1, "label": {"eng": "Cognition"}}, {"uri": "http://en.wikipedia.org/wiki/Problem_solving", "type": "wiki", "score": 1, "label": {"eng": "Problem solving"}}, {"uri": "http://en.wikipedia.org/wiki/Algorithm", "type": "wiki", "score": 1, "label": {"eng": "Algorithm"}}, {"uri": "http://en.wikipedia.org/wiki/Freedom_of_speech", "type": "wiki", "score": 1, "label": {"eng": "Freedom of speech"}}, {"uri": "http://en.wikipedia.org/wiki/Twitter", "type": "org", "score": 1, "label": {"eng": "Twitter"}}, {"uri": "http://en.wikipedia.org/wiki/Israel", "type": "loc", "score": 1, "label": {"eng": "Israel"}, "location": {"type": "country", "label": {"eng": "Israel"}}}], "categories": [{"uri": "dmoz/Society/Future", "label": "dmoz/Society/Future", "wgt": 100}, {"uri": "dmoz/Society/Issues/Science_and_Technology", "label": "dmoz/Society/Issues/Science and Technology", "wgt": 100}, {"uri": "dmoz/Society/Future/Transhumanism", "label": "dmoz/Society/Future/Transhumanism", "wgt": 100}, {"uri": "dmoz/Society/Work/Rethinking_Work", "label": "dmoz/Society/Work/Rethinking Work", "wgt": 100}, {"uri": "dmoz/Society/Future/Essays", "label": "dmoz/Society/Future/Essays", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 55}], "image": "https://kuenselonline.com/wp-content/uploads/2024/08/AI.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3803921568627451, "wgt": 113, "relevance": 1}
{"uri": "8259689530", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "08:16:41", "dateTime": "2024-08-05T08:16:41Z", "dateTimePub": "2024-08-05T08:15:30Z", "dataType": "news", "sim": 0.4392156898975372, "url": "https://www.tmtpost.com/7196963.html", "title": "Founder of 360 Group Advocates for Open Access to AI Models-\u949b\u5a92\u4f53\u5b98\u65b9\u7f51\u7ad9", "body": "Zhou Hongyi noted that general AI models are not free due to high costs, justifying token-based charges. Meanwhile, he defended the use of APIs, arguing that creating APIs is meant to encourage integration. He opposed developing plugins, advocating for direct integration of AI capabilities into browsers.\n\nTMTPOST--Artificial Intelligence (AI) models should not be monopolized by a few companies as exclusive moneymakers and instead they should be more accessible, said Zhou Hongyi, the founder of 360 Group, at the 12th International Security Conference (ISC).\n\nHe noted that general AI models are not free due to high costs, justifying token-based charges. Meanwhile, he defended the use of APIs, arguing that creating APIs is meant to encourage integration. He opposed developing plugins, advocating for direct integration of AI capabilities into browsers.\n\nDuring the event, Zhou revisited 360 Group's return to Chinese stock markets from the New York Stock Exchange and the subsequent sanctions from the U.S. Department of Commerce and Department of Defense. He explained that this move aligned 360 Group with national interests, replacing foreign shareholders with domestic ones, thus resolving identity issues.\n\nZhou revealed that 360 has identified and countered 54 state-level Advanced Persistent Threat (APT) organizations, which led to the U.S. sanctions. The company's role in exposing long-term cyber espionage by intelligence agencies on critical infrastructure, research institutions, and government bodies was highlighted 12 times in the 2022 U.S. Congressional Cybersecurity Report, marking 360 as an alleged threat to U.S. cybersecurity.\n\nReflecting on 360's decade-long journey, Zhou disclosed an investment of nearly 30 billion yuan in cybersecurity research and development. This investment surpasses the combined total of the second to tenth largest companies in the industry. Zhou humorously said that 360's business model relies on internet advertising revenue to subsidize its security business, thanking users for their support through ad views.\n\nZhou said AI introduced a new era akin to the internet's rise, with large language models at the forefront. He identified two key challenges AI poses to cybersecurity: the potential use of AI by malicious actors and the evolving nature of cyber threats into human-machine and machine-machine confrontations. To address these challenges, 360 has announced the free availability of its security AI models as part of ISC2024.\n\nHowever, the 360 security large model being made available for free is different from the previously launched 360 Intelligent Brain large model. The former is a vertical model focused on the cybersecurity domain, while the latter is a general-purpose model. The security large model primarily targets the B2B market, whereas the Zhibrain model is aimed at consumer users. Due to this distinction, the free access to the 360 security large model comes with conditions:\n\nThe standard capabilities of the large model are provided for free to users who purchase 360's standard products. Additionally, existing customers who have already purchased 360 products will receive free upgrades to the security large model.\n\n\"Free access to the 360 security large model refers to six security industry-specific models. These models need to work in conjunction with 360's endpoint security and the 360 Security Brain. The security large model itself is not intended to be sold as a standalone product... It's akin to upgrading from a steam engine to an electric motor without any additional cost,\" Zhou explained during a discussion.\n\nHe emphasized that he does not want large models to become exclusive tools controlled by a few companies to generate profit. Instead, he aims to make professional large models accessible to every enterprise. \"360 strongly supports open source, which will benefit productivity across all enterprises in China,\" he said.\n\nDuring the conference on July 31, 360 announced two major initiatives for consumer users: first, the launch of the \"AI Assistant\" product, which integrates models from 15 different large model providers; second, the release of the 360 AI Office Suite, a comprehensive learning and office toolset.\n\nThe 15 large model providers in China collaborating on the \"AI Assistant\" include Zhipu AI, SenseTime, Baichuan Intelligent, Volcano Engine, Baidu Intelligent Cloud, Tencent, iFlytek, Huawei Cloud, MiniMax, ZeroOne, and Mianbi Intelligence. As a result of this collaboration, users can directly call upon the AI Assistant within key 360 products such as 360 Security Guard, 360 Security Browser, 360 Search, and 360 Smart Hardware, and select the appropriate model.\n\nHowever, Zhou is not entirely in favor of the approach where many large model providers create browser plugins for their applications. He believes that the overuse of plugins can be annoying to users. \"During the internet boom, multiple companies attempted to add their plugins to the same browser, ultimately degrading the user experience. Therefore, we do not advocate for plugins. Instead, we aim to integrate capabilities directly into the browser,\" Zhou pointed out, explaining one of the considerations behind the AI Assistant's development.\n\nThe 360 AI Office Suite includes AI-powered tools for images, document writing, video and audio, PPT, and a comprehensive set of office templates. This suite is also included in the 360 VIP membership benefits, priced at 216 yuan per year. Zhao Jun, President of 360 Group, disclosed that the 360 AI VIP membership will introduce ten new benefits each quarter, totaling over 300 benefits by next year.\n\nAs a key focus area for 360, the user data and usage metrics of 360 AI Search were also disclosed during the conference. Zhou said that 360 AI Search now has over ten million monthly active users. Liang Zhihui, Vice President of 360 Group and head of 360 AI Applications, revealed that the total visits to 360 AI Search from April to July exceeded 100 million, surpassing the combined total of the second and third-place competitors.\n\nWhile the B2B security large model is being offered for free, Zhou has a different strategy for monetizing the consumer-facing large model. \"The general-purpose large model is not free because its costs are too high. Large model providers charge based on API usage and tokens, which is reasonable due to the costs associated with inference. Therefore, future AI-based tools and business models may not solely rely on the internet model of free access supported by advertising,\" Zhou said.\n\nHe explained that during the internet era, software costs were relatively fixed, with zero marginal cost, allowing for free use supported by advertising. However, with the advent of large models, it is necessary to account for partner and inference costs. Subscription fees without advertisements can enhance the user experience. \"It may be difficult for developers to charge users for a single product. By bundling developers' products with 360's membership services, we can explore reasonable business models that support developers,\" he added.\n\nRegarding concerns about whether collaborating with Zhipu AI and other large model providers constitutes \"wrapping\" large models, Zhou believes that the key is in the application. \"There are different levels of wrapping -- shallow and deep. Calling an API is a simple form of wrapping, but integrating the models into our office suite and various scenarios is a deep form of wrapping. Simply calling an API is not inherently inferior; providers create APIs hoping for integration,\" he said.", "source": {"uri": "tmtpost.com", "dataType": "news", "title": "tmtpost.com"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/API", "type": "wiki", "score": 5, "label": {"eng": "API"}}, {"uri": "http://en.wikipedia.org/wiki/Zhou_dynasty", "type": "loc", "score": 5, "label": {"eng": "Zhou dynasty"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Zhou_Hongyi", "type": "person", "score": 5, "label": {"eng": "Zhou Hongyi"}}, {"uri": "http://en.wikipedia.org/wiki/Web_browser", "type": "wiki", "score": 5, "label": {"eng": "Web browser"}}, {"uri": "http://en.wikipedia.org/wiki/Computer_security", "type": "wiki", "score": 5, "label": {"eng": "Computer security"}}, {"uri": "http://en.wikipedia.org/wiki/Plug-in_(computing)", "type": "wiki", "score": 5, "label": {"eng": "Plug-in (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Advanced_persistent_threat", "type": "wiki", "score": 4, "label": {"eng": "Advanced persistent threat"}}, {"uri": "http://en.wikipedia.org/wiki/China", "type": "loc", "score": 4, "label": {"eng": "China"}, "location": {"type": "country", "label": {"eng": "China"}}}, {"uri": "http://en.wikipedia.org/wiki/United_States_sanctions", "type": "wiki", "score": 3, "label": {"eng": "United States sanctions"}}, {"uri": "http://en.wikipedia.org/wiki/Economic_sanctions", "type": "wiki", "score": 3, "label": {"eng": "Economic sanctions"}}, {"uri": "http://en.wikipedia.org/wiki/Cyber_spying", "type": "wiki", "score": 3, "label": {"eng": "Cyber spying"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Defense", "type": "wiki", "score": 3, "label": {"eng": "United States Department of Defense"}}, {"uri": "http://en.wikipedia.org/wiki/Renminbi", "type": "wiki", "score": 3, "label": {"eng": "Renminbi"}}, {"uri": "http://en.wikipedia.org/wiki/United_States_Department_of_Commerce", "type": "wiki", "score": 3, "label": {"eng": "United States Department of Commerce"}}, {"uri": "http://en.wikipedia.org/wiki/Intelligence_agency", "type": "wiki", "score": 3, "label": {"eng": "Intelligence agency"}}, {"uri": "http://en.wikipedia.org/wiki/Research_and_development", "type": "wiki", "score": 3, "label": {"eng": "Research and development"}}, {"uri": "http://en.wikipedia.org/wiki/Stock_market", "type": "wiki", "score": 3, "label": {"eng": "Stock market"}}, {"uri": "http://en.wikipedia.org/wiki/Shareholder", "type": "wiki", "score": 3, "label": {"eng": "Shareholder"}}, {"uri": "http://en.wikipedia.org/wiki/New_York_Stock_Exchange", "type": "wiki", "score": 3, "label": {"eng": "New York Stock Exchange"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 2, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Open_source_model", "type": "wiki", "score": 2, "label": {"eng": "Open source model"}}, {"uri": "http://en.wikipedia.org/wiki/Cyberattack", "type": "wiki", "score": 2, "label": {"eng": "Cyberattack"}}, {"uri": "http://en.wikipedia.org/wiki/SenseTime", "type": "org", "score": 1, "label": {"eng": "SenseTime"}}, {"uri": "http://en.wikipedia.org/wiki/IFlytek", "type": "org", "score": 1, "label": {"eng": "IFlytek"}}, {"uri": "http://en.wikipedia.org/wiki/Tencent", "type": "org", "score": 1, "label": {"eng": "Tencent"}}, {"uri": "http://en.wikipedia.org/wiki/Baidu", "type": "org", "score": 1, "label": {"eng": "Baidu"}}, {"uri": "http://en.wikipedia.org/wiki/Huawei", "type": "org", "score": 1, "label": {"eng": "Huawei"}}], "categories": [{"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 100}, {"uri": "dmoz/Computers/Artificial_Intelligence/Belief_Networks", "label": "dmoz/Computers/Artificial Intelligence/Belief Networks", "wgt": 100}, {"uri": "dmoz/Computers/CAD_and_CAM/3D_Modelling", "label": "dmoz/Computers/CAD and CAM/3D Modelling", "wgt": 100}, {"uri": "dmoz/Computers/CAD_and_CAM/NX_(Unigraphics)_and_Solid_Edge", "label": "dmoz/Computers/CAD and CAM/NX (Unigraphics) and Solid Edge", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 92}], "image": "https://images.tmtpost.com/uploads/images/zhaopian/nuxtpic/change_logo3/og_image.png", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": [{"amb": false, "imp": true, "date": "2024-07-31", "textStart": 3965, "textEnd": 3972}], "sentiment": 0.06666666666666665, "wgt": 112, "relevance": 1}
{"uri": "2024-08-443908180", "lang": "eng", "isDuplicate": false, "date": "2024-08-04", "time": "22:22:52", "dateTime": "2024-08-04T22:22:52Z", "dateTimePub": "2024-08-04T22:14:51Z", "dataType": "news", "sim": 0.4392156898975372, "url": "https://siliconangle.com/2024/08/04/organizations-can-optimize-generative-ai-costs/", "title": "How organizations can optimize generative AI costs", "body": "Generative artificial intelligence models are at the heart of the AI revolution today. As enterprises expand their gen AI initiatives, they recognize that the cost of developing, deploying and operating these models can be significant as use cases scale and expand.\n\nOrganizations transitioning from gen AI pilots to production experience a rude awakening when it comes to costs. Creating a production-ready gen AI system can be orders of magnitude more expensive than running a pilot.\n\nOrganizations can take advantage of the following five best practices to optimize gen AI costs. Implementing these best practices allow organizations to maximize the return on their gen AI investment and unlock its full potential.\n\n1. Be objective about model accuracy, performance and cost tradeoffs\n\nSelecting the appropriate model often involves making the right tradeoffs between several factors, with model accuracy, performance and costs being the most significant ones. The size of a gen AI model (measured by the number of its training parameters) has significant bearing on these metrics. Though larger gen AI models deliver higher accuracy, they often come with higher costs and latency in model responses.\n\nSelecting the right model must be a multidimensional evaluation process. Model accuracy needs to be validated through a broad set of accuracy metrics such as fluency, coherence, relevancy and contextual understanding. If choosing a gen AI model delivered as an applied programming interface, remember that the same model may be offered by multiple providers. This enables organizations to choose a provider that delivers superior price and performance, yet meets the security and support needs of the organization.\n\n2. Create a model garden to promote choice and make model price/performance transparent to developers and users\n\nA great way to enable safe experimentation is to create an AI model garden with multiple models being made available to users and developers. An AI model garden features available models in a self-service manner as part of a model catalog, underpinned by basic security and privacy principles. Early adopters make gen AI models available from more than one provider and often mix and match models in the model catalog. This makes both large and small AI models available, while ensuring the availability of open-source models alongside closed-source ones.\n\nInformation technology leaders should create an AI model garden and offer multiple, diverse models for users to safely experiment. Make the model costs transparent to the users via reporting tools, which enables them to make better economical choices without jeopardizing their accuracy, performance and other selection metrics.\n\n3. Balance upfront and operational costs in model augmentation and customization\n\nWhen augmenting and customizing gen AI models, businesses need to weigh upfront and running costs. Upfront costs are dedicated to the selection of different approaches, encompassing model augmentation such as prompt engineering and retrieval-augmented generation, or RAG, and model customization such as fine-tuning and training a model from scratch -- each increasing in complexity and cost.\n\nRunning costs can be mitigated by careful choice of models that balance price/performance, or even by efficiently fine-tuning a model on a specific dataset through instruction tuning or continuing pretraining. This is notable, as it could reduce the need for additional text via prompt engineering or RAG.\n\nIT leaders should consider augmentation and customizations sequentially, only moving to a more advanced approach if a simpler one doesn't meet the required output quality. They can evaluate the different approaches not only to achieve better output quality, but also to reduce running costs -- especially if the model usage will be high volume and predictable.\n\n4. Understand the tradeoffs of self-hosting\n\nSelf-hosting gen AI models (often on-premises) can seem attractive for businesses seeking increased control and data privacy. It is also true that model inference will be more hybrid in the future, driven by costs, performance and privacy needs. However, it's crucial to be aware of the potential tradeoffs, as the list of cost drivers for self-hosting is extensive.\n\nConsider the complexity and cost implications before opting to self-host gen AI models. If an organization decides to self-host, it must ensure it can deliver opex-based pricing models or managed services for it. IT leaders should evaluate their organization's capacity for upfront investment, ongoing maintenance and expertise before opting for self-hosting, considering that the costs and complexities can escalate -- especially with larger models and high usage volumes.\n\n5. Embrace guided prompting design for efficient prompting of models\n\nPrompt design involves crafting prompts that effectively evoke the desired responses from gen AI models. Crafting well-structured prompts is crucial for guaranteeing precise, top-notch outputs. Prompt design is important since it has a significant implication on the accuracy and relevancy of model responses, adaptability of the models to specific tasks and, most importantly, on model inference costs. Well-crafted prompts can ensure model responses are concise, relevant and accurate, and are generally a cheaper way to steer AI models.\n\nExplore prompt design tools that can boost the quality of prompting and save money in the long run. Document these best practices and encourage wider dissemination through knowledge sharing sessions.\n\nOrganizations should analyze and uncover hidden gen AI costs across various approaches. Avoid expensive model customizations and understand the tradeoffs of self-hosting AI models. Lower model inference costs though techniques such as prompt design. Conduct monthly or quarterly reviews of gen AI costs to ensure ongoing optimization and instill a culture of accountability.\n\nArun Chandrasekaran is a distinguished VP analyst at Gartner Inc., where he researches emerging technologies and trends, with an emphasis on artificial intelligence and cloud computing. He wrote this article for SiliconANGLE.", "source": {"uri": "siliconangle.com", "dataType": "news", "title": "SiliconANGLE"}, "authors": [{"uri": "guest_author@siliconangle.com", "name": "Guest Author", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Best_practice", "type": "wiki", "score": 4, "label": {"eng": "Best practice"}}, {"uri": "http://en.wikipedia.org/wiki/Self-hosting_(compilers)", "type": "wiki", "score": 3, "label": {"eng": "Self-hosting (compilers)"}}, {"uri": "http://en.wikipedia.org/wiki/Latency_(engineering)", "type": "wiki", "score": 3, "label": {"eng": "Latency (engineering)"}}, {"uri": "http://en.wikipedia.org/wiki/Use_case", "type": "wiki", "score": 3, "label": {"eng": "Use case"}}, {"uri": "http://en.wikipedia.org/wiki/Order_of_magnitude", "type": "wiki", "score": 3, "label": {"eng": "Order of magnitude"}}, {"uri": "http://en.wikipedia.org/wiki/Information_technology", "type": "wiki", "score": 3, "label": {"eng": "Information technology"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 3, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Prompt_engineering", "type": "wiki", "score": 2, "label": {"eng": "Prompt engineering"}}, {"uri": "http://en.wikipedia.org/wiki/Open-source_software", "type": "wiki", "score": 2, "label": {"eng": "Open-source software"}}, {"uri": "http://en.wikipedia.org/wiki/Proprietary_software", "type": "wiki", "score": 2, "label": {"eng": "Proprietary software"}}, {"uri": "http://en.wikipedia.org/wiki/Inference", "type": "wiki", "score": 1, "label": {"eng": "Inference"}}, {"uri": "http://en.wikipedia.org/wiki/Emerging_technologies", "type": "wiki", "score": 1, "label": {"eng": "Emerging technologies"}}, {"uri": "http://en.wikipedia.org/wiki/On-premises_software", "type": "wiki", "score": 1, "label": {"eng": "On-premises software"}}, {"uri": "http://en.wikipedia.org/wiki/Gartner", "type": "org", "score": 1, "label": {"eng": "Gartner"}}, {"uri": "http://en.wikipedia.org/wiki/Mathematical_optimization", "type": "wiki", "score": 1, "label": {"eng": "Mathematical optimization"}}, {"uri": "http://en.wikipedia.org/wiki/Cloud_computing", "type": "wiki", "score": 1, "label": {"eng": "Cloud computing"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 1, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Information_privacy", "type": "wiki", "score": 1, "label": {"eng": "Information privacy"}}], "categories": [{"uri": "dmoz/Business/Arts_and_Entertainment/Models", "label": "dmoz/Business/Arts and Entertainment/Models", "wgt": 37}, {"uri": "dmoz/Recreation/Models", "label": "dmoz/Recreation/Models", "wgt": 43}, {"uri": "dmoz/Recreation/Models/Scale", "label": "dmoz/Recreation/Models/Scale", "wgt": 46}, {"uri": "dmoz/Recreation/Collecting/Models", "label": "dmoz/Recreation/Collecting/Models", "wgt": 39}, {"uri": "dmoz/Recreation/Models/Boats_and_Ships", "label": "dmoz/Recreation/Models/Boats and Ships", "wgt": 43}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 86}], "image": "https://d15shllkswkct0.cloudfront.net/wp-content/blogs.dir/1/files/2024/08/aiexpensive.jpeg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.2862745098039217, "wgt": 112, "relevance": 1}
{"uri": "8259328331", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "02:50:06", "dateTime": "2024-08-05T02:50:06Z", "dateTimePub": "2024-08-05T02:49:16Z", "dataType": "news", "sim": 0.43529412150383, "url": "https://earth.org/generative-ai-is-exhausting-the-power-grid/", "title": "Generative AI Is Exhausting the Power Grid | Earth.Org", "body": "Generative AI has very quickly been adopted across various sectors. However, this has led to increased global electricity consumption that is only predicted to increase further as the technology expands, with many tech companies already at risk of defaulting on their net-zero commitments.\n\n--\n\nOpenAI's launch of ChatGPT in late 2022 introduced the world to generative artificial intelligence -commonly referred to as \"genAI\" - allowing users to generate text and answer complex questions in an almost human-like manner and at incredible speed. The new technology took the world by storm, reaching 100 million active users in the first two months and sparking a race among companies to embed the technology across their operations and products.\n\nBeyond ChatGPT, genAI has already begun disrupting large industries, from biopharma, where the technology can generate millions of candidate molecules for certain diseases, to marketing, where it can personalise content and customer experiences. However, there is a dark side to all this.\n\nBesides requiring huge quantities of fresh water to keep data centres cool, when powered by non-renewable energy sources, artificial intelligence also releases significant amounts of carbon emissions. Each individual use of genAI to answer a question or produce an image comes at an incredible cost to the planet; with the technology spreading at unprecedented pace around the world, its environmental footprint is only destined to increase. To put things into perspective, a single ChatGPT query requires 2.9 watt-hours of electricity, compared with 0.3 watt-hours for a Google search, as found in the International Energy Agency's (IEA) Electricity 2024 forecast which was released earlier this year for global energy use over the next two years. For the first time, it included projections for energy consumption by data centres, cryptocurrency, and AI, citing market trends including the fast incorporation of AI across a variety of sectors as reasons for increasing electricity demand.\n\nLarge Language Models (LLMs), which sit at the heart of many gen AI systems, are trained on vast stores of information, allowing them to generate a response to virtually any query from scratch. A December 2023 study, which is yet to be peer-reviewed, found that using large generative models to create outputs is far more energy-intensive than using smaller AI models tailored to specific tasks. The reason behind this conclusion is that generative AI models tend to do many things at once, such as generating, classifying, and summarising text; this results in the whole model getting activated in response to a query, which is \"wildly inefficient from a computational perspective\".\n\nGen AI runs an immense number of calculations to perform tasks very quickly, usually on specialised Graphical Processing Units (GPUs). Compared to other chips, GPUs are more energy-efficient for AI, and most efficient when running in large cloud data centres - specialised buildings containing computers equipped with those chips. The gen AI revolution led to the rapid expansion of these centres around the world, resulting in a significant rise in power consumption. The IEA's report projects data centres' electricity consumption in 2026 to double 2022 levels, reaching 1,000 terawatts, roughly Japan's total consumption.\n\nConsequently, organisations have reported a rise in their emissions that goes against their commitments to reduce their environmental impact. According to a study by Google and UC Berkeley, training OpenAI's GPT-3 generated 552 metric tonnes of carbon -- the equivalent to driving 112 petrol cars for a year. Last year, Google's total data centre electricity consumption grew by 17%. While the tech giant did not reveal how much of this was directly linked to gen AI, it admitted that it expects to see this trend grow in the future. Similarly, Microsoft announced in May that its emissions were up almost 30% from 2020 as a result of building new data centres.\n\nMore on the topic: Google Emissions Grow 48% in Five Years Owing to Large-Scale AI Deployment, Jeopardizing Company's Net Zero Plans\n\nAs mentioned earlier, the water usage of this technology cannot go unmentioned. To cool delicate electronics, water is required to be free of impurities, resulting in data centres competing for the same water used by people to drink, cook, and wash. In 2022, Google's data centres consumed around 5 million gallons of freshwater for cooling, 20% more than in 2021. In the same time period, Microsoft's water consumption rose by 34%.\n\nIt is difficult to get accurate estimates on the impact of gen AI, in part due to machine learning models being incredibly variable, able to be configured in ways that can dramatically impact their power consumption, but also due to organisations like Meta, Microsoft, OpenAI not openly sharing relevant information. Data is not systematically collected on AI's energy use and environmental impact and there is a need for greater transparency and tracking - especially as models grow and gen AI becomes more embedded into society.\n\nAs gen AI becomes more mainstream, environmental costs will grow. And with the world heating up, companies working to meet the rising demand of generative AI must commit to more transparency regarding their operations and begin shifting to clean energy. As the IEA report emphasises, governments must introduce regulations to restrain energy consumed by data centres, requiring mandatory reporting obligations, and setting energy efficiency standards, while companies must work on improving efficiency and reducing the amount of energy required by data centres.", "source": {"uri": "earth.org", "dataType": "news", "title": "Earth.Org - Past | Present | Future"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 5, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Electric_energy_consumption", "type": "wiki", "score": 5, "label": {"eng": "Electric energy consumption"}}, {"uri": "http://en.wikipedia.org/wiki/Data_center", "type": "wiki", "score": 5, "label": {"eng": "Data center"}}, {"uri": "http://en.wikipedia.org/wiki/Electricity", "type": "wiki", "score": 5, "label": {"eng": "Electricity"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Kilowatt-hour", "type": "wiki", "score": 4, "label": {"eng": "Kilowatt-hour"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 4, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Greenhouse_gas_emissions", "type": "wiki", "score": 3, "label": {"eng": "Greenhouse gas emissions"}}, {"uri": "http://en.wikipedia.org/wiki/OpenAI", "type": "wiki", "score": 3, "label": {"eng": "OpenAI"}}, {"uri": "http://en.wikipedia.org/wiki/Non-renewable_resource", "type": "wiki", "score": 3, "label": {"eng": "Non-renewable resource"}}, {"uri": "http://en.wikipedia.org/wiki/Carbon_neutrality", "type": "wiki", "score": 3, "label": {"eng": "Carbon neutrality"}}, {"uri": "http://en.wikipedia.org/wiki/International_Energy_Agency", "type": "org", "score": 3, "label": {"eng": "International Energy Agency"}}, {"uri": "http://en.wikipedia.org/wiki/Molecule", "type": "wiki", "score": 3, "label": {"eng": "Molecule"}}, {"uri": "http://en.wikipedia.org/wiki/Graphics_processing_unit", "type": "wiki", "score": 3, "label": {"eng": "Graphics processing unit"}}, {"uri": "http://en.wikipedia.org/wiki/Marketing", "type": "wiki", "score": 3, "label": {"eng": "Marketing"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_model", "type": "wiki", "score": 2, "label": {"eng": "Generative model"}}, {"uri": "http://en.wikipedia.org/wiki/Energy_consumption", "type": "wiki", "score": 2, "label": {"eng": "Energy consumption"}}, {"uri": "http://en.wikipedia.org/wiki/Cryptocurrency", "type": "wiki", "score": 2, "label": {"eng": "Cryptocurrency"}}, {"uri": "http://en.wikipedia.org/wiki/Ecological_footprint", "type": "wiki", "score": 2, "label": {"eng": "Ecological footprint"}}, {"uri": "http://en.wikipedia.org/wiki/Cloud_computing", "type": "wiki", "score": 2, "label": {"eng": "Cloud computing"}}, {"uri": "http://en.wikipedia.org/wiki/Peer_review", "type": "wiki", "score": 2, "label": {"eng": "Peer review"}}, {"uri": "http://en.wikipedia.org/wiki/Microsoft", "type": "org", "score": 2, "label": {"eng": "Microsoft"}}, {"uri": "http://en.wikipedia.org/wiki/Meta_Platforms", "type": "org", "score": 1, "label": {"eng": "Meta Platforms"}}, {"uri": "http://en.wikipedia.org/wiki/University_of_California,_Berkeley", "type": "org", "score": 1, "label": {"eng": "University of California, Berkeley"}}], "categories": [{"uri": "dmoz/Business/Energy", "label": "dmoz/Business/Energy", "wgt": 100}, {"uri": "dmoz/Science/Technology/Energy", "label": "dmoz/Science/Technology/Energy", "wgt": 100}, {"uri": "dmoz/Business/Energy/Utilities", "label": "dmoz/Business/Energy/Utilities", "wgt": 100}, {"uri": "dmoz/Business/Energy/Management", "label": "dmoz/Business/Energy/Management", "wgt": 100}, {"uri": "dmoz/Science/Anomalies_and_Alternative_Science/Orgone_Energy", "label": "dmoz/Science/Anomalies and Alternative Science/Orgone Energy", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 64}], "image": "https://u4d2z7k9.rocketcdn.me/wp-content/uploads/2024/08/Copy-of-Untitled-683-x-1024-px-3.jpg", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.3333333333333333, "wgt": 111, "relevance": 1}
{"uri": "8260080574", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "12:25:41", "dateTime": "2024-08-05T12:25:41Z", "dateTimePub": "2024-08-05T12:24:57Z", "dataType": "news", "sim": 0.4196078479290009, "url": "https://www.dataguidance.com/news/germany-bafin-publishes-guidance-financial-service", "title": "Germany: BaFin publishes guidance for financial service providers on", "body": "On August 1, 2024, the Federal Financial Supervisory Authority (BaFin) published a guidance for financial service providers regarding artificial intelligence (AI). The guidance focuses on the fairness and bias of AI systems, includes a summary of the relevant provisions from the EU Artificial Intelligence Act (the EU AI Act), and clarifies how BaFin would address discriminatory practices.\n\nNotably, the guidance identifies that fairness encompasses three important aspects:\n\nAccording to BaFin, different definitions of fairness have been proposed in machine learning (ML) research and one approach used in practice is to use statistical measures to evaluate whether groups of people are evaluated equally. These measures are often referred to as fairness metrics and come in three main variants:\n\nBaFin noted that the problem of insufficient fairness might be exacerbated when generative AI such as large language models (LLMs) are used.\n\nBaFin stated, among other things, that companies must adapt or supplement their governance processes with regard to AI/ML. In its conduct of business supervision, BaFin expects the supervised institutions and companies to clearly define responsibilities, raise awareness, and train employees entrusted with the development and use of AI/ML in order to mitigate risks.\n\nFurthermore, BaFin suggested that financial service providers avoid unjustified discrimination against customers through the use of AI/ML and set up review processes to identify possible sources of discrimination and take measures to eliminate them. Reliable and transparent data governance and data management are crucial to ensure fair and non-discriminatory treatment of consumers. In addition, human oversight may be required to ensure responsible operations, compensate for technical deficiencies, and close data gaps. Furthermore, companies can play a key role in promoting transparency through their choice of model.\n\nFinally, BaFin noted that if the use of AI/ML leads to discrimination prohibited by law, it will take appropriate measures, for example within the framework of malpractice supervision.", "source": {"uri": "dataguidance.com", "dataType": "news", "title": "DataGuidance"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Federal_Financial_Supervisory_Authority", "type": "wiki", "score": 5, "label": {"eng": "Federal Financial Supervisory Authority"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Machine_learning", "type": "wiki", "score": 4, "label": {"eng": "Machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/European_Union", "type": "loc", "score": 4, "label": {"eng": "European Union"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Bias", "type": "wiki", "score": 3, "label": {"eng": "Bias"}}, {"uri": "http://en.wikipedia.org/wiki/Financial_services", "type": "wiki", "score": 3, "label": {"eng": "Financial services"}}, {"uri": "http://en.wikipedia.org/wiki/Large_language_model", "type": "wiki", "score": 2, "label": {"eng": "Large language model"}}, {"uri": "http://en.wikipedia.org/wiki/Generative_artificial_intelligence", "type": "wiki", "score": 2, "label": {"eng": "Generative artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Discrimination", "type": "wiki", "score": 2, "label": {"eng": "Discrimination"}}], "categories": [{"uri": "dmoz/Society/Work", "label": "dmoz/Society/Work", "wgt": 100}, {"uri": "dmoz/Business/Accounting", "label": "dmoz/Business/Accounting", "wgt": 100}, {"uri": "dmoz/Health/Reproductive_Health/Birth_Control", "label": "dmoz/Health/Reproductive Health/Birth Control", "wgt": 100}, {"uri": "dmoz/Society/Work/Telecommuting", "label": "dmoz/Society/Work/Telecommuting", "wgt": 100}], "image": "https://www.dataguidance.com/sites/default/files/default_images/default.png", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.1294117647058823, "wgt": 107, "relevance": 1}
{"uri": "8260082918", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "12:27:19", "dateTime": "2024-08-05T12:27:19Z", "dateTimePub": "2024-08-05T12:26:38Z", "dataType": "news", "sim": 0.4196078479290009, "url": "https://www.analyticsinsight.net/artificial-intelligence/how-ai-is-transforming-cryptocurrency", "title": "How AI is Transforming Cryptocurrency?", "body": "This proactive approach ensures that mining operations run smoothly, maximizing efficiency and profitability. AI in Cryptocurrency mining also aids in energy optimization, reducing the environmental impact of mining activities.\n\nWhile AI can enhance security measures, it also introduces new vulnerabilities. AI systems are susceptible to various forms of attacks, such as data poisoning and adversarial attacks, where malicious inputs are designed to deceive and manipulate AI models. These attacks can lead to inaccurate market predictions, flawed trading strategies, and even unauthorized transactions. The sophistication of these threats requires robust security protocols and constant monitoring to prevent exploitation.\n\nRegulatory Uncertainty\n\nThe regulatory landscape for both AI and cryptocurrency remains in flux, posing a significant challenge. The rapid development of AI technologies often outpaces the creation and implementation of relevant regulations. This discrepancy can lead to legal ambiguities, complicating compliance efforts for companies operating in the cryptocurrency space. Regulators are still grappling with how to classify and govern AI-driven activities, such as automated trading and data analysis, within existing legal frameworks.", "source": {"uri": "analyticsinsight.net", "dataType": "news", "title": "Analytics Insight"}, "authors": [{"uri": "harshini_chakka@analyticsinsight.net", "name": "Harshini Chakka", "type": "author", "isAgency": false}], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Mining", "type": "wiki", "score": 5, "label": {"eng": "Mining"}}, {"uri": "http://en.wikipedia.org/wiki/Cryptocurrency", "type": "wiki", "score": 3, "label": {"eng": "Cryptocurrency"}}, {"uri": "http://en.wikipedia.org/wiki/Environmental_degradation", "type": "wiki", "score": 3, "label": {"eng": "Environmental degradation"}}, {"uri": "http://en.wikipedia.org/wiki/Mathematical_optimization", "type": "wiki", "score": 3, "label": {"eng": "Mathematical optimization"}}, {"uri": "http://en.wikipedia.org/wiki/Vulnerability_(computing)", "type": "wiki", "score": 3, "label": {"eng": "Vulnerability (computing)"}}, {"uri": "http://en.wikipedia.org/wiki/Adversarial_machine_learning", "type": "wiki", "score": 2, "label": {"eng": "Adversarial machine learning"}}, {"uri": "http://en.wikipedia.org/wiki/Trading_strategy", "type": "wiki", "score": 2, "label": {"eng": "Trading strategy"}}, {"uri": "http://en.wikipedia.org/wiki/Cryptographic_protocol", "type": "wiki", "score": 2, "label": {"eng": "Cryptographic protocol"}}, {"uri": "http://en.wikipedia.org/wiki/Data_analysis", "type": "wiki", "score": 1, "label": {"eng": "Data analysis"}}, {"uri": "http://en.wikipedia.org/wiki/Grappling", "type": "wiki", "score": 1, "label": {"eng": "Grappling"}}], "categories": [{"uri": "dmoz/Computers/Software/Master_Data_Management", "label": "dmoz/Computers/Software/Master Data Management", "wgt": 100}, {"uri": "dmoz/Computers/Security/Intrusion_Detection_Systems", "label": "dmoz/Computers/Security/Intrusion Detection Systems", "wgt": 100}, {"uri": "dmoz/Business/E-Commerce/Standards_and_Protocols", "label": "dmoz/Business/E-Commerce/Standards and Protocols", "wgt": 100}, {"uri": "dmoz/Computers/Hacking/Cryptography", "label": "dmoz/Computers/Hacking/Cryptography", "wgt": 100}, {"uri": "dmoz/Business/Mining_and_Drilling/Consulting", "label": "dmoz/Business/Mining and Drilling/Consulting", "wgt": 100}, {"uri": "news/Business", "label": "news/Business", "wgt": 58}], "image": "https://media.assettype.com/analyticsinsight%2F2024-08%2F3698f507-5d1d-4714-9154-7ce6b60b872d%2FHow-AI-is-Transforming-Cryptocurrency%20(1).jpg?w=1200&ar=40%3A21&auto=format%2Ccompress&ogImage=true&mode=crop&enlarge=true&overlay=false&overlay_position=bottom&overlay_width=100", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.09019607843137245, "wgt": 107, "relevance": 1}
{"uri": "8260172794", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "13:24:52", "dateTime": "2024-08-05T13:24:52Z", "dateTimePub": "2024-08-05T13:23:49Z", "dataType": "news", "sim": 0.5215686559677124, "url": "https://www.thinkwithgoogle.com/intl/en-apac/marketing-strategies/automation/how-to-use-ai-for-marketing/", "title": "A framework for using AI in marketing - Think with Google APAC", "body": "As the leaders of Google APAC's Ads and Cloud marketing teams -- and as marketers ourselves -- we talk to many partners and friends about AI in marketing. One of the things we hear most clearly is that people want to move beyond the hype to the how.\n\nSo, to help marketers get their heads around the opportunities and how to make the most of what AI enables, we've developed a framework for how to put AI to work in your marketing.\n\nThis article lays out essential actions you can take to get started and how to scale when you're ready.\n\nInvesting in your first-party data strategy can give you a solid AI foundation and drive quick wins, growth, and efficiency for your business. Google's AI-powered campaign products and off-the-shelf products and tools can help you achieve these benefits.\n\nFor those who want to do more, Google Cloud offers a powerful platform for broader AI transformation. Tap its offerings, which can include purpose-built solutions like scaled creative production or AI-powered predictive audiences and analytics, to give you a competitive edge.\n\nWhether you're just getting started or looking to maximise what AI can do, our AI framework is a great resource to help you think about how to take advantage of using AI in your marketing, and to assess what you're already doing vis-\u00e0-vis what's possible.", "source": {"uri": "thinkwithgoogle.com", "dataType": "news", "title": "Think with Google"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Marketing", "type": "wiki", "score": 5, "label": {"eng": "Marketing"}}, {"uri": "http://en.wikipedia.org/wiki/Google", "type": "org", "score": 4, "label": {"eng": "Google"}}, {"uri": "http://en.wikipedia.org/wiki/Asia-Pacific", "type": "loc", "score": 3, "label": {"eng": "Asia-Pacific"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Google_Cloud_Platform", "type": "wiki", "score": 1, "label": {"eng": "Google Cloud Platform"}}, {"uri": "http://en.wikipedia.org/wiki/Analytics", "type": "wiki", "score": 1, "label": {"eng": "Analytics"}}], "categories": [{"uri": "dmoz/Society/Relationships", "label": "dmoz/Society/Relationships", "wgt": 100}, {"uri": "dmoz/Recreation/Humor/Useless_Pages", "label": "dmoz/Recreation/Humor/Useless Pages", "wgt": 100}, {"uri": "dmoz/Society/Advice", "label": "dmoz/Society/Advice", "wgt": 100}, {"uri": "news/Technology", "label": "news/Technology", "wgt": 51}], "image": "https://storage.googleapis.com/twg-content/images/TwG_APAC_6180_V4_1.width-1200.png", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.6235294117647059, "wgt": 460560292, "relevance": 2}
{"uri": "2024-08-444851337", "lang": "eng", "isDuplicate": false, "date": "2024-08-05", "time": "17:45:01", "dateTime": "2024-08-05T17:45:01Z", "dateTimePub": "2024-08-05T14:44:35Z", "dataType": "news", "sim": 0.7921568751335144, "url": "https://securityboulevard.com/2024/08/ai-policy-and-governance-shaping-the-future-of-artificial-intelligence/", "title": "AI Policy and Governance: Shaping the Future of Artificial Intelligence", "body": "Welcome to the exciting and complex world of AI policy and governance! As AI continues to revolutionize industries and redefine our everyday lives, it becomes crucial to have solid frameworks in place to guide its development and use. Think of AI policy and governance as the rules of the road for AI technologies, ensuring they drive us toward a future that's innovative, ethical, and beneficial for all. In this blog, we'll explore the importance of these frameworks, the challenges we face, the current approaches being taken, and what the future might hold. Ready to dive in? Let's do this!\n\nThe Importance of AI Policy and Governance\n\nArtificial intelligence (AI) is transforming industries and societies at pace which quite frankly, is hard to keep up with, making the need for solid AI policy and governance more important than ever. But why is this so important? Well, think of AI as a powerful tool. In the right hands, it can build wonders, but without proper oversight, it could also create complete chaos. Having effective AI policy and governance measures in place makes sure that AI technologies are developed and deployed in a manner that is ethical, transparent, and accountable. These frameworks aim to balance innovation with the protection of individual rights, public safety, and societal values.\n\nAI policy and governance provide guidelines that help steer the development and use of AI systems in directions that benefit society as a whole. This includes establishing principles that promote transparency in AI decision-making processes, and ensure accountability for the outcomes of AI systems. Additionally, AI policy frameworks help to address potential risks associated with AI, such as bias, discrimination, and privacy violations. By implementing effective AI governance mechanisms, we can build trust in AI technologies and ensure that they are used responsibly and for the greater good.\n\nChallenges in AI Policy and Governance\n\nNavigating the labyrinth of AI policy and governance is no easy feat. One of the biggest hurdles is the rapid pace of AI development, which often outstrips the ability of policymakers to keep up. This creates a gap between technological advancements and regulatory frameworks, leading to potential risks and unintended consequences. Additionally, the global nature of AI technologies poses significant challenges, as different countries have varying approaches to AI governance, making it difficult to establish cohesive international standards.\n\nAnother challenge is the complexity and opacity of AI systems, which can make it difficult to understand how they work and to identify and address potential biases and ethical concerns. This is particularly relevant in the context of the data governance of ChatGPT systems, where ensuring the ethical use and management of data is critical. Plus, there is often a lack of expertise among policymakers regarding the technical aspects of AI, which can hinder the development of effective governance frameworks.\n\nLastly, there are significant ethical and societal challenges associated with AI. These include issues related to privacy, security, accountability, and fairness. Developing AI ethics policy and governance frameworks that address these concerns while also promoting innovation is a delicate but important balancing act.\n\nCurrent Approaches to AI Policy and Governance\n\nVarious approaches to AI policy and governance are emerging around the world as governments, organizations, and institutions grapple with how best to manage the development and deployment of AI technologies. One notable example is the EU AI Act, which aims to create a comprehensive regulatory framework for AI within the European Union. The EU AI Act focuses on risk-based regulation, categorizing AI applications based on their potential impact on individuals and society, and imposing stricter requirements on high-risk AI systems.\n\nThe EU AI Act\n\nThe EU AI Act is a landmark piece of legislation that represents the first comprehensive attempt to regulate artificial intelligence within the European Union. This regulation aims to create a unified legal framework to address the risks and challenges posed by AI technologies while fostering innovation and competitiveness.\n\nThe primary objective of the EU AI Act is to ensure that AI systems placed on the market and used within the EU are safe and respect existing laws on fundamental rights and values. The regulation takes a risk-based approach, categorizing AI systems into four levels of risk: unacceptable, high, limited, and minimal.\n\nThe EU AI Act includes several key provisions designed to ensure the safe and ethical use of AI:\n\nThe EU AI Act is expected to have a significant impact on the development and deployment of AI technologies within the European Union and beyond. By setting clear rules and standards, the regulation aims to foster trust in AI systems and promote their adoption in a way that respects fundamental rights and values. Additionally, the EU AI Act is likely to influence AI policy and governance frameworks in other regions, as countries and organizations look to align their own regulations with this comprehensive approach.\n\nHowever, the EU AI Act also presents challenges for businesses and organizations developing AI technologies. Compliance with the regulation's requirements may require significant investments in testing, documentation, and transparency measures. Additionally, navigating the complex regulatory landscape may require specialized legal and technical expertise. Despite these challenges, the EU AI Act represents a crucial step toward ensuring that AI technologies are developed and used responsibly and ethically.\n\nAn important standard in the landscape of AI policy and governance is ISO/IEC 42001. This international standard provides guidelines for the management of AI systems, focusing on ethical considerations, risk management, and compliance with regulatory requirements. ISO/IEC 42001 helps organizations establish a structured approach to managing AI technologies, ensuring that they are used in ways that are safe, transparent, and aligned with ethical principles.\n\nBest Practices in AI Policy and Governance\n\nSo, how do we put these lofty ideals into practice? AI policy and governance aren't just theoretical constructs -- they require actionable strategies and meticulous implementation. Here are some best practices to guide the way:\n\nBy implementing these best practices, organizations can develop effective AI policy and governance frameworks that promote ethical, transparent, and accountable AI systems.\n\nFuture Directions in AI Policy and Governance\n\nAs AI technologies continue to evolve, so too must our approaches to AI policy and governance. One potential future direction is the development of more dynamic and adaptive regulatory frameworks that can keep pace with the rapid advancements in AI. This could involve the use of AI itself to monitor and enforce compliance with AI policy and governance standards, ensuring that regulations remain relevant and effective.\n\nEmphasis on Ethical Considerations\n\nAnother important direction is the increased emphasis on ethical considerations in AI policy and governance. This includes developing and implementing robust AI ethics policy and governance frameworks that address issues such as bias, fairness, and transparency. By prioritizing ethical considerations, we can ensure that AI technologies are developed and used in ways that are beneficial to society as a whole. Ethical AI not only fosters public trust but also promotes long-term sustainability and social acceptance of AI innovations.\n\nInternational Collaboration\n\nFurthermore, there is a growing recognition of the need for international collaboration and coordination in AI policy and governance. Given the global nature of AI technologies and the potential for cross-border impacts, international cooperation is crucial. Countries can work together to develop harmonized standards and guidelines that promote the responsible development and use of AI on a global scale. This includes sharing best practices, establishing common regulatory frameworks, and fostering dialogue among international stakeholders.\n\nRole of Education and Training\n\nFinally, there is an increasing focus on the role of education and training in AI policy and governance. By equipping policymakers, industry leaders, and the general public with the knowledge and skills needed to understand and navigate the complexities of AI, we can build a more informed and engaged society. Educational initiatives can help demystify AI, making its benefits and risks more accessible to everyone, and prepare society to manage the challenges and opportunities associated with AI.\n\nBy embracing these future directions and harnessing the power of Gen AI, we can ensure that AI technologies continue to evolve in a manner that is ethical, transparent, and beneficial for all. This proactive approach to AI policy and governance will help us navigate the challenges of the AI-driven future and unlock the full potential of these transformative technologies.\n\nConclusion\n\nAlright, folks, we've covered a lot of ground on AI policy and governance, but let's wrap it up on a high note. Imagine a world where AI not only makes our lives easier but does so responsibly and ethically. That's the dream, and with robust AI policy and governance, it's within reach. It's like setting the rules for a giant game where everyone gets to play fair and safe. Sure, there are challenges, but with collaboration, innovation, and a sprinkle of common sense, we can navigate them like pros.\n\nSo, here's to a future where AI doesn't just change the game but makes it better for everyone. Let's keep those ethics in check, stay transparent, and, most importantly, never stop learning. Here's to shaping a future where AI and humanity thrive together!\n\nThe post AI Policy and Governance: Shaping the Future of Artificial Intelligence appeared first on Scytale.\n\n*** This is a Security Bloggers Network syndicated blog from Blog | Scytale authored by Kyle Morris, Senior Compliance Success Manager, Scytale. Read the original post at: https://scytale.ai/resources/ai-policy-and-governance-shaping-the-future-of-artificial-intelligence/", "source": {"uri": "securityboulevard.com", "dataType": "news", "title": "Security Boulevard"}, "authors": [], "concepts": [{"uri": "http://en.wikipedia.org/wiki/Ethics", "type": "wiki", "score": 5, "label": {"eng": "Ethics"}}, {"uri": "http://en.wikipedia.org/wiki/Artificial_intelligence", "type": "wiki", "score": 5, "label": {"eng": "Artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/European_Union", "type": "loc", "score": 5, "label": {"eng": "European Union"}, "location": null}, {"uri": "http://en.wikipedia.org/wiki/Transparency_(behavior)", "type": "wiki", "score": 4, "label": {"eng": "Transparency (behavior)"}}, {"uri": "http://en.wikipedia.org/wiki/Accountability", "type": "wiki", "score": 4, "label": {"eng": "Accountability"}}, {"uri": "http://en.wikipedia.org/wiki/Decision-making", "type": "wiki", "score": 3, "label": {"eng": "Decision-making"}}, {"uri": "http://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence", "type": "wiki", "score": 3, "label": {"eng": "Ethics of artificial intelligence"}}, {"uri": "http://en.wikipedia.org/wiki/Right_to_privacy", "type": "wiki", "score": 3, "label": {"eng": "Right to privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Unintended_consequences", "type": "wiki", "score": 3, "label": {"eng": "Unintended consequences"}}, {"uri": "http://en.wikipedia.org/wiki/Fundamental_rights", "type": "wiki", "score": 3, "label": {"eng": "Fundamental rights"}}, {"uri": "http://en.wikipedia.org/wiki/Discrimination", "type": "wiki", "score": 3, "label": {"eng": "Discrimination"}}, {"uri": "http://en.wikipedia.org/wiki/Bias", "type": "wiki", "score": 3, "label": {"eng": "Bias"}}, {"uri": "http://en.wikipedia.org/wiki/ChatGPT", "type": "wiki", "score": 2, "label": {"eng": "ChatGPT"}}, {"uri": "http://en.wikipedia.org/wiki/Best_practice", "type": "wiki", "score": 2, "label": {"eng": "Best practice"}}, {"uri": "http://en.wikipedia.org/wiki/International_Organization_for_Standardization", "type": "wiki", "score": 2, "label": {"eng": "International Organization for Standardization"}}, {"uri": "http://en.wikipedia.org/wiki/Blog", "type": "wiki", "score": 2, "label": {"eng": "Blog"}}, {"uri": "http://en.wikipedia.org/wiki/International_Electrotechnical_Commission", "type": "wiki", "score": 2, "label": {"eng": "International Electrotechnical Commission"}}, {"uri": "http://en.wikipedia.org/wiki/Privacy", "type": "wiki", "score": 2, "label": {"eng": "Privacy"}}, {"uri": "http://en.wikipedia.org/wiki/Imagine_(John_Lennon_song)", "type": "wiki", "score": 1, "label": {"eng": "Imagine (John Lennon song)"}}, {"uri": "http://en.wikipedia.org/wiki/Common_sense", "type": "wiki", "score": 1, "label": {"eng": "Common sense"}}, {"uri": "http://en.wikipedia.org/wiki/Risk_management", "type": "wiki", "score": 1, "label": {"eng": "Risk management"}}], "categories": [{"uri": "dmoz/Computers/Security/Policy", "label": "dmoz/Computers/Security/Policy", "wgt": 20}, {"uri": "dmoz/Society/Issues/Government_Operations", "label": "dmoz/Society/Issues/Government Operations", "wgt": 21}, {"uri": "dmoz/Computers/Artificial_Intelligence/Publications", "label": "dmoz/Computers/Artificial Intelligence/Publications", "wgt": 29}, {"uri": "dmoz/Computers/Artificial_Intelligence/Games", "label": "dmoz/Computers/Artificial Intelligence/Games", "wgt": 38}, {"uri": "dmoz/Computers/Artificial_Intelligence/Philosophy", "label": "dmoz/Computers/Artificial Intelligence/Philosophy", "wgt": 25}], "image": "https://scytale.ai/wp-content/uploads/2024/07/three-badges.png", "originalArticle": null, "storyUri": "eng-9784991", "eventUri": "eng-9784991", "location": null, "extractedDates": null, "sentiment": 0.4745098039215687, "wgt": 460575901, "relevance": 2}
