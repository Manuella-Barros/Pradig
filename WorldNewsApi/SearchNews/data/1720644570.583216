{"id": 231222496, "title": "AI has its strong points. Intelligence isn\u2019t one of them", "text": "Until about five years ago, whenever I interviewed someone for a writing project, I would be faced with the gruelling prospect of having to transcribe the recorded conversation, often running to many hours. This was exactly the sort of clerical tedium for which, in becoming a writer, I imagined I\u2019d forgone financial security and societal respectability to avoid. The process was so grimly repetitive that there was usually a point, somewhere around the fourth or fifth hour of transcription, where I would resolve to give up writing entirely and get a proper job. But then I started using an app that employed machine learning to convert recorded speech into text. The thing was surprisingly accurate and efficient, and I was impressed by its ability to automate a process I found incredibly dull and time-consuming. It wasn\u2019t perfect; it struggled with strong accents, and muffled words, and it often made completely stupid errors for no obvious reason \u2013 but then, so did I, and it took me a lot longer to make them. [ Meta wants to use your Facebook and Instagram data to train AI. Here\u2019s how you can you stop it ] After I finished the reporting for my last book, almost two years ago, I was doing other kinds of writing, and had no need for the transcription software. Then, a couple of weeks back, I started work on a long magazine piece, involving hours of interviews, and I began using it again. And I was, frankly, pretty amazed by how much the technology had improved in the time I\u2019d been away. The whole \u201cartificial intelligence\u201d aspect of the thing had previously seemed a little abstract to me, but now, all of a sudden, I was seeing it. It wasn\u2019t just that the accuracy of the transcription had improved; it was that it provided a detailed, bullet-pointed breakdown of the conversations, arranged under thematic headings, along with a startlingly accurate summary. It was the sort of thing I might expect if I had employed a very efficient person to do all the annoying but necessary drudgery that my work involves, the kind of stuff that I hate doing and am very bad at. As a tool for minimising labour and freeing up time for the more creative aspects of my work, AI was undoubtedly powerful (There is a certain ambivalence here: although I myself was never going to be forking out a fee for a person to do these tasks, I\u2019m aware that this is the sort of work that people do get paid for, or at least did until recently, and that this technology is now presumably beginning to replace their labour.) I have long been highly sceptical of many of the claims made for machine learning, and the things it might be capable of. But this most recent leap in transcription software seemed to me to present a strong case for the technology\u2019s potential. As a tool, a device for minimising labour and freeing up time for the more creative aspects of my work, it was undoubtedly powerful. [ Meta gets 11 EU complaints over use of personal data to train AI models ] But the usefulness of this software hints at some of the ways in which the Large Language Model (LLM) technology it\u2019s based on has been wildly oversold. As a speech-to-text transcription tool, it does a modest and narrowly delineated thing extremely well. It generates a primary text based on recorded speech, and secondary texts \u2013 the bullet-point outline and the longer summary \u2013 based on an automated analysis of the primary text. In this sense, it\u2019s sort of a tightly defined microcosm of the more broad LLM technologies like ChatGPT, which generate secondary texts not from a single source, but from pretty much the entirety of the internet. Which is where things very often go badly wrong. See, for instance, the farcical rollout of Overviews, Google\u2019s new AI search tool, which uses LLM technology to synthesise, into a short text summary, the vast field of search results for a given input. In recent days, social media has been flooded with screenshots of the tool\u2019s increasingly unhinged responses to perfectly innocuous search terms. One representative response, to the query \u201chow to pass kidney stones quickly\u201d, advised that \u201cYou should aim to drink at least 2 quarts (2 litres) of urine every 24 hours, and your urine should be light in colour.\u201d (In the interest of accuracy, and to avoid a barrage of reprimands in the letters pages, I should clarify here that the correct amount of urine to drink in a 24-hour period is, of course, between 500 and 750ml, preferably unsweetened.) It was the sort of thing I might expect if I had employed a very efficient person to do all the annoying but necessary drudgery that my work involves Another much-shared Overviews error suggested, in response to the query of how to get cheese to stick to pizza, that \u201cyou can add about 1/8 cup of non-toxic glue to the sauce to give it more tackiness\u201d. The source for this obvious absurdity seems to have been an 11-year-old joke on Reddit, by a user named \u201cf**ksmith\u201d. Overviews, like all LLMs, draws from whatever seemingly-relevant information it can find in its data set; and because it\u2019s a neural network and not a human being, it is incapable of distinguishing between useful results and useless ones \u2013 misinformation, stuff posted on Reddit by guys named \u201cf**ksmith\u201d and things that are just plain old wrong. [ Tech companies have \u2018big job to do\u2019 to build trust in AI, committee hears ] In an interview with the Financial Times last year, the brilliant American sci-fi writer Ted Chiang offered a half-serious but fully useful definition of AI. He quoted a tweet which called it \u201ca bad choice of words in 1954\" \u2013 by which he meant that if the postwar computer scientists who conceived of this technology had chosen a different name for the concept, we would all have been spared a lot of confusion. A better term, he suggested, would have been \u201capplied statistics\u201d \u2013 less suggestive, certainly, but more accurate in terms of what is actually going on with these networks, and less likely to have led to delusions about machines \u201cthinking\u201d or becoming self-aware. This technology absolutely has its applications and is in many ways getting increasingly powerful as a labour-saving device. But as for \u201cintelligence\u201d \u2013 well, it\u2019s very much still drinking piss and eating glue.", "summary": "If the postwar computer scientists who conceived of AI had chosen a different name such as \u2018applied statistics\u2019, we would be spared a lot of confusion", "url": "https://www.irishtimes.com/opinion/2024/06/08/ai-has-its-strong-points-intelligence-isnt-one-of-them/", "image": "https://www.irishtimes.com/resizer/pXhrKGtGXLj8fRkO0mrezmgUj6w=/1600x900/filters:format(jpg):quality(70)/cloudfront-eu-central-1.images.arcpublishing.com/irishtimes/OWW3UALEXVFBXHUVFNTZP4DFVU.jpg", "video": null, "publish_date": "2024-06-08 12:43:26", "author": "Mark O'connell", "authors": ["Mark O'connell"], "language": "en", "catgory": "politics", "source_country": "ie", "sentiment": -0.322}